# Abstract
This document provides a definition of and terminology for approximate matching. Approximate matching is a promising technology designed to identify similarities between two digital artifacts. It is used to find objects that resemble each other or to find objects that are contained in another object. This can be very useful for filtering data for security monitoring, digital forensics, or other applications. The purpose of this document is to provide a definition and terminology to describe approximate matching in order to promote discussion, research, tool development, and tool acquisition.

# Introduction

## 1.1 Purpose and Scope
Approximate matching is a promising technology designed to identify similarities between two digital artifacts. It is used to find objects that resemble each other or to find objects that are contained in another object. This can be very useful for filtering data for security monitoring, digital forensics, or other applications. The purpose of this document is to provide a definition and terminology to describe approximate matching in order to promote discussion, research, tool development, and tool acquisition. Approximate matching has the potential to provide valuable filtering in a world inundated with information, but the technique is not widely used. The goal of the document is to provide infrastructure to support advances in approximate matching and its use in forensics and security.

## 1.2 Audience
The intended audience of this document is security digital forensics programmers and other technical professionals with a need to determine, build, or use technology to identify similarity.

# 2. Definition and Terminology
Approximate matching is a generic term describing any technique designed to identify similarities between two digital artifacts. In this context, an artifact (or an object) is defined as an arbitrary byte sequence, such as a file, which has some meaningful interpretation. Different approximate matching methods may operate at different levels of abstraction. At the lowest level, generic techniques may detect the presence of common byte sequences (substrings) without any attempt to interpret the artifacts. At higher levels, approximate matching can incorporate more abstract analysis. In general, lower level methods are expected to be faster and more generic in their applicability, whereas higher level methods are typically more targeted and require more processing.

One common approach in security and forensic analysis is to find identical objects using cryptographic hashing. Approximate matching can be viewed as a generalization of that idea in that, instead of providing a yes/no {0, 1} answer to a comparison, it provides a range of outcomes, [0, 1], with the result interpreted as a measure of similarity.

## 2.1 Use Cases# Similarity Queries

Broadly, there are two types of similarity queries that are of interest – resemblance and containment [1].

## Resemblance
In the case of resemblance, we compare two similarly sized objects and interpret the result as a measure of the commonality between them; for example, two successive versions of a piece of code are likely to resemble each other substantially.

## Containment
When the compared objects differ in size significantly, such as a file and a whole-disk image, the test for commonality is interpreted as a containment query because it addresses the question of whether the large object contains the smaller one.

## Approximate Matching Algorithm
An approximate matching algorithm should address at least one of the following problems (divided according to whether the query type is (R)esemblance or (C)ontainment) [2, 3]:

### Object Similarity Detection (R)
Identify related artifacts, e.g., different versions of a document.

### Cross Correlation (R)
Identify artifacts that share a common object, e.g., a Microsoft Word document and a PDF document containing the same image, or other embedded object.

### Embedded Object Detection (C)
Identify a given object inside an artifact, e.g., an image within a compound document or an executable inside a memory capture.

### Fragment Detection (C)
Identify the presence of traces/fragments of a known artifact, e.g., identify the presence of a file in a network stream based on individual packets.

## Analytical Scenarios
In most analytical scenarios, approximate matching is used to filter data in, or out, based on a known reference set. In security monitoring applications, approximate matching could potentially be used to blacklist known bad artifacts, and (by extension) anything closely resembling them. However, approximate matching is not nearly as useful when it comes to whitelisting artifacts as malicious content can often be quite similar to benign content; e.g., a backdoored SSH server would approximately match a regular one.

# 2.2 Terminology
Although the common language definition of ‘similarity’ is sufficient to give an intuitive sense of the term, the multitude of ways in which two artifacts can be said to be similar poses a challenge when attempting to describe the purpose and behavior of approximate matching algorithms.

For example, two strings ‘ababa’ and ‘cdcdc’ might be considered similar in that they both have five characters ranging over two alternating values, or they might be treated as dissimilar because they have no common characters. To resolve this ambiguity, approximate matching algorithms define similarity in terms of features that represent characteristics of the artifacts pertinent to the algorithm’s method of comparison.

## Features
The basic elements through which artifacts are compared. Comparison of two features always yields a binary {0, 1} outcome indicating a match or non-match; because features are defined as the most basic comparison unit that the algorithm considers, partial matches are not permitted. Generally, a feature can be any value derived from an artifact. Each approximate matching algorithm must define the structure of its features and the method by which they are derived.# Approximate Matching Algorithms

## Feature Definition
For example, an algorithm might define a feature as a (byte, offset) pair produced by reading the value of a byte and storing it along with the offset at which it was read.

## Feature Set
The set of all features associated with a single artifact is its feature set. Each algorithm must include criteria by which candidate features are selected for inclusion in this set. For example, an algorithm might select all the (byte, offset) pairs produced by reading every 16th byte in the artifact.

## Similarity
The similarity of two artifacts, as measured by a particular approximate matching algorithm, is defined as an increasing monotonic function of the number of matching features contained in their respective feature sets.

## Categories of Approximate Matching Methods
Based on the level of abstraction of the similarity analysis performed, approximate matching methods can be placed in one of three main categories:

### 1. Bytewise Matching
Bytewise matching relies only on the sequences of bytes that make up a digital object, without reference to any structures within the data stream, or to any meaning the byte stream may have when appropriately interpreted. Such methods have the widest applicability as they can be applied to any piece of data; however, they also carry the implicit assumption that artifacts that humans perceive as similar have similar byte-level encodings. This assumption is not universally valid. Analyst expertise is necessary to evaluate the significance of a byte-level match.

### 2. Syntactic Matching
Syntactic matching uses internal structures present in digital objects. For example, the structure of a TCP network packet is defined by an international standard, and matching tools can make use of this structure during network packet analysis to match the source, destination, or content of the packet. Syntax-sensitive similarity measurements are specific to a particular class of objects that share an encoding but require no interpretation of the content to produce meaningful results.

### 3. Semantic Matching
Semantic matching uses contextual attributes of the digital object to interpret the artifact in a manner that more closely corresponds with human perceptual categories. For example, perceptual hashes allow the matching of visually similar images and are unconcerned with the low-level details of how the images are persistently stored. Semantic methods tend to provide the most specific results but also tend to be the most computationally expensive ones.

## Terminology in Current Literature
In current literature, researchers use a number of terms to refer to various approximate matching methods:
- **Fuzzy hashing** and **similarity hashing** denote bytewise approximate matching.
- **Perceptual hashing** and **robust hashing** denote semantic approximate matching.

There is no widely-used pre-existing terminology for syntactic approximate matching as it is mostly viewed as pre-processing (to separate the features) before hashing, or applying bytewise approximate matching algorithms. For example, network flows are usually reconstructed before any processing is done on them.

## Bytewise Approximate Matching Algorithms
Bytewise approximate matching algorithms work in two phases:
1. In the first phase, a similarity digest representation (also referred to as a signature or fingerprint) is generated from the original data.
2. In the second phase, digests are compared to produce a similarity score.

### Similarity Digest
A similarity digest is a (compressed) representation of the original data.# Approximate Matching Techniques

## Overview
Approximate matching techniques involve creating a feature set that is suitable for comparison with other similarity digests generated by the same algorithm. Typically, the digest is significantly smaller than the original artifact, and the original object cannot be recovered from the digest.

## Core Functions
Every bytewise approximate matching technique requires at least two core functions:

### 1. Feature Extraction Function
This function identifies and extracts features or attributes from each digital artifact. The method of selecting and interpreting features depends on the approximate matching algorithm. The collection of these features is represented as the similarity digest of the object.

### 2. Similarity Function
The similarity function compares two similarity digests and outputs a score. The recommended approach is to assign a score \( s \) in the range \( 0 \leq s \leq 1 \), where:
- **0** indicates no similarity
- **1** indicates high similarity

This score represents a normalized estimate of the number of matching features in the feature sets corresponding to the artifacts from which the similarity digests were created.

## Normalization Strategy
The similarity function can follow one of two normalization strategies, depending on whether the algorithm describes resemblance or containment:

- **Resemblance Queries**: The number of matching features is weighed against the total number of features in both objects.
- **Containment Queries**: The algorithm may disregard unmatched features in the larger of the two feature sets.

## Interpretation of Similarity Scores
Due to the complexity of features and feature sets, as well as the byte-level structures involved, interpreting the similarity score can be challenging. Some approximate matching algorithms use an empirically determined threshold value to correlate bytewise similarity scores with higher-level properties of interest. In these cases, the similarity score can be treated as a confidence score, where results above the threshold are likely to exhibit common human-recognizable traits.

## Essential Requirements
Like traditional hash functions, approximate matching functions should exhibit several defining characteristics. Each algorithm should define how it incorporates these properties and how it satisfies the reporting requirements for those properties, where appropriate.

### 1. Similarity Preservation
Similarity digests must be constructed so that the outcome of a comparison between any two digests is uniquely determined by the similarity of the artifacts from which they were produced. For example, if \( A' \) is a similarity digest created from artifact \( A \) and \( B' \) is a similarity digest created from artifact \( B \), the results of comparing \( A' \) and \( B' \) should be uniquely determined by the similarity of \( A \) and \( B \).

### 2. Self-Evaluation
The similarity measure should be accompanied by a measure of the accuracy of the matching technique under the circumstances in which it is used, such as a margin of error or confidence level. The description of the output score should also clarify whether a score of 1 indicates an exact match.

### 3. Compression
A compact similarity digest is desirable as it typically allows for faster comparisons and requires less storage space. Ideally, it will have a fixed length similar to the output of traditional hash functions. If the efficiency and reliability of the results remain unchanged, a shorter similarity digest is preferable.

### 4. Ease of Computation
The algorithm description should include the results of the computations involved in generating the similarity digests.# Testing Runtime Efficiency and Reliability of Approximate Matching Algorithms

## 1. Runtime Efficiency

The runtime efficiency of the feature extraction function and the similarity function can be expressed relative to a standard hashing algorithm, such as SHA-1.

### 1.1 Theoretical Complexity

The algorithm description should state the theoretical complexity for a similarity digest comparison in big O notation. Common lookup complexities for comparing a single digest against a database with n entries are:

- **O(1)** for fixed-length digests stored in hash tables (e.g., dictionaries)
- **O(log2 n)** for fixed-length digests stored in binary trees or a sorted list
- **O(n)** for fixed-length digests stored in an unsorted list, or other scenarios in which no indexing or sorting is possible

## 2. Reliability of Results

The reliability of the results for a given approximate matching technique depends on three factors. Each algorithm should define how it incorporates these factors and how it satisfies their reporting requirements.

### 2.1 Sensitivity & Robustness

The algorithm should provide some measure of its robustness. A technique’s robustness will define the operating conditions in which it can function effectively, also called its performance envelope. For example, robustness addresses the minimum and maximum sizes of objects that an algorithm can reliably distinguish between.

### 2.2 Precision & Recall

The algorithm should include a description of the methods used to determine its reliability and to select the test data. Specifically, it should indicate whether test data is culled from existing collections or developed solely to support testing. Test results may include precision, recall, F-score, and other relevant measures of effectiveness.

### 2.3 Security of Results

The algorithm should indicate whether it includes security properties designed to prevent attacks. Such attacks include manipulation of the matching technique or input data such that a data object appears dissimilar to another object to which it is similar or similar to another object with which it has little in common.

## 3. Testing Bytewise Approximate Matching Algorithms

This section gives a general overview of the motives and methods behind testing approximate matching algorithms. Defining a universal testing criteria is difficult; the effectiveness of a given approximate matching algorithm depends largely on the particular task against which it is evaluated. As such, rather than attempt to enumerate a comprehensive evaluation strategy, we focus on key considerations that arise during test design and evaluation. We also describe several properties of approximate matching algorithms that may be useful for characterizing their behavior.

### 3.1 Motivation

There are at least three major motivations for testing bytewise approximate matching algorithms. The first and most basic is to understand the classes of objects that the algorithm identifies as similar. For example, an algorithm may define its feature set such that it measures similarity as a function of the number of certain common byte sequences shared between two digital artifacts. Because this comparison occurs at a very low level, its semantic interpretation is not obvious. Testing across various tasks and types of data is necessary to determine whether the algorithm performs effectively.# Approximate Matching Algorithms

## Introduction
Such an algorithm is useful for identifying, say, HTML documents that contain similar content, or PDFs with the same embedded font.

## Algorithm Development and Testing
As an algorithm is developed, a standard suite of tests, such as those proposed by Breitinger, Stivaktakis, and Baier [3], allows new versions to be compared against previous versions. Testing against a fixed set of tasks helps to highlight any changes in the algorithm’s similarity score as a function of its input. Improvements in speed or space efficiency can also be measured.

### Comparison of Algorithms
Testing allows approximate matching algorithms to be compared to each other. The use of a standard suite of tasks can be beneficial in this testing scenario also. Additional measures must be taken, however, to ensure that tests produce comparable results. Because the algorithms define their similarity score independently, direct comparison of scores is rarely meaningful.

One solution for this problem is to use a threshold or some other criteria to translate scores from their [0,1] range back to a binary {0,1} output which can be evaluated against known ground truth to produce confusion matrices (Roussev’s comparison of sdhash and ssdeep offers an example of this approach [2]). Alternately, the tester might define other high-level criteria for the expected behavior of an algorithm in a specific use case of interest, and evaluate the algorithms against this expectation.

## Test Data
Approximate matching algorithms can be tested against either controlled (synthetic) data [7] or real data (i.e., data originally created for purposes other than testing).

### Controlled Data
The former typically consists of randomly generated blocks or files; its main advantage is that ground truth is constructed and, therefore, precisely known. This allows tests to be run automatically and the results to be interpreted with standard statistical measures.

The drawback to using randomly generated data is that it is not necessarily representative. For example, random data tends to be unique, high-entropy, and internally varied. These properties may be appropriate for use cases involving compressed or encrypted data, but could prove misleading for other file types (such as text documents). A potential workaround is to develop more sophisticated randomization that preserves the characteristic properties of the target file type.

### Real Data
The obvious advantage of using real data is that the results can be directly related to practical applications. However, the challenges of defining a representative sample, establishing the ground truth, and running experiments at scale (without a human in the loop) are non-trivial. See Appendix A1 for example test methodologies for both controlled and real data.

## Properties of Special Interest
The following properties may be especially useful for testing and comparing approximate matching algorithms.# Matching Algorithms

This list is not meant to be exhaustive. Note that the properties enumerated here are adapted from those proposed by Breitinger, Stivaktakis, and Baier. See their work on the FRASH testing framework for an example of a complete description (including full implementation details and suggested test values) of a testing framework that incorporates these properties.

## 3.3.1 Efficiency

The efficiency of an algorithm is measured in terms of the space and time it requires; the latter property is further subdivided according to time needed for generating similarity digests and time needed for comparing them.

### Space Efficiency

Traditional hash functions return a fixed length fingerprint; in contrast, the length of similarity digests is sometimes variable and proportional to the input length. If the digest is of variable length, space efficiency measures the ratio between input and the digest and returns a percentage value.

### Generation Efficiency

Generation efficiency measures the throughput of an algorithm when producing a similarity digest from raw input. To enable useful comparisons across different architectures, it is recommended that the throughput of a standard algorithm implementation, such as SHA-1 in OpenSSH, be included as a reference point.

### Comparison Efficiency

The comparison efficiency measures the rate at which similarity digests can be compared. It is useful to have both a formal analysis, which provides the theoretical complexity of the comparison (in O-notation), and an empirical evaluation based on a reference data set.

A related property of note is the ability of the algorithm to leverage parallel computational resources; these may include conventional multi-core CPU architectures, as well as massively parallel ones, such as GPUs. To that end, tests should include scalability analysis, which shows speedup as a function of available hardware concurrency.

## 3.3.2 Sensitivity

Sensitivity is a measure of the ability of an approximate matching algorithm to find correlations among objects based on fine-grained commonality—the smaller the features being correlated, the more sensitive the algorithm is. Clearly, there is a threshold below which the sensitivity will be too high and all objects will appear similar; it is up to the algorithm designer to identify that threshold and incorporate it into the implementation.

### Examples of Sensitivity Tests

Two examples of tests for measuring an algorithm’s sensitivity are fragment detection and single-common-block correlation.

- **Fragment Detection**: Fragment detection quantifies the length of the shortest sample from a data object, for which the similarity tool reliably correlates the sample and the whole object. Common uses include correlating a disk block or network packet to a file.

- **Single-Common-Block Correlation**: The single-common-block correlation test is designed to characterize the behavior of an algorithm in the case where two files share a single common object. That is, given two files f1 and f2 that share a single common object.# Common Object Similarity and Robustness

## 1. Introduction
In the context of approximate matching algorithms, understanding the correlation between similar objects is crucial. This document discusses the smallest object (O) for which a similarity tool can reliably correlate two targets.

## 2. Robustness
Robustness refers to the ability of an approximate matching algorithm to find correlations among related objects despite the presence of noise and routine transformations.

### 2.1 Common Transformations
Common transformations that can affect the robustness of an algorithm include:
- **Internal Fragmentation**: This occurs during network transmission.
- **Misalignment**: This happens when content is added during artifact editing.

### 2.2 Tests of Robustness
Two primary tests measure an algorithm’s robustness:

#### 2.2.1 Alignment Robustness
Alignment robustness quantifies the sensitivity of an algorithm to alignment shifts. This test specifically analyzes the impact of inserting sequences of bytes at the beginning of one of the compared artifacts.

#### 2.2.2 White Noise Resistance
White noise resistance measures the amount of uniformly random noise that can be added to an object before the approximate matching algorithm fails to correlate the original and modified versions. For instance, with the ssdeep algorithm, it has been demonstrated that a few changes distributed over the input can be sufficient to prevent a match.