NIST Special Publication 1500-4r2 NIST Big Data Interoperability Framework: Volume 4, Security and Privacy Version 3 NIST Big Data Public Working Group Definitions and Taxonomies Subgroup This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST Special Publication 1500-4r2 NIST Big Data Interoperability Framework: Volume 4, Security and Privacy Version 3 NIST Big Data Public Working Group Definitions and Taxonomies Subgroup Information Technology Laboratory National Institute of Standards and Technology Gaithersburg, MD 20899 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2 October 2019 U.S. Department of Commerce Wilbur L. Ross, Jr., Secretary National Institute of Standards and Technology Walter Copan, NIST Director and Undersecretary of Commerce for Standards and TechnologyNIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY National Institute of Standards and Technology (NIST) Special Publication 1500-4r2 176 pages (October 2019) NIST Special Publication series 1500 is intended to capture external perspectives related to NIST standards, measurement, and testing-related efforts. These external perspectives can come from industry, academia, government, and others. These reports are intended to document external perspectives and do not represent official NIST positions. Certain commercial entities, equipment, or materials may be identified in this document to describe an experimental procedure or concept adequately. Such identification is not intended to imply recommendation or endorsement by NIST, nor is it intended to imply that the entities, materials, or equipment are necessarily the best available for the purpose. There may be references in this publication to other publications currently under development by NIST in accordance with its assigned statutory responsibilities. The information in this publication, including concepts and methodologies, may be used by federal agencies even before the completion of such companion publications. Thus, until each publication is completed, current requirements, guidelines, and procedures, where they exist, remain operative. For planning and transition purposes, federal agencies may wish to closely follow the development of these new publications by NIST. Organizations are encouraged to review all draft publications during public comment periods and provide feedback to NIST. All NIST publications are available at http://www.nist.gov/publication-portal.cfm. Copyrights and Permissions Official publications of the National Institute of Standards and Technology are not subject to copyright in the United States. Foreign rights are reserved. Questions concerning the possibility of copyrights in foreign countries should be referred to the Office of Chief Counsel at NIST via email to nistcounsel@nist.gov. Comments on this publication may be submitted to Wo Chang National Institute of Standards and Technology Attn: Wo Chang, Information Technology Laboratory 100 Bureau Drive (Mail Stop 8900) Gaithersburg, MD 20899-8930 Email: SP1500comments@nist.gov ii This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY Reports on Computer Systems Technology The Information Technology Laboratory (ITL) at NIST promotes the U.S. economy and public welfare by providing technical leadership for the Nation’s measurement and standards infrastructure. ITL develops tests, test methods, reference data, proof of concept implementations, and technical analyses to advance the development and productive use of information technology (IT). ITL’s responsibilities include the development of management, administrative, technical, and physical standards and guidelines for the cost-effective security and privacy of other than national security-related information in federal information systems. This document reports on ITL’s research, guidance, and outreach efforts in IT and its collaborative activities with industry, government, and academic organizations. Abstract Big Data is a term used to describe the large amount of data in the networked, digitized, sensor-laden, information-driven world. While opportunities exist with Big Data, the data can overwhelm traditional technical approaches and the growth of data is outpacing scientific and technological advances in data analytics. To advance progress in Big Data, the NIST Big Data Public Working Group (NBD-PWG) is working to develop consensus on important, fundamental concepts related to Big Data. The results are reported in the NIST Big Data Interoperability Framework (NBDIF) series of volumes. This volume, Volume 4, contains an exploration of security and privacy topics with respect to Big Data. The volume considers new aspects of security and privacy with respect to Big Data, reviews security and privacy use cases, proposes security and privacy taxonomies, presents details of the Security and Privacy Fabric of the NIST Big Data Reference Architecture (NBDRA), and begins mapping the security and privacy use cases to the NBDRA. Keywords Big Data characteristics; Big Data forensics; Big Data privacy; Big Data risk management; Big Data security; Big Data taxonomy, computer security; cybersecurity; encryption standards; information assurance; information security frameworks; role-based access controls; security and privacy fabric; use cases. iii This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY Acknowledgements This document reflects the contributions and discussions by the membership of the NBD-PWG, cochaired by Wo Chang (NIST ITL), Bob Marcus (ET-Strategies), and Chaitan Baru (San Diego Supercomputer Center; National Science Foundation). The document contains input from members of the NBD-PWG Security and Privacy Subgroup. For all versions, the Subgroups were led by the following people: Nancy Grady (SAIC), Natasha Balac (San Diego Supercomputer Center), and Eugene Luster (R2AD) for the Definitions and Taxonomies Subgroup; Geoffrey Fox (Indiana University) and Tsegereda Beyene (Cisco Systems) for the Use Cases and Requirements Subgroup; Arnab Roy (Fujitsu), Mark Underwood (Krypton Brothers; Synchrony Financial), and Akhil Manchanda (GE) for the Security and Privacy Subgroup; David Boyd (InCadence Strategic Solutions), Orit Levin (Microsoft), Don Krapohl (Augmented Intelligence), and James Ketner (AT&T) for the Reference Architecture Subgroup; and Russell Reinsch (Center for Government Interoperability), David Boyd (InCadence Strategic Solutions), Carl Buffington (Vistronix), and Dan McClary (Oracle), for the Standards Roadmap Subgroup. The editors for this document were the following: • Version 1: Arnab Roy (Fujitsu), Mark Underwood (Krypton Brothers; Synchrony Financial) and Wo Chang (NIST) • Version 2: Arnab Roy (Fujitsu), Mark Underwood (Krypton Brothers; Synchrony Financial) and Wo Chang (NIST) • Version 3: Arnab Roy (Fujitsu), Mark Underwood (Krypton Brothers; Synchrony Financial) and Wo Chang (NIST) Laurie Aldape (Energetics Incorporated) and Elizabeth Lennon (NIST) provided editorial assistance across all NBDIF volumes. NIST SP1500-4, Version 3 has been collaboratively authored by the NBD-PWG. As of the date of this publication, there are over six hundred NBD-PWG participants from industry, academia, and government. Federal agency participants include the National Archives and Records Administration (NARA), National Aeronautics and Space Administration (NASA), National Science Foundation (NSF), and the U.S. Departments of Agriculture, Commerce, Defense, Energy, Health and Human Services, Homeland Security, Transportation, Treasury, and Veterans Affairs. NIST would like to acknowledge the specific contributions to this volume, during Version 1, Version 2, and/or Version 3 activities, by the following NBD-PWG members: Cavan Capps Pavithra Kenjige Sanjay Mishra U.S. Census Bureau PK Technologies Verizon Pw McKenna Carey, III Orit Levin Robert Reyling Compliance Partners, Microsoft Wyle Aerospace Corporation LLC/RALAND Yale Li Ann Racuya-Robbins Wo Chang Microsoft World Knowledge Bank NIST Akhil Manchanda Arnab Roy Brent Comstock General Electric Fujitsu Cox Communications Marcia Mangold Anh-Hong Rucker Lee Anne Davies General Electric Jet Propulsion Laboratory Agenomics Serge Mankovski Paul Savitz Jacob Dilles CA Technologies ATIS Mount Airey Group Robert Marcus John Schiel ET-Strategies CenturyLink, Inc. iv This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY Michele Drgon Lisa Martinez Mark Underwood Data Probity Northbound Transportation and Krypton Brothers; Synchrony Infrastructure, US Financial Roy D'Souza AlephCloud Systems, Inc. William Miller Alicia Zuniga-Alvarado MaCT USA Consultant Eddie Garcia Gazzang, Inc. David Harper Johns Hopkins University/ Applied Physics Laboratory v This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY T C ABLE OF ONTENTS EXECUTIVE SUMMARY .............................................................................................................................. IX 1 INTRODUCTION .................................................................................................................................... 1 1.1 BACKGROUND ............................................................................................................................................... 1 1.2 SCOPE AND OBJECTIVES OF THE SECURITY AND PRIVACY SUBGROUP ........................................................ 3 1.3 REPORT PRODUCTION ................................................................................................................................... 4 1.4 REPORT STRUCTURE ..................................................................................................................................... 4 2 BIG DATA SECURITY AND PRIVACY ................................................................................................ 6 2.1 WHAT IS DIFFERENT ABOUT BIG DATA SECURITY AND PRIVACY ................................................................. 6 2.2 OVERVIEW .................................................................................................................................................... 7 2.3 SECURITY AND PRIVACY IMPACTS ON BIG DATA CHARACTERISTICS .......................................................... 9 2.3.1 Volume ..................................................................................................................................................... 9 2.3.2 Velocity .................................................................................................................................................... 9 2.3.3 Variety ................................................................................................................................................... 10 2.3.4 Veracity .................................................................................................................................................. 10 2.3.5 Volatility ................................................................................................................................................ 12 2.4 EFFECTS OF EMERGING TECHNOLOGY ON BIG DATA SECURITY AND PRIVACY .......................................... 12 2.4.1 Cloud Computing ................................................................................................................................... 12 2.4.2 Big Data Security and Privacy Safety Levels ......................................................................................... 13 2.4.3 Internet of Things and CPS .................................................................................................................... 15 2.4.4 Mobile Devices and Big Data ................................................................................................................ 15 2.4.5 Integration of People and Organizations............................................................................................... 15 2.4.6 System Communicator ........................................................................................................................... 16 2.4.7 Ethical Design ....................................................................................................................................... 16 2.4.7.1 Self-Cleaning Systems .................................................................................................................................. 16 2.4.7.2 The Toxic Data Model .................................................................................................................................. 17 2.4.7.3 Big Data Security Safety Annotation ............................................................................................................ 17 2.4.7.4 Big Data Trust and Federation ...................................................................................................................... 17 2.4.7.5 Orchestration in Weak Federation Scenarios ................................................................................................ 18 2.4.7.6 Consent and the Glass-Breaking Scenario .................................................................................................... 18 2.4.8 Big Data Transparency .......................................................................................................................... 18 3 EXAMPLE USE CASES FOR SECURITY AND PRIVACY ................................................................. 21 3.1 RETAIL/MARKETING ................................................................................................................................... 21 3.1.1 Consumer Digital Media Usage ............................................................................................................ 21 3.1.2 Nielsen Homescan: Project Apollo ........................................................................................................ 22 3.1.3 Web Traffic Analytics............................................................................................................................. 23 3.2 HEALTHCARE .............................................................................................................................................. 23 3.2.1 Health Information Exchange ................................................................................................................ 23 3.2.2 Genetic Privacy ..................................................................................................................................... 24 3.2.3 Pharma Clinical Trial Data Sharing ..................................................................................................... 25 3.3 CYBERSECURITY ......................................................................................................................................... 25 3.3.1 Network Protection ................................................................................................................................ 25 3.4 GOVERNMENT ............................................................................................................................................. 26 3.4.1 Unmanned Vehicle Sensor Data ............................................................................................................ 26 3.4.2 Education: Common Core Student Performance Reporting .................................................................. 27 3.5 INDUSTRIAL: AVIATION .............................................................................................................................. 28 v This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 3.5.1 Sensor Data Storage And Analytics ....................................................................................................... 28 3.6 TRANSPORTATION ....................................................................................................................................... 28 3.6.1 Cargo Shipping ...................................................................................................................................... 28 3.7 ADDITIONAL SECURITY AND PRIVACY USE CASES ..................................................................................... 29 3.7.1 SEC Consolidated Audit Trail ............................................................................................................... 29 3.7.2 IoT Device Management ........................................................................................................................ 29 3.7.3 Statewide Education Data Portal .......................................................................................................... 29 4 TAXONOMY OF SECURITY AND PRIVACY TOPICS ...................................................................... 31 4.1 CONCEPTUAL TAXONOMY OF SECURITY AND PRIVACY TOPICS ................................................................. 31 4.1.1 Data Confidentiality .............................................................................................................................. 32 4.1.2 Provenance ............................................................................................................................................ 32 4.1.3 System Health ........................................................................................................................................ 33 4.1.4 Public Policy, Social and Cross-Organizational Topics ....................................................................... 33 4.2 OPERATIONAL TAXONOMY OF SECURITY AND PRIVACY TOPICS ................................................................ 34 4.2.1 Device and Application Registration ..................................................................................................... 35 4.2.2 Identity and Access Management ........................................................................................................... 35 4.2.3 Data Governance ................................................................................................................................... 36 4.2.3.1 Compliance, Governance and Management as Code .................................................................................... 37 4.2.4 Infrastructure Management ................................................................................................................... 37 4.2.5 Risk and Accountability ......................................................................................................................... 38 4.3 ROLES RELATED TO SECURITY AND PRIVACY TOPICS ................................................................................ 39 4.3.1 Infrastructure Management ................................................................................................................... 39 4.3.2 Governance, Risk Management, and Compliance ................................................................................. 39 4.3.3 Information Worker ............................................................................................................................... 40 4.4 RELATION OF ROLES TO THE SECURITY AND PRIVACY CONCEPTUAL TAXONOMY ..................................... 40 4.4.1 Data Confidentiality .............................................................................................................................. 40 4.4.2 Provenance ............................................................................................................................................ 41 4.4.3 System Health Management ................................................................................................................... 41 4.4.4 Public Policy, Social, and Cross-Organizational Topics ...................................................................... 42 4.5 ADDITIONAL TAXONOMY TOPICS ............................................................................................................... 42 4.5.1 Provisioning, Metering, And Billing ...................................................................................................... 42 4.5.2 Data Syndication ................................................................................................................................... 43 4.5.3 ACM Taxonomy ..................................................................................................................................... 43 4.6 WHY SECURITY ONTOLOGIES MATTER FOR BIG DATA .............................................................................. 44 5 BIG DATA REFERENCE ARCHITECTURE AND SECURITY AND PRIVACY FABRIC ................ 46 5.1 RELATION OF THE BIG DATA SECURITY OPERATIONAL TAXONOMY TO THE NBDRA ............................. 47 5.2 SECURITY AND PRIVACY FABRIC IN THE NBDRA ...................................................................................... 49 5.3 SECURITY AND PRIVACY FABRIC PRINCIPLES ............................................................................................. 50 5.4 SECURITY AND PRIVACY APPROACHES IN ANALYTICS ............................................................................... 50 5.5 CRYPTOGRAPHIC TECHNOLOGIES FOR DATA TRANSFORMATIONS .............................................................. 51 5.5.1 Classification ......................................................................................................................................... 51 5.5.2 Homomorphic Encryption ...................................................................................................................... 52 5.5.3 Functional Encryption ........................................................................................................................... 53 5.5.4 Access Control Policy-Based Encryption .............................................................................................. 53 5.5.5 Secure Multi-Party Computations ......................................................................................................... 54 5.5.6 Blockchain ............................................................................................................................................. 55 5.5.7 Hardware Support for Secure Computations ......................................................................................... 56 5.5.8 Cryptographic Key Rotation .................................................................................................................. 57 5.5.9 Federal Standard FIPS140-2 on Cryptographic Systems ...................................................................... 57 5.6 RISK MANAGEMENT ................................................................................................................................... 58 5.6.1 PII as Requiring Toxic Substance Handling .......................................................................................... 58 vi This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 5.6.2 Consent Withdrawal Scenarios .............................................................................................................. 58 5.6.3 Transparency Portal Scenarios ............................................................................................................. 59 5.6.4 Big Data Forensics and Operational AAR ............................................................................................ 59 5.7 BIG DATA SECURITY MODELING AND SIMULATION (MODSIM) .................................................................. 59 5.8 SECURITY AND PRIVACY MANAGEMENT PHASES ....................................................................................... 60 6 DOMAIN-SPECIFIC SECURITY .......................................................................................................... 62 7 AUDIT AND CONFIGURATION MANAGEMENT .............................................................................. 63 7.1 PACKET-LEVEL TRACEABILITY / REPRODUCIBILITY ................................................................................... 63 7.2 AUDIT ......................................................................................................................................................... 63 7.3 MONITORING .............................................................................................................................................. 63 8 STANDARDS, BEST PRACTICES AND GAPS ..................................................................................... 65 8.1 NIST CYBERSECURITY FRAMEWORK ......................................................................................................... 65 8.2 CONFIGURATION MANAGEMENT FOR BIG DATA ........................................................................................ 65 8.2.1 Emergence of DevSecOps ...................................................................................................................... 65 8.2.2 Dependency Models ............................................................................................................................... 66 8.3 BIG DATA SDLC STANDARDS AND GUIDELINES ........................................................................................ 66 8.3.1 Big Data Security in DevOps ................................................................................................................. 66 8.3.1.1 Application Life Cycle Management ............................................................................................................ 67 8.3.1.2 Security and Privacy Events in Application Release Management ............................................................... 67 8.3.1.3 Orchestration ................................................................................................................................................. 67 8.3.1.4 API-First ....................................................................................................................................................... 67 8.3.2 Model Driven Development ................................................................................................................... 68 8.3.3 Other Standards Through a Big Data Lens ........................................................................................... 68 8.3.3.1 ISO 21827:2008 and SSE-CMM................................................................................................................... 68 8.3.3.2 ISO 27018: Protection of PII in Public Clouds Acting as PII Processors ...................................................... 69 8.3.4 Big Data Test Engineering .................................................................................................................... 69 8.3.5 API-First and Microservices ................................................................................................................. 69 8.3.6 Application Security for Big Data .......................................................................................................... 70 8.3.6.1 RBAC, ABAC, and Workflow ...................................................................................................................... 70 8.3.6.2 ‘Least Exposure’ Big Data Practices ............................................................................................................. 70 8.3.6.3 Logging ......................................................................................................................................................... 71 8.3.6.4 Ethics and Privacy by Design ....................................................................................................................... 71 8.4 BIG DATA GOVERNANCE ............................................................................................................................ 72 8.5 EMERGING TECHNOLOGIES ......................................................................................................................... 72 8.5.1 Network Security for Big Data ............................................................................................................... 72 8.5.2 Machine Learning, AI, and Analytics for Big Data Security and Privacy ............................................. 72 APPENDIX A: NIST BIG DATA SECURITY AND PRIVACY SAFETY LEVELS ...................................... 73 APPENDIX B: EXISTING STANDARDS IN RELATION TO THE SECURITY AND PRIVACY FABRIC 99 APPENDIX C: INTERNAL SECURITY CONSIDERATIONS WITHIN CLOUD ECOSYSTEMS ............ 124 APPENDIX D: BIG DATA ACTORS AND ROLES—ADAPTATION TO BIG DATA SCENARIOS ........ 129 APPENDIX E: MAPPING USE CASES TO NBDRA ................................................................................... 131 E.1 RETAIL/MARKETING ................................................................................................................................. 131 E.1.1 Consumer Digital Media Use .............................................................................................................. 131 E.1.2 Nielsen Homescan: Project Apollo ...................................................................................................... 132 E.1.3 Web Traffic Analytics........................................................................................................................... 133 E.2 HEALTHCARE ............................................................................................................................................ 134 E.2.1 Health Information Exchange .............................................................................................................. 134 E.2.2 Pharmaceutical Clinical Trial Data Sharing ....................................................................................... 136 vii This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY E.3 CYBERSECURITY ....................................................................................................................................... 137 E.3.1 Network Protection .............................................................................................................................. 137 E.4 GOVERNMENT ........................................................................................................................................... 138 E.4.1 Unmanned Vehicle Sensor Data .......................................................................................................... 138 E.4.2 Education: Common Core Student Performance Reporting ................................................................ 139 E.5 TRANSPORTATION ..................................................................................................................................... 140 E.5.1 Cargo Shipping .................................................................................................................................... 140 APPENDIX F: VERSION 2 CHANGES AND NEW TOPICS ...................................................................... 142 APPENDIX G: ACRONYMS ........................................................................................................................ 143 APPENDIX H: BIBLIOGRAPHY................................................................................................................. 146 Figures FIGURE 1: NBDIF DOCUMENTS NAVIGATION DIAGRAM PROVIDES CONTENT FLOW BETWEEN VOLUMES ................... 5 FIGURE 2: HIGH-LEVEL CAT REQUIREMENTS ............................................................................................................. 29 FIGURE 3: EDWISE FIGURE .......................................................................................................................................... 30 FIGURE 4: SECURITY AND PRIVACY CONCEPTUAL TAXONOMY ................................................................................... 31 FIGURE 5: SECURITY AND PRIVACY OPERATIONAL TAXONOMY .................................................................................. 35 FIGURE 6: NIST BIG DATA REFERENCE ARCHITECTURE .............................................................................................. 47 FIGURE 7: NOTIONAL SECURITY AND PRIVACY FABRIC OVERLAY TO THE NBDRA .................................................... 49 FIGURE C-1: COMPOSITE CLOUD ECOSYSTEM SECURITY ARCHITECTURE ................................................................. 124 Tables TABLE 1: DRAFT SECURITY OPERATIONAL TAXONOMY MAPPING TO THE NBDRA COMPONENTS ............................. 48 TABLE 2: CLASSIFICATION OF CRYPTOGRAPHIC TECHNOLOGIES ................................................................................. 51 TABLE A-1: APPENDIX A: NIST BIG DATA SECURITY AND PRIVACY SAFETY LEVELS ................................................ 73 TABLE B-1: TERMS AND STANDARDS IN RELATION TO THE SECURITY AND PRIVACY FABRIC ..................................... 99 TABLE C-1: STANDARDS AND GUIDES RELEVANT TO CLOUD COMPUTING ................................................................ 125 TABLE E-1: MAPPING CONSUMER DIGITAL MEDIA USAGE TO THE REFERENCE ARCHITECTURE ............................... 131 TABLE E-2: MAPPING NIELSEN HOMESCAN TO THE REFERENCE ARCHITECTURE ...................................................... 132 TABLE E-3: MAPPING WEB TRAFFIC ANALYTICS TO THE REFERENCE ARCHITECTURE .............................................. 133 TABLE E-4: MAPPING HIE TO THE REFERENCE ARCHITECTURE ................................................................................ 134 TABLE E-5: MAPPING PHARMACEUTICAL CLINICAL TRIAL DATA SHARING TO THE REFERENCE ARCHITECTURE ..... 136 TABLE E-6: MAPPING NETWORK PROTECTION TO THE REFERENCE ARCHITECTURE .................................................. 137 TABLE E-7: MAPPING MILITARY UNMANNED VEHICLE SENSOR DATA TO THE REFERENCE ARCHITECTURE ............ 138 TABLE E-8: MAPPING COMMON CORE K–12 STUDENT REPORTING TO THE REFERENCE ARCHITECTURE .................. 139 TABLE E-9: MAPPING CARGO SHIPPING TO THE REFERENCE ARCHITECTURE ............................................................ 141 viii This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY EXECUTIVE SUMMARY 1 2 This NIST Big Data Interoperability Framework (NBDIF): Volume 4, Security and Privacy document 3 was prepared by the NIST Big Data Public Working Group (NBD-PWG) Security and Privacy Subgroup 4 to identify security and privacy issues that are specific to Big Data. 5 Big Data application domains include healthcare, drug discovery, insurance, finance, retail, and many 6 others from both the private and public sectors. Among the scenarios within these application domains are 7 health exchanges, clinical trials, mergers and acquisitions, device telemetry, targeted marketing, and 8 international anti-piracy. Security technology domains include identity, authorization, audit, network and 9 device security, and federation across trust boundaries. 10 Clearly, the advent of Big Data has necessitated paradigm shifts in the understanding and enforcement of 11 security and privacy requirements. Significant changes are evolving, notably in scaling existing solutions 12 to meet the volume, variety, velocity, and variability of Big Data and retargeting security solutions amid 13 shifts in technology infrastructure (e.g., distributed computing systems and non-relational data storage). In 14 addition, diverse datasets are becoming easier to access and increasingly contain personal content. A new 15 set of emerging issues must be addressed, including balancing privacy and utility, enabling analytics and 16 governance on encrypted data, and reconciling authentication and anonymity. 17 With the key Big Data characteristics of variety, volume, velocity, and variability in mind, the Subgroup 18 gathered use cases from volunteers, developed a consensus-based security and privacy taxonomy, related 19 the taxonomy to the NIST Big Data Reference Architecture (NBDRA), and validated the NBDRA by 20 mapping the use cases to the NBDRA. 21 The NIST Big Data Interoperability Framework (NBDIF) was released in three versions, which 22 correspond to the three stages of the NBD-PWG work. Version 3 (current version) of the NBDIF volumes 23 resulted from Stage 3 work with major emphasis on the validation of the NBDRA Interfaces and content 24 enhancement. Stage 3 work built upon the foundation created during Stage 2 and Stage 1. The current 25 effort documented in this volume reflects concepts developed within the rapidly evolving field of Big 26 Data. The three stages (in reverse order) aim to achieve the following with respect to the NIST Big Data 27 Reference Architecture (NBDRA). 28 Stage 3: Validate the NBDRA by building Big Data general applications through the general 29 interfaces; 30 Stage 2: Define general interfaces between the NBDRA components; and 31 Stage 1: Identify the high-level Big Data reference architecture key components, which are 32 technology-, infrastructure-, and vendor-agnostic. 33 The NBDIF consists of nine volumes, each of which addresses a specific key topic, resulting from the 34 work of the NBD-PWG. The nine volumes are as follows: 35 • Volume 1, Definitions  36 • Volume 2, Taxonomies  37 • Volume 3, Use Cases and General Requirements  38 • Volume 4, Security and Privacy (this volume) 39 • Volume 5, Architectures White Paper Survey  40 • Volume 6, Reference Architecture  41 • Volume 7, Standards Roadmap  42 • Volume 8, Reference Architecture Interfaces  43 • Volume 9, Adoption and Modernization  ix This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 44 During Stage 1, Volumes 1 through 7 were conceptualized, organized, and written. The finalized Version 45 1 documents can be downloaded from the V1.0 Final Version page of the NBD-PWG website 46 (https://bigdatawg.nist.gov/V1_output_docs.php). 47 During Stage 2, the NBD-PWG developed Version 2 of the NBDIF Version 1 volumes, with the 48 exception of Volume 5, which contained the completed architecture survey work that was used to inform 49 Stage 1 work of the NBD-PWG. The goals of Stage 2 were to enhance the Version 1 content, define 50 general interfaces between the NBDRA components by aggregating low-level interactions into high-level 51 general interfaces, and demonstrate how the NBDRA can be used. As a result of the Stage 2 work, the 52 need for NBDIF Volume 8 and NBDIF Volume 9 was identified and the two new volumes were created. 53 Version 2 of the NBDIF volumes, resulting from Stage 2 work, can be downloaded from the V2.0 Final 54 Version page of the NBD-PWG website (https://bigdatawg.nist.gov/V2_output_docs.php). 55 Version 2 of NBDIF: Volume 4, Security and Privacy was principally informed by the introduction of the 56 NIST Big Data Security and Privacy Safety Levels (NBD-SPSL). Using the NBD-SPSL, organizations 57 can identify specific elements to which their systems conform. Readers are encouraged to study the NBD- 58 SPSL (Appendix A) before launching into the body of this version of the document. Appendix A is 59 designed to be a stand-alone, readily transferred artifact that can be used to share concepts that can 60 improve Big Data security and privacy safety engineering. 61 By declaring conformance with selected elements from the NBD-SPSL, practitioners in Big Data can 62 voluntarily attest to specific steps they have undertaken to improve Big Data security and privacy in their 63 systems. The NBD-SPSL provides a clear path to implement the recommendations of standards aimed at 64 improving ethical practices (e.g., Institute of Electrical and Electronics Engineers [IEEE] P7000, IEEE 65 P7002, IEEE P7007, International Organization for Standardization [ISO] 27500:2016), as well as 66 methods to integrate security and privacy into Big Data DevOps, (e.g., IEEE P2675). 67 x This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 1 INTRODUCTION 68 69 1.1 BACKGROUND 70 There is broad agreement among commercial, academic, and government leaders about the potential of 71 Big Data to spark innovation, fuel commerce, and drive progress. Big Data is the common term used to 72 describe the deluge of data in today’s networked, digitized, sensor-laden, and information-driven world. 73 The availability of vast data resources carries the potential to answer questions previously out of reach, 74 including the following: 75 • How can a potential pandemic reliably be detected early enough to intervene? 76 • Can new materials with advanced properties be predicted before these materials have ever been 77 synthesized? 78 • How can the current advantage of the attacker over the defender in guarding against cybersecurity 79 threats be reversed? 80 There is also broad agreement on the ability of Big Data to overwhelm traditional approaches. The growth 81 rates for data volumes, speeds, and complexity are outpacing scientific and technological advances in data 82 analytics, management, transport, and data user spheres. 83 Despite widespread agreement on the inherent opportunities and current limitations of Big Data, a lack of 84 consensus on some important fundamental questions continues to confuse potential users and stymie 85 progress. These questions include the following: 86 • How is Big Data defined? 87 • What attributes define Big Data solutions? 88 • What is new in Big Data? 89 • What is the difference between Big Data and bigger data that has been collected for years? 90 • How is Big Data different from traditional data environments and related applications? 91 • What are the essential characteristics of Big Data environments? 92 • How do these environments integrate with currently deployed architectures? 93 • What are the central scientific, technological, and standardization challenges that need to be 94 addressed to accelerate the deployment of robust, secure Big Data solutions? 95 Within this context, on March 29, 2012, the White House announced the Big Data Research and 96 Development Initiative . The initiative’s goals include helping to accelerate the pace of discovery in 97 science and engineering, strengthening national security, and transforming teaching and learning by 98 improving analysts’ ability to extract knowledge and insights from large and complex collections of 99 digital data. 100 Six federal departments and their agencies announced more than $200 million in commitments spread 101 across more than 80 projects, which aim to significantly improve the tools and techniques needed to 102 access, organize, and draw conclusions from huge volumes of digital data. The initiative also challenged 103 industry, research universities, and nonprofits to join with the federal government to make the most of the 104 opportunities created by Big Data. 105 Motivated by the White House initiative and public suggestions, the National Institute of Standards and 106 Technology (NIST) has accepted the challenge to stimulate collaboration among industry professionals to 107 further the secure and effective adoption of Big Data. As one result of NIST’s Cloud and Big Data Forum 108 held on January 15–17, 2013, there was strong encouragement for NIST to create a public working group 109 for the development of a Big Data Standards Roadmap. Forum participants noted that this roadmap 1 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 110 should define and prioritize Big Data requirements, including interoperability, portability, reusability, 111 extensibility, data usage, analytics, and technology infrastructure. In doing so, the roadmap would 112 accelerate the adoption of the most secure and effective Big Data techniques and technology. 113 On June 19, 2013, the NIST Big Data Public Working Group (NBD-PWG) was launched with extensive 114 participation by industry, academia, and government from across the nation. The scope of the NBD-PWG 115 involves forming a community of interests from all sectors—including industry, academia, and 116 government—with the goal of developing consensus on definitions, taxonomies, secure reference 117 architectures, security and privacy, and from these, a standards roadmap. Such a consensus would create a 118 vendor-neutral, technology- and infrastructure-independent framework that would enable Big Data 119 stakeholders to identify and use the best analytics tools for their processing and visualization requirements 120 on the most suitable computing platform and cluster, while also allowing added value from Big Data 121 service providers. 122 The NIST Big Data Interoperability Framework (NBDIF) was released in three versions, which 123 correspond to the three stages of the NBD-PWG work. Version 3 (current version) of the NBDIF volumes 124 resulted from Stage 3 work with major emphasis on the validation of the NBDRA Interfaces and content 125 enhancement. Stage 3 work built upon the foundation created during Stage 2 and Stage 1. The current 126 effort documented in this volume reflects concepts developed within the rapidly evolving field of Big 127 Data. The three stages (in reverse order) aim to achieve the following with respect to the NIST Big Data 128 Reference Architecture (NBDRA). 129 Stage 3: Validate the NBDRA by building Big Data general applications through the general 130 interfaces; 131 Stage 2: Define general interfaces between the NBDRA components; and 132 Stage 1: Identify the high-level Big Data reference architecture key components, which are 133 technology-, infrastructure-, and vendor-agnostic. 134 The NBDIF consists of nine volumes, each of which addresses a specific key topic, resulting from the 135 work of the NBD-PWG. The nine volumes are as follows: 136 • Volume 1, Definitions  137 • Volume 2, Taxonomies  138 • Volume 3, Use Cases and General Requirements  139 • Volume 4, Security and Privacy (this volume) 140 • Volume 5, Architectures White Paper Survey  141 • Volume 6, Reference Architecture  142 • Volume 7, Standards Roadmap  143 • Volume 8, Reference Architecture Interfaces  144 • Volume 9, Adoption and Modernization  145 During Stage 1, Volumes 1 through 7 were conceptualized, organized, and written. The finalized Version 146 1 documents can be downloaded from the V1.0 Final Version page of the NBD-PWG website 147 (https://bigdatawg.nist.gov/V1_output_docs.php). 148 During Stage 2, the NBD-PWG developed Version 2 of the NBDIF Version 1 volumes, with the 149 exception of Volume 5, which contained the completed architecture survey work that was used to inform 150 Stage 1 work of the NBD-PWG. The goals of Stage 2 were to enhance the Version 1 content, define 151 general interfaces between the NBDRA components by aggregating low-level interactions into high-level 152 general interfaces, and demonstrate how the NBDRA can be used. As a result of the Stage 2 work, the 153 need for NBDIF Volume 8 and NBDIF Volume 9 was identified and the two new volumes were created. 154 Version 2 of the NBDIF volumes, resulting from Stage 2 work, can be downloaded from the V2.0 Final 155 Version page of the NBD-PWG website (https://bigdatawg.nist.gov/V2_output_docs.php). 2 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 156 1.2 SCOPE AND OBJECTIVES OF THE SECURITY AND 157 PRIVACY SUBGROUP 158 The focus of the NBD-PWG Security and Privacy Subgroup is to form a community of interest from 159 industry, academia, and government with the goal of developing consensus on a reference architecture to 160 handle security and privacy issues across all stakeholders. This includes understanding what standards are 161 available or under development, as well as identifying which key organizations are working on these 162 standards. Early standards work, including the efforts of this Public Working Group, helped to focus 163 attention on emerging risks as well as on the underlying technology. 164 The scope of the Subgroup’s work includes the following topics: 165 • Provide a context from which to begin Big Data-specific security and privacy discussions; 166 • Analyze/prioritize a list of challenging security and privacy requirements that may delay or 167 prevent adoption of Big Data deployment; 168 • Develop a Security and Privacy Reference Architecture that supplements the NBDRA; 169 • Produce a working draft of this Big Data Security and Privacy document; 170 • Develop Big Data security and privacy taxonomies; 171 • Explore mapping between the Big Data security and privacy taxonomies and the NBDRA; and 172 • Explore mapping between the use cases and the NBDRA. 173 While there are many issues surrounding Big Data security and privacy, the focus of this Subgroup is on 174 the technology aspects of security and privacy with respect to Big Data. 175 In Version 1, the NBD-PWG introduced the concept of a security and privacy fabric. The fundamental 176 idea is that security and privacy considerations impact all components within the NBDRA. Version 2 of 177 this document extended and amplified this concept into the NIST Big Data Security and Privacy Safety 178 Levels (NBD-SPSL) set forth in a single artifact (Appendix A). The single broadest objective for this 179 document is to offer a three-level security and privacy safety rating for a Big Data system. This high- 180 medium-low simplification is offered in a list form (Appendix A), though it can be implemented through 181 semi-automated means; the latter are indicated but not proscriptive. 182 In addition, rather than embracing a maturity model, a safety engineering approach was chosen. The 183 threats to safety and privacy in Big Data are sufficiently grave, and the teams involved in Big Data 184 creation and analytics potentially so small, that a heavyweight, organizationally demanding framework 185 seemed inappropriate for broad use. Other frameworks, both existing and under development, including 186 some at NIST, address that space for Big Data and Internet of Things (IoT). 187 Since the initial version of this document, recent developments—some refocusing the practice of software 188 engineering on specific components such as scalability, others form part of the steady march of 189 technology—have impacted security and privacy. These recent developments include the following: 190 • Risks for intentional/unintentional breaches of privacy or discrimination against protected groups 191 through machine learning and algorithmic reasoning; 192 • Need for decentralization of high-risk data, particularly authenticating resources; 193 • Adoption and integration of safety engineering practices; 194 • Security and safety engineering in DevOps (a clipped compound of software DEVelopment and 195 information technology OPerationS) frameworks (DevSecOps); 196 • Security and privacy practices in agile development; 197 • Collaborative use of software-defined networks to partition and protect data, application realms, 198 and physical infrastructure; 199 • Integral use of domain, application, and utility models to guide security and privacy practices; 200 • Blockchain and higher-granularity dynamic smart contracts; 3 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 201 • Cryptography and privacy-preserving methods; 202 • Big Data forensics frameworks to be concurrently engineered, not constructed after-the-fact; 203 • Increased use of attribute-based access control ; 204 • Providing a broadly usable self-assessment for conformance to Big Data security levels; and 205 • Microservices, containers, and software-defined network as opportunity areas for security and 206 privacy fabric enhancements. 207 1.3 REPORT PRODUCTION 208 The NBD-PWG Security and Privacy Subgroup explored various facets of Big Data security and privacy 209 to develop this document. The major steps involved in this effort included the following: 210 • Announce that the NBD-PWG Security and Privacy Subgroup is open to the public to attract and 211 solicit a wide array of subject matter experts and stakeholders in government, industry, and 212 academia; 213 • Identify use cases specific to Big Data security and privacy; 214 • Expand the security and privacy fabric of the NBDRA and identify specific topics related to 215 NBDRA components; and 216 • Begin mapping of identified security and privacy use cases to the NBDRA. 217 This report is a compilation of contributions from the NBD-PWG. Since this is a community effort, there 218 are several topics covered that are related to security and privacy. While an effort has been made to 219 connect the topics, gaps may exist. 220 1.4 REPORT STRUCTURE 221 Following this introductory section, the remainder of this document is organized as follows: 222 • Section 2 discusses security and privacy issues particular to Big Data. 223 • Section 3 presents examples of security- and privacy-related use cases. 224 • Section 4 offers a preliminary taxonomy for security and privacy. 225 • Section 5 explores details of the NBDRA, Security and Privacy Fabric, cryptographic 226 technologies, risk management, Big Data security modeling and simulation (ModSim), and 227 security and privacy management. 228 • Section 6 introduces the topic of domain-specific security. 229 • Section 7 introduces the topic of audit and configuration management. 230 • Section 8 considers standards, best practices, and gaps with respect to security and privacy. 231 • Appendix A presents the draft NBD-SPSL. 232 • Appendix B introduces concepts developed in selected existing standards. 233 • Appendix C discusses considerations when implementing a mature security and privacy 234 framework within a Big Data cloud ecosystem enterprise architecture. 235 • Appendix D expands the notion of actors and roles. 236 • Appendix E maps the security- and privacy-related use cases presented in Section 3 to the 237 NBDRA components. 238 • Appendix F provides a high-level list of additional topics explored in Version 2. 239 • Appendix G contains the acronyms used in this document. 240 • Appendix H lists the references used in the document. 241 While each NBDIF volume was created with a specific focus within Big Data, all volumes are 242 interconnected. During the creation of the volumes, information from some volumes was used as input for 243 other volumes. Broad topics (e.g., definition, architecture) may be discussed in several volumes with each 4 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 244 discussion circumscribed by the volume’s particular focus. Arrows shown in Figure 1 indicate the main 245 flow of information input and/or output from the volumes. Volumes 2, 3, and 5 (blue circles) are 246 essentially standalone documents that provide output to other volumes (e.g., to Volume 6). These 247 volumes contain the initial situational awareness research. During the creation of Volumes 4, 7, 8, and 9 248 (green circles), input from other volumes was used. The development of these volumes took into account 249 work on the other volumes. Volumes 1 and 6 (red circles) were developed using the initial situational 250 awareness research and continued to be modified based on work in other volumes. The information from 251 these volumes was also used as input to the volumes in the green circles. 252 253 Figure 1: NBDIF Documents Navigation Diagram Provides Content Flow Between Volumes 254 5 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 2 BIG DATA SECURITY AND PRIVACY 255 256 Opinions, standards, and analysis on the topics of security and privacy are vast, with intensive work under 257 way in disciplines ranging from law and education to highly specialized aspects of systems engineering. 258 An overarching goal of the current work is to focus as narrowly as possible on Big Data security and 259 privacy concerns, while identifying related work elsewhere that can clarify or strengthen the present 260 undertaking. 261 2.1 WHAT IS DIFFERENT ABOUT BIG DATA SECURITY AND 262 PRIVACY 263 The NBD-PWG Security and Privacy Subgroup began this effort by identifying a number of ways that 264 security and privacy in Big Data projects can be different from traditional implementations. While not all 265 concepts apply all the time, the following principles were considered representative of a larger set of 266 differences: 267 1. Big Data projects often encompass heterogeneous components in which a single security scheme 268 has not been designed from the outset. 269 2. Most security and privacy methods have been designed for batch or online transaction processing 270 systems. Big Data projects increasingly involve one or more streamed data sources that are used 271 in conjunction with data at rest, creating unique security and privacy scenarios. 272 3. The use of multiple Big Data sources not originally intended to be used together can compromise 273 privacy, security, or both. Approaches to de-identify personally identifiable information (PII) that 274 were satisfactory prior to Big Data may no longer be adequate, while alternative approaches to 275 protecting privacy are made feasible. Although de-identification techniques can apply to data 276 from single sources as well, the prospect of unanticipated consequences from the fusion of 277 multiple datasets exacerbates the risk of compromising privacy. 278 4. A huge increase in the number of sensor streams for the Internet of Things (e.g., smart medical 279 devices, smart cities, smart homes) creates vulnerabilities in the Internet connectivity of the 280 devices, in the transport, and in the eventual aggregation. 281 5. Certain types of data thought to be too big for analysis, such as geospatial and video imaging, will 282 become commodity Big Data sources. These uses were not anticipated and/or may not have 283 implemented security and privacy measures. 284 6. Issues of veracity, context, provenance, and jurisdiction are greatly magnified in Big Data. 285 Multiple organizations, stakeholders, legal entities, governments, and an increasing amount of 286 citizens will find data about themselves included in Big Data analytics. 287 7. Volatility is significant because Big Data scenarios envision that data is permanent by default. 288 Security is a fast-moving field with multiple attack vectors and countermeasures. Data may be 289 preserved beyond the lifetime of the security measures designed to protect it. 290 8. Data and code can more readily be shared across organizations, but many standards presume 291 management practices that are managed inside a single organizational framework. A related 292 observation is that smaller firms, subject to fewer regulations or lacking mature governance 293 practices, can create valuable Big Data systems. Lack of common data schemas can further 294 inhibit consistent security and privacy practices. 295 The Security and Privacy Subgroup envisions further work to investigate the following list of potential 296 differences between Big Data projects and traditional implementations with respect to security and 297 privacy. 6 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 298 • Inter-organizational issues (e.g., federation, data licensing—not only for cloud); 299 • Mobile/geospatial increased risk for deanonymization; 300 • Change to life cycle processes (no archive or destroy due to Big Data); 301 • Related sets of standards are written with large organizational assumptions but currently, Big 302 Data can be created / analyzed with small teams; 303 • Audit and provenance for Big Data intersects in novel ways with other aspects; 304 • Big Data as a technology accelerator for improved audit (e.g., blockchain, noSQL, machine 305 learning for information security enabled by Big Data), analytics for intrusion detection, complex 306 event processing; 307 • Transborder data flows present challenges to Big Data as it moves across national boundaries 308 ; 309 • Consent (e.g., smart contracts) frameworks, perhaps implemented using blockchain; 310 • Impact of real-time Big Data on security and privacy; 311 • Risk management in Big Data moves the focus to inter-organizational risk and risks associated 312 with analytics versus a simplified four-walls perspective; and 313 • Of lesser importance, but relevant to how Big Data systems are often built, DevOps and agile 314 processes inform the efforts of small teams (even single-developer efforts) in creation and fusion 315 with Big Data. 316 2.2 OVERVIEW 317 Security and privacy measures are becoming ever more important with the increase of Big Data 318 generation and utilization and the increasingly public nature of data storage and availability. 319 The importance of security and privacy measures is increasing along with the growth in the generation, 320 access, and utilization of Big Data. Data generation is expected to double every two years to about 40,000 321 exabytes in 2020. It is estimated that over one-third of the data in 2020 could be valuable if analyzed. 322 (EMC2) Less than a third of data needed protection in 2010, but more than 40 percent of data will need 323 protection in 2020. (EMC2) 324 Security and privacy measures for Big Data involve a different approach than for traditional systems. Big 325 Data is increasingly stored on public cloud infrastructure built by employing various hardware, operating 326 systems, and analytical software. Traditional security approaches usually addressed small-scale systems 327 holding static data on firewalled and semi-isolated networks. The surge in streaming cloud technology 328 necessitates extremely rapid responses to security issues and threats . 329 Big Data system representations that rely on concepts of actors and roles present a different facet to 330 security and privacy. The Big Data systems should be adapted to the emerging Big Data landscape, which 331 is embodied in many commercial and open source access control frameworks. These security approaches 332 will likely persist for some time and may evolve with the emerging Big Data landscape. Appendix C 333 considers actors and roles with respect to Big Data security and privacy. 334 Big Data is increasingly generated and used across diverse industries such as healthcare, drug discovery, 335 finance, insurance, and marketing of consumer-packaged goods. Effective communication across these 336 diverse industries will require standardization of the terms related to security and privacy. The NBD- 337 PWG Security and Privacy Subgroup aims to encourage participation in the global Big Data discussion 338 with due recognition to the complex and difficult security and privacy requirements particular to Big 339 Data. 340 There is a large body of work in security and privacy spanning decades of academic study and 341 commercial solutions. While much of that work may be applicable for protection of Big Data, it may have 342 been produced using different assumptions. One of the primary objectives of this document is to 7 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 343 understand how Big Data security and privacy requirements arise out of the defining characteristics of 344 Big Data and related emerging technologies, and how these requirements are different from traditional 345 security and privacy requirements. 346 The following list is a representative—though not exhaustive—list of differences between what is new for 347 Big Data security and privacy and those of other big systems: 348 • Big Data may be gathered from diverse end points. Actors include more types than just traditional 349 providers and consumers—data owners, such as mobile users and social network users, are 350 primary actors in Big Data. Devices that ingest data streams for physically distinct data 351 consumers may also be actors. This alone is not new, but the mix of human and device types is on 352 a scale that is unprecedented. The resulting combination of threat vectors and potential protection 353 mechanisms to mitigate them is new. 354 • Data aggregation and dissemination must be secured inside the context of a formal, 355 understandable framework. The availability of data and transparency of its current and past use 356 by data consumers is an important aspect of Big Data. However, Big Data systems may be 357 operational outside formal, readily understood frameworks, such as those designed by a single 358 team of architects with a clearly defined set of objectives. In some settings, where such 359 frameworks are absent or have been unsystematically composed, there may be a need for public 360 or walled garden portals and ombudsman-like roles for data at rest. These system combinations, 361 and unforeseen combinations, call for a renewed Big Data framework. 362 • Data search and selection can lead to privacy or security policy concerns. There is a lack of 363 systematic understanding of the capabilities that should be provided by a data provider in this 364 respect. A combination of well-educated users, well-educated architects, and system protections 365 may be needed, as well as excluding databases or limiting queries that may be foreseen as 366 enabling re-identification. If a key feature of Big Data is, as one analyst called it, “the ability to 367 derive differentiated insights from advanced analytics on data at any scale,” the search and 368 selection aspects of analytics will accentuate security and privacy concerns . 369 • Privacy-preserving mechanisms are needed for Big Data, such as for PII. The privacy and 370 integrity of data coming from end points should be protected at every stage because there may be 371 disparate, potentially unanticipated processing steps between the data owner, provider, and data 372 consumer. End-to-end information assurance practices for Big Data are not dissimilar from other 373 systems but must be designed on a larger scale. 374 • Big Data is pushing beyond traditional definitions for information trust, openness, and 375 responsibility. Governance, previously consigned to static roles and typically employed in larger 376 organizations, is becoming an increasingly important intrinsic design consideration for Big Data 377 systems.a 378 • Legacy security solutions need to be retargeted to the infrastructural shift due to Big Data. Legacy 379 security solutions address infrastructural security concerns that persist in Big Data, such as 380 authentication, access control, and authorization. These solutions need to be retargeted to the 381 underlying Big Data High Performance Computing (HPC) resources or completely replaced. 382 Oftentimes, such resources can face the public domain, and thus necessitate vigilant security 383 monitoring methods to prevent adversarial manipulation and to preserve integrity of operations. 384 • Information assurance (IA) and disaster recovery (DR) for Big Data Systems may require unique 385 and emergent practices. Because of its extreme scalability, Big Data presents challenges for IA 386 and DR practices that were not previously addressed in a systematic way. Traditional backup and 387 replication methods may be impractical for Big Data systems. In addition, test, verification, and 388 provenance assurance for Big Data replicas may not complete in time to meet temporal 389 requirements that were readily accommodated in smaller systems. a Reference to NBDRA Data Provider. 8 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 390 • Big Data creates potential targets of increased value. The effort required to consummate system 391 attacks will be scaled to meet the opportunity value. Big Data systems will present concentrated, 392 high-value targets to adversaries. As Big Data becomes ubiquitous, such targets are becoming 393 more numerous—a new information technology (IT) scenario in itself. 394 • Risks have increased for deanonymization and transfer of PII without consent traceability. 395 Security and privacy can be compromised through unintentional lapses or malicious attacks on 396 data integrity. Managing data integrity for Big Data presents additional challenges related to all 397 the Big Data characteristics, but especially for PII. While there are technologies available to 398 develop methods for de-identification, some experts caution that equally powerful methods can 399 leverage Big Data to re-identify personal information. For example, the availability of 400 unanticipated datasets could make re-identification possible. Even when technology can preserve 401 privacy, proper consent and use may not follow the path of the data through various custodians. 402 Because of the broad collection and set of uses of Big Data, consent for collection is much less 403 likely to be sufficient and should be augmented with technical and legal controls to provide 404 auditability and accountability for use , . 405 • There are emerging risks in open data and Big Data science. Data identification, metadata 406 tagging, aggregation, and segmentation—widely anticipated for data science and open datasets— 407 if not properly managed, may have degraded veracity because they are derived and not primary 408 information sources. Retractions of peer-reviewed research due to inappropriate data 409 interpretations may become more commonplace as researchers leverage third-party Big Data. 410 2.3 SECURITY AND PRIVACY IMPACTS ON BIG DATA 411 CHARACTERISTICS 412 Volume, velocity, variety, and variability are key characteristics of Big Data and commonly referred to as 413 the Vs of Big Data. Where appropriate, these characteristics shaped discussions within the NBD-PWG 414 Security and Privacy Subgroup. While the Vs provide a useful shorthand description used in the public 415 discourse about Big Data, there are other important characteristics of Big Data that affect security and 416 privacy, such as veracity, validity, and volatility. These elements are discussed below with respect to their 417 impact on Big Data security and privacy. 418 2.3.1 VOLUME 419 The volume of Big Data describes the size of the dataset. In Big Data parlance, this typically ranges from 420 gigabytes (GB) to exabytes and beyond. As a result, the volume of Big Data has necessitated storage in 421 multitiered storage media. The movement of data between tiers has led to a requirement of cataloging 422 threat models and a surveying of novel techniques. The threat model for network-based, distributed, auto- 423 tier systems includes the following major scenarios: confidentiality and integrity, provenance, availability, 424 consistency, collusion attacks, roll-back attacks, and recordkeeping disputes . 425 A flip side of having volumes of data is that analytics can be performed to help detect security breach 426 events. This is an instance where Big Data technologies can fortify security. This document addresses 427 both facets of Big Data security. 428 2.3.2 VELOCITY 429 Velocity describes the rate of data flow. The data usually arrives in batches or is streamed continuously. 430 As with certain other non-relational databases, distributed programming frameworks were not developed 431 with security and privacy in mind . Malfunctioning computing nodes might leak confidential data. 432 Partial infrastructure attacks could compromise a significantly large fraction of the system due to high 9 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 433 levels of connectivity and dependency. If the system does not enforce strong authentication among 434 geographically distributed nodes, rogue nodes can be added that can eavesdrop on confidential data. 435 2.3.3 VARIETY 436 Variety describes the organization of the data—whether the data is structured, semi-structured, or 437 unstructured. Retargeting traditional relational database security to non-relational databases has been a 438 challenge . These systems were not designed with security and privacy in mind, and these functions 439 are usually relegated to middleware. Traditional encryption technology also hinders organization of data 440 based on semantics. The aim of standard encryption is to provide semantic security, which means that the 441 encryption of any value is indistinguishable from the encryption of any other value. Therefore, once 442 encryption is applied, any organization of the data that depends on any property of the data values 443 themselves are rendered ineffective, whereas organization of the metadata, which may be unencrypted, 444 may still be effective. 445 An emergent phenomenon, introduced by Big Data variety that has gained considerable importance is the 446 ability to infer identity from anonymized datasets by correlating with apparently innocuous public 447 databases. The inference process is also aided by data volume, but the diversity of data sources is the 448 primary cause here. While several formal models to address privacy-preserving data disclosure have been 449 proposed , , in practice, sensitive data is shared after sufficient removal of apparently unique 450 identifiers, and indirectly identifying information by the processes of anonymization and aggregation. 451 This is an ad hoc process that is often based on empirical evidence  and has led to many instances of 452 deanonymization in conjunction with publicly available data . Although some laws/regulations 453 recognize only identifiers per se, laws such as the Health Insurance Portability and Accountability Act 454 (HIPAA; the statistician provision), the Family Educational Rights and Privacy Act (FERPA), and 45 455 Code of Federal Regulations (CFR) 46 recognize that combinations of attributes, even if not the 456 identifiers by themselves, can lead to actionable personal identification, possibly in conjunction with 457 external information. 458 2.3.4 VERACITY 459 Big Data veracity encompass several sub-characteristics as described below. 460 Veracity encompasses information assurance for the methods through which information was collected. 461 For example, when sensors are used, traceability, calibration, version, sampling, and device configuration 462 are needed. See reference  for a deeper discussion. In the NBDIF, veracity may be seen as a technical 463 attribute required for provenance, just as confidentiality is a technical attribute required for privacy. 464 “Veracity refers to the accuracy of the data, and relates to the vernacular garbage-in, garbage-out 465 description for data quality issues in existence for a long time. If the analytics are causal, then the quality 466 of every data element is very important. If the analytics are correlations or trending over massive volume 467 datasets, then individual bad elements could be lost in the overall counts and the trend would still be 468 accurate. Data quality concerns, for the most part, are still vitally important for Big Data analytics. This 469 concept is not new to Big Data, but remains important.” (NBDIF: Volume 1, Definitions) 470 Provenance: Big Data frequently moves across individual boundaries to groups and communities of 471 interest, and across state, national, and international boundaries. Provenance addresses the problem of 472 understanding the data’s original source, such as through metadata, though the problem extends beyond 473 metadata maintenance. Also, as noted before, with respect to privacy policy, additional context is needed 474 to make responsible decisions over collected data, which may include the form of consent, intended use, 475 temporal connotations (e.g., Right to be Forgotten), or broader context of collection. The additional 476 context could be considered a type of provenance, broadly, but goes beyond the range of provenance 477 information typically collected in production information systems. Various approaches have been tried, 478 such as for glycoproteomics , but no clear guidelines yet exist. 10 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 479 A common understanding holds that provenance data is metadata establishing pedigree and chain of 480 custody, including calibration, errors, missing data (e.g., time stamp, location, equipment serial number, 481 transaction number, and authority). 482 Some experts consider the challenge of defining and maintaining metadata to be the overarching 483 principle, rather than provenance. The two concepts, though, are clearly interrelated. 484 Curation, an integral concept, includes processes to improve the veracity of information, and is related to 485 which binds veracity and provenance to principles of governance, as well as to data quality assurance. 486 Curation, for example, may improve raw data by fixing errors, filling in gaps, modeling, calibrating 487 values, and ordering data collection. 488 Transparency is succinctly defined in ISO 16759:2013  as “open, comprehensive, accessible, clear 489 and understandable presentation of information.” This definition reflects a general purpose, lay 490 understanding of transparency. The definition is one among several important dimensions of a 491 transparency framework. 492 More detail is specified in this NBDIF framework. Big Data transparency is discussed in depth in Section 493 2.4.8. Additional context is usually required as data may be aggregated or disaggregated across and 494 between Big Data systems. Application of algorithmic processing on data creates additional 495 responsibilities for data owners. Changes in ownership, governance and system configurations over time 496 are an integral part of Big Data security and privacy fabric. In addition to the System Communicator, 497 NBDIF support for transparency is buttressed by optional System Learner Models and Interaction 498 Profiles. 499 Validity refers to the usefulness, accuracy, and correctness of data for its application. Traditionally, this 500 has been referred to as data quality. In the Big Data security scenario, validity refers to a host of 501 assumptions about data from which analytics are being applied. For example, continuous and discrete 502 measurements have different properties. The field gender can be coded as 1=Male, 2=Female, but 1.5 503 does not mean halfway between male and female. In the absence of such constraints, an analytical tool 504 can make inappropriate conclusions. There are many types of validity whose constraints are far more 505 complex. By definition, Big Data allows for aggregation and collection across disparate datasets in ways 506 not envisioned by system designers. 507 “While the data may have high veracity (accurate representation of the real-world processes that created 508 it), there are times when the data is no longer valid for the hypothesis being asked. For example, in a fast- 509 changing environment such as the stock market, while historical price data has high veracity, it is not 510 valid for certain types of analysis that rely upon real-time pricing information. In many cases, there is a 511 time window before which the data is no longer valid for analysis. This concept is not new to Big Data, 512 but remains important.” (NBDIF: Volume 1, Definitions) 513 Fraud. Invalid uses of Big Data can be malicious or unintended. Several examples of invalid uses for Big 514 Data have been cited. Click fraud, conducted on a Big Data scale, but which can be detected using Big 515 Data techniques, has been cited as the cause of perhaps $11 billion in wasted advertisement spending 516 . A software executive listed seven different types of online ad fraud, including nonhuman-generated 517 impressions, nonhuman-generated clicks, hidden ads, misrepresented sources, all-advertising sites, 518 malicious ad injections, and policy-violating content such as pornography or privacy violations . Each 519 of these can be conducted at Big Data scale and may require Big Data solutions to detect and combat. 520 While not malicious, some trend-producing applications that use social media to predict the incidence of 521 flu have been called into question. A study by Lazer et al.  suggested that one application 522 overestimated the prevalence of flu for 100 of 108 weeks studied. Careless interpretation of social media 523 to answer questions not related to the reason the data was collected is possible when attempts are made to 524 characterize or even predict consumer behavior using imprecise meanings and intentions for like and 525 follow. Researchers have also identified big data as both a palliative tool and a contributing factor to fake 11 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 526 news (e.g., Vargo, Guo, Amazeen, 2018). These examples show that what passes for valid Big Data can 527 be innocuously lost in translation, misinterpreted, or intentionally corrupted to malicious intent. 528 2.3.5 VOLATILITY 529 Volatility of data—how data structures change over time—directly affects provenance. Big Data is 530 transformational in part because systems may produce indefinitely persisting data—data that outlives the 531 instruments on which it was collected; the architects who designed the software that acquired, processed, 532 aggregated, and stored it; and the sponsors who originally identified the project’s data consumers. 533 Volatility is related to governance. Roles are time-dependent in nature. For instance, the role associated 534 with “admin” may change when system responsibilities are reassigned. Security and privacy requirements 535 shift when systems undergo such transitions. In fact, governance can shift as responsible organizations 536 merge or even disappear. 537 While research has been conducted into how to manage temporal data (e.g., for satellite instrument data in 538 IEEE e-Science) , there are few standards beyond simplistic time stamps and even fewer common 539 practices available as guidance. To manage security and privacy for long-lived Big Data, data temporality 540 should be taken into consideration. 541 For example, in health care, temporal data can be critical. Consider the following: 542 • Permissions for healthcare proxy in malpractice litigation; 543 • Administration dates and symptom onset for clinical trials; 544 • Medical records sharing across enterprises when carriers or employers change policies; 545 • Identification of high-cost patient populations; and 546 • Predictive analytics for adverse treatment and lifestyle choice events. 547 Increased adoption of big data-enabled clinical analytics includes numerous use cases in which patient 548 safety, security or privacy must be considered. Researchers (e.g., see Bates, Saria, Ohno-Machado, Shah, 549 Escobar, 2014) warn that these “findings have implications for regulatory oversight [and] ways to address 550 privacy concerns.” 551 2.4 EFFECTS OF EMERGING TECHNOLOGY ON BIG DATA 552 SECURITY AND PRIVACY 553 2.4.1 CLOUD COMPUTING 554 Many Big Data systems will be designed using cloud architectures. Any strategy to achieve proper access 555 control and security risk management within a Big Data cloud ecosystem enterprise architecture must 556 address the complexities associated with cloud-specific security requirements triggered by cloud 557 characteristics, including, but not limited to, the following: 558 • Broad network access; 559 • Decreased visibility and control by consumers 560 • Dynamic system boundaries and commingled roles and responsibilities between consumers and 561 providers 562 • Multi-tenancy; 563 • Different organizations are responsible for different parts of one system; 564 • Data residency; 565 • Measured service; and 566 • Order-of-magnitude increases in scale (e.g., on demand), dynamics (e.g., elasticity and cost 567 optimization), and complexity (e.g., automation and virtualization). 12 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 568 These cloud computing characteristics often present different security risks to an organization than the 569 traditional IT solutions, altering the organization’s security posture. 570 To preserve security when migrating data to the cloud, organizations need to identify all cloud-specific, 571 risk-adjusted security controls or components in advance. It may be necessary in some situations to 572 request from the cloud service providers, through contractual means and service-level agreements, that all 573 required security components and controls be fully and accurately implemented. A further discussion of 574 internal security considerations within cloud ecosystems can be found in Appendix C. 575 Even though cloud computing is driving innovation in technologies that support Big Data, some Big Data 576 projects are not in the cloud. However, because of the resurgence of the cloud, considerable work has 577 been invested in developing cloud standards to alleviate concerns over its use. A number of organizations, 578 including NIST, are diligently engaged in standards work around cloud computing. Central among these 579 for Big Data security and privacy is NIST SP 800-144 , which included a then-current list of related 580 standards and guides, which is reproduced in Appendix C. In the EU, the European Telecommunications 581 Standards Institute (ETSI) produced the Cloud Standards Coordination Report . More recently, the 582 Defense Information Systems Agency (DISA) at the U.S. Department of Defense (DoD) published its 583 Cloud Security Requirements Guide , which covers DoD projects through the secret level. 584 On the privacy front, when the Federal Chief Information Officer (CIO) Council published 585 recommendations for Digital Privacy Controls , Big Data received a mention in a footnote: 586 “The potential for re-identifying, tracing, or targeting individuals may arise from the 587 application of predictive analyses and other “data mining” techniques to “big data” 588 (i.e., the increasing availability of vast amounts of stored and streaming digital 589 information). See, e.g., NIST Data Mining Portal (describing ongoing programs, 590 projects, and workshops), http://www.nist.gov/data-mining-portal.cfm. Agencies should 591 ensure that their PIAs for digital services and programs consider whether data mining 592 could be used to identify, trace or target individuals, and be aware of statutory reporting 593 obligations when engaged in data mining for the detection of criminal or terrorist 594 activities. See GAO, Data Mining; Agencies Have Taken Key Steps to Protect Privacy in 595 Selected Efforts, but Significant Compliance Issues Remain (Aug. 2005) (noting need for 596 agencies to provide proper notice and perform PIAs), 597 http://www.gao.gov/new.items/d05866.pdf; Federal Agency Data Mining Reporting Act 598 of 2007, 42 U.S.C. 2000ee3 (requiring the reporting to Congress of pattern-based 599 queries, searches, or analyses of one or more databases by or on behalf of the Federal 600 Government to discover or locate a predictive pattern or anomaly indicative of terrorist 601 or criminal activity on the part of any individual or individuals) (p. 10).” 602 2.4.2 BIG DATA SECURITY AND PRIVACY SAFETY LEVELS 603 Following the practice of standards work elsewhere, this document offers guidance to enterprises wishing 604 to commit to improving security practices. During work on Version 2, an understanding emerged from 605 discussions within the Security and Privacy Subgroup of the links between safety and security. This link 606 is increasingly noted in the literature. For example, Draeger noted : 607 "The close connection between safety and security has led to a growing 608 interest in a combined handling of these two areas of research … The 609 conditions enabling a combined safety and security analysis are identified 610 and used as starting point of the elaboration. Utilizing these properties, a 611 theoretical framework unifying key aspects of both safety and security is 612 developed, whereby a model-based approach is chosen .” 13 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 613 The Security and Privacy Subgroup proposes the NIST Big Data Security and Privacy Safety Levels 614 (NBD-SPSL), which contains three levels of conformance to security safety practices for Big Data 615 security and privacy. The initial development work on the NBD-SPSL is presented in Appendix A and 616 contains some Big Data security and privacy elements with details of the three Big Data security and 617 privacy safety levels. When paired with a checklist and recommended practices, organizations can self- 618 designate their systems as conforming to a level of the NBD-SPSL, as identified in this report. 619 That safety engineering has a clear counterpart in Big Data security and privacy can be seen by 620 considering the fabric of safety that encompasses commercial and military aviation. Aviation is a complex 621 milieu of human, mechanical, and geospatial aspects, yet aviation has achieved extraordinary safety 622 levels. 623 A closer look at the analogy between the aviation safety fabric and Big Data security and privacy safety 624 considerations is illustrative. Taken as a whole, the aviation industry (e.g., aircraft and engine 625 manufacturers, Federal Aviation Administration [FAA], airports, airline maintenance, airline crews, travel 626 agents, Transportation Security Administration [TSA]) is one the oldest and most mature Big Data 627 verticals. From the earliest days of automaton, aviation has utilized computer networks and the most 628 modern testing equipment as early adopters. Aviation is distributed globally. Every aircraft down to nuts 629 and bolts is registered by tail number and then monitored for safety incidents throughout its life. Every 630 significant line replaceable unit is numbered and tracked during its life cycle, representing comprehensive 631 traceability.b Every instrument is recalibrated periodically. Every licensed pilot is periodically checked 632 out medically and for proficiency. Crews are scheduled within strict safety rules. Currently, all the 633 information is stored in computers federated around the globe. Many terabytes stream from commercial 634 aircraft every day, to ground computers . Currently, ground controllers record much flight data. The 635 digital data is stovepiped and networked globally. 636 These aviation industry concepts and practices of data collection, traceability, parts registration, and 637 safety monitoring can be translated to analogous elements of Big Data systems. The state of the art in 638 aviation Big Data for operational analytics is dynamic and expanding . Someday, future Big Data 639 generating elements, functional components, and other pieces of the Big Data ecosystem might be as 640 closely monitored as aircraft, flights, pilots, and air crews. At present, most nascent cyber-physical 641 systems (CPSs), including IoT items, are very far removed from a regulated and enforced Big Data-driven 642 environment. Much work remains before artificial intelligence (AI) systems and Big Data achieve 643 acceptable security safety levels. 644 Extensive literature surveys have demonstrated an intimate connection between “methods, models, tools 645 and techniques” employed in safety engineering and “transposed to security engineering, or vice versa 646 .” The Piètre-Cambacédès & Bouissou study observed the following. 647 “A careful screening of the literature (this paper contains 201 references) 648 made it possible to identify cross-fertilizations in various fields such as 649 architectural concepts (e.g., defense in depth, security or safety kernels), 650 graphical formalisms (e.g., attack trees), structured risk analyses or fault 651 tolerance and prevention techniques”  (p. 110) 652 The time for a Big Data security and privacy safety framework has arrived—to protect not only the public 653 but also its practitioners enmeshed in a complex web of engineering and marketing of Big Data. The 654 proposed NBD-SPSL is intended to serve as an accessible first step. b Some historians believe that the Titanic sank because some of the rivets used were substandard, which could be proven by tracing the rivets to their original point of manufacture. http://www.bbem.com/military-hardware- traceability 14 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 655 2.4.3 INTERNET OF THINGS AND CPS 656 The Big Data security and privacy community has identified relevant intersections with work in IoT 657 security and crosswalks to related standards efforts in those communities at NIST  and elsewhere. 658 Methods to secure individual IoT devices fall outside the scope of the NBDRA; however, it is worthwhile 659 to note that IoT devices present unique security challenges due to limited hardware capability, rapid 660 market evolution, and lack of a widely used security standard. While some progress has been made with 661 industrial devices , , consumer device manufactures have no regulatory or market incentive to 662 secure their devices. 663 Until IoT hardware reaches sufficient maturity to allow TLS communication and support other 664 cryptographic authentication mechanisms, IoT data required for a BDRA will typically be collected under 665 a single provider per device type or class. Volume and Velocity for an individual IoT device are low, due 666 to power and processing constraints, though in an aggregate provider, very high volumes are easily 667 realized. Veracity of this provider is strongly dependent on hardware and protocol implementation details, 668 which might be opaque to relying Big Data consumers. 669 IoT aggregate NBDRA Data Providers should authenticate individual IoT device connections prior to 670 accepting data wherever possible. While statistical analytics might detect a security breach, relying on this 671 alone is undesirable as it lacks means to distinguish between individual and compromised devices – 672 resulting in a complete loss of functionality in the event of a breach. 673 2.4.4 MOBILE DEVICES AND BIG DATA 674 On its face, mobile devices are simply an evolution of decades-old concepts in distributed computing. 675 While this is undeniable, there are certainly lessons in distributed computing that must be updated for 676 current security concerns. Mobile must be viewed as a critical element of Big Data. 677 Although mobile spans many facets of computer security, there are several reasons for addressing mobile 678 in any comprehensive Big Data security and privacy checklist, including the following: 679 • Mobile devices challenge governance and controls for enterprises, especially in BYOD (bring 680 your own device) environments. As a result, specialized security approaches enabling mobile- 681 centric access controls have been proposed . 682 • Some web-based and desktop applications may be migrated to mobile versions without adequate 683 security and privacy protections. 684 • Mobile devices are less subject to physical security protection, yet they can access Big Data 685 systems as well as any desktop. 686 • Many organizations lag in the control of mobile device security, preferring to focus on server and 687 desktop security, which has a longer history and is more profitable for tools suppliers. 688 • Mobile devices often disclose geospatial data, which can be used in Big Data settings to enrich 689 other datasets, and even to perform deanonymization. 690 2.4.5 INTEGRATION OF PEOPLE AND ORGANIZATIONS 691 The Security and Privacy Fabric did not integrate the ways in which people and organizations impact Big 692 Data workflow and contribute to the strength or weakness of a Big Data system’s security and privacy. 693 To communicate across organizations, eXtensible Markup Language (XML)-based solutions should be 694 considered. For example, Lenz and Oberweis suggested using an XML variant of Petri nets . They 695 point out that, “Due to the fast growth of Internet-based electronic business activities, languages for 696 modeling as well as methods for analyzing and executing distributed business processes are becoming 697 more and more important. Efficient inter-organizational business processes in the field of ecommerce 15 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 698 require the integration of electronic document interchange and inter-organizational process management 699 .” (p. 243) 700 Similarly, Hypertext Markup Language (HTML) microdata can be used to transfer or house information 701 exchanged across organizational boundaries . Microdata has been extended for use with Resource 702 Description Framework (RDF) . 703 The Security and Privacy Subgroup looked at a body of research that addressed concerns for digital 704 systems sharing across organizations. The scope is considerable. Information sharing is key to exchanges 705 in finance, supply chain, healthcare, emergency services, and defense . 706 That said, in mature systems such as the Enterprise Data Management (EDM) Council’s Financial 707 Industry Business Ontology (FIBO; https://www.edmcouncil.org/financialbusiness), the issues of Big 708 Data security and privacy, despite its regulatory facets, may be understated. Additional work is needed to 709 ensure that such frameworks address security and privacy knowledge representation—thus permitting 710 automated reasoning about some aspects of a Big Data system’s level of compliance, as well as 711 facilitating comparisons across Big Data security and privacy frameworks by deployment of a unifying 712 model. 713 Various Institute of Electrical and Electronics Engineers (IEEE) and ISO standards address 714 organizational, life cycle, and systems development processes (e.g., ISO 15288 ). It remains as an 715 open task to consider if and how such standards affect Big Data security and privacy and whether 716 improvements are needed to enhance Big Data security and privacy safety. 717 2.4.6 SYSTEM COMMUNICATOR 718 Big Data systems that collect, store, manage, or transform data considered in need of protection (e.g., data 719 called out as payment card industry [PCI]) should be designed with accessible portals that enable classes 720 of persons to review their own data, direct its removal or extraction, and to understand how it is being 721 used. 722 The System Communicator is one of the elements in the NBD-SPSL. Additional work is needed to 723 identify how System Communicator requirements should be crafted to meet both usability objectives 724 (e.g., for public PII) and interoperability requirements to work with legacy as well as greenfield Big Data 725 applications. 726 By providing a System Communicator capability that can be accessed by all stakeholders—potentially 727 including software agents, as well as human stakeholders—Big Data systems can be made more 728 transparent, responsive to citizen- or stakeholder-initiated data correction, and offer feature continuity for 729 such capabilities as data and code moves between organizations. 730 2.4.7 ETHICAL DESIGN 731 Journalists, as well as technologists, have decried the apparent lack of ethical standards in Big Data. The 732 incorporation of ethical, and often technical, guidelines is part of ISO 27500  and a suite of IEEE 733 working groups, especially P7000 , P7002 , P7003 , and P7007 . As the work of these 734 teams proceed, features and capabilities that enhance the Security and Privacy Fabric and add to the 735 NBD-SPSL will surface. The subsections below touch on a few aspects of ethical design. 736 2.4.7.1 Self-Cleaning Systems 737 Some reports suggest that as much as 20% of the data in global firms is not fully reliable. This citation is 738 repeated in a proposal by Khayyat et al. , in which the case is made for self-cleaning Big Data 739 systems. The presence of erroneous or misleading information, such as citizens who are mistakenly 740 placed on terrorist watch lists or falsely connected to other criminal activities, is a Big Data security and 16 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 741 privacy problem. Their work and other research  reflect increased attention to data quality, data 742 curation, and its associated risk. 743 2.4.7.2 The Toxic Data Model 744 In other fields of study, toxicity is employed as a construct to help represent risk associated with a 745 material or process. An analogous approach to high-risk data is suggested in Appendix A. Data elements 746 should be assessed based on their toxicity. For example, a U.S. passport number or an HIV diagnosis on 747 an electronic health record could be said to have high toxicity. A standard, based on the well-established 748 Material Safety Data Sheets, should be employed for data elements in Big Data systems. 749 For instance, the U.S. Department of Labor, Occupational Safety and Health Administration promulgates 750 a standard communication format for chemical hazards 751 (https://www.osha.gov/Publications/OSHA3514.html). Future standards could specify the content and 752 format that should accompany Big Data elements shared across and within enterprises. Recipients of a 753 data communications might decline to accept certain types of Big Data, or recognize what changes would 754 be required in their systems and processes to accommodate toxic data. System and process changes, for 755 information-intensive organizations such as the U.S. Census Bureau or social media firms, could prove 756 essential to their mission. 757 2.4.7.3 Big Data Security Safety Annotation 758 Federation is key to information supply chains. Most of the world’s global enterprises and governments 759 rely upon extensive information system supply chains, yet managing these to ensure security and privacy 760 is challenging. A review of currently available approaches is needed. One approach is seen in marketplace 761 notions (e.g., closed clearinghouses, federation as an engineering principle, InCommon, GENI.net, 762 Organization for the Advancement of Structured Information Standards [OASIS] IDTrust). However, 763 sometimes there will also be requirements for out-of-band guest identity, such as for emergencies, 764 regulatory, or other exceptional circumstances. 765 2.4.7.4 Big Data Trust and Federation 766 Federation and trust are aspects of information sharing. These are sometimes explicit, sometimes not. The 767 level of detail exchanged between organizations varies wildly. Some limit themselves to a one-off 768 exchange of keys. One research team has suggested the use of transactional memory managed through the 769 use of cloud brokers . 770 The scope of this document is necessarily limited, whereas there are entire disciplines within computing 771 dedicated to various aspects of federation. 772 Middleware, message-passing, and enterprise service bus remain important concepts for Big Data. For 773 example, in SE-CLEVER investigators wanted to address issues raised by the Cloud Security Alliance in 774 their Extensible Messaging and Presence Protocol (XMPP)-based middleware . 775 Enterprises large and small will increasingly automate functions and share information, creating new and 776 varied Big Data sources. Even for relatively mature organizations, federation across a supply chain or 777 customer federation multiplies threats while governance, risk management, and compliance (GRC) is 778 weakened. That weakening is a necessary byproduct of cross-organization sharing, but still a risk. While 779 shared standards, mutual open dialog, and other socialization and training techniques matter, systems 780 must be put in place that operate across organizational boundaries. 17 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 781 2.4.7.5 Orchestration in Weak Federation Scenarios 782 Orchestration design patterns may be needed for weak federation scenarios. How these interact with 783 broad orchestration for Big Data (e.g., Kubernetes, Topology and Orchestration Specification for Cloud 784 Applications [TOSCA]) requires further study. 785 2.4.7.6 Consent and the Glass-Breaking Scenario 786 The glass-breaking scenario is important to Big Data security and privacy because it identifies the need 787 for systematically framed exceptions to security and privacy hardening. 788 In healthcare standards such as Health Level Seven (HL7) Fast Healthcare Interoperability Resources 789 (FHIR; http://hl7.org/fhir/), glass-breaking may be needed to save a life in an emergency. The emergency 790 itself occasions a different security and privacy context, which a Big Data application may need to 791 recognize. 792 The importance of geospatial Big Data for emergency management is acknowledged , , and the 793 absence of consent to single out disabled individuals in a high-rise fire point to nuanced rules around 794 information access, as well as the velocity of the underlying decision support infrastructure. 795 An abuse-resistant glass-break mechanism for time-critical situations (such as fires, medical emergencies) 796 across multiple Providers may require machine learning, as policy reconfiguration for even a highly 797 skilled human operator would take too long, or be too easy to bypass. The mechanism must have strong 798 authentication and non-repudiation, with the identity, location, and motive of the initiator preserved 799 permanently through a cryptographic mechanism (such as blockchain). 800 2.4.8 BIG DATA TRANSPARENCY 801 For Big Data systems, a layered approach is required to provide a safe, scalable, composable security and 802 privacy transparency fabric. The NBDIF specifies three levels of voluntary conformance to Big Data 803 system transparency: 804 1. Transparency Level 1 Conformance: Level 1 utilizes the System Communicator to provide 805 online explanations to users and stakeholders. These explanations, subject to other security and 806 privacy guidelines and constraints, include explanation of the output of system processes to 807 include, most commonly, a natural language explanation understandable by identified target user 808 populations. “User populations” roughly follow the definition of roles in the ISO/IEC 27000 809 series family of information security standards . Transparency contracts and explanations 810 shall be retained with the system, along with a record of what has been disclosed, accepted or 811 rejected. Granularity shall be sufficient to meet the needs of the identified user populations. This 812 shall be achieved through NBDIF Interaction Profiles at individual user granularity. 813 Accompanying disclosure records may, for instance, include information requested but not 814 provided due to system constraints or regulation, but Interaction Profiles are recommended at 815 Level 1. Interaction Profiles will likely include elements derived from baselines and profiles 816 specified in the NIST Cybersecurity Framework  (SP 800-53B Revision 5 control baselines 817 ). 818 2. Transparency Level 2 Conformance: Level 2 specifies a domain-specific system model, along 819 with System Communicator protocols included in Transparency Level 1. Each system domain has 820 potentially unique roles, attributes, phases, elements and dependencies which must be modeled. 821 In addition, Big Data Interaction Profiles are mandatory at Level 2 and shall include a full, 822 privacy-preserving record of all transparency-related transactions with a Big Data system. 823 Interaction Profile integrity may be ensured using Big Data techniques discussed in this 824 document, such as blockchain. Level 2 conformance shall also include a System Learner Model 825 for individual users . This model “teaches” what a Big Data system does, what risks may be 18 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 826 involved, what impacts on privacy or security should be considered, how data may be shared and 827 “learns” more. A continuously evolved “System Learner model” is preserved and tightly linked to 828 the domain model of the application. While privacy is a key part of the model, the security and 829 privacy fabric must include other facets of Big Data systems as they evolve over time and touch 830 other aspects of their interactions with users or systems. 831 3. Transparency Level 3 Conformance: Level 3 incorporates Level 2 practices plus digital 832 ontologies for the associated domains and learner models. Automated reasoning systems at Level 833 3 allow for fully traceable explanations that are system-, learner-, feature-, time- and domain- 834 dependent. Level 3 conformance may require linkage to a natural language processing subsystem. 835 The System Learner Models and Interaction Profiles shall permit automated reasoning, such as 836 that specified in ISO 18629, and automation of processes outlined in NIST SP 800-162  for 837 attribute-based security. The additional capabilities enable automated escalation of system 838 processes based upon elevated risk, safety, adjustment of user interfaces for impaired users or 839 children, automation of notification and alerting, and ease of interoperability with legacy systems 840 such as metadata management or compliance engines. 841 In the NBDPWG Big Data framework, “information” has a broader meaning that is normally associated 842 with systems design. Hence, transparency has a broader implication as well. For instance, transparency 843 may include anthropological elements . Empirical methods may be needed to provide for 844 measurement of transparency effectiveness, so that tuning and improvements can evolve with Big Data 845 systems deployments in DevOps. They may incorporate empirically based effective information design 846 . These capabilities in turn demand measurement data which contributes both to a Big Data system’s 847 purview, but also enlarges the scope of the security and privacy fabric. 848 Transparency may have necessary versus sufficient considerations. For instance, regulators may mandate 849 that lenders explain why credit is denied, even though credit decisions may be fully or partially supported 850 by algorithms (e.g., Fair Credit Reporting Act, 15 U.S.C. § 1681 ). Some Big Data transparency 851 considerations are outlined below. 852 • It is important to understand that data may consist of information that is fully or partially 853 anonymized. 854 • It is important to recognize that data sources can include current but also legacy data sources 855 (e.g., earlier versions of IoT devices) or systems. 856 • Promises regarding transparency and privacy must be retained across enterprises and original 857 system architects. 858 • When data is shared, transparency and privacy data must travel with it at equivalent or better 859 provenance and granularity. 860 • Stakeholders, users and data providers must be provided with risk as part of transparency. ISO 861 16759:2013  does not address risk. Risk is highly domain-specific, thus additional metadata 862 and modeling data will likely accompany mechanisms that support transparency. 863 • Transparency references should be consulted. Transparency is further discussed in NIST SP 800- 864 37 Rev 2 , which asserts one goal for the NIST Risk Management Framework as “To support 865 consistent, informed, and ongoing authorization decisions (through continuous monitoring), 866 reciprocity, and the transparency and traceability of security and privacy information” ( 867 Chapter 1, p. 3, December 2018, italics added). Added challenges associated with the information 868 supply chain were also highlighted: “Effective risk decisions by authorizing officials depend on 869 the transparency of controls selected and implemented by external providers and the quality and 870 efficacy of the assessment evidence produced by those providers. Transparency is essential to 871 achieve the assurance necessary to ensure adequate protection for organizational asset” ( 872 Appendix G, italics added). The NBDIF specifies guidelines to support transparency, traceability, 873 and monitoring of data, algorithms, ownership, and relevant system attributes. 19 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 874 • Audit records (e.g., when transparency was disclosed, to whom was it disclosed, what was 875 disclosed) shall be retained beyond individual system life cycle design patterns. System life cycle 876 status can be a critical component of transparency disclosures. 877 • Transparency should be provided for withdrawal of consent. For instance, compliance with 878 GDPR specifies a right to be forgotten, but there will be practical or system limitations. Full 879 transparency would include what data has been quarantined (i.e., forgotten), but as noted 880 elsewhere in the NBDIF, Big Data will often persist beyond its originating system(s), and this 881 process creates transparency requirements. 882 • In some cases, where extensive granularity is required, support for dual privacy and transparency 883 could require or add significantly to Big Data systems. 884 • Timelines must be maintained for significant transparency events, such as changes to algorithms, 885 data ownership, increased or decreased data governance, configuration management. 886 • When making changes to algorithms, such as joins with geospatial or other data sources, 887 additional transparency mandates should be expected. 888 • Increases or decreases in risk experienced by Big Data systems over time should be considered. 889 For example, a small data set could be merged with a much larger data set, or when data is moved 890 from a high security data center to a lower security data center. Shifts in risk profile shall be 891 disclosed as part of transparency conformance. 892 • For machine-to-machine implementations, transparency may be best achieved by implementing 893 domain-specific languages, which can be dynamically linked to scenarios, images, or natural 894 language text. Ad hoc solutions will likely fail to scale in systems with Big Data variety or in 895 specialized domains with frequent software releases or changes in the science, technology, or 896 regulatory landscape. 897 Explanations will often focus on data providers and data provider processes. For example, in a clinical 898 setting, an explanation for why a particular medicine was prescribed could be different for the patient, 899 patient’s family, a clinical decision support system, the primary care physician, a radiologist, a 900 pharmacist, public health official, or malpractice attorney. For a Big Data system, explanations of a real 901 time Big Data stream to a data consumer may be needed for future system implementers to understand 902 how that data source should be ingested. In addition, some Big Data systems will need an explanation of 903 the processes that include how data is being collated with other sources. 904 To support transparency, a Big Data system provider output should include, at a minimum, a natural 905 language explanation that is understandable to the identified target user population(s). When the 906 explanation is challenging to offer (e.g., explaining what a system does), the best alternative may be to 907 explain what it is (e.g., how the process works, how the process came about) or to provide representative 908 scenarios. 909 20 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 3 EXAMPLE USE CASES FOR 910 SECURITY AND PRIVACY 911 912 There are significant Big Data challenges in science and engineering. Many of these are described in the 913 use cases in NBDIF: Volume 3, Use Cases and General Requirements. However, the primary focus of 914 these use cases was on science and engineering applications, and therefore, security and privacy impacts 915 on system architecture were not highlighted. Consequently, a different set of use cases, presented in this 916 document, was developed specifically to discover security and privacy issues. Some of these use cases 917 represent inactive or legacy applications, but were selected to demonstrate characteristic security/privacy 918 design patterns. 919 The use cases selected for security and privacy are presented in the following subsections. The use cases 920 included are grouped to organize this presentation, as follows: retail/marketing, healthcare, cybersecurity, 921 government, industrial, aviation, and transportation. However, these groups do not represent the entire 922 spectrum of industries affected by Big Data security and privacy. 923 The security and privacy use cases, collected when the reference architecture was not mature, were 924 provided by NBD-PWG members to identify representative security and privacy scenarios thought to be 925 suitably classified as particular to Big Data. An effort was made to map the use cases to the NBDRA. 926 Additional security and privacy use cases were collected (in the same format as the original security and 927 privacy use cases) during Version 2 work, which have helped guide the development of the NBD-SPSL. 928 However, the need for more specific and standardized use case information lead to the creation of a new 929 use case template. 930 During Version 2 activities, the Security and Privacy Subgroup collaborated with the Use Cases and 931 Requirements Subgroup to develop the new Use Case Template 2, was used to collect additional use 932 cases. In addition to questions from the original use case template, the Use Case Template 2 contains 933 questions aimed at providing a comprehensive view of security, privacy, and other topics for each use 934 case. 935 3.1 RETAIL/MARKETING 936 3.1.1 CONSUMER DIGITAL MEDIA USAGE 937 Scenario Description: Consumers, with the help of smart devices, have become very conscious of price, 938 convenience, and access before they decide on a purchase. Content owners license data for use by 939 consumers through presentation portals, such as Netflix, iTunes, and others. 940 Comparative pricing from different retailers, store location and/or delivery options, and crowd-sourced 941 rating have become common factors for selection. To compete, retailers are keeping a close watch on 942 consumer locations, interests, and spending patterns to dynamically create marketing strategies to reach 943 customers who would buy their products. 944 Current Security and Privacy Issues/Practices: Individual data is collected by several means, including 945 smartphone GPS (global positioning system) or location, browser use, social media, and applications 946 (apps) on smart devices. 21 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 947 • Privacy: 948 Controls are inconsistent and/or not established to appropriately achieve the following o 949 objectives: 950  Predictability around the processing of personal information, to give individuals a reliable 951 sense of how their information is processed and enable them to make appropriate 952 determinations for themselves, or prevent problems arising from actions such as 953 unanticipated revelations about individuals 954  Manageability of personal information, to prevent problems arising from actions such as 955 dissemination of inaccurate information 956  Controls may not address the inability of some consumers to access information about 957 themselves that is available to enterprises or governments 958  Unlinkability of information from individuals to prevent actions such as surveillance of 959 individuals 960 • Security: 961 Controls are inconsistent and/or not established appropriately to achieve the following: o 962  Isolation, containerization, and encryption of data 963  Monitoring and detection of threats, as well as incident handling 964  Identification of users and devices for data feed 965  Interfacing with other data sources 966  Anonymization of users: while some data collection and aggregation uses anonymization 967 techniques, individual users can be re-identified by leveraging other public Big Data pools. 968  Original digital rights management (DRM) techniques were not built to scale to meet 969 demand for the forecasted use for the data. “DRM refers to a broad category of access 970 control technologies aimed at restricting the use and copy of digital content on a wide 971 range of devices .” DRM can be compromised, diverted to unanticipated purposes, 972 defeated, or fail to operate in environments with Big Data characteristics—especially 973 velocity and aggregated volume. 974 Current Research: There is limited research on enabling privacy and security controls that protect 975 individual data (whether anonymized or non-anonymized) for consumer digital media usage settings such 976 as these. 977 3.1.2 NIELSEN HOMESCAN: PROJECT APOLLO 978 Scenario Description: Nielsen Homescan is a subsidiary of Nielsen that collects family-level retail 979 transactions. Project Apollo was a project designed to better unite advertising content exposure to 980 purchase behavior among Nielsen panelists. Project Apollo did not proceed beyond a limited trial, but 981 reflects a Big Data intent. The description is a best-effort general description and is not an official 982 perspective from Nielsen, Arbitron or the various contractors involved in the project. The information 983 provided here should be taken as illustrative rather than as a historical record. 984 A general retail transaction has a checkout receipt that contains all SKUs (stock keeping units) purchased, 985 time, date, store location, etc. Nielsen Homescan collected purchase transaction data using a statistically 986 randomized national sample. As of 2005, this data warehouse was already a multi-terabyte dataset. The 987 warehouse was built using structured technologies but was built to scale many terabytes. Data was 988 maintained in-house by Homescan but shared with customers who were given partial access through a 989 private web portal using a columnar database. Additional analytics were possible using third-party 990 software. Other customers would only receive reports that include aggregated data, but greater granularity 991 could be purchased for a fee. 22 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 992 Then current (2005-2006) Security and Privacy Issues/Practices: 993 • Privacy: There was a considerable amount of PII data. Survey participants are compensated in 994 exchange for giving up segmentation data, demographics, and other information. 995 • Security: There was traditional access security with group policy, implemented at the field level 996 using the database engine, component-level application security, and physical access controls. 997 • There were audit methods in place, but were only available to in-house staff. Opt-out data 998 scrubbing was minimal. 999 3.1.3 WEB TRAFFIC ANALYTICS 1000 Scenario Description: Visit-level webserver logs are high-granularity and voluminous. To be useful, log 1001 data must be correlated with other (potentially Big Data) data sources, including page content (buttons, 1002 text, navigation events), and marketing-level events such as campaigns, media classification, etc. There 1003 are discussions—if not deployment—of plans for traffic analytics using complex event processing (CEP) 1004 in real time. One nontrivial problem is segregating traffic types, including internal user communities, for 1005 which collection policies and security are different. 1006 Current Security and Privacy Issues/Practices: 1007 • Opt-in defaults are relied upon in some countries to gain visitor consent for tracking of website 1008 visitor IP addresses. In some countries Internet Protocol (IP) address logging can allow analysts 1009 to identify visitors down to levels as detailed as latitude and longitude, depending on the quality 1010 of the maps and the type of area being mapped. 1011 • Media access control (MAC) address tracking enables analysts to identify IP devices, which is a 1012 form of PII. 1013 • Some companies allow for purging of data on demand, but most are unlikely to expunge 1014 previously collected web server traffic. 1015 • The EU has stricter regulations regarding collection of such data, which in some countries is 1016 treated as PII. Such web traffic is to be scrubbed (anonymized) or reported only in aggregate, 1017 even for multinationals operating in the EU but based in the United States . 1018 3.2 HEALTHCARE 1019 3.2.1 HEALTH INFORMATION EXCHANGE 1020 Scenario Description: Health Information Exchanges (HIEs) facilitate sharing of healthcare information 1021 that might include electronic health records (EHRs) so that the information is accessible to relevant 1022 covered entities, but in a manner that enables patient consent. 1023 HIEs tend to be federated, where the respective covered entity retains custodianship of its data. This poses 1024 problems for many scenarios, such as emergencies, for a variety of reasons that include technical (such as 1025 interoperability), business, and security concerns. 1026 Cloud enablement of HIEs is through strong cryptography and key management to meet the HIPAA 1027 requirements for protected health information (PHI). Ideally this does not require the cloud service 1028 operator to sign a business associate agreement (BAA). Cloud usage would provide several benefits, 1029 including patient safety, lowered healthcare costs, and regulated accesses during emergencies. 1030 The following are some preliminary scenarios that have been proposed by the NBD PWG: 1031 • Break-the-Glass: There could be situations where the patient is not able to provide consent due to 1032 a medical situation, or a guardian is not accessible, but an authorized party needs immediate 1033 access to relevant patient records. Cryptographically enhanced key life cycle management can 23 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 1034 provide a sufficient level of visibility and non-repudiation that would enable tracking violations 1035 after the fact. 1036 • Informed Consent: When there is a transfer of EHRs between covered entities and business 1037 associates, it would be desirable and necessary for patients to be able to convey their approval, as 1038 well as to specify what components of their EHR can be transferred (e.g., their dentist would not 1039 need to see their psychiatric records). Through cryptographic techniques, one could leverage the 1040 ability to specify the fine-grain cipher text policy that would be conveyed. (For related standards 1041 efforts regarding consent, see NIST SP 800-53 , Appendix J, Section IP-1; U.S. DHS Health 1042 IT Policy Committee, Privacy and Security Workgroup; and Health Level Seven (HL7) 1043 International Version 3 standards for Data Access Consent, Consent Directives.) 1044 • Pandemic Assistance: There will be situations when public health entities, such as the CDC and 1045 perhaps other nongovernmental organizations that require this information to facilitate public 1046 safety, will require controlled access to this information, perhaps in situations where services and 1047 infrastructures are inaccessible. A cloud HIE with the right cryptographic controls could release 1048 essential information to authorized entities through authorization and audits in a manner that 1049 facilitates the scenario requirement. 1050 • Cross-government and cross-industry sharing 1051 Current Security and Privacy Issues/Practices: 1052 • Security: 1053 Lightweight but secure off-cloud encryption: There is a need for the ability to perform o 1054 lightweight but secure off-cloud encryption of an EHR that can reside in any container 1055 that ranges from a browser to an enterprise server, and that leverages strong symmetric 1056 cryptography. 1057 Homomorphic encryption is not widely deployed but is anticipated by some experts as a o 1058 medium-term practice . 1059 Applied cryptography: Tight reductions, realistic threat models, and efficient techniques o 1060 • Privacy: 1061 Differential privacy: Techniques for guaranteeing against inappropriate leakage of PII o 1062 HIPAA o 1063 3.2.2 GENETIC PRIVACY 1064 Scenario Description: A consortium of policy makers, advocacy organizations, individuals, academic 1065 centers, and industry has formed an initiative, Free the Data!, to fill the public information gap caused by 1066 the lack of available genetic information for the BRCA1 and BRCA2 genes. The consortium also plans to 1067 expand to provide other types of genetic information in open, searchable databases, including the National 1068 Center for Biotechnology Information’s database, ClinVar. The primary founders of this project include 1069 Genetic Alliance, the University of California San Francisco, InVitae Corporation, and patient advocates. 1070 This initiative invites individuals to share their genetic variation on their own terms and with appropriate 1071 privacy settings in a public database so that their family, friends, and clinicians can better understand 1072 what the mutation means. Working together to build this resource means working toward a better 1073 understanding of disease, higher-quality patient care, and improved human health. 1074 Current Security and Privacy Issues/Practices: 1075 • Security: 1076 Secure Sockets Layer (SSL)/ Transport Layer Security (TLS)-based authentication and o 1077 access control. Basic user registration with low attestation level 1078 Concerns over data ownership and custody upon user death o 24 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 1079 Site administrators may have access to data—strong encryption and key escrow are o 1080 recommended 1081 • Privacy: 1082 Transparent, logged, policy-governed controls over access to genetic information o 1083 Full life cycle data ownership and custody controls o 1084 3.2.3 PHARMA CLINICAL TRIAL DATA SHARING 1085 Scenario Description: Companies routinely publish their clinical research, collaborate with academic 1086 researchers, and share clinical trial information on public websites, atypically at three different stages: the 1087 time of patient recruitment, after new drug approval, and when investigational research programs have 1088 been discontinued. Access to clinical trial data is limited, even to researchers and governments, and no 1089 uniform standards exist. 1090 The Pharmaceutical Research and Manufacturers of America (PhRMA) represents the country’s leading 1091 biopharmaceutical researchers and biotechnology companies. In July 2013, PhRMA joined with the 1092 European Federation of Pharmaceutical Industries and Associations (EFPIA) in adopting joint Principles 1093 for Responsible Clinical Trial Data Sharing . According to the agreement, companies will apply these 1094 Principles as a common baseline on a voluntary basis, and PhRMA encouraged all medical researchers, 1095 including those in academia and government, to promote medical and scientific advancement by adopting 1096 and implementing the following commitments: 1097 • Enhancing data sharing with researchers 1098 • Enhancing public access to clinical study information 1099 • Sharing results with patients who participate in clinical trials 1100 • Certifying procedures for sharing trial information 1101 • Reaffirming commitments to publish clinical trial results 1102 Current Security and Privacy Issues/Practices: 1103 PhRMA does not directly address security and privacy, but these issues were identified either by PhRMA 1104 or by reviewers of the proposal. 1105 • Security: 1106 Longitudinal custody beyond trial disposition is unclear, especially after firms merge or o 1107 dissolve. 1108 Standards for data sharing are unclear. o 1109 There is a need for usage audit and security. o 1110 Publication restrictions: Additional security will be required to protect the rights of o 1111 publishers, for example, Elsevier or Wiley. 1112 • Privacy: 1113 Patient-level data disclosure—elective, per company. o 1114 The PhRMA mentions anonymization (re-identification), but mentions issues with small o 1115 sample sizes. 1116 Study-level data disclosure—elective, per company. o 1117 3.3 CYBERSECURITY 1118 3.3.1 NETWORK PROTECTION 1119 Scenario Description: Network protection includes a variety of data collection and monitoring. Existing 1120 network security packages monitor high-volume datasets, such as event logs, across thousands of servers. 1121 Improved security software will include physical data correlates (e.g., access card usage for devices as 25 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 1122 well as building entrance/exit) and likely be more tightly integrated with applications, which will generate 1123 logs and audit records of previously undetermined types or sizes. Big Data analytics systems will be 1124 required to process and analyze this data to deliver meaningful results. These systems could also be multi- 1125 tenant, catering to more than one distinct company. 1126 The roles that Big Data plays in protecting networks can be grouped into two broad categories: 1127 • Security for Big Data: When launching a new Big Data initiative, new security issues often arise, 1128 such as a new attack surface for server clusters, user authentication and access from additional 1129 locations, new regulatory requirements due to Big Data Variety, or increased use of open source 1130 code with the potential for defaulted credentials or other risks . 1131 • Big Data for security: Big Data can be used to enhance network security. For example, a Big Data 1132 application can enhance or eventually even replace a traditional Security Information and Event 1133 Management (SIEM) . 1134 Current Security and Privacy Issues/Practices: 1135 • Security 1136 Big Data security in this area is under active research, and maintaining data integrity and o 1137 confidentiality while data is in-motion and/or at-rest warrants constant 1138 encryption/decryption that works well for Small Data, but is still inadequate for Big Data. 1139 In addition, privacy concepts are even less mature. 1140 Traditional policy-type security prevails, though temporal dimension and monitoring of o 1141 policy modification events tends to be nonstandard or unaudited. 1142 Cybersecurity apps run at high levels of security and thus require separate audit and o 1143 security measures. 1144 No cross-industry standards exist for aggregating data beyond operating system o 1145 collection methods. 1146 Implementing Big Data cybersecurity should include data governance, encryption/key o 1147 management, and tenant data isolation/containerization. 1148 Volatility should be considered in the design of backup and disaster recovery for Big o 1149 Data cybersecurity. The useful life of logs may extend beyond the lifetime of the devices 1150 which created them. 1151 • Privacy: 1152 Need to consider enterprise practices for data release to external organizations o 1153 Lack of protection of PII data o 1154 Currently vendors are adopting Big Data analytics for mass-scale log correlation and incident response, 1155 such as for SIEM. 1156 3.4 GOVERNMENT 1157 3.4.1 UNMANNED VEHICLE SENSOR DATA 1158 Scenario Description: Unmanned Aerial Vehicles (UAVs), also called Remotely Piloted Vehicles (RPVs) 1159 or Unmanned Aerial Systems (UAS), can produce petabytes of data, some of it streamed, and often stored 1160 in proprietary formats. These streams, which can include what in military circles is referred to as full 1161 motion video, are not always processed in real time. UAVs are also used domestically. The Predator 1162 drone is used to patrol U.S. border areas, and sometimes flood areas; it allows authorized government 1163 workers to see real-time video and radar . 1164 Current Security and Privacy Issues/Practices: 26 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 1165 • Military UAV projects are governed by extensive rules surrounding security and privacy 1166 guidelines. Security and privacy requirements are further dictated by applicable service (Navy, 1167 Army, Air Force, Marines) instructions . 1168 • Not all UAV data uses are military. For example, NASA, National Oceanic and Atmospheric 1169 Administration and the FAA may have specific use for UAV data. Issues and practices regarding 1170 the use of sensor data gathered non-DoD UAVs is still evolving, as demonstrated by a draft U.S. 1171 Department of Justice (DOJ) policy guideline produced by the DOJ Office of Legal Policy . 1172 The guideline acknowledges the value of UAS data as “a viable law enforcement tool” and 1173 predicts that “UAS are likely to come into greater use.” The draft reiterates that UAS monitoring 1174 must be consistent with First and Fourth Amendment guarantees, and that data “may only be used 1175 in connection with properly authorized investigations.” Additional guidance addresses PII that 1176 has been collected, such that it cannot be retained for more than 180 days except when certain 1177 conditions are met. Annual privacy reviews and accountability for compliance with security and 1178 privacy regulations are prominent in the draft. 1179 • Collection of data gathered by UAVs outside of the United States is subject to local regulation. 1180 For example, in the EU, guidelines are under discussion, which incorporate Remotely Piloted 1181 Aircraft Systems in the European Aviation System. The EU sponsored a report addressing 1182 potential privacy, data protection, and ethical risks related to civil Remotely Piloted Aircraft 1183 System (RPAS) applications (http://ec.europa.eu/enterprise/sectors/aerospace/uas /). 1184 3.4.2 EDUCATION: COMMON CORE STUDENT PERFORMANCE REPORTING 1185 Scenario Description: Forty-five states have decided to unify standards for K–12 student performance 1186 measurement. Outcomes are used for many purposes, and the program is incipient, but it will obtain 1187 longitudinal Big Data status. The datasets envisioned include student-level performance across students’ 1188 entire school history and across schools and states, as well as taking into account variations in test stimuli. 1189 Current Security and Privacy Issues/Practices: 1190 • Data is scored by private firms and forwarded to state agencies for aggregation. Classroom, 1191 school, and district identifiers remain with the scored results. The status of student PII is 1192 unknown; however, it is known that teachers receive classroom-level performance feedback. The 1193 extent of student/parent access to test results is unclear. As set forth in the Data Quality 1194 Campaign, protecting student data is seen as a state education agency responsibility: to define 1195 “the permissible collection and uses of data by external technologies and programs used in 1196 classrooms.” This source identifies additional resources for safeguarding student data and 1197 communicating with parents and staff about data and privacy rights . 1198 • Privacy-related disputes surrounding education Big Data are illustrated by the reluctance of states 1199 to participate in the InBloom initiative . 1200 • According to some reports, parents can opt students out of state tests, so opt-out records must also 1201 be collected and used to purge ineligible student records . 1202 Current Research: 1203 • Longitudinal performance data would have value for program evaluators and educators. Work in 1204 this area was proposed by Deakin Crack, Broadfoot & Claxton  as a “Lifelong Learning 1205 Inventory,” and further by Ferguson , whose reference to data variety observed that 1206 “Increasingly, learners will be looking for support from learning analytics outside the Virtual 1207 Learning Environment or Learning Management System, whilst engaged in lifelong learning in 1208 open, informal or blended settings. This will require a shift towards more challenging datasets 1209 and combinations of datasets, including mobile data, biometric data, and mood data. To solve the 1210 problems faced by learners in different environments, researchers will need to investigate what 1211 those problems are and what success looks like from the perspective of learners .” 27 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 1212 • Data-driven learning  will involve access to students’ performance data, probably more often 1213 than at test time, and at higher granularity, thus requiring more data. One example enterprise is 1214 Civitas Learning’s  predictive analytics for student decision making. 1215 3.5 INDUSTRIAL: AVIATION 1216 3.5.1 SENSOR DATA STORAGE AND ANALYTICS 1217 Scenario Description: Most commercial airlines are equipped with hundreds of sensors to constantly 1218 capture engine and/or aircraft health information during a flight. For a single flight, the sensors may 1219 collect multiple GB of data and transfer this data stream to Big Data analytics systems. Several companies 1220 manage these Big Data analytics systems, such as parts/engine manufacturers, airlines, and plane 1221 manufacturers, and data may be shared across these companies. The aggregated data is analyzed for 1222 maintenance scheduling, flight routines, etc. Companies also prefer to control how, when, and with whom 1223 the data is shared, even for analytics purposes. Many of these analytics systems are now being moved to 1224 infrastructure cloud providers. 1225 Current Security and Privacy Issues/Practices: 1226 • Encryption at rest: Big Data systems should encrypt data stored at the infrastructure layer so that 1227 cloud storage administrators cannot access the data. 1228 • Key management: The encryption key management should be architected so that end customers 1229 (e.g., airliners) have sole/shared control on the release of keys for data decryption. 1230 • Encryption in motion: Big Data systems should verify that data in transit at the cloud provider is 1231 also encrypted. 1232 • Encryption in use: Big Data systems will desire complete obfuscation/encryption when 1233 processing data in memory (especially at a cloud provider). 1234 • Sensor validation and unique identification (e.g., device identity management) 1235 • Protocols for API security, such as OAuth 2.0 1236 Researchers are currently investigating the following security enhancements: 1237 • Virtualized infrastructure layer mapping on a cloud provider 1238 • Homomorphic encryption 1239 • Quorum-based encryption 1240 • Multiparty computational capability 1241 • Device public key infrastructure (PKI) 1242 3.6 TRANSPORTATION 1243 3.6.1 CARGO SHIPPING 1244 The following use case outlines how the shipping industry (e.g., FedEx, UPS, DHL) regularly uses Big 1245 Data. Big Data is used in the identification, transport, and handling of items in the supply chain. The 1246 identification of an item is important to the sender, the recipient, and all those in between with a need to 1247 know the location of the item while in transport and the time of arrival. Currently, the status of shipped 1248 items is not relayed through the entire information chain. This will be provided by sensor information, 1249 GPS coordinates, and a unique identification schema based on the new ISO 29161  standards under 1250 development within the ISO joint technical committee (JTC) ISO JTC1 SC31 WG2. There are likely 1251 other standards evolving in parallel. The data is updated in near real time when a truck arrives at a depot 1252 or when an item is delivered to a recipient. Intermediate conditions are not currently known, the location 1253 is not updated in real time, and items lost in a warehouse or while in shipment represent a potential 28 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 1254 problem for homeland security. The records are retained in an archive and can be accessed for system- 1255 determined number of days. 1256 3.7 ADDITIONAL SECURITY AND PRIVACY USE CASES 1257 The following use cases were collected to further inform the work of the Security and Privacy Subgroup. 1258 These use cases were in the initial phases of collection when the need for the Use Case Template 2 arose. 1259 Therefore, the use cases have not been as fully developed as the previously presented use cases that were 1260 collected during Version 1 work. However, the information provided below contains valuable information 1261 that guided Version 2 work, including formation of the NBD-SPSL. 1262 3.7.1 SEC Consolidated Audit Trail 1263 The SEC Consolidated Audit Trail (CAT) project  is forecast to consume 10 terabytes of data daily 1264 (SEC Rule 613 ). The system’s security requirements, which stemmed from a past system failure with 1265 lack of traceability, are considerable. Figure 2  presents the High-Level CAT Security Requirements. 1266 1267 Figure 2: High-Level CAT Requirements 1268 3.7.2 IOT DEVICE MANAGEMENT 1269 This family of use cases involves the onboarding, decommissioning, and/or quarantining of numerous 1270 devices, such as for IoT and CPS. The sheer number of devices and the limited defenses against 1271 tampering that low-cost devices can incorporate, put Big Data systems at risk. 1272 Safety systems incorporating voluminous sensor streams represent this family of use cases. Preliminary 1273 research addressing IoT safety is already under way , , . The latter work was reported during 1274 an international conference now more than a decade old, the International Conference on System Safety 1275 and Cybersecurity. 1276 One application of IoT is in smart homes. Smart homes allow for remote monitoring through Wi-Fi 1277 networks and present new Big Data sources and new attack surfaces for private residences, government 1278 facilities, and other entities. 1279 3.7.3 STATEWIDE EDUCATION DATA PORTAL 1280 The Kauffman Foundation EdWise web resource provides public access to higher education data for 1281 consumers, parents, support organizations, and leaders. It is a data aggregator as well as an analytics 29 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 1282 portal . The portal attempts to provide anonymized student and institutional performance data for 1283 educational decision support. 1284 1285 Figure 3: EdWise Figure 1286 30 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 4 TAXONOMY OF SECURITY AND 1287 PRIVACY TOPICS 1288 1289 A candidate set of topics from the Cloud Security Alliance Big Data Working Group (CSA BDWG) 1290 article, Top Ten Challenges in Big Data Security and Privacy Challenges, was used in developing these 1291 security and privacy taxonomies . Candidate topics and related material used in preparing this section 1292 are provided in Appendix C. 1293 A taxonomy for Big Data security and privacy should encompass the aims of existing useful taxonomies. 1294 While many concepts surround security and privacy, the objective in the taxonomies contained herein is 1295 to highlight and refine new or emerging principles specific to Big Data. 1296 The following subsections present an overview of each security and privacy taxonomy, along with lists of 1297 topics encompassed by the taxonomy elements. These lists are the results of preliminary discussions of 1298 the Subgroup. The focus has been predominantly on security and security-related privacy risks (i.e., risks 1299 that result from unauthorized access to personally identifiable information). Privacy risks that may result 1300 from the processing of information about individuals, and how the taxonomy may account for such 1301 considerations, is an important topic but one which the Subgroup did not have time to explore in depth. 1302 4.1 CONCEPTUAL TAXONOMY OF SECURITY AND PRIVACY 1303 TOPICS 1304 The conceptual security and privacy taxonomy, presented in Figure 4, contains four main groups: data 1305 confidentiality; data provenance; system health; and public policy, social, and cross-organizational topics. 1306 The first three topics broadly correspond with the traditional classification of confidentiality, integrity, 1307 and availability (CIA), reoriented to parallel Big Data considerations. 1308 Data Provenance Confidentiality Security and Privacy Conceptual Taxonomy Public Policy, Social, and Cross- System Health Organizational Topics 1309 Figure 4: Security and Privacy Conceptual Taxonomy 31 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 1310 4.1.1 DATA CONFIDENTIALITY 1311 • Confidentiality of data in transit: For example, enforced by using Transport Layer Security (TLS) 1312 • Confidentiality of data at rest 1313 Policies to access data based on credentials o 1314  Systems: Policy enforcement by using systems constructs such as Access Control 1315 Lists (ACLs) and Virtual Machine (VM) boundaries 1316  Crypto-enforced: Policy enforcement by using cryptographic mechanisms, such 1317 as PKI and identity/attribute-based encryption 1318 • Computing on encrypted data 1319 Searching and reporting: Cryptographic protocols, such as Functional Encryption  o 1320 that support searching and reporting on encrypted data—any information about the plain 1321 text not deducible from the search criteria is guaranteed to be hidden 1322 Homomorphic encryption: Cryptographic protocols that support operations on the o 1323 underlying plain text of an encryption—any information about the plain text is 1324 guaranteed to be hidden 1325 • Secure data aggregation: Aggregating data without compromising privacy 1326 • Data anonymization 1327 De-identification of records to protect privacy o 1328 • Key management 1329 As noted by Chandramouli and Iorga , cloud security for cryptographic keys, an o 1330 essential building block for security and privacy, takes on additional complexity, which 1331 can be rephrased for Big Data settings: (1) greater variety due to more cloud consumer- 1332 provider relationships, and (2) greater demands and variety of infrastructures “on which 1333 both the Key Management System and protected resources are located .” 1334 Big Data systems are not purely cloud systems, but as noted elsewhere in this document, o 1335 the two are closely related. One possibility is to retarget the key management framework 1336 that Chandramouli and Iorga developed for cloud service models to the NBDRA security 1337 and privacy fabric. Cloud models would correspond to the NBDRA and cloud security 1338 concepts to the proposed fabric. NIST 800-145  provides definitions for cloud 1339 computing concepts, including infrastructure as a service (IaaS), platform as a service 1340 (PaaS), and software as a service (SaaS) cloud service models. 1341 Challenges for Big Data key management systems (KMS) reflect demands imposed by o 1342 Big Data characteristics (i.e., volume, velocity, variety, and variability). For example, 1343 relatively slow-paced data warehouse key creation is insufficient for Big Data systems 1344 deployed quickly and scaled up using massive resources. The lifetime for a Big Data 1345 KMS will likely outlive the period of employment of the Big Data system architects who 1346 designed it. Designs for location, scale, ownership, custody, provenance, and audit for 1347 Big Data key management is an aspect of a security and privacy fabric. 1348 4.1.2 PROVENANCE 1349 • End-point input validation: A mechanism to validate whether input data is coming from an 1350 authenticated source, such as digital signatures 1351 Syntactic: Validation at a syntactic level o 1352 Semantic: Semantic validation is an important concern. Generally, semantic validation o 1353 would validate typical business rules such as a due date. Intentional or unintentional 1354 violation of semantic rules can lock up an application. This could also happen when using 1355 data translators that do not recognize the particular variant. Protocols and data formats 1356 may be altered by a vendor using, for example, a reserved data field that will allow their 1357 products to have capabilities that differentiate them from other products. This problem 32 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 1358 can also arise in differences in versions of systems for consumer devices, including 1359 mobile devices. The semantics of a message and the data to be transported should be 1360 validated to verify, at a minimum, conformity with any applicable standards. The use of 1361 digital signatures will be important to provide assurance that the data from a sensor or 1362 data provider has been verified using a validator or data checker and is, therefore, valid. 1363 This capability is important, particularly if the data is to be transformed or involved in the 1364 curation of the data. If the data fails to meet the requirements, it may be discarded, and if 1365 the data continues to present a problem, the source may be restricted in its ability to 1366 submit the data. These types of errors would be logged and prevented from being 1367 disseminated to consumers. 1368 Digital signatures will be very important in the Big Data system. o 1369 • Communication integrity: Integrity of data in transit, enforced, for example, by using TLS 1370 • Authenticated computations on data: Ensuring that computations taking place on critical 1371 fragments of data are indeed the expected computations 1372 Trusted platforms: Enforcement through the use of trusted platforms, such as Trusted o 1373 Platform Modules (TPMs) 1374 Crypto-enforced: Enforcement through the use of cryptographic mechanisms o 1375 • Granular audits: Enabling audit at high granularity 1376 • Control of valuable assets 1377 Life cycle management o 1378 Retention and disposition o 1379 DRM o 1380 4.1.3 SYSTEM HEALTH 1381 In a separate discussion, the interwoven notions of design, development, and management are addressed 1382 directly. A Big Data system likely requires additional measures to ensure availability, as illustrated by the 1383 unanticipated restore time for a major outage . 1384 • System availability is a key element in CIA—Security against denial of service (DoS) 1385 Construction of cryptographic protocols (developed with encryption, signatures, and o 1386 other cryptographic integrity check primitives) proactively resistant to DoS 1387 • System Immunity—Big Data for Security 1388 Analytics for security intelligence o 1389 Data-driven abuse detection o 1390 Big Data analytics on logs, cyber-physical events, intelligent agents o 1391 Security breach event detection o 1392 Forensics o 1393 Big Data in support of resilience o 1394 4.1.4 PUBLIC POLICY, SOCIAL AND CROSS-ORGANIZATIONAL TOPICS 1395 The following set of topics is drawn from an Association for Computing Machinery (ACM) grouping. 1396 . Each of these topics has Big Data security and privacy dimensions that could affect how a fabric 1397 overlay is implemented for a specific Big Data project. For instance, a medical devices project might need 1398 to address human safety risks, whereas a banking project would be concerned with different regulations 1399 applying to Big Data crossing borders. Further work to develop these concepts for Big Data is anticipated 1400 by the Subgroup. 1401 • Abuse and crime involving computers 1402 • Computer-related public private health systems 1403 • Ethics (within data science, but also across professions) 33 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 1404 • Human safety 1405 • Intellectual property rights and associated information managementc 1406 • Regulation 1407 • Transborder data flows 1408 • Use/abuse of power 1409 • Assistive technologies for persons with disabilities (e.g., added or different security/privacy 1410 measures may be needed for subgroups within the population) 1411 • Employment (e.g., regulations applicable to workplace law may govern proper use of Big Data 1412 produced or managed by employees) 1413 • Social aspects of ecommerce 1414 • Legal: Censorship, taxation, contract enforcement, forensics for law enforcement 1415 4.2 OPERATIONAL TAXONOMY OF SECURITY AND 1416 PRIVACY TOPICS 1417 Current practice for securing Big Data systems is diverse, employing widely disparate approaches that 1418 often are not part of a unified conceptual framework. The elements of the operational taxonomy, shown in 1419 Figure 5, represent groupings of practical methodologies. These elements are classified as operational 1420 because they address specific vulnerabilities or risk management challenges to the operation of Big Data 1421 systems. These methodologies have not been incorporated as part of a cohesive security fabric. They are 1422 potentially valuable checklist-style elements that can solve specific security or privacy needs. These 1423 methodologies could be better integrated with risk management guidelines developed by others (e.g., 1424 NIST Special Publication 800-37 Revision 1, Guide for Applying the Risk Management Framework to 1425 Federal Information Systems , NIST Internal Report (NISTIR) 8062, An Introduction to Privacy 1426 Engineering and Risk Management in Federal Systems , and COBIT Risk IT Framework . 1427 In the proposed operational taxonomy, broad considerations of the conceptual taxonomy appear as 1428 recurring features. For example, confidentiality of communications can apply to governance of data at rest 1429 and access management, but it is also part of a security metadata model . 1430 The operational taxonomy will overlap with small data taxonomies while drawing attention to specific 1431 issues with Big Data , . c For further information, see the frameworks suggested by the Association for Information and Image Management (AIIM; http://www.aiim.org /) and the MIKE 2.0 Information Governance Association (http://mike2.openmethodology.org/wiki/MIKE2.0_Governance_Association). 34 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY Device and Application Registration Identity and Risk and Access Accountability Management Security and Privacy Operational Taxonomy Infrastructure Data Management Governance 1432 Figure 5: Security and Privacy Operational Taxonomy 1433 4.2.1 DEVICE AND APPLICATION REGISTRATION 1434 • Device, User, Asset, Services, and Applications Registration: Includes registration of devices in 1435 machine to machine (M2M) and IoT networks, DRM-managed assets, services, applications, and 1436 user roles 1437 • Security Metadata Model 1438 The metadata model maintains relationships across all elements of a secured system. It o 1439 maintains linkages across all underlying repositories. Big Data often needs this added 1440 complexity due to its longer life cycle, broader user community, or other aspects. 1441 A Big Data model must address aspects such as data velocity, as well as temporal aspects o 1442 of both data and the life cycle of components in the security model. 1443 • Policy Enforcement 1444 Environment build o 1445 Deployment policy enforcement o 1446 Governance model o 1447 Granular policy audit o 1448 Role-specific behavioral profiling o 1449 4.2.2 IDENTITY AND ACCESS MANAGEMENT 1450 • Virtualization layer identity (e.g., cloud console, PaaS) 1451 Trusted platforms o 1452 • Application layer Identity 1453 • End-user layer identity management 1454 Roles o 35 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 1455 • Identity provider (IdP) 1456 An IdP is defined in the Security Assertion Markup Language (SAML) . In a Big o 1457 Data ecosystem of data providers, orchestrators, resource providers, framework 1458 providers, and data consumers, a scheme such as the SAML/Security Token Service 1459 (STS) or eXtensible Access Control Markup Language (XACML) is seen as a helpful-but 1460 not proscriptive-way to decompose the elements in the security taxonomy. 1461 Big Data may have multiple IdPs. An IdP may issue identities (and roles) to access data o 1462 from a resource provider. In the SAML framework, trust is shared via SAML/web 1463 services mechanisms at the registration phase. 1464 In Big Data, due to the density of the data, the user "roams" to data (whereas in o 1465 conventional virtual private network [VPN]-style scenarios, users roam across trust 1466 boundaries). Therefore, the conventional authentication/authorization (AuthN/AuthZ) 1467 model needs to be extended because the relying party is no longer fully trusted-they are 1468 custodians of somebody else's data. Data is potentially aggregated from multiple resource 1469 providers. 1470 One approach is to extend the claims-based methods of SAML to add security and o 1471 privacy guarantees. 1472 • Additional XACML Concepts 1473 XACML introduces additional concepts that may be useful for Big Data security. In Big o 1474 Data, parties are not just sharing claims, but also sharing policies about what is 1475 authorized. There is a policy access point at every data ownership and authoring location, 1476 and a policy enforcement point at the data access. A policy enforcement point calls a 1477 designated policy decision point for an auditable decision. In this way, the usual meaning 1478 of non-repudiation and trusted third parties is extended in XACML. Big Data presumes 1479 an abundance of policies, "points," and identity issuers, as well as data: 1480  Policy authoring points 1481  Policy decision points 1482  Policy enforcement point 1483  Policy access points 1484 4.2.3 DATA GOVERNANCE 1485 However large and complex Big Data becomes in terms of data volume, velocity, variety, and variability, 1486 Big Data governance will, in some important conceptual and actual dimensions, be much larger. Data 1487 governance refers to administering, or formalizing, discipline (e.g., behavior patterns) around the 1488 management of data. Big Data without Big Data governance may become less useful to its stakeholders. 1489 To stimulate positive change, data governance will need to persist across the data life cycle at rest, in 1490 motion, in incomplete stages, and transactions while serving the security and privacy of the young, the 1491 old, individuals as organizations, and organizations as organizations. It will need to cultivate economic 1492 benefits and innovation but also enable freedom of action and foster individual and public welfare. It will 1493 need to rely on standards governing technologies and practices not fully understood while integrating the 1494 human element. Big Data governance will require new perspectives yet accept the slowness or inefficacy 1495 of some current techniques. Some data governance considerations are listed below. 1496 Big Data Apps to Support Governance: The development of new applications employing Big Data 1497 principles and designed to enhance governance may be among the most useful Big Data applications on 1498 the horizon. 1499 • Encryption and key management 1500 At rest o 1501 In memory o 1502 In transit o 36 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 1503 • Isolation/containerization 1504 • Storage security 1505 • Data loss prevention and detection 1506 • Web services gateway 1507 • Data transformation 1508 Aggregated data management o 1509 Authenticated computations o 1510 Computations on encrypted data o 1511 • Data life cycle management 1512 Disposition, migration, and retention policies o 1513 PII microdata as “hazardous”  o 1514 De-identification and anonymization o 1515 Re-identification risk management o 1516 • End-point validation 1517 • DRM 1518 • Trust 1519 • Openness 1520 • Fairness and information ethics  1521 4.2.3.1 Compliance, Governance and Management as Code 1522 The Fedramp-related initiative Open Control seizes upon the connection between increased use of 1523 automation for all facets of today’s systems. Its proponents argue for the following progression: 1524 • Software as code, 1525 • Tests as code, 1526 • Infrastructure as code, and 1527 • Compliance as code. 1528 Just as software-defined network (SDN) can be seen as a way to create and manage infrastructure with 1529 reduced manual intervention, Open Control was used by GSA’s lean startup-influenced digital services 1530 agency 18F to facilitate continuous authorization. Continuous authorization is seen as logically similar to 1531 agile’s continuous deployment. The 18F team employs YAML to implement a schema which is publicly 1532 available on GitHub. 1533 4.2.4 INFRASTRUCTURE MANAGEMENT 1534 Infrastructure management involves security and privacy considerations related to hardware operation and 1535 maintenance. Some topics related to infrastructure management are listed below. 1536 • Threat and vulnerability management 1537 DoS-resistant cryptographic protocols o 1538 • Monitoring and alerting 1539 As noted in the NIST Critical Infrastructure Cybersecurity Framework, Big Data affords o 1540 new opportunities for large-scale security intelligence, complex event fusion, analytics, 1541 and monitoring. 1542 • Mitigation 1543 Breach mitigation planning for Big Data may be qualitatively or quantitatively different. o 1544 • Configuration Management 1545 Configuration management is one aspect of preserving system and data integrity. It can o 1546 include the following: 1547 Patch management o 37 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 1548 Upgrades o 1549 • Logging 1550 Big Data must produce and manage more logs of greater diversity and velocity. For o 1551 example, profiling and statistical sampling may be required on an ongoing basis. 1552 • Malware surveillance and remediation 1553 This is a well-understood domain, but Big Data can cross traditional system ownership o 1554 boundaries. Review of NIST’s “Identify, Protect, Detect, Respond, and Recover” 1555 framework may uncover planning unique to Big Data. 1556 • Network boundary control 1557 Establishes a data-agnostic connection for a secure channel o 1558  Shared services network architecture, such as those specified as “secure channel 1559 use cases and requirements” in the ETSI TS 102 484 Smart Card specifications 1560 . 1561  Zones/cloud network design (including connectivity) 1562 • Resilience, Redundancy, and Recovery 1563 Resilience o 1564  The security apparatus for a Big Data system may be comparatively fragile in 1565 comparison to other systems. A given security and privacy fabric may be 1566 required to consider this. Resilience demands are domain-specific, but could 1567 entail geometric increases in Big Data system scale. 1568 Redundancy o 1569  Redundancy within Big Data systems presents challenges at different levels. 1570 Replication to maintain intentional redundancy within a Big Data system takes 1571 place at one software level. At another level, entirely redundant systems designed 1572 to support failover, resilience or reduced data center latency may be more 1573 difficult due to velocity, volume, or other aspects of Big Data. 1574 Recovery o 1575  Recovery for Big Data security failures may require considerable advance 1576 provisioning beyond that required for small data. Response planning and 1577 communications with users may be on a similarly large scale. 1578 4.2.5 RISK AND ACCOUNTABILITY 1579 Risk and accountability encompass the following topics: 1580 • Accountability 1581 Information, process, and role behavior accountability can be achieved through various o 1582 means, including: 1583  Transparency portals and inspection points 1584  Forward- and reverse-provenance inspection 1585 • Compliance 1586 Big Data compliance spans multiple aspects of the security and privacy taxonomy, o 1587 including privacy, reporting, and nation-specific law 1588 • Forensics 1589 Forensics techniques enabled by Big Data o 1590 Forensics used in Big Data security failure scenarios o 1591 • Business risk level 1592 Big Data risk assessments should be mapped to each element of the taxonomy . o 1593 Business risk models can incorporate privacy considerations. 38 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 1594 4.3 ROLES RELATED TO SECURITY AND PRIVACY TOPICS 1595 Discussions of Big Data security and privacy should be accessible to a diverse audience both within an 1596 organization and across supply chains. Access should include individuals who specialize in cryptography, 1597 security, compliance, or IT. In addition, the ideal audience includes domain experts and organization 1598 decision makers who understand the costs and impact of these controls. Ideally, written guidelines setting 1599 forth policy and compliance for Big Data security and privacy would be prefaced by additional 1600 information that would help specialists find the content relevant to them. The specialists could then 1601 provide feedback on those sections. Organizations typically contain diverse roles and workflows for 1602 participating in a Big Data ecosystem. Therefore, this document proposes a pattern to help identify the 1603 axis of an individual’s roles and responsibilities, as well as classify the security controls in a similar 1604 manner to make these more accessible to each class. 1605 4.3.1 INFRASTRUCTURE MANAGEMENT 1606 Typically, the individual role axis contains individuals and groups who are responsible for technical 1607 reviews before their organization is on-boarded in a data ecosystem. After the onboarding, they are 1608 usually responsible for addressing defects and security issues. 1609 When infrastructure technology personnel work across organizational boundaries, they accommodate 1610 diverse technologies, infrastructures, and workflows and the integration of these three elements. For Big 1611 Data security, these aspects typically include topics in identity, authorization, access control, and log 1612 aggregation. This is not an exhaustive list. 1613 Their backgrounds and practices, as well as the terminologies they use, tend to be uniform, and they face 1614 similar pressures within their organizations to constantly do more with less. Save money is the underlying 1615 theme, and infrastructure technology usually faces pressure when problems arise. 1616 4.3.2 GOVERNANCE, RISK MANAGEMENT, AND COMPLIANCE 1617 Data governance is a fundamental element in the management of data and data systems. Data governance 1618 refers to administering, or formalizing, discipline (e.g., behavior patterns) around the management of 1619 data. Risk management involves the evaluation of positive and negative risks resulting from the handling 1620 of Big Data. Compliance encompasses adherence to laws, regulations, protocols, and other guiding rules 1621 for operations related to Big Data. Typically, GRC is a function that draws participation from multiple 1622 areas of the organization, such as legal, human resources (HR), IT, and compliance. In some industries 1623 and agencies, there may be a strong focus on compliance, often in isolation from disciplines. 1624 Professionals working in GRC tend to have similar backgrounds, share a common terminology, and 1625 employ similar processes and workflows, which typically influence other organizations within the 1626 corresponding vertical market or sector. 1627 Within an organization, GRC professionals aim to protect the organization from negative outcomes that 1628 might arise from loss of intellectual property, liability due to actions by individuals within the 1629 organization, and compliance risks specific to its vertical market. 1630 In larger enterprises and government agencies, GRC professionals are usually assigned to legal, 1631 marketing, or accounting departments or staff positions connected to the CIO. Internal and external 1632 auditors are often involved. 1633 Smaller organizations may create, own, or process Big Data, yet may not have GRC systems and 1634 practices in place, due to the newness of the Big Data scenario to the organization, a lack of resources, or 1635 other factors specific to small organizations. Prior to Big Data, GRC roles in smaller organizations 1636 received little attention. 39 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 1637 A one-person company can easily construct a Big Data application and inherit numerous unanticipated 1638 related GRC responsibilities. This is a new GRC scenario in which Big Data operates. 1639 A security and privacy fabric entails additional data and process workflow in support of GRC, which is 1640 most likely under the control of the System Orchestrator component of the NBDRA, as explained in 1641 Section 5. 1642 4.3.3 INFORMATION WORKER 1643 Information workers are individuals and groups who work on the generation, transformation, and 1644 consumption of content. Due to the nascent nature of the technologies and related businesses in which 1645 they work, they tend to use common terms at a technical level within a specialty. However, their roles and 1646 responsibilities and the related workflows do not always align across organizational boundaries. For 1647 example, a data scientist has deep specialization in the content and its transformation, but may not focus 1648 on security or privacy until it adds effort, cost, risk, or compliance responsibilities to the process of 1649 accessing domain-specific data or analytical tools. 1650 Information workers may serve as data curators. Some may be research librarians, operate in quality 1651 management roles, or be involved in information management roles such as content editing, search 1652 indexing, or performing forensic duties as part of legal proceedings. 1653 Information workers are exposed to a great number of products and services. They are under pressure 1654 from their organizations to deliver concrete business value from these new Big Data analytics capabilities 1655 by monetizing available data, monetizing the capability to transform data by becoming a service provider, 1656 or optimizing and enhancing business by consuming third-party data. 1657 4.4 RELATION OF ROLES TO THE SECURITY AND PRIVACY 1658 CONCEPTUAL TAXONOMY 1659 The next sections cover the four components of the conceptual taxonomy: data confidentiality, data 1660 provenance, system health, and public policy, social and cross-organizational topics. To leverage these 1661 three axes and to facilitate collaboration and education, a stakeholder can be defined as an individual or 1662 group within an organization who is directly affected by the selection and deployment of a Big Data 1663 solution. A ratifier is defined as an individual or group within an organization who is tasked with 1664 assessing the candidate solution before it is selected and deployed. For example, a third-party security 1665 consultant may be deployed by an organization as a ratifier, and an internal security specialist with an 1666 organization’s IT department might serve as both a ratifier and a stakeholder if tasked with ongoing 1667 monitoring, maintenance, and audits of the security. 1668 The upcoming sections also explore potential gaps that would be of interest to the anticipated 1669 stakeholders and ratifiers who reside on these three new conceptual axes. 1670 4.4.1 DATA CONFIDENTIALITY 1671 IT specialists who address cryptography should understand the relevant definitions, threat models, 1672 assumptions, security guarantees, and core algorithms and protocols. These individuals will likely be 1673 ratifiers, rather than stakeholders. IT specialists who address end-to-end security should have an 1674 abbreviated view of the cryptography, as well as a deep understanding of how the cryptography would be 1675 integrated into their existing security infrastructures and controls. 1676 GRC should reconcile the vertical requirements (e.g., HIPAA requirements related to EHRs) and the 1677 assessments by the ratifiers that address cryptography and security. GRC managers would in turn be 1678 ratifiers to communicate their interpretation of the needs of their vertical. Persons in these roles also serve 1679 as stakeholders due to their participation in internal and external audits and other workflows. 40 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 1680 4.4.2 PROVENANCE 1681 Provenance (or veracity) is related in some ways to data privacy, but it might introduce information 1682 workers as ratifiers because businesses may need to protect their intellectual property from direct leakage 1683 or from indirect exposure during subsequent Big Data analytics. Information workers would need to work 1684 with the ratifiers from cryptography and security to convey the business need, as well as understand how 1685 the available controls may apply. 1686 Similarly, when an organization is obtaining and consuming data, information workers may need to 1687 confirm that the data provenance guarantees some degree of information integrity and address incorrect, 1688 fabricated, or cloned data before it is presented to an organization. 1689 Additional risks to an organization could arise if one of its data suppliers does not demonstrate the 1690 appropriate degree of care in filtering or labeling its data. As noted in the U.S. Department of Health and 1691 Human Services (DHHS) press release announcing the HIPAA final omnibus rule: 1692 “The changes announced today expand many of the requirements to business 1693 associates of these entities that receive protected health information, such as 1694 contractors and subcontractors. Some of the largest breaches reported to 1695 HHS have involved business associates. Penalties are increased for 1696 noncompliance based on the level of negligence with a maximum penalty of 1697 $1.5 million per violation .” 1698 Organizations using or sharing health data among ecosystem partners, including mobile apps and SaaS 1699 providers, may need to verify that the proper legal agreements are in place. Compliance may be needed to 1700 ensure data veracity and provenance . 1701 4.4.3 SYSTEM HEALTH MANAGEMENT 1702 System health is typically the domain of IT, and IT managers will be ratifiers and stakeholders of 1703 technologies, protocols, and products that are used for system health. IT managers will also design how 1704 the responsibilities to maintain system health would be shared across the organizations that provide data, 1705 analytics, or services—an area commonly known as operations support systems (OSS) in the telecom 1706 industry, which has significant experience in syndication of services. 1707 Security and cryptography specialists should scrutinize the system health to spot potential gaps in the 1708 operational architectures. The likelihood of gaps increases when a system infrastructure includes diverse 1709 technologies and products. 1710 System health is an umbrella concept that emerges at the intersection of information worker and 1711 infrastructure management. As with human health, monitoring nominal conditions for Big Data systems 1712 may produce Big Data volume and velocity—two of the Big Data characteristics. Following the human 1713 health analogy, some of those potential signals reflect defensive measures such as white cell count. Others 1714 could reflect compromised health, such as high blood pressure. Similarly, Big Data systems may employ 1715 applications like SIEM or Big Data analytics more generally to monitor system health. 1716 Volume, velocity, variety, and variability of Big Data systems health make it different from small data 1717 system health. Health tools and design patterns for existing systems are likely insufficient to handle Big 1718 Data—including Big Data security and privacy. At least one commercial web services provider has 1719 reported that its internal accounting and systems management tool uses more resources than any other 1720 single application. The volume of system events and the complexity of event interactions is a challenge 1721 that demands Big Data solutions to defend Big Data systems. Managing systems health—including 1722 security—will require roles defined as much by the tools needed to manage as by the organizational 1723 context. Stated differently, Big Data is transforming the role of the Computer Security Officer. 41 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 1724 For example, one aspect motivated by the DevOps movement (i.e., move toward blending tasks 1725 performed by applications development and systems operations teams) is the rapid launch, 1726 reconfiguration, redeployment, and distribution of Big Data systems. Tracking intended vs. accidental or 1727 malicious configuration changes is increasingly a Big Data challenge. 1728 4.4.4 PUBLIC POLICY, SOCIAL, AND CROSS-ORGANIZATIONAL TOPICS 1729 Roles in setting public policy related to security and privacy are established in the United States by 1730 federal agencies such as the FTC, the U.S. Food and Drug Administration (FDA), or the DHHS Office of 1731 National Coordinator. Examples of agency responsibilities or oversight are: 1732 • DHS is responsible for aspects of domestic U.S. computer security through the activities of US- 1733 CERT (U.S. Computer Emergency Readiness Team). US-CERT describes its role as “[leading] 1734 efforts to improve the Nation's cybersecurity posture, coordinate cyber information sharing, and 1735 proactively manage cyber risks to the Nation while protecting the constitutional rights of 1736 Americans .” 1737 • The Federal Trade Commission offers guidance on compliance with the Children’s Online 1738 Privacy Protection Act (COPPA) via a hot line (CoppaHotLine@ftc.gov), with website privacy 1739 policies, and compliance with the Fair Credit Reporting Act. The Gramm-Leach-Bliley Act, Red 1740 Flags Rule, and the US-EU Safe Harbor Framework . 1741 • The DHHS Office of National Coordinator offers guidance and regulations regarding health 1742 information privacy, security and health records, including such tools as a Security Risk 1743 Assessment, HIPAA rule enforcement, and the embedding of HIPAA privacy and security 1744 requirements into Medicare and Medicaid EHR Meaningful Use requirements . 1745 • Increased use of EHRs and smart medical devices has resulted in new privacy and security 1746 initiatives at the FDA related to product safety, such as the Cybersecurity of Medical Devices as 1747 related to the FDA’s Medical Product Safety Network (MedSun) . 1748 Social roles include the influence of nongovernmental organizations, interest groups, professional 1749 organizations, and standards development organizations. Cross-organizational roles include design 1750 patterns employed across or within certain industries such as pharmaceuticals, logistics, manufacturing, 1751 distribution to facilitate data sharing, curation, and even orchestration. Big Data frameworks will impact, 1752 and are impacted by cross-organizational considerations, possibly industry-by-industry. Further work to 1753 develop these concepts for Big Data is anticipated by the Subgroup. 1754 4.5 ADDITIONAL TAXONOMY TOPICS 1755 Additional topics have been identified but not scrutinized, and it is not yet clear whether these would fold 1756 into existing categories or if new categories for security and privacy concerns would need to be identified 1757 and developed. Some candidate topics are briefly described below. 1758 4.5.1 PROVISIONING, METERING, AND BILLING 1759 Provisioning, metering, and billing are elements in typically commercial systems used to manage assets, 1760 meter their use, and invoice clients for that usage. Commercial pipelines for Big Data can be constructed 1761 and monetized more readily if these systems are agile in offering services, metering access suitably, and 1762 integrating with billing systems. While this process can be manual for a small number of participants, it 1763 can become complex very quickly when there are many suppliers, consumers, and service providers. 1764 Information workers and IT professionals who are involved with existing business processes would be 1765 candidate ratifiers and stakeholders. Assuring privacy and security of provisioning and metering data may 1766 or may not have already been designed into these systems. The scope of metering and billing data will 1767 explode, so potential uses and risks have likely not been fully explored. 42 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 1768 There are both veracity and validity concerns with these systems. GRC considerations, such as audit and 1769 recovery, may overlap with provisioning and metering. 1770 4.5.2 DATA SYNDICATION 1771 A feature of Big Data systems is that data is bought and sold as a valuable asset. Free search engines rely 1772 on users giving up information about their search terms on a Big Data scale. Search engines and social 1773 media sites can choose to repackage and syndicate that information for use by others for a fee. 1774 Similar to service syndication, a data ecosystem is most valuable if any participant can have multiple 1775 roles, which could include supplying, transforming, or consuming Big Data. Therefore, a need exists to 1776 consider what types of data syndication models should be enabled; again, information workers and IT 1777 professionals are candidate ratifiers and stakeholders. For some domains, more complex models may be 1778 required to accommodate PII, provenance, and governance. Syndication involves transfer of risk and 1779 responsibility for security and privacy. 1780 4.5.3 ACM TAXONOMY 1781 Where possible, this document uses the terminology adopted by the ACM Computing Classification 1782 System , . The ACM 2012 CCS is accessible online  and can be represented in Simple 1783 Knowledge Organization System (SKOS) format . A snippet of the Security and Privacy Category 1784 from the 2012 CSS is presented below. 1785 • Database and storage security 1786 Data anonymization and sanitation o 1787 Management and querying of encrypted data o 1788 Information accountability and usage control o 1789 Database activity monitoring o 1790 • Software and application security 1791 Software security engineering o 1792 Web application security o 1793 Social network security and privacy o 1794 Domain-specific security and privacy architectures o 1795 Software reverse engineering o 1796 • Human and societal aspects of security and privacy 1797 Economics of security and privacy o 1798 Social aspects of security and privacy o 1799 Privacy protections o 1800 Usability in security and privacy o 1801 A systematic taxonomy has several benefits for Big Data security and privacy. In addition to tracking new 1802 research and guidelines (e.g., software and application security snippet from the list above), standardized 1803 terminology can, in some limited contexts, allow for automated reasoning. Automated reasoning, based 1804 on cybersecurity ontologies, for example, could enable fine-grained alerts, which could elevate as the 1805 need arises, while minimizing false positives and less significant events. One approach extended a 1806 malware ontology to include elements of upper ontologies, which can add utility-domain aspects such as 1807 temporal, geospatial, person, events, and network operations . Utility domains form part of the 1808 NBD-SPSL. 1809 Other taxonomies may be useful. For example, the NISTIR 8085 draft Forming Common Platform 1810 Enumeration (CPE) Names from Software Identification (SWID) Tags is designed to “support automated 1811 and accurate software asset management , p. iii. 43 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 1812 4.6 WHY SECURITY ONTOLOGIES MATTER FOR BIG DATA 1813 Suppose an engineer inherits software and/or data from a third party. Whether it’s within the organization, 1814 or across organizations, it’s important to know what security components are present in the inherited 1815 system. Yet the terminology and underlying components are rarely described in terms that are readily 1816 exchanged between practitioners, much less between analysts, SMEs, testers, and users. However, 1817 standardizing the terminology is insufficient. 1818 As noted in the literature , systematic use of ontologies could enable information security tools to 1819 process standardized information streams from third parties, using methods such as the Security Content 1820 Automation Protocol (SCAP). This model could enable automated reasoning to address potential breaches 1821 closer to real time, or which have indirect effects on networks or applications which require a mixture of 1822 human and machine cognition. 1823 While SCAP is mainly used to facilitate alignment between configuration settings and NIST SP 800-53, 1824 this approach was not designed for the velocity or volume of Big Data security information. Attempts to 1825 integrate real-time logs with internal and external SCAP feeds are likely to encounter scalability 1826 challenges, numerous false positives, and crippling information overload from the human computer 1827 interaction (HCI) perspective. 1828 DAEDALUS-VIZ was a research project whose architects felt it necessary to build a “novel real-time 3D 1829 visualization engine called DAEDALUS-VIZ that enables operators to grasp visually and in real time a 1830 complete overview of alert circumstances .” Scaling these projects to Big Data dimensions would 1831 tax even the most gifted security analysts. 1832 SIEM and related tools are today relatively unsophisticated in their reasoning capabilities. Big Data 1833 demands a more sophisticated framework for security and privacy frameworks than are currently 1834 available. As Obrst et al. explain, 1835 “Events are entities that describe the occurrences of actions and changes in the real 1836 world. Situations represent histories of action occurrences. In this context at least, 1837 situations are not equivalent to states. Events and situations are dynamic and challenging 1838 to model in knowledge representation systems. As in the temporal and spatial domains, 1839 logic formalisms have been created for representing and reasoning about events and 1840 situations. These are the event calculus and situation calculus. Both calculi employ the 1841 notion of fluents. A fluent is a condition that can change over time. The main elements of 1842 the event calculus are fluents and actions, and for the situation calculus they are fluents, 1843 actions and situations .” 1844 An arguably chronic weakness in conventional databases is their ability to manage point in time 1845 representations. Big Data applications allow for unstructured repositories but do not themselves solve the 1846 problem of integrating temporal and spatial elements. If network topologies are analogs or even literal 1847 spatial representations, it is clear that reasoning about cyber events and situations will require ontological 1848 discipline and Big Data. While visualization is often seen as the cure-all for this, Shabtai et al.  1849 referred to the real underlying need as “knowledge-based interpretation, summarization, query, 1850 visualization and interactive exploration of time-oriented data.” Among other requirements, the 1851 researchers cite “a domain-specific knowledge base” as an essential component. 1852 As shown in the proposed NBD-SPSL (Appendix A), ontologies that represent knowledge of 1853 applications, domains and utility (so-called middle and upper ontologies) are likely to comprise the most 1854 effective means of processing cybersecurity Big Data. Cloud-centric work by Takahashi et al.  1855 demonstrated the feasibility of the approach. 1856 Additional ontologies to support privacy will be needed for some Big Data systems. While it did not 1857 result in ontologies, at least one project took a model-based systems engineering (MBSE) approach to 44 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 1858 produce “a model of private information flow and a graphical notation for visualizing this flow are 1859 proposed. An application example of using the notation to identify privacy vulnerabilities is given .” 1860 45 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 5 BIG DATA REFERENCE 1861 ARCHITECTURE AND SECURITY AND 1862 PRIVACY FABRIC 1863 1864 Security and privacy considerations are a fundamental aspect of the NBDRA. Using the material gathered 1865 for this volume and extensive brainstorming among the NBD-PWG Security and Privacy Subgroup 1866 members and others, the proposed Security and Privacy Fabric was developed.d This is geometrically 1867 depicted in Figure 6 by the Security and Privacy Fabric surrounding the five main components, since all 1868 components are affected by security and privacy considerations. The role of security and privacy is 1869 correctly depicted in relation to the components but does not expand into finer details, which may be best 1870 relegated to a more detailed security and privacy reference architecture. The Data Provider and Data 1871 Consumer are included in the Security and Privacy Fabric since, at the least, they should agree on the 1872 security protocols and mechanisms in place. The Security and Privacy Fabric is an approximate 1873 representation that alludes to the intricate interconnected nature and ubiquity of security and privacy 1874 throughout the NBDRA. The NBDIF: Volume 6, Reference Architecture document discusses in detail the 1875 other components of the NBDRA. d The concept of a fabric for security and privacy has precedent in the hardware world, where the notion of a fabric of interconnected nodes in a distributed computing environment was introduced. Computing fabrics were invoked as part of cloud and grid computing, as well as for commercial offerings from both hardware and software manufacturers. 46 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 1876 1877 Figure 6: NIST Big Data Reference Architecture 1878 At this time, explanations as to how the proposed security and privacy fabric concept is implemented 1879 across each NBDRA component are cursory—more suggestive than prescriptive. However, it is believed 1880 that, in time, a template will evolve and form a sound basis for more detailed iterations. 1881 Figure 6 introduces two new concepts that are particularly important to security and privacy 1882 considerations: information value chain and IT value chain. 1883 • Information value chain: While it does not apply to all domains, there may be an implied 1884 processing progression through which information value is increased, decreased, refined, defined, 1885 or otherwise transformed. Application of provenance preservation and other security mechanisms 1886 at each stage may be conditioned by the state-specific contributions to information value. 1887 • IT value chain: Platform-specific considerations apply to Big Data systems when scaled-up or 1888 scaled-out. In the process of scaling, specific security, privacy, or GRC mechanism or practices 1889 may need to be invoked. 1890 5.1 RELATION OF THE BIG DATA SECURITY OPERATIONAL 1891 TAXONOMY TO THE NBDRA 1892 Table 1 represents a preliminary mapping of the operational taxonomy to the NBDRA components. The 1893 topics and activities from the operational taxonomy elements (Section 4.2) have been allocated to a 47 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 1894 NBDRA component under the Activities column in Table 1. The description column provides additional 1895 information about the security and privacy aspects of each NBDRA component. 1896 Table 1: Draft Security Operational Taxonomy Mapping to the NBDRA Components Activities Description System Orchestrator • Policy Enforcement Several security functions have been mapped to the • Security Metadata Model System Orchestrator block, as they require • Data Loss Prevention, Detection architectural level decisions and awareness. Aspects of • Data Life Cycle Management these functionalities are strongly related to the Security • Threat and Vulnerability Management Fabric and thus touch the entire architecture at various points in different forms of operational details. • Mitigation Such security functions include nation-specific • Configuration Management compliance requirements, vastly expanded demand for • Monitoring, Alerting forensics, and domain-specific, privacy-aware business • Malware Surveillance and Remediation risk models. • Resiliency, Redundancy, and Recovery • Accountability • Compliance • Forensics • Business Risk Model Data Provider • Device, User, Asset, Services, Applications Data Providers are subject to guaranteeing authenticity Registration of data, and in turn require that sensitive, copyrighted, • Application Layer Identity or valuable data be adequately protected. This leads to • End User Layer Identity Management operational aspects of entity registration and identity • End Point Input Validation ecosystems. • Digital Rights Management • Monitoring, Alerting Data Consumer • Application Layer Identity Data Consumers exhibit a duality with Data Providers • End User Layer Identity Management in terms of obligations and requirements—only they • Web Services Gateway face the access/visualization aspects of the Big Data • Digital Rights Management Application Provider. • Monitoring, Alerting Big Data Application Provider • Application Layer Identity The Big Data Application Provider interfaces between • Web Services Gateway the Data Provider and Data Consumer. It takes part in • Data Transformation all the secure interface protocols with these blocks as • Digital Rights Management well as maintains secure interaction with the Big Data • Monitoring, Alerting Framework Provider. Big Data Framework Provider • Virtualization Layer Identity The Big Data Framework Provider is responsible for • Identity Provider the security of data/computations for a significant • Encryption and Key Management portion of the life cycle of the data. This includes • Isolation/Containerization security of data at rest through encryption and access • Storage Security control; security of computations via isolation/virtualization; and security of communication • Network Boundary Control with the Big Data Application Provider. • Monitoring, Alerting 48 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 1897 5.2 SECURITY AND PRIVACY FABRIC IN THE NBDRA 1898 Figure 7 provides an overview of several security and privacy topics with respect to some key NBDRA 1899 components and interfaces. The figure represents a beginning characterization of the interwoven nature of 1900 the Security and Privacy Fabric with the NBDRA components. It is not anticipated that Figure 6 will be 1901 further developed. 1902 Figure 7: Notional Security and Privacy Fabric Overlay to the NBDRA 1903 The groups and interfaces depicted in Figure 7 are described below. 1904 A. INTERFACE BETWEEN DATA PROVIDERS  BIG DATA APPLICATION PROVIDER 1905 Data coming in from data providers may have to be validated for integrity and authenticity. Incoming 1906 traffic may be maliciously used for launching DoS attacks or for exploiting software vulnerabilities on 1907 premise. Therefore, real-time security monitoring is useful. Data discovery and classification should be 1908 performed in a manner that respects privacy. 1909 B. INTERFACE BETWEEN BIG DATA APPLICATION PROVIDER DATA CONSUMER 1910 Data, including aggregate results delivered to data consumers, must preserve privacy. Data accessed by 1911 third parties or other entities should follow legal regulations such as HIPAA. Concerns include access to 1912 sensitive data by the government. 1913 C. INTERFACE BETWEEN APPLICATION PROVIDER  BIG DATA FRAMEWORK 1914 PROVIDER 1915 Data can be stored and retrieved under encryption. Access control policies should be in place to assure 1916 that data is only accessed at the required granularity with proper credentials. Sophisticated encryption 1917 techniques can allow applications to have rich policy-based access to the data as well as enable searching, 1918 filtering on the encrypted data, and computations on the underlying plaintext. 49 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 1919 D. INTERNAL INTERFACE WITHIN THE BIG DATA FRAMEWORK PROVIDER 1920 Data at rest and transaction logs should be kept secured. Key management is essential to control access 1921 and keep track of keys. Non-relational databases should have a layer of security measures. Data 1922 provenance is essential to having proper context for security and function of the data at every stage. DoS 1923 attacks should be mitigated to assure availability of the data. Certifications (not self-signed) should be 1924 used to mitigate man-in the-middle attacks. 1925 E. SYSTEM ORCHESTRATOR 1926 A System Orchestrator may play a critical role in identifying, managing, auditing, and sequencing Big 1927 Data processes across the components. For example, a workflow that moves data from a collection stage 1928 to further preparation may implement aspects of security or privacy. 1929 System Orchestrators present an additional attractive attack surface for adversaries. System Orchestrators 1930 often require permanent or transitory elevated permissions. System Orchestrators present opportunities to 1931 implement security mechanisms, monitor provenance, access systems management tools, provide audit 1932 points, and inadvertently subjugate privacy or other information assurance measures. 1933 Appendix E contains mapping of Security and Privacy use cases to the fabric overlay described in Figure 1934 7. 1935 5.3 SECURITY AND PRIVACY FABRIC PRINCIPLES 1936 Big Data security and privacy should leverage existing standards and practices. In the privacy arena, a 1937 systems approach that considers privacy throughout the process is a useful guideline to consider when 1938 adapting security and privacy practices to Big Data scenarios. The OASIS Privacy Management 1939 Reference Model (PMRM), consisting of seven foundational principles, provides appropriate basic 1940 guidance for Big System architects. When working with any personal data, privacy should be an integral 1941 element in the design of a Big Data system. Appendix B introduces a comprehensive list of additional 1942 security and privacy concepts developed in selected existing standards. There is an intentional emphasis 1943 on privacy concepts, reflecting public and enterprise concerns about Big Data security and privacy. 1944 Although not all concepts are fully addressed in the current release of this volume, readers may identify 1945 particular notions which can focus attention for particular Big Data security and privacy implementations 1946 or domain-specific scenarios. 1947 Other privacy engineering frameworks, including the model presented in NISTIR 8062 are also under 1948 consideration , –. 1949 Related principles include identity management frameworks such as proposed in the National Strategy for 1950 Trusted Identities in Cyberspace (NSTIC)  and considered in the NIST Cloud Computing Security 1951 Reference Architecture . 1952 Big Data frameworks can also be used for strengthening security. Big Data analytics can be used for 1953 detecting privacy breaches through security intelligence, event detection, and forensics. 1954 5.4 SECURITY AND PRIVACY APPROACHES IN ANALYTICS 1955 The introduction to the IEEE P7003 working group notes that “individuals or organizations creating 1956 algorithms, largely in regard to autonomous or intelligent systems, [need] certification-oriented 1957 methodologies to provide clearly articulated accountability and clarity around how algorithms are 1958 targeting, assessing, and influencing the users and stakeholders of said algorithm .” 1959 (https://standards.ieee.org/develop/project/7003.html) 1960 Big Data analytical and machine learning capabilities are central goals of many Big Data systems, yet not 1961 all address the associated security and privacy issues surrounding them. Analysts and the consumers of 50 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 1962 conclusions reached by Big Data systems require guidance to help interpret and manage visualizations 1963 such as dashboards and narratives derived from Big Data systems. 1964 THE CASE OF CRISP-DM 1965 Despite its widespread adoption for Big Data analytics, CRISP-DM has been criticized for its omission of 1966 domain-specific processes. For example, Li, et al.  point out that even as Big Data has taken hold in 1967 hospital information systems, “There are [only] a few known attempts to provide a specialized [CRISP- 1968 DM] methodology or process model for applications in the medical domain …” (p. 73). 1969 One of the few cited attempts provides extensions for CRISP-DM, but domain specificity is rare . A 1970 result of this lightweight coverage for domain-specific granularity is potentially weak coverage for Big 1971 Data security and privacy concerns that emerge from the specifics of that system. 1972 In U.S. healthcare, disclosure of health information associated with HIV/AIDS, alcohol use, or social 1973 status is potentially damaging to patients and can put caregivers and analysts at risk, yet CRISP-DM 1974 models may not take these issues into account. 1975 Securing intellectual property, reputation, and privacy are concerns for individuals, organizations as well 1976 as governments—though the objectives are sometimes in conflict. Risks associated with loss of 1977 algorithmic security and lack of transparency are challenges that often are associated with Big Data 1978 systems. 1979 Transparency of such systems affects user performance, as a study by Schaffer et al. demonstrated . 1980 That said, achieving transparency is not a skill that most developers have attained, and for some domains, 1981 transparency has attendant risks that must also be addressed. 1982 5.5 CRYPTOGRAPHIC TECHNOLOGIES FOR DATA 1983 TRANSFORMATIONS 1984 Security and privacy of Big Data systems are enforced by ensuring integrity and confidentiality at the 1985 datum level, as well as architectural awareness at the fabric level. Diversity of ownership, sensitivity, 1986 accuracy, and visibility requirements of individual datum is a defining characteristic of Big Data. This 1987 requires cryptographic encapsulation of the right nature at the right levels. Homomorphic, Functional, and 1988 Attribute-based Encryption are examples of such encapsulation. Data transactions respecting trust 1989 boundaries and relations between interacting entities can be enabled by distributed cryptographic 1990 protocols such as Secure MPC and Blockchain. Many of the expensive cryptographic operations can be 1991 substituted by hardware primitives with circumscribed roots of trust, but one must be aware that there are 1992 inherent limitations and dangers to such approaches. 1993 5.5.1 CLASSIFICATION 1994 Table 2 provides a classification of cryptographic technologies in terms of their relation to the NBDRA, 1995 the features they support, and the data visibility they enforce. 1996 Table 2: Classification of Cryptographic Technologies Technology Data Provider Application Feature Visibility Provider Homomorphic Encrypts data Stores encrypted Capability to Only at Data Encryption data perform Provider computations 51 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY Technology Data Provider Application Feature Visibility Provider Functional Encrypts data Stores encrypted Capability to Result of allowed Encryption data perform computations visible computations at Application Provider Access Control Encrypts data Stores encrypted No capability to Only for entities Policy-Based data perform which have a secret Encryption computations key satisfying the access control policy Secure Multi- Plaintext data Stores plaintext Collaborative Application Party data computation Providers do not Computation among multiple learn others’ inputs. Application They only learn the Providers jointly computed function. Blockchain Plaintext or Decentralized Immutable Transaction logging encrypted data decentralized in a decentralized, database untrusted environment Hardware Encrypts data Stores encrypted Capability to Controllable primitives for data perform visibility at secure computations. Application Provider. computations Verified execution. 1997 1998 5.5.2 HOMOMORPHIC ENCRYPTION 1999 Scenario: Data Provider has data to be kept confidential. Application Provider is 2000 requested to do computations on the data. Data Provider gets back results from 2001 Application Provider. 2002 Consider that a client wants to send all its sensitive data to a cloud—photos, medical records, financial 2003 records, and so on. She could send everything encrypted, but this wouldn't be of much use if she wanted 2004 the cloud to perform some computations on them, such as calculating the amount she spent on movies last 2005 month. With Fully Homomorphic Encryption (FHE), a cloud can perform any computation on the 2006 underlying plaintext, all while the results are encrypted. The cloud obtains no information about the 2007 plaintext or the results . 2008 Technically, for a cryptographic protocol for computation on encrypted data, the adversary should not be 2009 able to identify the corresponding plaintext data by looking at the ciphertext, even if given the choice of a 2010 correct and an incorrect plaintext. Note that this is a very stringent requirement because the adversary is 2011 able to compute the encryption of arbitrary functions of the encryption of the original data. In fact, a 2012 stronger threat model called chosen ciphertext security for regular encryption does not have a meaningful 2013 counterpart in this context - search to find such a model continues . 2014 In a breakthrough result in 2009 , Gentry constructed the first FHE scheme. Such a scheme allows 2015 one to compute the encryption of arbitrary functions of the underlying plaintext. Earlier results  2016 constructed partially homomorphic encryption schemes. Gentry’s original construction of a FHE scheme 2017 used ideal lattices over a polynomial ring. Although lattice constructions are not terribly inefficient, the 52 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 2018 computational overhead for FHE is still far from practical. Research is ongoing to find simpler 2019 constructions , , efficiency improvements , , and partially homomorphic schemes 2020  that suffice for an interesting class of functions. 2021 5.5.3 FUNCTIONAL ENCRYPTION 2022 Scenario: Data Provider has data to be kept confidential. Application Provider or Data 2023 Consumer are allowed to do only a priori specified class of computations on the data and 2024 see the results. 2025 Consider a system to receive emails encrypted under the owner's public key. However, the owner does 2026 not want to receive spam mails. With plain public key encryption, there is no way to distinguish a 2027 legitimate email ciphertext from a spam ciphertext. However, with recent techniques, one can give a token 2028 to a filter, such that the filter can apply the token to the ciphertext only deducing whether it satisfies the 2029 filtering criteria or not. However, the filter does not get any clue about any other property of the encrypted 2030 message ! 2031 Technically, for a cryptographic protocol for searching and filtering encrypted data, the adversary should 2032 not be able to learn anything about the encrypted data beyond whether the corresponding predicate was 2033 satisfied. Recent research has also succeeded in hiding the search predicate itself so that a malicious entity 2034 learns nothing meaningful about the plaintext or the filtering criteria. 2035 Boneh and Waters  construct a public key system that supports comparison queries, subset queries, 2036 and arbitrary conjunction of such queries. In a recent paper , Cash et al. present the design, analysis, 2037 and implementation of the first sub-linear searchable symmetric encryption (SSE) protocol that supports 2038 conjunctive search and general Boolean queries on symmetrically-encrypted data and that scales to very 2039 large datasets and arbitrarily-structured data including free text search. 2040 While with standard functional encryption, the objective is to compute a function over a single user’s 2041 encrypted input, multi-input functional encryption (MIFE) is a relatively recent cryptographic primitive 2042 which allows restricted function evaluation over independently encrypted values from multiple users. It is 2043 possible to realize this primitive over the broadest class of permitted functions with a basic primitive 2044 called indistinguishability obfuscation, which to this date is prohibitively impractical. However, MIFE for 2045 important practical classes of functions such as vector inner products , equality and approximation 2046 testing and order evaluation are known using practically available tools like elliptic curves and lattices. 2047 5.5.4 ACCESS CONTROL POLICY-BASED ENCRYPTION 2048 Scenario: The Infrastructure Provider is part of an organization which employs many 2049 people in different roles. The requirement is to encrypt data so that only roles with the 2050 right combination of attributes can decrypt the data. 2051 Traditionally access control to data has been enforced by systems—Operating Systems, Virtual 2052 Machines—which restrict access to data, based on some access policy. The data is still in plaintext. There 2053 are at least two problems to the systems paradigm: (1) systems can be hacked, and (2) security of the 2054 same data in transit is a separate concern . 2055 The other approach is to protect the data itself in a cryptographic shell depending on the access policy. 2056 Decryption is only possible by entities allowed by the policy. One might make the argument that keys can 2057 also be hacked. However, this exposes a much smaller attack surface. Although covert side-channel 2058 attacks ,  are possible to extract secret keys, these attacks are far more difficult to mount and 2059 require sanitized environments. Also encrypted data can be moved around, as well as kept at rest, making 2060 its handling uniform. 53 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 2061 Technically, for a cryptographically-enforced access control method using encryption, the adversary 2062 should not be able to identify the corresponding plaintext data by looking at the ciphertext, even if given 2063 the choice of a correct and an incorrect plaintext. This should hold true even if parties excluded by the 2064 access control policy collude among each other and with the adversary. 2065 Identity-based encryption (IBE) and attribute-based encryption (ABE) methods enforce access control 2066 using cryptography. In identity-based systems , plaintext can be encrypted for a given identity, and 2067 the expectation is that only an entity with that identity can decrypt the ciphertext. Any other entity will be 2068 unable to decipher the plaintext, even with collusion. Boneh and Franklin  came up with the first 2069 IBE using pairing-friendly elliptic curves. Since then, there have been numerous efficiency and security 2070 improvements –. 2071 ABE extends this concept to attribute-based access control. Sahai and Waters  presented the first 2072 ABE, in which a user's credentials is represented by a set of string called attributes and the access control 2073 predicate is represented by a formula over these attributes. Subsequent work  expanded the 2074 expressiveness of the predicates and proposed two complementary forms of ABE. In Key-Policy ABE, 2075 attributes are used to annotate the ciphertexts, and formulas over these attributes are ascribed to users' 2076 secret keys. In Ciphertext-Policy ABE, the attributes are used to describe the user's credentials and the 2077 formulas over these credentials are attached to the ciphertext by the encrypting party. The first work to 2078 explicitly address the problem of Ciphertext-Policy Attribute-Based Encryption was by Bethencourt, 2079 Sahai, and Waters , with subsequent improvement by Waters . 2080 As an example of Ciphertext-Policy ABE, consider a hospital with employees who have some possible 2081 combination of four attributes: is a doctor, is a nurse, is an admin, and works in Intensive Care Unit 2082 (ICU). Take for instance a nurse who works in ICU—she will have the attributes is a nurse and works in 2083 ICU, but not the attribute is a doctor. The patient can encrypt his data under his access control policy of 2084 choice, such as, only a doctor OR a nurse who works in ICU can decrypt his data. Only employees who 2085 have the exact attributes necessary can decrypt the data. Even if two employees collude, who together 2086 have a permissible set of attributes, but not individually so, should not be able to decrypt the data. For 2087 example, an admin who works in the ICU and a nurse who doesn’t work in the ICU should not be able to 2088 decrypt data encrypted using the above access control policy. 2089 5.5.5 SECURE MULTI-PARTY COMPUTATIONS 2090 Consider a scenario where a government agency has a list of terrorism suspects and an airline has a list of 2091 passengers. For passenger privacy, the airline does not wish to give the list in the clear to the agency, while 2092 the agency too does not wish to disclose the name of the suspects. However, both the organizations are 2093 interested to know the name of the suspects who are going to travel using the airline. Communicating all 2094 the names in each list is a breach of privacy and clearly more information than required by either. On the 2095 other hand, knowing the intersection is beneficial to both the organizations. 2096 Secure multi-party computations (MPC) are a class of distributed cryptographic protocols which address 2097 the general class of such problems. In an MPC between n entities, each entity has a private input and 2098 there is a joint function that everyone wants to know the value of. In the above scenario, the 2099 private inputs are the respective list of names and the joint function is the se𝑃𝑃t 𝑖𝑖 intersection. The pr𝑥𝑥o𝑖𝑖 tocol 2100 proceeds through comm𝑓𝑓u(n𝑥𝑥i1 c,a…tio,n𝑥𝑥 𝑛𝑛 r)ounds between the entities, in which each message depends on the 2101 entity’s own input, the result of some random coin flips and the transcript of all the previous messages. At 2102 the end of the protocol, the entities are expected to have enough information to compute . 2103 What makes such a protocol tricky to construct is the privacy guarantee it provides, which essentially says 𝑓𝑓 2104 that each entity just learns the value of the function, and nothing else about the input of the other parties. 2105 Of course, given the output of the function, one can narrow down the possibilities for the inputs of the other 2106 parties—but, that is the only additional knowledge that it is allowed to gain. 54 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 2107 Other examples include privacy-preserving collaborative analytics, voting protocols, medical research on 2108 private patient data, and so on. The foundations of MPC were given by Yao , with a long line of 2109 work described in the survey by Saia and Mahdi . This is a very active area of cryptography research 2110 and some practical implementations can be found in the multi-party computation library by Zamani . 2111 5.5.6 BLOCKCHAIN 2112 Bitcoin is a digital asset and a payment system invented by an unidentified programmer, or group of 2113 programmers, under the name of Satoshi Nakamoto [https://bitcoin.org/bitcoin.pdf]. While Bitcoin has 2114 become the most popular cryptocurrency, its core technological innovation, called the blockchain, has the 2115 potential to have a far greater impact. 2116 The evidence of possession of a Bitcoin is given by a digital signature. While the digital signature can be 2117 efficiently verified by using a public key associated with the source entity, the signature can only be 2118 generated by using the secret key corresponding to the public key. Thus, the evidence of possession of a 2119 Bitcoin is just the secret key. 2120 Digital signatures are well studied in the cryptographic literature. However, by itself this does not provide 2121 a fundamental characteristic of money—one should not be able to spend more than one has. A trusted and 2122 centralized database recording and verifying all transactions, such as a bank, is able to provide this 2123 service. However, in a distributed network, where many participating entities may be untrusted, even 2124 malicious, this is a challenging problem. 2125 This is where blockchain comes in. Blockchain is essentially a record of all transactions ever maintained 2126 in a decentralized network in the form of a linked list of blocks. New blocks get added to the blockchain 2127 by entities called miners. To add a new block, a miner has to verify the current blockchain for consistency 2128 and then solve a hard cryptographic challenge, involving both the current state of the blockchain and the 2129 block to be added, and publish the result. When enough blocks are added ahead of a given block 2130 collectively, it becomes extremely hard to unravel it and start a different fork. As a result, once a 2131 transaction is deep enough in the chain, it’s virtually impossible to remove. At a high level, the trust 2132 assumption is that the computing power of malicious entities is collectively less than that of the honest 2133 participants. The miners are incentivized to add new blocks honestly by getting rewarded with bitcoins. 2134 The blockchain provides an abstraction for public ledgers with eventual immutability. Thus, beyond 2135 cryptocurrency, it can also support decentralized record keeping which can be verified and accessed 2136 widely. Examples of such applications can be asset and ownership management, transaction logging for 2137 audit and transparency, bidding for auctions, and contract enforcement. 2138 While the verification mechanism for the Bitcoin blockchain is tailored specifically for Bitcoin 2139 transactions, it can in general be any algorithm such as a complex policy predicate. Recently a number of 2140 such frameworks called Smart Contracts, such as Ethereum, have recently come to the fore. The Linux 2141 Foundation has instituted a public working group called Hyperledger which is building a blockchain core 2142 on which smart contracts, called chain codes, can be deployed. 2143 As specialized blockchain platforms emerge, guidance on blockchain uses and its possible applications in 2144 Big Data (and as Big Data) are needed. The WG is monitoring standards work under way in IEEE P2418 2145 (Standard for the Framework of Blockchain use in IoT). 2146 Another potential Big Data blockchain influence could come from the “Digital Inclusion, Identity, Trust, 2147 and Agency” (DIITA) Industry Connections Program , whose possible initiative outcomes see 2148 distributed ledger (blockchain-like) solutions as facilitating the following broad social aims: 55 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 2149 • Have agency over our data and cyber-identity; 2150 • Provide the capacity to identify ourselves online in a way that protects our privacy, our right to be 2151 forgotten, and our off-line ability to have multiple personas; 2152 • Give a voice to the underserved and vulnerable with the creation of standards that are inclusive of 2153 their needs; 2154 • Encourage distributed ledger technology (e.g., Blockchain) standards that facilitate financial 2155 inclusion and other decentralized data sharing capabilities; and 2156 • Develop a collaborative approach to technology and policy design regarding digital inclusion, 2157 trust, personal data, agency, security, and privacy for all demographics. 2158 5.5.7 HARDWARE SUPPORT FOR SECURE COMPUTATIONS 2159 While sophisticated cryptographic technologies like homomorphic and functional encryption work 2160 directly on encrypted data without decrypting it, currently practical implementations remain out of reach 2161 for most applications. Secure hardware primitives, such as TPM (Trusted Platform Module) and SGX 2162 (Software Guard Extensions), provide a middle ground where the central processing unit (CPU) and a 2163 dedicated portion of the hardware contain private keys and process data after decrypting the ciphertexts 2164 communicated to these components. 2165 The premise is that all communications within a Trusted Computing Base (TCB) is considered sensitive 2166 and is carried out using an isolated and protected segment of memory. Communications to and from the 2167 TCB with external code and memory spaces are always encrypted. This segregation of a trusted zone and 2168 the untrusted environment can be carefully engineered and leveraged to provide higher-level security 2169 guarantees. 2170 Verifiable Confidential Cloud Computing (VC3)  is a recent work which is aimed at trustworthy 2171 data analytics on Hadoop using the SGX primitive. The work addresses the following two objectives in 2172 their implemented framework: 2173 1. Confidentiality and integrity for both code and data (i.e., the guarantee that they are not changed 2174 by attackers and that they remain secret); and 2175 2. Verifiability of execution of the code over the data (i.e., the guarantee that their distributed 2176 computation globally ran to completion and was not tampered with). 2177 VC3’s threat model includes malicious adversaries that may control the whole cloud provider’s software 2178 and hardware infrastructure, except for the SGX-enabled processors. However, DoS attacks, side 2179 channels, and traffic analyses are out of scope. 2180 Advantages: 2181 • Secure code runs competitively fast with respect to native execution of the same code. 2182 • The only entity trusted is the CPU itself. Not even the operating system is trusted. 2183 Disadvantages: 2184 • Secure code execution is susceptible to side-channel leakage like timing, electromagnetic and 2185 power analysis attacks. 2186 • Once secret keys embedded within the CPU are leaked, the hardware is rendered ineffective for 2187 further secure execution. If the leakage is detected, there are revocation mechanisms to invalidate 2188 the public keys for the victim. However, a compromised CPU cannot be re-provisioned with a 2189 fresh key. 56 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 2190 5.5.8 CRYPTOGRAPHIC KEY ROTATION 2191 To limit leakage of sensitive data, cryptographic keys should be refreshed periodically. The period 2192 depends on the security level offered by the scheme (technically, the security parameter), level of 2193 protection given to storing the key, sensitivity of the data being operated on by the key, and the frequency 2194 of usage of the key. 2195 The PCI-DSS (Payment Card Industry Data Security Standard, https://www.pcisecuritystandards.org) 2196 standard lists key rotation as a requirement. To quote, it requires “Cryptographic key changes for keys 2197 that have reached the end of their cryptoperiod (for example, after a defined period of time has passed 2198 and/or after a certain amount of cipher-text has been produced by a given key), as defined by the 2199 associated application vendor or key owner, and based on industry best practices and guidelines (for 2200 example, NIST Special Publication 800-57) .” 2201 NIST Special Publication 800-57  has a very detailed set of recommendations regarding key 2202 management in general, with a comprehensive treatment of key rotation. The recommendations are 2203 intended for a spectrum of roles in an IT environment and apply to a Big Data system orchestrator when 2204 making key management decisions about cryptographic operations to secure the following interfaces and 2205 storage: 2206 • Communication interface between Data Consumers and Application Provider; 2207 • Internal storage of sensitive data in the Framework Provider; 2208 • Communication interface between Application Provider and Framework Provider; and 2209 • Communication interface between Application Provider and Data Consumer. 2210 The recommendations span description of cryptographic algorithms for specific goals, different types of 2211 keys that are needed, states that the keys cycle through, how long the keys need to be retained, and 2212 guidance for audit and accountability. 2213 5.5.9 FEDERAL STANDARD FIPS140-2 ON CRYPTOGRAPHIC SYSTEMS 2214 NIST publication FIPS140-2  describes security requirements for cryptographic modules intended to 2215 handle sensitive data, in four increasing levels of stringency. The levels are intended to cater to the degree 2216 of data sensitivity required by the applications utilizing a given module. The security levels presented in 2217 FIPS 140-2 are as follows: 2218 Security Level 1 is the lowest level which “allows the software and firmware components of a 2219 cryptographic module to be executed on a general-purpose computing system using an unevaluated 2220 operating system. Such implementations may be appropriate for some low-level security applications 2221 when other controls, such as physical security, network security, and administrative procedures are 2222 limited or nonexistent .” (p.1) 2223 “Security Level 2 enhances the physical security mechanisms of a Security Level 1 cryptographic module 2224 by adding the requirement for tamper-evidence, which includes the use of tamper-evident coatings or 2225 seals or for pick-resistant locks on removable covers or doors of the module. Tamper-evident coatings or 2226 seals are placed on a cryptographic module so that the coating or seal must be broken to attain physical 2227 access to the plaintext cryptographic keys and critical security parameters (CSPs) within the module. 2228 Tamper-evident seals or pick-resistant locks are placed on covers or doors to protect against unauthorized 2229 physical access. Security Level 2 requires, at a minimum, role-based authentication in which a 2230 cryptographic module authenticates the authorization of an operator to assume a specific role and perform 2231 a corresponding set of services .” (p. 2) 2232 Security Level 3: “In addition to the tamper-evident physical security mechanisms required at Security 2233 Level 2, Security Level 3 attempts to prevent the intruder from gaining access to CSPs [critical security 2234 parameters] held within the cryptographic module. Physical security mechanisms required at Security 57 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 2235 Level 3 are intended to have a high probability of detecting and responding to attempts at physical access, 2236 use or modification of the cryptographic module. The physical security mechanisms may include the use 2237 of strong enclosures and tamper detection/response circuitry that zeroizes all plaintext CSPs [critical 2238 security parameters] when the removable covers/doors of the cryptographic module are opened. Security 2239 Level 3 requires identity-based authentication mechanisms, enhancing the security provided by the role- 2240 based authentication mechanisms specified for Security Level 2. A cryptographic module authenticates 2241 the identity of an operator and verifies that the identified operator is authorized to assume a specific role 2242 and perform a corresponding set of services .” (p. 2) 2243 “Security Level 4 provides the highest level of security defined in this standard. At this security level, the 2244 physical security mechanisms provide a complete envelope of protection around the cryptographic 2245 module with the intent of detecting and responding to all unauthorized attempts at physical access. 2246 Penetration of the cryptographic module enclosure from any direction has a very high probability of being 2247 detected, resulting in the immediate zeroization of all plaintext CSPs [critical security parameters]. 2248 Security Level 4 cryptographic modules are useful for operation in physically unprotected environments. 2249 Security Level 4 also protects a cryptographic module against a security compromise due to 2250 environmental conditions or fluctuations outside of the module's normal operating ranges for voltage and 2251 temperature. Intentional excursions beyond the normal operating ranges may be used by an attacker to 2252 thwart a cryptographic module's defenses. A cryptographic module is required to either include special 2253 environmental protection features designed to detect fluctuations and zeroize CSPs [critical security 2254 parameters], or to undergo rigorous environmental failure testing to provide a reasonable assurance that 2255 the module will not be affected by fluctuations outside of the normal operating range in a manner that can 2256 compromise the security of the module .” (p. 3) 2257 These Security Levels provide a spectrum of local assurance of data protection. A consumer of these 2258 systems must remain aware that even Security Level 4 is not sufficient to provide security and privacy of 2259 sensitive data, unless the complete architecture that handles the data in consideration is analyzed with 2260 precise security and privacy guarantees that are intended. 2261 5.6 RISK MANAGEMENT 2262 To manage risk, NIST 800-39 recommends organizing risk across “three tiers of organization, 2263 mission/business processes, and information systems .” To some extent, this risk framework 2264 assumes an organizational monoculture that may not be present for Big Data. Managing risk across 2265 organizations may prove to be the norm under certain CPS/ IoT scenarios. 2266 5.6.1 PII AS REQUIRING TOXIC SUBSTANCE HANDLING 2267 Treating certain data elements as more toxic than others is necessary to highlight risks for developers, 2268 operators, auditors, and forensics. Section 2.4.7.2 discusses toxic data elements. For instance, information 2269 associating a patient with a highly contagious disease is important from a public safety perspective, but 2270 simultaneously creates privacy risks. Protecting both demands that tagging, traceability, and detailed data 2271 communications become more widely practiced in Big Data scenarios. 2272 5.6.2 CONSENT WITHDRAWAL SCENARIOS 2273 After a divorce, some previously provided consent must be withdrawn. In a few scenarios, this could be 2274 matter of life and death for an ex-spouse or a child, yet systematic methods for consent withdrawal are 2275 often ignored. Consent traceability through one of several means is seen as a Big Data priority for some 2276 scenarios. 58 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 2277 5.6.3 TRANSPARENCY PORTAL SCENARIOS 2278 How best to create data and algorithmic transparency is an emerging area of specialization in HCI. 2279 Several projects , ,  are illustrative of attempts in this area, and there is even a recent 2280 formulation for an “organizational transparency model .” Big Data systems are more likely to spur 2281 transparency model investments for several reasons including the following: 2282 • The element of surprise may occur when citizens realize where and how their data is being used 2283 in scenarios seemingly far afield from their original intent. Recently, increased use of automated 2284 image identification created new concerns. 2285 • Large scale breaches have occurred. 2286 • Increased reliance on automated systems is forecast for public IoT applications, such as outdoor 2287 parking management, environmental monitoring, precision irrigation and monitoring, traffic 2288 management, smart metering, and many other areas . This reliance will expose more people 2289 to Big Data-driven solutions, as well as to the security and privacy limitations of those systems. 2290 For some, engagement will become essential to protect basic services, such as access to 2291 healthcare or convenient air travel. 2292 • As federated systems become more common—especially between small- and mid-size 2293 enterprises, participants will demand greater process transparency as well as access to data. 2294 Transparency may prove essential for collaborative decision making. As noted by Grogan et al., 2295 “Design methods for federated systems must consider local incentives and interactive effects 2296 among independent decision-makers .” Access to shared Big Data pools is likely to be 2297 needed to fully leverage proprietary systems in-house. 2298 • Cross-organizational Risk Management is well understood in construction circles as best 2299 governed by “target value design principles” and characterized by “shared risk and reward .” 2300 As analogous concepts coalesce in Big Data systems, transparency of algorithms, data, and 2301 processes will become as important for participating enterprises as for the sources of data (e.g., 2302 consumers, devices, other systems). 2303 5.6.4 BIG DATA FORENSICS AND OPERATIONAL AAR 2304 After Action Review (AAR) is an essential component to effective security in the Big Data era. AAR 2305 demands huge volumes of data to support high-fidelity replay and log analytics. Yet most Big Data 2306 systems have haphazard or nonexistent support for audit, unless regulatory bodies demand more. 2307 Support for forensics in part derives from the need to build integrated test frameworks for continuous 2308 delivery (at least for agile projects). However, forensics scenarios often encompass broad swaths of 2309 scenarios, rather than specific test exercises. Accomplishing this in a systematic way is still beyond the 2310 reach of Big Data architects. This in turn weakens attempts to protect and anticipate risks to security and 2311 privacy. 2312 For many organizations, the starting point may be a reconsideration of logs and dependency models. Is 2313 the data needed for AAR being captured? Can scenarios be fully replayed? ModSim may be essential in 2314 more complex settings. 2315 5.7 BIG DATA SECURITY MODELING AND SIMULATION 2316 (MODSIM) 2317 Penetration testing is accepted as a best practice for security professionals. However, penetration testing 2318 cannot detect numerous security problems which arise. As systems become more complex and multi- 2319 organizational, unitary penetration is simply not feasible. Instead, a combination of live test, desktop 2320 walkthroughs, and simulation are likely to be needed. 59 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 2321 The domain, utility, and application models recommended in the NBD-SPSL are helpful preparatory 2322 efforts in support of ModSim. The NBD-SPSL includes multiple features which exploit ModSim. 2323 More than a decade ago, Nicol called for increased “emulation, in which real and virtual worlds are 2324 combined to study the interaction between malware and systems .” Such methods question the usual 2325 assumptions about attack surfaces; red teams typically focus on perimeter attacks. White hat efforts do not 2326 have these limitations, but lack the necessary tools to test what-if scenarios internally. ModSim, in 2327 addition to code walkthroughs and other methods, allows for security threats to complex systems to be 2328 more systematically studied. 2329 In studies focused on specific areas such as equipment maintenance, recent work has shown that Big Data 2330 systems call for different ModSim approaches . Future security and privacy Big Data scenarios are 2331 likely to include a complex mix of people, legacy software, smartphones, and multi-robotic systems 2332 . Dependency models that have been used for critical infrastructure modeling and analysis  are 2333 equally relevant for planning the Ops component of DevOps within the continuous delivery paradigm that 2334 is common in Big Data systems. 2335 Machine learning and simulation are increasingly seen as an essential element in situation awareness, 2336 leading some analysts to declare these two elements as a key enabler in the win of AlphaGo over a human 2337 Go champion . 2338 5.8 SECURITY AND PRIVACY MANAGEMENT PHASES 2339 Earlier versions of this document did not clarify design-time, in-situ, and forensic (i.e., after-the-fact) 2340 considerations. This version explicitly addresses three phases for managing security and privacy in Big 2341 Data. Explicit awareness of these phases is seen as critical for security and privacy models to operate with 2342 full situation awareness. 2343 1. Build Phase: The security and privacy Build Phase occurs when a system is being planned, or 2344 while under development (in the agile sense). In a straightforward case, the Build Phase takes 2345 place in a greenfield environment. However, significant Big Data systems will be designed as 2346 upgrades to legacy systems. The Build Phase typically incorporates heaviest requirements 2347 analysis, relies the most upon application domain-specific expertise, and is the phase during 2348 which most architectural decisions are made . 2349 a. Note: This phase is roughly analogous to NIST SP 800-53  planning controls. 2350 b. Build phases that incorporate explicit models include the business model canvas. As Scott 2351 Shaw argued, “If architecture is the thing you want to get right from the start of your project, 2352 you should be modelling the business domain as the sequence of events that occur .” 2353 c. At the build phase, delegated access management approaches should be designed in, using, 2354 for example, two-way TLS, OAuth, OpenID, JavaScript Object Notation (JSON) web tokens, 2355 hash message authentication code (HMAC) signing, NTLM, or other approaches. Architects 2356 must consider compatibility with the Big Data stack of choice. 2357 d. The design pattern recommended for authorization is stateless, not using sessions or cookies. 2358 2. In-Situ Phase: This phase reflects a fully deployed, operational system. An in-situ security 2359 scenario shares elements with operational intelligence and controls. In a small organization, 2360 operations management can subsume security operations. Development may be ongoing, as in an 2361 agile environment where code has been released to production. Microservices present “huge 2362 challenges with respect to performance of [an] overall integrated system .” Regardless of the 2363 predecessor tasks, once released into production, security challenges exist in an arena shared with 2364 operations—including issues such as performance monitoring and tuning, configuration 2365 management, and other well-understood concepts. This relationship is discussed in more detail in 2366 the NBDIF: Volume 6, Reference Architecture document in the Management Fabric section. 60 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 2367 3. Decommissioned Phase: In its simplest form, this phase reflects a system that is no longer 2368 operational. For example, data from a (probably) decommissioned application from a bankrupt 2369 company was provided by the bankruptcy court to a third party. There is a more nuanced version 2370 of the decommissioned phase as well. Significant changes to an existing app could be seen as a 2371 decommissioning. Gartner’s Structured Data Archiving and Application Requirement  2372 contains additional discussion of decommissioning. This phase also includes design for forensics 2373 analytics. 2374 In addition to prior work by Ruan et al. , the Cloud Security Alliance proposed a Cloud Forensics 2375 Capability Maturity Model. As that Model demonstrates, more mature organizations will address phase- 2376 specific aspects of Big Data systems, rather than merely focusing on design and post-deployment 2377 administration. 2378 MODIFICATIONS FOR AGILE METHODOLOGIES 2379 Agile methods may be particularly well-suited for Big Data projects, though little research has been 2380 focused solely on security and privacy aspects. Frankova et al. claim the following: 2381 The close cooperation of managers, CIOs, the owners of the product, the development 2382 team can … help find the right data, cleanse [data], and they can help in the decision to 2383 adopt or reject a hypothesis. In these cases, the agile iterative approach is very important 2384 because with Big Data [it] is difficult to predetermine return on investment  (p. 2385 581). 2386 Working under the assumption that agile and DevOps are mutually enabling, the IEEE P2675 workgroup 2387 is preparing a standard that will improve practices for the development of software for DevOps. The focus 2388 of that work is agile methods for building secure systems in DevOps. Integrating Big Data logging, 2389 monitoring, traceability, resource management, and safety engineering into DevOps is a challenge that the 2390 IEEE P2675 workgroup is seeking to address. Recommendations to be followed from IEEE P2675 2391 development activities may impact the NBD-SPSL. 2392 While its work is still under way, the following are several preliminary conclusions that can be drawn 2393 from P2675 deliberations for Big Data Systems Development Life Cycle (SDLC): 2394 • Interlocking, multi-organizational dependency models will demand that Big Data systems scale 2395 configuration management upward. 2396 • Continuous security can be built in using any SDLC methodology, but agile may decompose the 2397 process. 2398 • Test engineering for Big Data requires additional attention due to the velocity of releases, the Big 2399 Data impact on operations and infrastructure, sprint frequency, and the complexity of systems 2400 being architected. 2401 • Big Data systems are difficult to manage as well as to build, yet securing these systems requires 2402 flexible, powerful administrative capabilities that may not be initially seen as important because 2403 the impact of Big Data scale is difficult to assess. 2404 61 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 6 DOMAIN-SPECIFIC SECURITY 2405 2406 The importance of domain-specific considerations was a key insight derived from the HL7 FHIR consent 2407 workflow use case. Implementers cannot assume that genomic data should be treated using the same 2408 practices as electric utility smart meters. Domain-specific security considerations to be investigated 2409 further include the following: 2410 • Identify domain-specific workflow, 2411 • Consider domain-specific roles, and 2412 • Investigate domain-specific share policies, content, controls. 2413 Organizations (even including sole proprietorships) must identify which facets of Big Data systems are 2414 sharable and to whom. For some organizations, the domain model is not significantly different from that 2415 of the profession or industry sector; these models are in some sense, global utility models, and 2416 nonproprietary. Other aspects of the domain model contain intellectual property, internal roles, execution 2417 strategy, branding, and tools deployed; these aspects are shared only selectively. 2418 This can be simplified to public and private views . Using this approach, views can evolve (co- 2419 evolve with code, or as code itself) over time. When it comes time to federate, a public view is available 2420 of a NBDRA component. 2421 Consent has emerged as a key Big Data security and privacy element. Implementers may need to take into 2422 account consent traceability, withdrawal, and transferal scenarios. Aspects of consent include the 2423 following: 2424 • Consent management with respect to domain-specific Big Data security and privacy; 2425 • Consent management in healthcare across provider networks; 2426 • Relation to smart contracts, blockchain, and the law; 2427 • Smart building domain security; 2428 • Domain-specific provenance; 2429 Traceability; and o 2430 Domain-specific reasoning. o 2431 62 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 7 AUDIT AND CONFIGURATION 2432 MANAGEMENT 2433 2434 Auditing fabric topology, including configuration management (CM) changes (taxonomic issues with 2435 configuration change data versus audit data). In some Big Data systems, audit, logging, and configuration 2436 data—with full history—could become larger than the associated Big Data system itself. 2437 Audit and CM across organizational entities is only lightly covered in other standards. Planning for cross- 2438 organizational data transport is a Big Data concern. Of particular concern are the following cross- 2439 organizational data transport scenarios: 2440 • Private enterprise  government 2441 • Government agency government agency 2442 • Government (e.g., open data resource)  private enterprise 2443 • Private enterprise  external private enterprise 2444 7.1 PACKET-LEVEL TRACEABILITY / REPRODUCIBILITY 2445 An early participant in NBD-PWG proposed that a central Big Data application would keep every 2446 Transmission Control Protocol/Internet Protocol (TCP/IP) or User Datagram Protocol (UDP) packet, 2447 every binary, or every byte of firmware associated with a system. This exhaustive snapshot of system 2448 behavior would represent a fully reproducible dataset that Big Data tools could use for analytics, or if 2449 needed, to create an entire execution scenario. 2450 7.2 AUDIT 2451 SIEM applications increasingly rely on extensive log data for analytics. Similarly, log data is essential for 2452 many aspects of forensic analysis. Log data itself is increasingly Big Data. In a 2015 presentation, one of 2453 the cloud service providers stated that its largest application at the time was its self-monitoring data used 2454 for management and billing support. e 2455 In 2006, NIST provided a set of recommendations for managing computer logs in order to preserve their 2456 integrity . Big Data presents additional challenges for logging and monitoring due to scale and 2457 variety. Current InfoSec tools are beginning to take this into account but they lack the capabilities of most 2458 Big Data stacks. 2459 Incident response for Big Data has been discussed in literature. In 2006, NIST provided guidance on 2460 performing computer and network forensics in the Guide to Integrating Forensic Techniques into Incident 2461 Response . 2462 7.3 MONITORING 2463 While monitoring has a conventional place in the security specialist’s toolbox, the associated tools may 2464 not be sized properly for Big Data systems. For example, in the cloud setting, the following is argued: e Presentation at a 2015 NYC Storm Meetup. 63 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 2465 “Monitoring demonstrates several challenges including gathering metrics 2466 from a variety of layers (infrastructure, platform, application), the need for 2467 fast processing of this data to enable efficient elasticity and the proper 2468 management of this data in order to facilitate analysis of current and past 2469 data and future predictions. In this work, we classify monitoring as a big 2470 data problem and propose appropriate solutions in a layered, pluggable and 2471 extendable architecture for a monitoring component .” 2472 Big Data security and privacy support for audit and logging for monitoring and management is critical, 2473 but security operations must be able to scale along with associated Big Data applications. In addition, 2474 monitoring must be appropriate for both the utility, domain, and application models involved. This 2475 requires a close collaboration between application designers and security and privacy teams that is often 2476 not achieved. 2477 64 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 8 STANDARDS, BEST PRACTICES AND 2478 GAPS 2479 2480 8.1 NIST CYBERSECURITY FRAMEWORK 2481 During 2017, NIST published two drafts of proposed updates to the 2014 Cybersecurity Framework 2482 . Since its introduction in 2014, the framework  has seen considerable de facto adoption and 2483 mention across a variety of industries. In addition to its appearance in the DHS Critical Infrastructure 2484 Cyber Community C³ Voluntary Program , the NIST Cybersecurity Framework  appears in 2485 numerous job descriptions. Its appearance in cybersecurity hiring actions and its adaptation for other 2486 standards (e.g., SABSA’s SENC project ) further reflect the importance of the NIST Cybersecurity 2487 Framework. 2488 8.2 CONFIGURATION MANAGEMENT FOR BIG DATA 2489 8.2.1 EMERGENCE OF DEVSECOPS 2490 The Point in Time, temporally qualified nature of Big Data configuration management creates numerous 2491 challenges for security operations. This has contributed to the development of a movement in industry 2492 called DevSecOps, which applies DevOps concepts to security operations (SecOps). Big Data is 2493 increasingly part of this, but DevSecOps may also be essential to keep InfoSec tools abreast of fast- 2494 moving, fast-changing Big Data. 2495 For instance, one cloud provider “lets sys admins track the state of resources in their account via 2496 configuration items. These configuration items can be used in two different ways: They can produce a 2497 timeline of events using configuration item states to tell a story about the life cycle of a specific instance. 2498 And administrators can report and react to compliance problems using a rule engine called ‘Config- 2499 Rules,’ creating true DevSecOps .” 2500 More sophisticated notions of configuration management, and federated CMDB’s with semantic web and 2501 domain-specific model connections are on the horizon. 2502 A recent lessons learned piece by Textor et al. argues for a standards-based ontology as essential to 2503 integrating technology with less technical counterparts in risk or cost management: 2504 “We present a solution for the semantic information integration of different domain 2505 models in the context of automated IT management. For that, we formulate a core 2506 ontology based on the COBIT IT governance framework for integration on a conceptual 2507 level and discuss features of an extensible knowledge-based runtime system. We present a 2508 case study that integrates models from storage management, virtual machine 2509 management and a billing model .” 2510 In the meantime, smaller-scale tools are expected to struggle with the pace of change brought about both 2511 by Big Data and left shift. This will challenge SecOps. Few SecOps organizations are structured to 2512 leverage model-based approaches. Reliance on utility models, such as perimeter threat, has already 2513 proven to have diminished usefulness for Big Data applications, or in data centers hosting these apps. 2514 DevSecOps will likely encompass notions that are already part of NIST SP 800-190, Application 2515 Container Security Guide . 65 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 2516 8.2.2 DEPENDENCY MODELS 2517 Dependency models that encompass software bills of resources are less widely used than some standards 2518 suggest. In manufacturing, a standard feature of a Bill of Material is the Where Used capability, which 2519 allows for instant identification of everywhere a part is used, along with its revision level at the time of 2520 assembly. Software project management and build / quality management resources such as Apache 2521 Maven and other tools attempt to provide similar capabilities, and build tools must provide this at release 2522 time. However, Big Data demands a longitudinal perspective on the Where Used aspect that preserves all 2523 the components of a build for security traceability. 2524 The use of data traceability is even less widely implemented, and the infrastructure as code, left shift 2525 trend means that data traceability may follow a similar, gradualist path. There are statistical and 2526 methodological problems with using some data gathered for one purpose in another setting. Tracing data 2527 from its original source, a provenance challenge, is also needed to understand constraints on the contexts 2528 where Big Data can be used appropriately. 2529 The format that the dependency model takes and how it is integrated into the development, operations, 2530 and forensics setting for Big Data security and privacy requires further research. In HL7, for example, 2531 models are exchanged using the Model Interchange Format. Predictive analytical models can be 2532 exchanged using the Predictive Model Markup Language (PMML). OMG offers XML Metadata 2533 Interchange (XMI) and XML Metadata Interchange Diagram Interchange XMI[DI] as document formats 2534 to exchange models and diagrams between applications. 2535 The use of security models and a standardized language to express constraints and access are essential for 2536 Big Data scalability and interoperability between organizations. 2537 8.3 BIG DATA SDLC STANDARDS AND GUIDELINES 2538 Today’s developers operate under SDLC frameworks including agile , waterfall , and spiral 2539 , as well as other models. A significant number of developers operate under less explicit frameworks 2540 organized around GitHub practices—and this practice dominates in components used in many a Big Data 2541 stack. A convenient method of integrating for instance with the Integrated Development Environment 2542 (IDE) tool is essential to foster reuse of libraries, assurance tools, and test environments, yet standards for 2543 this have yet to be adopted. 2544 8.3.1 BIG DATA SECURITY IN DEVOPS 2545 The concept of DevSecOps was introduced by Gartner as an emerging principle in DevOps in 2012, 2546 shortly before this NIST working group began its work. Progress has been slow. Gartner, in a 2016 report 2547 noted the following: 2548 “… We estimate that fewer than 20% of enterprise security architects have 2549 engaged with their DevOps initiatives to actively and systematically 2550 incorporate information security into their DevOps initiatives; and fewer still 2551 have achieved the high degrees of security automation required to qualify as 2552 DevSecOps .” 2553 A deeper understanding, with solid technical underpinnings, is needed to specify how DevSecOps teams 2554 ought to operate in a Big Data development setting. For example, how should the DevOps pattern 2555 described by Cockroft for a major Big Data streaming service be applied to Big Data more generally 2556 ? This document recognizes the increasing importance of DevOps. DevOps enables small teams to 2557 create Big Data systems with much reduced effort—and potentially, much reduced oversight for security 2558 and privacy. DevOps does not preclude quality software , but it can reduce the importance of 2559 traditional checks and balances afforded by others in a larger organization. 66 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 2560 The notion of Infrastructure as Code is enabled by DevOps and other principally cloud computing 2561 technologies . The concept needs additional Big Data treatment to help foster security and privacy 2562 best practices in DevOps. 2563 The potential dilution, while not disappearance, of requirements phases and traceability in the agile 2564 development paradigm creates challenges for a security-aware SDLC. For instance, while a technology- 2565 agnostic process termed Secure Development Life Cycle (SDL-IT) was developed at Microsoft to 2566 improve its management of security and privacy processes , adoption is hardly widespread. Attempts 2567 such as Secure-SDLC (S-SDLC) and the Software Assurance Maturity Model (OpenSAMM, which 2568 became part of OWASP) are not integrated into IDE in ways that foster secure practices. For Big Data 2569 systems, developers rarely receive automated alerts as to practices which could create privacy risks, or 2570 which require additional, perhaps standards-based, attention to coding, administrative, and deployment 2571 practices. 2572 8.3.1.1 Application Life Cycle Management 2573 Both the application life cycle and the data life cycle must be managed, although they can be delinked in 2574 Big Data scenarios as data flows outside an organization. Nolle argues that “DevOps emerged for app 2575 developers to communicate deployment and redeployment rules into the operations processes driving 2576 application life cycle management .” 2577 8.3.1.2 Security and Privacy Events in Application Release Management 2578 Recent focus on release management has been identified as Application Release Management (ARM). 2579 Contributions are sought to help identify Big Data ARM practices, especially as they apply to DevOps 2580 and agile processes more generally. 2581 8.3.1.3 Orchestration 2582 Nolle insists that DevOps and orchestration are two different concepts in the cloud context, but that 2583 orchestration has a loftier aim: “In the long run, what separates DevOps and orchestration may not be 2584 their ALM-versus-cloud starting point, but that orchestration is actually a more general and future-proof 2585 approach .” Noelle cites TOSCA  as leading this charge. 2586 A Big Data adaptation of TOSCA-like concepts is needed that extends beyond cloud computing. NBDIF: 2587 Volume 8, Reference Architecture Implementation contains further discussion of this topic. 2588 8.3.1.4 API-First 2589 API-first is a concept that was advocated by several industry leaders. In part, it reflected the reality of web 2590 practice. Many startups developed business models around which services they would consume, and 2591 which they would provide—through Application Programming Interfaces (APIs). Thus, the business 2592 model referred to as API-First came into existence . 2593 API-first also addresses scalability challenges in domains such as healthcare. In the OpenID HEART 2594 major use case, the project team writes that, “The architecture of prior provider-to-provider technologies 2595 have not been able to scale naturally to patient and consumer environments. This is where an API-first 2596 approach has an edge.” 2597 In the NBDRA, at the conceptual level, this specifies that application providers and consumers operate 2598 through defined APIs which can provide additional safety. A recent example of an API that implements 2599 domain-specific resources is the HL7 FHIR Health Relationship Trust Profile for FHIR OAuth 2.0 2600 Scopes. Resources in the scope of this trust profile include patients, medication requests, medication 2601 dispensing, medication administration, and clinical observations. This is a design pattern for API-first— 2602 API’s are designed to operate in tandem with domain-specific resources. 67 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 2603 Further work is needed to identify which controls are most effective, but commercial services are already 2604 available which monitor API calls and can react to API threats in real time by throttling or closing 2605 services. 2606 8.3.2 MODEL DRIVEN DEVELOPMENT 2607 Big Data systems potentially entail multiple models from multiple disciplines implemented across diverse 2608 platforms, and often across different organizations. Previous attempts to share information across 2609 organizations have not fared well. Sharing of database schemas is a minimal starting point. Appendix A 2610 provides a number of citations for this topic. 2611 METAMODEL PROCESSES IN SUPPORT OF BIG DATA SECURITY AND PRIVACY 2612 ISO 33001  offers additional guidance on the use of models and information sharing. Project 2613 examples of working domain models include the following: 2614 • OpenBIM, a domain model for construction and facilities management (as in smart buildings) 2615 (ISO 16739:2013) Refer to ; 2616 • The Facility Smart Grid Information Model developed by ASHRAE/NEMA 201; 2617 • HVAC Engineering Standards for Smart Buildings; and 2618 • Automotive engineering models (SPICE). 2619 An approach taken by Atkinson et al.  and further developed by Burger offers methods which place 2620 domain models firmly inside the SDLC. 2621 “This provides a simple metaphor for integrating different development paradigms and 2622 for leveraging domain specific languages in software engineering. Development 2623 environments that support OSM essentially raise the level of abstraction at which 2624 developers interact with their tools by hiding the idiosyncrasies of specific editors, 2625 storage choices and artifact organization policies. The overall benefit is to significantly 2626 simplify the use of advanced software engineering methods .” 2627 Model-based approaches also provide more elastic approaches to Big Data security and privacy than is 2628 available through traditional methods like Role-based Access Control (RBAC) or explicit role-permission 2629 assignments (EPA). The authors of one approach, called Contextual Integrity, claim that its: 2630 “… norms focus on who personal information is about, how it is transmitted, 2631 and past and future actions by both the subject and the users of the 2632 information. Norms can be positive or negative depending on whether they 2633 refer to actions that are allowed or disallowed. Our model is expressive 2634 enough to capture naturally many notions of privacy found in legislation 2635 .” 2636 Leveraging domain-specific concepts from healthcare, related research demonstrated that EHR privacy 2637 policy could be, “… formalized as a logic program [and] used to automatically generate a form of access 2638 control policy used in Attribute-Based Encryption . 2639 Such recommendations must be carried further to promote security and privacy practices in development. 2640 Models such as these are not generally part of the Big Data system architect’s apprenticeship. 2641 8.3.3 OTHER STANDARDS THROUGH A BIG DATA LENS 2642 8.3.3.1 ISO 21827:2008 and SSE-CMM 2643 The International Systems Security Engineering Association (ISSEA) promoted a standard referred to as 2644 the Systems Security Engineering Capability Maturity Model (SSE-CMM). SSE-CMM was developed in 68 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 2645 collaboration with more than 40 partner organizations, and is codified in the ISO/IEC 21827:2008 2646 standard. Its roots date to the mid-1990s; it predated Big Data. 2647 8.3.3.2 ISO 27018: Protection of PII in Public Clouds Acting as PII Processors 2648 ISO 27018 is a recent standard that addresses protection of PII for cloud computing. ISO 27018 is based 2649 on ISO 27002 and adapted to public cloud considerations. Because much of today’s Big Data is cloud- 2650 based, this standard addresses concerns that many system owners with toxic PII face. 2651 Consent: CSPs (Cloud Service Providers) must not use the personal data 2652 they receive for advertising and marketing unless expressly instructed to do 2653 so by the customer. Moreover, a customer must be able to use the service 2654 without submitting to such use of its private information. 2655 Control: Customers have explicit control of how their personal data is used. 2656 Transparency: CSPs must inform customers where their personal data 2657 resides and make clear commitments as to how that data is handled. 2658 Accountability: ISO/IEC 27018 asserts that any breach of information 2659 security should trigger a review by the service provider to determine if there 2660 was any loss, disclosure, or alteration of personal data. 2661 Communication: In case of a breach, CSPs should notify customers, and 2662 keep clear records of the incident and the response to it. 2663 Independent and yearly audit: A successful third-party audit (see e.g., AWS 2664 CertifyPoint) of a CSP’s compliance documents the service’s conformance 2665 with the standard, and can then be relied upon by the customer to support 2666 their own regulatory obligations. To remain compliant, a CSP must subject 2667 itself to yearly third-party reviews. (Adapted from ) 2668 8.3.4 BIG DATA TEST ENGINEERING 2669 Techniques such as the ETSI Test Description Language can be employed to exercise an application to 2670 test for secure performance under test. For instance, which external sites and URLs should a web 2671 application access? 2672 Test engineering is important in software assurance because complex systems cannot be fully tested by 2673 developers, or even developer teams without automation assistance. In a recent report, a vice president of 2674 product marketing estimated that some 33 exabytes of data had been generated to date. In the same report, 2675 a powertrain simulation and tools research leader estimated that their company generates about 500GB of 2676 data daily . 2677 A fraction of this data is directly relevant to security and privacy, but even at 1%, this represents a 2678 daunting challenge. 2679 8.3.5 API-FIRST AND MICROSERVICES 2680 The notion of microservices has evolved from service-oriented architecture (SOA) and object-oriented 2681 practices, but is relevant to Big Data because it represents a convergence of several trends. A recent NIST 2682 draft NIST SP 800-180  attempts to put forth a standard definition. As explained in the draft, 2683 “Applications are decomposed into discrete components based on capabilities as opposed to services and 2684 placed into application containers with the resulting deployment paradigm called a Microservices 2685 Architecture. This Microservices Architecture, in turn, bears many similarities with SOAs in terms of 2686 their modular construction and hence formal definitions for these two terms are also needed in order to 2687 promote a common understanding among various stakeholders … ” (Preface, p. v) 69 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 2688 A full discussion of the approach is presented in greater detail elsewhere , but microservices offer 2689 applications designers, data center managers, and forensics specialists greater detail and thus control over 2690 relevant Big Data security and privacy system events. 2691 At a somewhat higher level in the stack, some have suggested frameworks to support microservices 2692 visible to users, as well as lower-level developer-centric services. This was the notion proposed by 2693 Versteden et al. in a scheme that supports discovery of semantically interconnected single-page web 2694 applications . 2695 8.3.6 APPLICATION SECURITY FOR BIG DATA 2696 8.3.6.1 RBAC, ABAC, and Workflow 2697 Initial work by NIST evolved to an ANSI / INCITS standard 369-2004 for RBAC . According to a 2698 later report, the “Committee CS1.1 within the International Committee for Information Technology 2699 Standards (INCITS) has initiated a revision with the goal of extending its usefulness to more domains, 2700 particularly distributed applications” . Kuhn et al. outline potential benefits of an alternative 2701 approach, Attribute-Based Access Control (ABAC), though no reference model had emerged. In the same 2702 paper, a combination of ABAC and RBAC is suggested. 2703 In 2015, NIST published a description of ABAC in NIST SP 800-162 . 2704 Beyond RBAC improvements, Big Data systems must incorporate workflow standards, if not formalisms, 2705 to transfer roles and policies along with data (or application / data bundles) between organizations. 2706 Previous work has studied ways to extend traditional RBAC to enterprise registries , or to include 2707 geospatial attributes . 2708 Because XACML does not support RBAC directly, Ferrini and Bertino note that while XACML profiles 2709 extended the original XACML to include RBAC, “the current RBAC profile does not provide any support 2710 for many relevant constraints, such as static and dynamic separation of duty .” Ferrini and Bertino 2711 recommended expanding the XACML framework to include OWL. More nuanced access control decision 2712 processes can be supported by leveraging the reasoning potential of OWL. 2713 “It is also important to take into account the semantics of role hierarchies with respect to 2714 the propagation of authorizations, both positive and negative, along the role inheritance 2715 hierarchies. Supporting such propagation and, at the same time, enforcing constraints 2716 requires some reasoning capabilities. Therefore, the main issue with respect to the 2717 XACML reference architecture and the engine is how to integrate such reasoning 2718 capabilities .” (p. 145) 2719 Integrating workflow into the RBAC framework has also been studied. Sun et al. argued that adding 2720 workflow to RBAC would better, “support the security, flexibility and expansibility” of RBAC . 2721 Workflow-specific as well as time-limited access improves not only controls for audit and forensics, but 2722 can help to limit the impact of insider threat. 2723 8.3.6.2 ‘Least Exposure’ Big Data Practices 2724 Just as legacy and software key fobs have rotating authorization keys, Big Data systems should enforce 2725 time windows during which data can be created or consumed. 2726 The increased use of massive identity management servers offers economy of scale and improved 2727 efficiency and usability through single sign-on. When breached, these datasets are massive losses 2728 affecting millions of users. A best practice is obviously to control access to Identity Access Management 2729 (IAM) servers, but more importantly to utilize distributed datasets with temporally restricted access. 70 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 2730 Big Data should cause system architects to reconsider the entire notion of admin and superuser in favor of 2731 more nuanced domain-specific models. Using those models, Big Data systems can be designed to 2732 minimize the size of a breach by segmenting identity, PII and other datasets and limited access to 2733 controlled time windows that are leased. 2734 8.3.6.3 Logging 2735 The following logging standards are applicable to Big Data security and privacy: 2736 • NIST SP 800-92 , 2737 • NIST SP 800-137 , and 2738 • DevOps Logging. 2739 Logging standards should be reviewed carefully because some recommendations in existing standards 2740 may not scale, or may create untenable risks due to Big Data variety. For Big Data logging to scale 2741 properly, domain, application and utility models must come into play. For instance, an array of a thousand 2742 IoT sensors sending thousands of samples per second may or may not need to be logged. Logging must 2743 often be correlated with other events, which is why complex event processing can be useful for IoT 2744 security . Application developers typically have a clearer understanding of the HCI aspects of their 2745 logs, but other model considerations also apply. In most cases, IoT security and privacy requires explicit 2746 models for sensors and their interfaces . 2747 IEEE P2675 is developing a standard that addresses the role of logging in DevOps agile projects. Big 2748 Data logs require additional metadata about themselves and the setting in which logs are collected, 2749 because the logs may persist far beyond the current infrastructure and could be used in settings outside the 2750 current enterprise. 2751 Logs will also be needed to supply data for ModSim, which many think will be key to self-managed 2752 infrastructure in the left shift movement. 2753 For an example of the scope of today’s thinking about logging, refer to The Art of Monitoring, which 2754 devotes more than 500 pages to the subject. Add Big Data and domain-specific models to the mix, and the 2755 complexity is no less prevalent . 2756 8.3.6.4 Ethics and Privacy by Design 2757 The following standards are related to ethics and privacy by design and could be applicable to Big Data 2758 systems: 2759 • IEEE P7000 , 2760 • IEEE P7002 , 2761 • IEEE P7003 , 2762 • IEEE P7007 , 2763 • ISO 27500 , 2764 • ISO 9241 , 2765 • FAIR, and 2766 • NIST IR 8062 . 2767 The IEEE initiative to address ethical consideration in systems design, paired with ISO 27500 , will 2768 provide future guidance in this area important to public consumers of Big Data. As documents are 2769 released from the IEEE working groups, this work should be surveyed for the needs of Big Data builders, 2770 managers, and consumers. 2771 In an overview of ISO 27500 , Tom Stewart summarizes the standard’s goal as: “... ISO 27500 The 2772 Human-centered Organization. Aimed at corporate board members, the standard explains the values and 71 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 2773 beliefs that make an organization human-centered, the significant business and operational benefits that 2774 arise, and the policies they need to put in place to achieve this .” 2775 Big Data is a part of this larger need to address organizational values and to trace how these are 2776 implemented in practice . Some work in this area is motivated by international cooperation around 2777 FAIR . Others are driven by regulation . 2778 8.4 BIG DATA GOVERNANCE 2779 Big Data Governance is characterized by cross-organizational governance, cross-border considerations, 2780 federation, marketplaces, and supply chain frameworks. What is different about Big Data systems in 2781 comparison to other systems is that reliance on manual processes is no longer possible. Governance as a 2782 separate function of oversight and audit may not always be feasible. Governance must be designed in, 2783 hence the need to understand Big Data governance requirements in depth. 2784 Apache Atlas is in incubation as of this writing, but aims to address compliance and governance needs for 2785 Big Data applications using Hadoop. 2786 8.5 EMERGING TECHNOLOGIES 2787 8.5.1 NETWORK SECURITY FOR BIG DATA 2788 Protecting virtual machines is the subject of guidelines, such as those in the NIST Secure Virtual Network 2789 Configuration for Virtual Machine (VM) Protection Special Publication . Virtual machine security 2790 also figures in PCI guidelines . Wider adoption may be possible in many data centers, but the 2791 technique is currently poorly integrated with developer and asset management capabilities. Refer to the 2792 work of IEEE P1915.1  for emerging standards work on secure network function virtualization. 2793 Big data challenges are converging with the 5G wireless standard, which will add velocity and volume 2794 stresses on telecommunications infrastructure. Representative of current thinking in this area is work on 2795 self-organizing networks (SONs) at a recent systems modeling conference. These investigators proposed, 2796 “…. novel Proactive SON methodology based on the Big Data framework to enable the shift in the SON 2797 paradigm. In this article, we present a comprehensive Big Data-based SON framework involving 2798 innovative Machine Learning techniques which would cater to scalability and programmability of 5G 2799 networks with respect to availability, reliability, speed, capacity, security and latency .” 2800 Architecture Standards for IoT, such as IEEE P2413 , are also of importance for Big Data network 2801 security. 2802 8.5.2 MACHINE LEARNING, AI, AND ANALYTICS FOR BIG DATA SECURITY AND 2803 PRIVACY 2804 AI and Big Data analytics are critical topics in Big Data, and are the focus of work such as IEEE P7003 2805 , IEEE P7007 , and ISO 27500 . Possible use cases could include conclusions from Medicare 2806 End-Stage Renal Disease, Dialysis Facility Compare (ESRD DFC, http://data.medicare.gov/data/dialysis- 2807 facility-compare). Additional investigations into machine learning, AI, and analytics with respect to Big 2808 Data security and privacy are needed and could include details on the following: 2809 • Risk / opportunity areas for enterprises, 2810 • Risk / opportunity areas for consumers, and 2811 • Risk / opportunities for government. 2812 72 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY Appendix A: NIST Big Data Security and Privacy 2813 Safety Levels 2814 2815 Version 2 of NBDIF: Volume 4, Security and Privacy was principally informed by the introduction of the NIST Big Data Security and Privacy 2816 Safety Levels (NBD-SPSL). Using the NBD-SPSL, organizations can identify specific elements to which their systems conform. Readers are 2817 encouraged to study the NBD-SPSL, presented in this appendix, before launching into the body of this document. Appendix A is designed to be a 2818 stand-alone, readily transferred artifact that can be used to share concepts that can improve Big Data security and privacy safety engineering. 2819 Table A-1: Appendix A: NIST Big Data Security and Privacy Safety Levels Brief Description Safety Level 1 Safety Level 2 Safety Level 3 "Where-is" monitoring and discovery of human touch points System is self-aware of its human touchpoints Traditional "role" artifacts, such as UML, SysML identification of System incorporates and is capable of maintaining a persistent CRT screen or mobile phone UI touchpoints within a domain awareness of touch points. safety framework that can identify and specifications. model. Automated alerts, escalation monitor where human interactions occur that when risk profile changes. involve risk for the affected domain. 73 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY Brief Description Safety Level 1 Safety Level 2 Safety Level 3 API-Oriented and API-first Safety As was the case with the SOA movement, the API-first designs in the enterprise Level 2 adds: automated API Add to Level 2: direct link to definition of clear interfaces is a key element take into account safety levels as testing, traceability to SnP domain, app and utility of Big Data systems. Some argue that the part of design, management and design patterns in use within models. Include awareness of numerous cloud-centric applications that have forensics. APIs are used not just for teams and across SnP utility dependencies on a potentially been built in the last decade have increasingly risk, but also management and models (e.g., SSO, database increasing pool of third-party relied on pub-sub design patterns. In creating an ecosystem around the encryption, encryption in APIs. (See Dependency particular, designers may consider API API. Using checklists and other transit). Third-party and InfoSec Model). characteristics early in the design of Big Data methods, ABAC and RBAC tools provide alerts and monitor systems. Once established, multiple APIs can elements are incorporated into for scalability and resilience. enhance security and privacy. APIs. Usage is routinely onboarded into enterprise tools. Selected References L. Xavier, A. Hora, and M. T. Valente, "Why do we break APIs? first answers from developers," in 2017 IEEE 24th International Conference on Software Analysis, Evolution and Reengineering (SANER), Feb. 2017, pp. 392-396. [Online]. Available: http://dx.doi.org/10.1109/SANER.2017.7884640 R. Malcolm, C. Morrison, T. Grandison, S. Thorpe, K. Christie, A. Wallace, D. Green, J. Jarrett, and A. Campbell, "Increasing the accessibility to big data systems via a common services API," in 2014 IEEE International Conference on Big Data (Big Data), Oct. 2014, pp. 883-892. [Online]. Available: http://dx.doi.org/10.1109/BigData.2014.7004319 V. Srivastava, M. D. Bond, K. S. McKinley, and V. Shmatikov, "A security policy oracle: Detecting security holes using multiple API implementations," in Proceedings of the 32Nd ACM SIGPLAN Conference on Programming Language Design and Implementation, ser. PLDI '11. New York, NY, USA: ACM, 2011, pp. 343-354. [Online]. Available: http://doi.acm.org/10.1145/1993498.1993539 Application Model An application model is an abstract Traditional waterfall or agile Advanced application design In addition to software- description of a system element or application, artifacts, milestone checks with and monitoring tuned to Big enabled APM, additional In- including its Big Data SnP components. Some Big Data support Data needs (streaming, IoT, app workflow implemented as version of an application model is a organization bleed-through) code with explicit model. Full requirement for the BDSQ safety framework. audit and logging to domain App models can foster transparency and model. Model artifacts are interoperability, essential for long-lived Big produced and consumed Data and potentially, Big Data systems. inside the Big Data system. Selected References M. Borek, K. Stenzel, K. Katkalov, and W. Reif, "Abstracting security-critical applications for model checking in a model-driven approach," in 2015 6th IEEE International Conference on Software Engineering and Service Science (ICSESS), Sep. 2015, pp. 11-14. [Online]. Available: http://dx.doi.org/10.1109/ICSESS.2015.7338996 74 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY Brief Description Safety Level 1 Safety Level 2 Safety Level 3 Authority to collect data Long-lived or PII-intensive Big Data systems XML or equivalent for authority, Use digital cert associated with Same as Level 1, but with must capture and maintain transparency for capture terms of service, legal collection. Written policies controls designed for data collection authority. This may be point in authorities, versioning information surrounding enterprise handling transferability to third parties, time. within overall enterprise for PII, but tend to be limited to especially in supply chain governance. a single enterprise. settings. Authority data is tracked using Big Data technologies, detail, audit, traceability. 75 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY Brief Description Safety Level 1 Safety Level 2 Safety Level 3 Big Data Security Fabric "Communicator" A central concern of public institutions and Big Data system implement a System Communicator is System Communicator fully citizenry places Big Data systems in a special, portal for users, developers and partially connected to the actual integrated: domain model- if not unique category. As a consequence of managers to access system Big Data system SnP apparatus, aware, persists when data this heightened concern, the safety framework artifacts, FAQs and other relevant including partial connectivity moves outside organizations, includes a Big Data System Communicator. information connected to risk, with the domain, app and utility self-updating. Potentially The System Communicator may include privacy, security and enterprise models involved. The agent-based or functionally internal artifacts, but its principal audience is a practices. Content and management Communicator hosts resources similar to agent-based. Full potentially wide spectrum of stakeholders is manual. such as consent management, awareness of data life cycle whose concerns it might allay, in part, through traceable requirements, for PII / PCI components, transparency and interactivity. limitations, changes in terms of relevant covenants and use, and historical tracking. consent. Selected References A. Garcia Frey, "Self-explanatory user interfaces by model-driven engineering," in Proceedings of the 2Nd ACM SIGCHI Symposium on Engineering Interactive Computing Systems, ser. EICS '10. New York, NY, USA: ACM, 2010, pp. 341-344. [Online]. Available: http://doi.acm.org/10.1145/1822018.1822076 J.Preece and Rombach, "A taxonomy for combining software engineering and human-computer interaction measurement approaches: towards a common framework," International Journal of Human-Computer Studies, vol. 41, no. 4, pp. 553-583, Oct. 1994. [Online]. Available: http://linkinghub.elsevier.com/retrieve/pii/S1071581984710731 C. R. Sugimoto, H. R. Ekbia, and M. Mattioli, Big Data and Individuals. MIT Press, 2016. [Online]. Available: http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=7862699 Big Data Forensics Playbooks Pre-Big Data forensics could fail operate Manual playbooks identify both in- Playbooks are directly linked to Add to Level 2: Playbooks are properly at Big Data scale. house and third-party (e.g., software releases, with directly linked to domain, app regulator) forensics. Playbooks functional capabilities added or and utility models. Playbooks encompass risk management, removed from playbooks with self-configure based on transparency, traceability, and each release. Playbooks are a changes to models. Playbooks whether monitoring is sufficient to well-defined mix of manual and are complemented by self- support forensics. automated processes, and are maintaining properties of test exercised with periodic forensic frameworks. Red teams "red team" operations. operate with real or simulated data to fully exercise playbooks, and are provided with tooling and access to perform these functions. 76 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY Brief Description Safety Level 1 Safety Level 2 Safety Level 3 Business continuity (BC) Business Continuity in the event of Big Data Written BC plan, but most Partially automated BC plans Fully automated dependency System failure can result in a wide range of processes are manual. Explicit which leverage domain, utility model, transition to/from scenarios, but could include breaches, lowered references to domain and utility and application models. alternative processing privacy shields, or inability to perform models with cross-reference to platforms, and support for customary authentication. application models. post-failure forensics. Test, verification, audit systems are pre-instrumented for BC configurations. Selected References R. Thomas and P. McSharry, Big Data Revolution: What farmers, doctors and insurance agents teach us about discovering big data patterns. Somerset NJ: Wiley, Mar. 2015, Chapter 20. T. Miksa, R. Mayer, M. Unterberger, and A. Rauber, "Resilient web services for timeless business processes," in Proceedings of the 16th International Conference on Information Integration and Web based Applications & Services, ser. iiWAS '14. New York, NY, USA: ACM, 2014, pp. 243-252. [Online]. Available: http://doi.acm.org/10.1145/2684200.2684281 Capacity management for Security Operations Big Data SnP support for audit and logging for Big Data SnP framework exists Partially scalable Failover or other plans, fully monitoring and management is critical, but within current platforms as implementation of plans to tested, for interruptions or security operations must be able to scale along deployed, but with limited ability to strengthen Security Operations pollution of streamed data with associated Big Data applications. sustain attacks across multiple Big to respond to planned and sources. Typically requires Data sources, especially for unplanned surges in Big Data simulations tied to domain streaming sources. SnP monitoring, management, and utility models, tied to and mitigation of threats and scalable and resilient protective measures. infrastructure within and across the infrastructure set of composable services and suppliers. Selected References M. M. Bersani, D. Bianculli, C. Ghezzi, S. Krstic, and P. S. Pietro, "Efficient Large-Scale trace checking using MapReduce," in 2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE), May 2016, pp. 888-898. [Online]. Available: http://dx.doi.org/10.1145/2884781.2884832 M. Andreolini, M. Colajanni, M. Pietri, and S. Tosi, "Adaptive, scalable and reliable monitoring of big data on clouds," Journal of Parallel and Distributed Computing, vol. 79, pp. 67-79, 2015, special Issue on Scalable Systems for Big Data Management and Analytics. [Online]. Available: http://www.sciencedirect.com/science/article/pii/S074373151400149X 77 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY Brief Description Safety Level 1 Safety Level 2 Safety Level 3 Consent Interoperability, traceability Big Data Systems add a layer of complexity Big Data framework for the Adds partial automation with Consent traceability fully for consent management (think terms of application includes consent domain models to consent, and integrated with domain service, for instance, across decades and tracking where applicable, with supports consent transference model. "Smart contracts" multiple data custodians). The Big Data Safety written policies to manage, and withdrawal through a mix represent one possible Framework recommends a traceable consent administer and support forensics. of manual and automated approach to traceability, but management system that addresses both methods. specific requirements are compliance and privacy safety. domain-specific, automatically resolved by consulting the domain model(s). Selected References A. T. Gjerdrum, H. D. Johansen, and D. Johansen, "Implementing informed consent as Information-Flow policies for secure analytics on eHealth data: Principles and practices," in 2016 IEEE First International Conference on Connected Health: Applications, Systems and Engineering Technologies (CHASE), Jun. 2016, pp. 107-112. [Online]. Available: http://dx.doi.org/10.1109/CHASE.2016.39 M.Benchoufi, R. Porcher, and P. Ravaud, "Blockchain protocols in clinical trials: Transparency and traceability of consent [version 1; referees: 1 approved, 1 not approved]," F1000Research, vol. 6, no. 66, 2017. [Online]. Available: http://dx.doi.org/10.12688/f1000research.10531.1 E. Luger, "Consent reconsidered; reframing consent for ubiquitous computing systems," in Proceedings of the 2012 ACMConference on Ubiquitous Computing, ser. UbiComp '12. New York, NY, USA: ACM, 2012, pp. 564-567. [Online]. Available: http://doi.acm.org/10.1145/2370216.2370310 Continuous delivery of SnP components As Big Data and its support software shifts Periodic Big Data dev team Periodic reviews plus library Fully deployed, transparent, and evolves over time, the associated SnP reviews, adoption of agile (see reuse, continuous delivery, continuously deployed SnP components will also evolve. Continuous IEEE P2675) methods for delivery. automated test and CMDB with microservices on build, test, Delivery of SnP elements can enhance safety No build server integration. partial domain and utility model production servers using agile by exposing dynamic aspects of SnP that can integration. or spiral delivery and rapidly evolve to meet new threats or integration with domain and opportunities to preserve secrecy. utility models. Selected References R. Heinrich, A. van Hoorn, H. Knoche, F. Li, L. E. Lwakatare, C. Pahl, S. Schulte, and J. Wettinger, "Performance engineering for microservices: Research challenges and directions," in Proceedings of the 8th ACM/SPEC on International Conference on Performance Engineering Companion, ser. ICPE '17 Companion. New York, NY, USA: ACM, 2017, pp. 223-226. [Online]. Available: http://doi.acm.org/10.1145/3053600.3053653 T. Margaria and B. Steffen, "Continuous Model-Driven engineering," Computer, vol. 42, pp. 106-109, 2009. [Online]. Available: http://dx.doi.org/10.1109/MC.2009.315 M. Sicker. (2017, Apr.) why use a microservice architecture. MuSigma. Chicago IL. [Online]. Available: http://musigma.org/architecture/2017/04/20/microservices.html 78 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY Brief Description Safety Level 1 Safety Level 2 Safety Level 3 Dependency and federation model Dependency models for Big Data SnP must Implements a dependency model Automated dependency model All capabilities of Level 2, but take into account variety, volume, and velocity that is largely manual but addresses that incorporates interoperating include greater automation as scalability and diversity stresses on the mandatory human and information security tools (e.g., and live connections to integrity and governance. Sometimes Big Data computer elements in place to SIEM) and addresses domain, app and utility systems will span organizations, thus requiring protect this particular Big Data dependencies outside the dependencies. Greenfield and related federation standards, which are needed system and deliver the stated safety enterprise, including suppliers maintenance software occurs for SnP continuity at scale. A dependency levels. of data (cross-industry with dependency constraints model takes into account the desired safety advisories) and software provided within IDEs. level; some Big Data systems will be deployed updates. Limited connectivity to with high risk out of necessity, in which case domain and app models. dependency models are critical. Selected References Z. Xu, Z. Wu, Z. Li, K. Jee, J. Rhee, X. Xiao, F. Xu, H. Wang, and G. Jiang, "High fidelity data reduction for big data security dependency analyses," in Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security, ser. CCS '16. New York, NY, USA: ACM, 2016, pp. 504-516. [Online]. Available: http://doi.acm.org/10.1145/2976749.2978378 DevOps Pipeline Safety Engineering Big Data systems are increasingly built using DevOps teams are provided with DevOps teams routinely Add to Level 2: DevOps CD DevOps pipelines. The Big Data DevOps indoctrination for enterprise-wide incorporate safety elements in pipeline integrates safety pipeline incorporates safety concerns. safety frameworks for SnP. Scrum scrums and refer to the Big Data constraints, violation masters and product owners SnP Elements by name. detection, monitoring, recognize which products and Elements can be tested and transparency, operational services are typically associated releases can be failed by citing resource simulation. with the safety concerns of the safety thresholds by element. enterprise. Selected References A. Froehlich, "Your big data strategy needs DevOps," Information Week, Feb. 2017. [Online]. Available: http://www.informationweek.com/big- data/your-big-data-strategy-needs-devops/a/d-id/1328184 Disaster Planning and Information Sharing The focus for disaster planning writ in general Community-level collaboration, Explicit model for DR and Fully tested environment for tends to be returning to full availability. Big such as generator-sharing, information sharing across digital information sharing, Data disaster planning must address the carpooling contingencies, and other domains, especially geospatial. e.g., XchangeCore, but fully impact of both lost availability and the impact "manual" plans. Automation is typically partial, integrated with SnP domain of massive breaches such as the OPM and with domain SnP only partially and utility models. Yahoo breaches. enumerated. 79 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY Brief Description Safety Level 1 Safety Level 2 Safety Level 3 Disaster Recovery (DR) Recovering from a Big Data system outage Written DR plan which Same as Level 3 but only Complete integration of DR can require measures beyond those required encompasses human and partially automated. plan with automated for smaller systems, as demonstrated by a computing infrastructure. Loosely connections to resilience 2017 AWS outage. In addition, DR plans must connected to domain and utility apparatus, human and include remediation of weakened or lost models. computing infrastructure. privacy, notification of affected parties, and Domain and utility models are mandated regulatory actions. part of system creation. Selected References Amazon_Web_Services, "Summary of the amazon s3 service disruption in the northern Virginia (US-EAST-1) region," Amazon Web Services Blog, Mar. 2017. [Online]. Available: https://aws.amazon.com/message/41926/ Domain model interoperability Big Data tends to move across organizational, Ability to produce SnP metrics, Partial automation of domain- Fully automated and even national boundaries. Because of this, alerts and to consume external specific interoperability exists, standards-based safety within a domain is strengthened when intelligence applicable to the e.g., SEC compliance, HIPAA interoperability at the highest the domain models minimize idiosyncratic domain. Some or all are manual. compliance. Explicit policies level supported by the domain constructs. mandating crosswalk to third or a fully elaborated scenario, party or industry standard e.g., HL7 FHIR. domain models (e.g., EHR, FIBO). Selected References X. Q. Huang, K. D. Zhang, C. Chen, Y. J. Cao, and C. Q. Chen, "Study on the integration architecture of electric power big data based on four kinds of integration patterns," in 10th International Conference on Advances in Power System Control, Operation Management (APSCOM 2015), Nov. 2015, pp. 1-6. [Online]. Available: http://dx.doi.org/10.1049/ic.2015.0234 80 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY Brief Description Safety Level 1 Safety Level 2 Safety Level 3 Explicit, reusable design patterns for SnP process orchestration Big Data systems may employ automated Enterprise standards are in place to Orchestration processes Same as Level 2, but with live orchestration practices. When used, identify how SnP is to be incorporate SnP practices that references to domain, app and orchestration is enhanced by SnP design orchestrated when containers or are integrated with utility models. patterns that script, test, and audit other methods are used to deploy infrastructure management orchestration using Big Data infrastructure, computing resources. Processes are (service management) as well as often mirroring underlying domain structures. largely manual or checklist- IDEs. Test engineering verifies oriented. compliance post-deployment. Selected References Luo and M. B. Salem, "Orchestration of software-defined security services," in 2016 IEEE International Conference on Communications Workshops (ICC), May 2016, pp. 436-441. [Online]. Available: http://dx.doi.org/10.1109/ICCW.2016.7503826 B. Pariseau, "EBay to bottle its special sauce for kubernetes management," Search Target IT Operations, May 2017. [Online]. Available: http://searchitoperations.techtarget.com/news/450419112/EBayto-bottle-its-special-sauce-for-Kubernetes-management N. Rathod and A. Surve, "Test orchestration a framework for continuous integration and continuous deployment," in 2015 International Conference on Pervasive Computing (ICPC), Jan. 2015, pp. 1-5. [Online]. Available: http://dx.doi.org/10.1109/PERVASIVE.2015.7087120 (repeated above) Exposure-limiting risk operations While there will be exceptions, the Big Data Closely managed RBAC and Same as Level 3 but only Big Data framework for safety framework eschews the aggregation of ABAC policies used in tandem that partially automated. limited access tightly PII/PCI in single, massive repositories using limit the scope of access and the integrated with live, Hadoop, SQL or any other technology. This is duration of access, taking into automated connections to especially true for identity and authentication account levels of risk associated domain, utility, application support systems. with usage patterns models. IDEs surface risk levels associated with specific application functions to developers and testers. Selected References W. H. Winsborough, A. C. Squicciarini, and E. Bertino, "Information carrying identity proof trees," in Proceedings of the 2007 ACM Workshop on Privacy in Electronic Society, ser. WPES '07. New York, NY, USA: ACM, 2007, pp. 76-79. [Online]. Available: http://doi.acm.org/10.1145/1314333.1314348 81 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY Brief Description Safety Level 1 Safety Level 2 Safety Level 3 Fully leveraged network layer SnP, including SDN A property of Big Data systems is that they Using traditional data center Partial use of SDN to limit SDN microsegmentation fully tend to be challenging to back up using the governance, leverages network access, especially for SnP data integrated with SDLC, design, usual methods. Thus, their storage filtering and DMZ to restrict, elements and when OpenStack test, resilience, forensics. requirements tend to favor network layer monitor, scale, manage access. is an option. Maturing SDN is leveraged to isolate isolation practices to enhance SnP. Limited if any use of SDN itself. collaboration between code and data and is used both Applications vary, but the method is being application and infrastructure by app teams and studied for 5G networks and vehicular teams to plan resilience and infrastructure specialists networks, for instance. secure platforms for apps. together rather than separately, relying on common domain, app and utility models. Selected References S. Marek, "How does Micro-Segmentation help security? explanation," SDx Central, 2017. [Online]. Available: https://www.sdxcentral.com/sdn/network-virtualization/definitions/how-does-microsegmentation-help-security-explanation/ L. Cui, F. R. Yu, and Q. Yan, "When big data meets software-defined networking: SDN for big data and big data for SDN," IEEE Network, vol. 30, no. 1, pp. 58-65, Jan. 2016. [Online]. Available: http://dx.doi.org/10.1109/MNET.2016.7389832 Information Assurance resilience engineering Engineering Big Data systems for resilience is Fallback plan(s) with written Same as Level 3 but only Automated playbooks fully required to provide the Assurance dimension playbooks for Big Data breaches partially automated. integrated with domain and of Big Data information safety. For instance, or loss of service. Plans are utility models. Some full redundancy may not be affordable or principally manual with checklists assurance claims can be tested feasible for some systems, whereas other Big and not subject to automated test. using continuously deployed Data systems can leverage sharded test frameworks on Big Data cloud/premise storage. platforms. HCI includes a transparent fully enumerated mix of machine and human test points. 82 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY Brief Description Safety Level 1 Safety Level 2 Safety Level 3 Integration of domain- and utility SnP models Domain models are specific to subjects such Models used for domain and/or Same as Level 3 but only Complete integration of the as healthcare or education scenarios. Utility cross-domain utilities (e.g., help partially automated. Big Data safety system with models address cross-domain practices such as desk, SAN representation) but are domain and utility models. storage management, passwords, containers, not cross-linked Advanced systems utilize access tokens, keys, certificates, DRM, ontologies or other explicit encryption at rest/in transit. Safety improves model representations of as these two types are integrated. security and privacy concepts through methods such as Domain Driven Development, Domain Specific Languages, or other techniques in support of domain-aware safety engineering. Integrated with test and management systems including simulation and DevOps continuous deployment processes for security and privacy frameworks. Selected References D. Zage, K. Glass, and R. Colbaugh, "Improving supply chain security using big data," in 2013 IEEE International Conference on Intelligence and Security Informatics, Jun. 2013, pp. 254-259. [Online]. Available: http://dx.doi.org/10.1109/ISI.2013.6578830 L. Obrst, P. Chase, and R. Markeloff, "Developing an ontology of the cyber security domain," in Proceedings of the Seventh International Conference on Semantic Technologies for Intelligence, Defense, and Security, P. C. G. Laskey and K. B. Laskey, Eds. CEUR, Oct. 2012, pp. 49-56. [Online]. Available: http://ceur-ws.org/Vol-966/ S. Fenz, "Ontology-based generation of IT-security metrics," in Proceedings of the 2010 ACM Symposium on Applied Computing, ser. SAC '10. New York, NY, USA: ACM, 2010, pp. 1833-1839. [Online]. Available: http://dx.doi.org/10.1145/1774088.1774478 83 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY Brief Description Safety Level 1 Safety Level 2 Safety Level 3 Integration of IoT scenarios, models IoT scenarios vary greatly from smart city Using traditional governance Loosely coupled IoT SnP IoT SnP model fully designs to wearable medical devices. IoT Big frameworks, an IoT model for the models allowing for partial integrated with domain and Data, poised to become one of the Biggest of system has been designed with integration with domain-specific utility models. Big Data, requires integration of sensor and separate models for sensors, and utility models for the big processing models. transducers, relays, protocols, and data application. other elements. Selected References D. Geneiatakis, I. Kounelis, R. Neisse, I. Nai-Fovino, G. Steri, and G. Baldini, "Security and privacy issues for an IoT based smart home," in 2017 40th International Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO), May 2017, pp. 1292-1297. [Online]. Available: http://dx.doi.org/10.23919/MIPRO.2017.7973622 M. A. Underwood, Big Data Complex Event Processing for Internet of Things Provenance: Benefits for Audit, Forensics and Safety. Hoboken NJ: Wiley, Nov. 2016, ch. 8. [Online]. Available: http://www.wiley.com/WileyCDA/WileyTitle/productCd-1119193869,subjectCd-EE23.html M. Underwood, M. Gruninger, L. Obrst, K. Baclawski, M. Bennett, G. Berg-Cross, T. Hahmann, and R. D. Sriram, "Internet of things: Toward smart networked systems and societies." Applied Ontology, vol. 10, no. 3-4, pp. 355-365, 2015. [Online]. Available: http://dblp.uni- trier.de/db/journals/ao/ao10.html#UnderwoodGOBBBH15 C. Jouvray, S. Gerard, F. Terrier, S. Bouaziz, and R. Reynaud, "Smart sensor modeling with the UML for real-time embedded applications," in IEEE Intelligent Vehicles Symposium, 2004, Jun. 2004, pp. 919-924. [Online]. Available: http://dx.doi.org/10.1109/IVS.2004.1336508 N. Foukia, D. Billard, and E. Solana, "PISCES: A framework for privacy by design in IoT," in 2016 14th Annual Conference on Privacy, Security and Trust (PST), Dec. 2016, pp. 706-713. [Online]. Available: http://dx.doi.org/10.1109/PST.2016.7907022 84 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY Brief Description Safety Level 1 Safety Level 2 Safety Level 3 Integration of key management practices with domain models Tokenization and key management practices Adoption of key management Key management is partially Fully integrated key are frequently central to managing proper practices to manage federated integrated with domain, app and management with domain, access to systems and data, especially across entities with manual transparency utility models. app and utility models. enterprises. The Big Data safety framework and audit. Testing is automated when advises the use of workflow-specific, domain- continuous deployment is specific, least-privilege distributed access practiced using Big Data patterns, using the temporally restricted frameworks. ('leased") permissions with full audit and traceability. Selected References R. Alguliyev and F. Abdullayeva, "Development of risk factor management method for federation of clouds," in 2014 International Conference on Connected Vehicles and Expo (ICCVE), Nov. 2014, pp. 24-29. [Online]. Available: http://dx.doi.org/10.1109/ICCVE.2014.7297548 D. R. dos Santos, S. Ranise, L. Compagna, and S. E. Ponta, Assisting the Deployment of Security-Sensitive Workflows by Finding Execution Scenarios. Cham: Springer International Publishing, 2015, pp. 85-100. [Online]. Available: http://dx.doi.org/10.1007/978-3-319-20810-7_6 Integration of risk models with CMDB at scale By definition, Big Data systems at scale may Mature risk management, mature Deployed CMDB, with semi- Fully integrated CMDB, risk, persist longer and accrue complexity at a configuration management automated connectivity / domain and utility models faster pace than other computation. Risk automated CMDB practices, but interoperability with domain across IDE, management, models can be integrated with domain and separately maintained from other and utility models administration, and forensics. utility models to accommodate configuration models. changes, especially in federation, key management, resilience strategies. Selected References J. Whyte, A. Stasis, and C. Lindkvist, "Managing change in the delivery of complex projects: Configuration management, asset information and 'big data'," International Journal of Project Management, vol. 34, no. 2, pp. 339-351, 2016. [Online]. Available: http://www.sciencedirect.com/science/article/pii/S0263786315000393 85 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY Brief Description Safety Level 1 Safety Level 2 Safety Level 3 Model-based simulation to assess security and risk at Big Data scale Big Data safety systems should incorporate ModSim is employed to identify ModSim is used for both Simulation processes fully simulation capabilities so that SnP issues with usability, scalability, infrastructure planning and integrated into Phase D and I, considerations with deployment—not manageability, and interoperability management as part of DevOps. and referencing domain and excluding HCI—can be simulated. of an app's SnP capabilities. Simulations are used to forecast utility models. Interoperability additional requirements for new with third-party models for applications, infrastructure environmental, geospatial, changes, mergers and biomedical (e.g., SNOMED) acquisitions, and staffing models is practiced. reductions. Selected References S. Schmidt, R. Bye, J. Chinnow, K. Bsufka, A. Camtepe, and S. Albayrak, "Application-level simulation for network security," SIMULATION, vol. 86, no. 5-6, pp. 311-330, May 2010. [Online]. Available: http://dx.doi.org/10.1177/0037549709340730 D. D. Dudenhoeffer, M. R. Permann, and E. M. Sussman, "General methodology 3: a parallel simulation framework for infrastructure modeling and analysis," in WSC '02: Proceedings of the 34th conference on Winter simulation. Winter Simulation Conference, 2002, pp. 1971-1977. 86 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY Brief Description Safety Level 1 Safety Level 2 Safety Level 3 Model-based systems engineering (MBSE) development practices MBSE is an approach to software engineering Post hoc models of legacy Hybrid: some legacy, some Defensive, surveillance, other which relies on abstract representations of applications, with views created by greenfield microservices design measures fully integrated into code. Security and privacy concepts for Big SMEs. Models are not directly patterns constructed using domain, utility and Data are best integrated with models vs. add- interoperable or communicating. model-based systems application models. Forensics, on, sandbox and "perimeter defense" engineering practices. Models IDE, test frameworks, SnP methods—though it does not exclude other are implemented with partial fully interoperable and live. software-building methods even within the integration across domain, same system. utility, application models. Selected References M. Borek, K. Stenzel, K. Katkalov, and W. Reif, "Abstracting security-critical applications for model checking in a model-driven approach," in 2015 6th IEEE International Conference on Software Engineering and Service Science (ICSESS), Sep. 2015, pp. 11-14. [Online]. Available: http://dx.doi.org/10.1109/ICSESS.2015.7338996 Estefan, J. 2008. Survey of Candidate Model-Based Systems Engineering (MBSE) Methodologies, rev. B. Seattle, WA, USA: International Council on Systems Engineering (INCOSE). INCOSE-TD-2007-003-02. Accessed April 13, 2015 at http://www.omgsysml.org/MBSE_Methodology_Survey_RevB.pdf A. Ross, "Interactive Model-Centric systems engineering," in 6th Annual SERC Sponsor Research Review, Georgetown University. Washington DC: Systems Engineering Institute, Dec. 2014. D. C.Schmidt, "Guest editor's introduction: Model-Driven engineering," Computer, vol. 39, no. 2, pp. 25-31, Feb. 2006. [Online]. Available: http://dx.doi.org/10.1109/mc.2006.58 A. Endert, S. Szymczak, D. Gunning, and J. Gersh, "Modeling in big data environments," in Proceedings of the 2014 Workshop on Human Centered Big Data Research, ser. HCBDR '14. New York, NY, USA: ACM, 2014. [Online]. Available: http://doi.acm.org/10.1145/2609876.2609890 R. Perry, M. Bandara, C. Kutay, and F. Rabhi, "Visualising complex event hierarchies using relevant domain ontologies: Doctoral symposium," in Proceedings of the 11th ACM International Conference on Distributed and Event-based Systems, ser. DEBS '17. New York, NY, USA: ACM, 2017, pp. 351-354. [Online]. Available: http://doi.acm.org/10.1145/3093742.3093901 87 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY Brief Description Safety Level 1 Safety Level 2 Safety Level 3 Models for Big Data provenance Whether for machine learning classifiers, data Provides explicit organizational Provenance is built into the Employ tools such as PROV- lineage, or other notions of provenance, Big guidance about the use of ML tools SDLC process through reusable O to manage and trace Data systems may require representations that and training datasets. libraries and requirements provenance. For IoT, track data sources, transport. Some have engineering. Test frameworks integration with the W3C proposed that this must encompass retaining check for provenance flow and PROV family of provenance the binaries and network traffic for entire integrity and exception metadata. Directly collection events. detection is an objective of Big incorporates domain, app, and Data monitoring. Monitoring in utility models where this setting applies primarily to applicable, and leverages SnP elements. results from industry- or domain-wide simulations. Selected References K. Taylor, R. Woodcock, S. Cuddy, P. Thew, and D. Lemon, A Provenance Maturity Model. Cham: Springer International Publishing, 2015, pp. 1-18. [Online]. Available: http://dx.doi.org/10.1007/978-3-319-15994-2_1 P. Missier, K. Belhajjame, and J. Cheney, "The W3C PROV family of specifications for modelling provenance metadata," in Proceedings of the 16th International Conference on Extending Database Technology, ser. EDBT '13. New York, NY, USA: ACM, 2013, pp. 773-776. [Online]. Available: http://dx.doi.org/10.1145/2452376.2452478 L. Moreau, J. Freire, J. Futrelle, R. Mcgrath, J. Myers, and P. Paulson, "The open provenance model: An overview," 2008, pp. 323-326. [Online]. Available: http://dx.doi.org/10.1007/978-3-540-89965-5_31 ModSim for security operations scalability Use of Modeling and Simulation (ModSim) Occasional use of ModSim to Plans are deployed which Same as Level 2, but with live for assessing the impact of scaling SnP Big support Big Data security routinely employ ModSim to connections to domain, Data systems. For DevOps, this has a more operations. estimate and forecast security application, and utility specialized meaning. operations as new applications, models. Application data centers, and technologies onboarding includes planning are onboarded. for ModSim support infrastructure including HR. Selected References S. Jain, C. W. Hutchings, Y. T. Lee, and C. R. McLean, "A knowledge sharing framework for homeland security modeling and simulation," in Proceedings of the 2010 Winter Simulation Conference, Dec. 2010, pp. 3460-3471. [Online]. Available: http://dx.doi.org/10.1109/WSC.2010.5679035 J. Kolodziej, H. González-Vélez, and H. D. Karatza, "High-performance modelling and simulation for big data applications," Simulation Modelling Practice and Theory, vol. 76, pp. 1-2, 2017, high-Performance Modelling and Simulation for Big Data Applications. [Online]. Available: http://www.sciencedirect.com/science/article/pii/S1569190X17300722 88 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY Brief Description Safety Level 1 Safety Level 2 Safety Level 3 PII identification practices Transparent, adaptable practices for Big Data Provides a user portal for Systematic approach to PII error In addition to Level 2, adds identification of PII should address safety by submitting claims of error or with automated and manual self-checking and self- allowing for remediation (misidentification), misinformation with manual methods to detect error or correcting methods with audit. continuous improvement of identification methods for remediation. spillage of misinformation Remediation is supported with process, and Big Data records retention. outside system boundaries. forwarding to downstream data consumers. Selected References R. Herschel and V. M. Miori, "Ethics & big data," Technology in Society, vol. 49, pp. 31-36, 2017. [Online]. Available: http://www.sciencedirect.com/science/article/pii/S0160791X16301373 PII vulnerability management PII (or "privacy") vulnerability management CFO designated with internal Enterprise has implemented a Using Big Data or other tools adopts principles from software vulnerability privacy controls and guidelines for PII/PCI vulnerability to test for PII leakage, detection and remediation, plus other federated entities. No separate management resource on a par including external techniques, and applies them to protecting PII. Vulnerability Management for PII with its traditional VM SecOps nonfederated entities. Same as resource. and software assurance Level 2, but integrated with capabilities. domain, app, and utility models to accelerate risk detection. Selected References N. J. King and J. Forder, "Data analytics and consumer profiling: Finding appropriate privacy principles for discovered data," Computer Law & Security Review, vol. 32, no. 5, pp. 696-714, 2016. [Online]. Available: http://www.sciencedirect.com/science/article/pii/S0267364916300802 B. Austin, "When to use PII discovery in the audit process," Solarwinds MSP, Apr. 2014. [Online]. Available: https://www.solarwindsmsp.com/blog/when-to-use-pii-discovery-in-the-audit-process 89 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY Brief Description Safety Level 1 Safety Level 2 Safety Level 3 PII/PCI isolation For some Big Data systems, safety Separate "files" or tables for Separation is integrated with Workflow model controls engineering requires separation of PII/PCI designated PII data and code. test and assurance frameworks time windows, total exposure from other data elements. Separation can be with regular "penetration" to PII using a Geiger counter- achieved through a variety of technologies, testing using Big Data variety style avoidance model. Self- including SDN. techniques. Partial integration monitoring according to with domain models. embedded models. Automated testing using domain-specific test and assurance frameworks in continuous deployment. Some advanced safety frameworks may support user- configured privacy protections and notifications. Selected References M. Li, W. Zang, K. Bai, M. Yu, and P. Liu, "MyCloud: Supporting user-configured privacy protection in cloud computing," in Proceedings of the 29th Annual Computer Security Applications Conference, ser. ACSAC '13. New York, NY, USA: ACM, 2013, pp. 59-68. [Online]. Available: http://doi.acm.org/10.1145/2523649.2523680 PII/PCI Toxicity orientation and traceability The Big Data SnP safety framework positions Written policies and procedures are PII/PCI toxicity concept is fully Big Data analytics used to PII/PCI data to be handled with information in place, which treat PII/PCI integrated into the security "penetration-test" aggregated systems analog to the chemical industry's disclosure as safety risks. culture, but crosswalk to data with automated alerts. Material Safety Data Sheets. Traceability is Automation is minimal. domain, app, and utility models Automated crosswalk of toxic required, just as chain of custody is traced for is not automated. MSDS for data elements in domain, app, certain class of prescription medications. data elements are integrated into and utility models with enterprise business glossaries, MSDS-like processes fully data catalogs. automated. Selected References M. Benchoufi, R. Porcher, and P. Ravaud, "Blockchain protocols in clinical trials: Transparency and traceability of consent [version 1; referees: 1 approved, 1 not approved]," F1000Research, vol. 6, no. 66, 2017. [Online]. Available: http://dx.doi.org/10.12688/f1000research.10531.1 90 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY Brief Description Safety Level 1 Safety Level 2 Safety Level 3 Policies for data or performance uncertainty, error and quality management for Big Data The ability to ingest massive amounts of data Rough measures of uncertainty / Explicit, software-based alerts Automated alerts are raised ensures that the absolute number of erroneous error communicated to providers for error and data quality when tools (e.g., machine or faulty data will also be ingested. The safety and consumers. Can be integrated assurance. Some level of self- learning) attempt to make framework requires inclusion of policies to with quality management systems. healing processes is in place inferences that violate address management of uncertainty and error. Largely manual, using checklists. that operates in tandem with statistical or regulatory data quality metrics and guidelines and are alerted stewardship. according to protocols and importance determined by domain, app, and utility models delivered in automated format. Selected References J. Bendler, S. Wagner, T. Brandt, and D. Neumann, "Taming uncertainty in big data," Business & Information Systems Engineering, vol. 6, no. 5, pp. 279-288, Oct. 2014. [Online]. Available: http://dx.doi.org/10.1007/s12599-014-0342-4 J. R. Busemeyer, "Decision making under uncertainty: a comparison of simple scalability, fixed-sample, and sequential-sampling models." J Exp Psychol Learn Mem Cogn, vol. 11, no. 3, pp. 538-564, Jul. 1985. [Online]. Available: http://view.ncbi.nlm.nih.gov/pubmed/3160815 Safety Orientation As with the 1988 Challenger accident, Systematic use of safety Failure analytics applied to Safety metrics integrated into breaches of Big Data systems (especially terminology, personnel orientation, SDLC: e.g., Failure Mode and IDEs, performance cloud-based, but IoT systems are likely to third-party safety standards and Effects Analysis (FMEA), Fault monitoring, simulation, suffer a similar fate) should result in remediation planning. Capture Tree Analysis (FTA), Failure domain models. Agile team investments in a safety engineering culture. failure events related to Big Data Modes Effects and Diagnostic peering routinely considers The same must be true for Big Data system analytics, processes. Most Analysis (FMEDA). Related safety engineering. Fully architects, managers, and users. processes are manual, using monitoring and simulation is integrated supply chain safety checklists and orientation. partially automated. engineering. Selected References M. Broy, C. Leuxner, and T. Hoare, Eds., Software and Systems Safety - Specification and Verification, ser. NATO Science for Peace and Security Series - D: Information and Communication Security. IOS Press, 2011, vol. 30. [Online]. Available: http://dx.doi.org/10.3233/978-1-60750-711-6 91 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY Brief Description Safety Level 1 Safety Level 2 Safety Level 3 Semantic Web / Linked Data Awareness Some Big Data systems, arguably all, should A knowledge engineering Adds to Level 1: Use of RDC or Adds direct links to domain- map their elements to the semantic web using framework, typically manually OWL to represent SnP and specific and upper ontologies canonical structures such as ontologies. The maintained through tagging or related components. Allows for so that reasoning, for instance, semantic web supports artificial intelligence concept trees, is provided to allow automated reasoners and other about which test scenarios test through inductive reasoning as well as for recognition of SnP components. AI tools to be employed to which sorts of aspects of the machine learning. Big Data architects and May or may not be implemented manage knowledge about SnP SnP design, can be users should consider safety aspects of these using semantic web standards; issues in the Big Data system. automatically interrogated and technologies could be COTS or open source but scheduled. idiosyncratic. Selected References Y. Pandey and S. Bansal, "Safety check: A semantic web application for emergency management," in Proceedings of The International Workshop on Semantic Big Data, ser. SBD '17. New York, NY, USA: ACM, 2017. [Online]. Available: http://doi.acm.org/10.1145/3066911.3066917 92 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY Brief Description Safety Level 1 Safety Level 2 Safety Level 3 SnP for Location-based Services Big Data Variety can facilitate Checklists and other manual Protections and monitoring Geospatial reasoning deanonymization. Often Variety comes from processes are in place to support capabilities are in place to integrated into Big Data IDE, mobile device-enabled geospatial data sources. risks and/or planned usage of manage geospatial data sources, SDLC with live links to Some applications must mitigate and educate geospatial data. Includes Big Data including those used by third domain, utility, and app regarding the impact of geospatial Big Data. variety and current or potential parties, customers, or partners to models. Proactive detection Other applications may require geospatial Big mobile data sources. perform unauthorized and advisories identify risk Data as an essential resource, such as deanonymization. areas for users, developers, Emergency Management. and managers through process and automated links to domain, app, and utility models. Selected References UN-GGIM, "A guide to the role of standards in Geospatial information management," UN Committee of Experts on Global Geospatial Information Management, Aug. 2015. [Online]. UN-GGIM, "A guide to the role of standards in Geospatial information management," UN Committee of Experts on Global Geospatial Information Management, Aug. 2015. [Online]. Available: http://kbros.co/2ulVyQv K. Liu, Y. Yao, and D. Guo, "On managing geospatial big-data in emergency management: Some perspectives," in Proceedings of the 1st ACM SIGSPATIAL International Workshop on the Use of GIS in Emergency Management, ser. EM-GIS '15. New York, NY, USA: ACM, 2015. [Online]. Available: http://doi.acm.org/10.1145/2835596.2835614 S. Sadri, Y. Jarraya, A. Eghtesadi, and M. Debbabi, "Towards migrating security policies of virtual machines in software defined networks," in Proceedings of the 2015 1st IEEE Conference on Network Softwarization (NetSoft), Apr. 2015, pp. 1-9. [Online]. Available: http://dx.doi.org/10.1109/NETSOFT.2015.7116165 E. Bertino, B. Thuraisingham, M. Gertz, and M. L. Damiani, "Security and privacy for geospatial data: Concepts and research directions," in Proceedings of the SIGSPATIAL ACM GIS 2008 International Workshop on Security and Privacy in GIS and LBS, ser. SPRINGL '08. New York, NY, USA: ACM, 2008, pp. 6-19. [Online]. Available: http://doi.acm.org/10.1145/1503402.1503406 93 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY Brief Description Safety Level 1 Safety Level 2 Safety Level 3 Support for user annotation, notification, advisories To address user and enterprise safety Web-based resources with Annotations are connected to Annotation capabilities are concerns, a Big Data system should support annotation resources which persist the domain and app models. connected with domain, app, consumer, "user," subscriber natural language across user sessions. Notifications can be user and and utility models. Data annotations, notifications, and explanations. system-managed and respond to collected is used for SnP Notifications should be treated by analogy internal and external SnP threat process improvement / with food recall and safety notices, but survive or warnings. refactoring. Notifications and according to Big Data planning horizons. self-managed with support for multiple channels. Must also support consent forwarding, persistence, transfer, withdrawal. Selected References S. Szymczak, D. J. Zelik, and W. Elm, "Support for big data's limiting resource: Human attention," in Proceedings of the 2014 Workshop on Human Centered Big Data Research, ser. HCBDR '14. New York, NY, USA: ACM, 2014. [Online]. Available: http://doi.acm.org/10.1145/2609876.2609887 J. Schaffer, P. Giridhar, D. Jones, T. Höllerer, T. Abdelzaher, and J. O'Donovan, "Getting the message? A study of explanation interfaces for microblog data analysis," in Proceedings of the 20th International Conference on Intelligent User Interfaces, ser. IUI '15. New York, NY, USA: ACM, 2015, pp. 345-356. [Online]. Available: http://dx.doi.org/10.1145/2678025.2701406 E. U. Weber, "Risk attitude and preference," Wiley Interdisciplinary Reviews: Cognitive Science, vol. 1, no. 1, pp. 79-88, 2010. [Online]. Available: http://dx.doi.org/10.1002/wcs.5 94 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY Brief Description Safety Level 1 Safety Level 2 Safety Level 3 System "Read-In" Process In intelligence circles, being "read into" a Persistent, career-long record of Level 1 plus: spans multiple Big Data identity program formalizes the training associated individual employee access to Big employers and tracks roles management, RBAC, ABAC with a compartmented program. This feature Data resources. Explicit read-in as assigned to employees (e.g., fully integrated with "Where serves an analogous purpose for Big Data part of employee and team member infrastructure, project manager, used" functionality, use of ML systems: people are read into the Big Data onboarding. Exit interviews include scrum master, developer, QA) or AI to detect insider threat risks and guidelines of the program when they offboarding, such as cautions within a Big Data System. Adds at the application level. are onboarded to the project. against unauthorized information "read out" when employees Offboarding process is part of sharing. leave that changes the Big Data the IDE and app teams configuration beyond mere regularly build ABAC-aware password expiration. onboarding and offboarding roles as part of app domain. Domain and utility models are utilized in real time. Selected References S. Zehra Haidry, K. Falkner, and C. Szabo, "Identifying Domain-Specific cognitive strategies for software engineering," in Proceedings of the 2017 ACM Conference on Innovation and Technology in Computer Science Education, ser. ITiCSE '17. New York, NY, USA: ACM, 2017, pp. 206-211. [Online]. Available: http://doi.acm.org/10.1145/3059009.3059032 S. Link, P. Hoyer, T. Kopp, and S. Abeck, "A Model-Driven development approach focusing human interaction," International Conference on Advances in Computer-Human Interaction, vol. 0, pp. 90-96, 2009. Y. Takahashi, T. Abiko, E. Negishi, G. Itabashi, Y. Kato, K. Takahashi, and N. Shiratori, "An Ontology-Based e-Learning system for network security," AINA, vol. 01, pp. 197-202, 2005. System/SW/Fingerprinting (Big Data CM) Big Data systems should leverage scale, App designs incorporate Add to Level 1: Automatic Adds live connection to velocity, and variety to automatically capture fingerprinting of key app events, connection to CMDB with domain and utility models to event information, such as version and such as adding a new employee to transparent updating. IDEs Level 2 conformance. timestamping at the moment of data capture, an HR system. Level 1 goes include workflow design e.g., the instance of medication dispensing beyond mere logging of database patterns for key app events that should capture all relevant details, not only accesses. include full Big Data patient, drug, and timestamp. fingerprinting. Selected References C. Dincer, G. Akpolat, and E. Zeydan, "Security issues of big data applications served by mobile operators," in 2017 25th Signal Processing and Communications Applications Conference (SIU), May 2017, pp. 1-4. [Online]. Available: http://dx.doi.org/10.1109/SIU.2017.7960253 95 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY Brief Description Safety Level 1 Safety Level 2 Safety Level 3 Temporal authority traceability A working assumption for Big Data systems is No point-in-time traceability for Integrated point-in-time Full point-in-time and replay that data persists, might be never archived, and authority, but role auditing is authority traceability capturing capability (may imply full represents a steady trend toward limitless, performed. authority metadata and events packet and EXE capture). low-cost storage. Thus, traceability for Big using Big Data infrastructure. Traceability expands beyond Data granting authority for design, use, and single enterprises, and is administrative policies must span integrated with domain, app, infrastructure in ways that non-Big Data and utility models. systems did not. Selected References S. Maro, A. Anjorin, R. Wohlrab, and J.-P. Steghöfer, "Traceability maintenance: Factors and guidelines," in Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering, ser. ASE 2016. New York, NY, USA: ACM, 2016, pp. 414-425. [Online]. Available: http://doi.acm.org/10.1145/2970276.2970314 Test Engineering for SnP aspects across Big Data platforms Test engineering for Big Data is needed to Test engineering for SnP includes Enterprise-wide SDLC practices In addition to Level 2, adds ensure that SnP measures can scale across manual checklists (e.g., NIST support test engineering. ability to automatically create both human (taking into account human and Cybersecurity Framework) plus Developers routinely create test test scripts for SnP elements enterprise constraints) and computer scripts to test compliance with SnP frameworks for SnP within the IDE, directly constraints. (See also Big Data Dev Ops and requirements. components using both off-the- referencing domain, app, and Continuous Deployment.) shelf, reusable components and utility models to guide test app-specific tools. behavior. Test engineering frameworks are available to support audit and forensics activities. Selected References J. G. Enr'ıquez, R. Blanco, F. J. Dom'ınguez-Mayo, J. Tuya, and M. J. Escalona, "Towards an MDE-based approach to test entity reconciliation applications," in Proceedings of the 7th International Workshop on Automating Test Case Design, Selection, and Evaluation, ser. A-TEST 2016. New York, NY, USA: ACM, 2016, pp. 74-77. [Online]. Available: http://doi.acm.org/10.1145/2994291.2994303 N. Garg, S. Singla, and S. Jangra, "Challenges and techniques for testing of big data," Procedia Computer Science, vol. 85, pp. 940-948, 2016, international Conference on Computational Modelling and Security (CMS 2016). [Online]. Available: http://www.sciencedirect.com/science/article/pii/S1877050916306354 N. Rathod and A. Surve, "Test orchestration a framework for continuous integration and continuous deployment," in 2015 International Conference on Pervasive Computing (ICPC), Jan. 2015, pp. 1-5. [Online]. Available: http://dx.doi.org/10.1109/PERVASIVE.2015.7087120 96 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY Brief Description Safety Level 1 Safety Level 2 Safety Level 3 Use ABAC to improve safety Expanded use of ABAC, alone or in SDLC process explicitly states that ABAC is built into IDEs. Add to Level 2: ABAC is conjunction with traditional RBAC, as part of ABAC is to be used in conjunction Developers routinely identify directly linked to domain, domain model integration. with RBAC. Use of "admin" design appropriate RBAC metadata for app, and utility models. Test is deprecated. ABAC is manually SnP as well as for monitoring frameworks exercise ABAC tied to enterprise metadata and management. ABAC and attribute defense and management catalogs. Insider RBAC are parts of a merging vulnerabilities. Mature threat receives only light attention continuum. Level 2 sees a heavy scenarios exist for insider at Level 1 of ABAC reliance on domain experts to threat which are tied to the implementation. set ABAC requirements. ABAC use of Big Data systems to requirements include some detect as well as to mitigate insider threat consideration in risk. requirements development. Selected References V. C. Hu, D. Ferraiolo, R. Kuhn, A. Schnitzer, K. Sandlin, R. Miller, and K. Scarfone, "Guide to attribute based access control (ABAC) definition and considerations," NIST, Gaithersburg, MD, Tech. Rep. SP 800-162, Jan. 2014. [Online]. Available: http://dx.doi.org/10.6028/NIST.SP.800-162D. R. Kuhn, E. J. Coyne, and T. R. Weil, "Adding attributes to Role-Based access control," Computer, vol. 43, no. 6, pp. 79-81, Jun. 2010. [Online]. Available: http://dx.doi.org/10.1109/MC.2010.155 J. Longstaff and J. Noble, "Attribute based access control for big data applications by query modification," in 2016 IEEE Second International Conference on Big Data Computing Service and Applications (BigDataService), Mar. 2016, pp. 58-65. [Online]. Available: http://dx.doi.org/10.1109/BigDataService.2016.35 97 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY Brief Description Safety Level 1 Safety Level 2 Safety Level 3 Value Chain Traceability In Big Data systems, the value chain should be Explicit, readily available checklist Add to Level 1: Value Add to Level 2: direct link to preserved with the same priority that is given of values baked into the Big Data Requirements are present within domain, app and utility requirements traceability, e.g., the specialized system requirements that enable software traceability schemes models. code associated with "under test" scenarios in users and managers to trace system within the enterprise SDLC, the VW emissions software should be features to intentional SnP risks e.g., encryption and intentional traceable to the original specifications and and the levels of protection aggregation, classifiers in ML specifiers. afforded given the value are directly traceable to the proposition. For citizens, specific value proposition so that trade- statements of value with a plain offs and risks are visible. explanation of the benefits should inform documents such as Terms of Service. Selected References A. P. J. Mol, "Transparency and value chain sustainability," Journal of Cleaner Production, vol. 107, pp. 154-161, 2015. [Online]. Available: http://www.sciencedirect.com/science/article/pii/S0959652613007762 Heindl and S. Biffl, "A case study on value-based requirements tracing," in Proceedings of the 10th European Software Engineering Conference Held Jointly with 13th ACM SIGSOFT International Symposium on Foundations of Software Engineering, ser. ESEC/FSE-13. New York, NY, USA: ACM, 2005, pp. 60-69. [Online]. Available: http://doi.acm.org/10.1145/1081706.1081717 2820 2821 2822 98 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY Appendix B: Existing Standards in 2823 Relation to the Security and 2824 Privacy Fabric 2825 2826 The following table introduces concepts developed in selected existing standards. There is an intentional 2827 emphasis on privacy concepts, reflecting public and enterprise concerns about Big Data security and 2828 privacy. The third column, Security and Privacy Fabric, is directional and notional rather than definitive 2829 at this stage of the effort. The objective is to identify Security and Privacy Fabric-specific elements of the 2830 standards and the associated concepts cited. 2831 Table B-1: Terms and Standards in Relation to the Security and Privacy Fabric Security and Term Sources Comments Privacy Fabric Privacy disassociability NIST IR 8062 Privacy fabric for Needs refinement. “Enabling the purposes of this processing of PII or events without analysis association to individuals or devices beyond the operational requirements of the system.” Privacy subsystem NISTIR 8062 Needs refinement for Big Data predictability Privacy subsystem NISTIR 8062 TBD Needs refinement for Big Data manageability Role: privacy subsystem oversight Role: privacy subsystem operations Role: privacy Architect NISTIR 8062 groups ops & design. subsystem design responsibilities Separation is indicated. call-out Personal information “For the purpose of risk assessment, personal information is considered broadly as any information that can uniquely identify an individual as well as any other information, events, or behavior that can be associated with an individual. Where agencies are conducting activities subject to specific laws, regulation, or policy, more precise definitions may apply.” Privacy risk Roughly, adverse impact X likelihood of occurrence, scoped 99 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY Security and Term Sources Comments Privacy Fabric Privacy controls: administrative Privacy controls: technical Privacy controls: physical Adverse privacy event Privacy context: system Privacy engineering NISTIR 8062 Use for narrative “A specialty discipline of systems only. May not engineering focused on achieving have normative freedom from conditions that can value beyond create problems for individuals with describing unacceptable consequences that arise collection of from the system as it processes PII.” system features, workflow elements. Operationalizing domain-specific privacy is critical. NIST privacy risk NISTIR 8062 Section model 3.2 Privacy metasystem Draft NISTIR 8062 used “Summary issues Issues.” “Initial contextual analyses about data actions that may heighten or decrease the assessment of privacy risk.” Privacy attack vector Attack against Personal Information, a privacy subsystem, role, etc. Owner/originator System component, role or individual originating a data element. Access* NISTIR 7298r2, Includes access to NIST SP 800-32 workflow, orchestration Role: Access CNSSI-4009 Person or software authority* Access Control FIPS 201 ACL* FIPS 201, CNSSI- Consider local vs. 4009 global Big Data ACLs. How should this be integrated with ABAC? 100 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY Security and Term Sources Comments Privacy Fabric Access control CNSSI-4009 mechanism* Access type* Accountability NISTIR 7298 Grouped subprocesses: traceability, non-repudiation, deterrence, fault isolation, intrusion detection, intrusion prevention, after-action recovery, legal action. Active content NISTIR 7298r2 “Electronic documents that can carry out or trigger actions automatically on a computer platform without the intervention of a user. “ Active/passive security Big data testing exchanges will often entail passively tested, or passive assurance for exchanges between componentsf Administrative NISTIR 7298r2 Focus on mobile and inter- Safeguards organizational safeguards. Advisory Big Data may “Notification of significant new trends require a “new” or developments regarding the threat grouping of to the information systems of an advisories organization. This notification may include analytical insights into trends, intentions, technologies, or tactics of an adversary targeting information systems.” Privacy agent Program acting on There are some commercial startups behalf of person or that use agent-based approaches. organization to automate a privacy-related process f For example, identifying where there is no active testing available (e.g., encryption assurance). 101 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY Security and Term Sources Comments Privacy Fabric Allocation NIST SP 800-37 Useful for The process an organization employs workflow in to determine whether security controls determining are defined as system-specific, hybrid, privacy or common. responsibilities: The process an organization employs design-time, to assign security controls to specific governance-time information system components responsible for providing a particular security capability (e.g., router, server, remote sensor). Application NIST SP 800-37 How would a NBDRA app be different? Refer to the application model concept in the NBD-SPSL. Assessment NIST SP 800-53A Apply to NBDRA Grouping of terms: findings, method, privacy (also object, objective, procedure, Security sec?). How Control Assessor different from audit? Refer to audit in the NBD- SPSL. Assurance NIST SP 800-27, Is it possible to “Grounds for confidence that the other NIST SP 800-53A, map to Privacy four security goals (integrity, CNSSI-4009 Assurance (i.e., availability, confidentiality, and map to analogous accountability) have been adequately goals?) met by a specific implementation. “Adequately met” includes (1) functionality that performs correctly, (2) sufficient protection against unintentional errors (by users or software), and (3) sufficient resistance to intentional penetration or by-pass.” Assurance Case (for Is it possible to “A structured set of arguments and a privacy) map to Privacy body of evidence showing that an Assurance (i.e., information system satisfies specific map to analogous claims with respect to a given quality goals?). Also see attribute. “ below. Assured Information Analogy for “The ability to confidently share sharing privacy sharing information with those who need it, when and where they need it, as determined by operational need and an acceptable level of security risk.” 102 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY Security and Term Sources Comments Privacy Fabric Attack, sensing, Attack signature “Detection, correlation, identification, warning; attack for privacy is not and characterization of intentional signature (for the same as a unauthorized activity with notification privacy)g general attack to decision makers so that an appropriate response can be developed. “ Audit, audit data, Subset created for audit log, reduction privacy. Could be tools, audit review, a smaller problem audit trail to solve, or a larger one, depending.h Authentication Could be needed (various terms) to allow “owner” of privacy data to see or correct their own data. Authority Centralized vs. decentralized authority. See blockchain as a decentralization of authority. See federation. In most applications, highly domain- specific but there are cross- functional “authorities.” Authenticity Provenance Authorization Time-limited authorization to access, or use privacy data Authorization to Interop issues for Big Data concerning operate privacy data Automated privacy To Do Use of automated procedures to ensure monitoring that privacy controls are not circumvented or the use of these tools to track actions taken by subjects suspected of misusing the information system. g Useful: Notion of a privacy attack vector is a useful big data discriminator, and may be highly system-specific. h Audit for privacy could entail audit for a small subset of a larger database, or audit intended to verify that security or privacy controls are being enforced. 103 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY Security and Term Sources Comments Privacy Fabric Back door (privacy) Use of Big Data variety to circumvent privacy safeguards Baseline security (for The minimum privacy controls privacy controls) required for safeguarding an IT system based on its identified needs for confidentiality, integrity, and/or availability protection. Behavioral outcome Useful for cross- (for privacy fabric org privacy training) Biometric information Special concern for privacy in any system? Body of Evidence (for “The set of data that documents the security and privacy information system’s adherence to the controls adherence) security controls applied. The BoE will include a Requirements Verification Traceability Matrix (RVTM) delineating where the selected security and privacy controls are met and evidence to that fact can be found. The BoE content required by an Authorizing Official will be adjusted according to the impact levels selected. Refer to NIST 800-52 Section 2.3 (Rev 4).“ Boundary; boundary Boundaries may protection need to be clarified in the NBDRA Browsing (for identity info) Business impact “An analysis of an information assessment (for system’s requirements, functions, and privacy fabric) interdependencies used to characterize system contingency requirements and priorities in the event of a significant disruption.” Certificate (esp. CNSSI-4009 No different Certificate management may be identity certificate) meaning vs. different in privacy fabric when security, but individual citizens (including children) perhaps more are involved. urgent context? 104 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY Security and Term Sources Comments Privacy Fabric Certification (see also Identify a baseline “A comprehensive assessment of the baseline), certifier point at which management, operational, and privacy fabric technical security controls in an controls were information system, made in support applied & certified of security accreditation, to determine as operational the extent to which the controls are implemented correctly, operating as intended, and producing the desired outcome with respect to meeting the security requirements for the system.” Chain of Custody IoT plus Big Data “A process that tracks the movement for privacy of evidence through its collection, safeguarding, and analysis life cycle by documenting each person who handled the evidence, the date/time it was collected or transferred, and the purpose for the transfer.” Chain of Evidence IoT plus Big Data “A process and record that shows who for privacy. Same, obtained the evidence; where and but applied to when the evidence was obtained; who privacy data subset secured the evidence; and who had control or possession of the evidence. The “sequencing” of the chain of evidence follows this order: collection and identification; analysis; storage; preservation; presentation in court; return to owner.” Chief Privacy Officer To be adapted from other standards Classified information NIST SP 800-60, EO Adapt meaning (*privacy subset) 13292, CNSSI-4009 from U.S. mil to apply to privacy subset Classified (privacy) data spillage 105 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY Security and Term Sources Comments Privacy Fabric Clearance for access to Useful to identify “Formal certification of authorization privacy data or tools fabric roles to have access to classified (both?) permitted to access information other than that protected privacy data, or to in a special access program (including use re-identifying SCI). Clearances are of three types: tools. Obvious: confidential, secret, and top secret. A Data access, tools top-secret clearance permits access to access aren’t the top secret, secret, and confidential same. See access, material; a secret clearance, to secret authorization. and confidential material; and a confidential clearance, to confidential material.” Common Control / Across app and “A security control that is inherited by Security Control data providers one or more organizational Inheritance / Common possibly spanning information systems.” criteria organizations. “Common criteria” is a document for privacy fabric requirements Common Control Role responsible “An organizational official responsible Provider (role for for inherited for the development, implementation, privacy) privacy controls assessment, and monitoring of common controls (i.e., security controls inherited by information systems).” Common Misuse A rough metric for “A set of measures of the severity of Scoring System for potential privacy software feature misuse Privacy fabric weaknesses vulnerabilities. A software feature is a functional capability provided by software. A software feature misuse vulnerability is a vulnerability in which the feature also provides an avenue to compromise the security of a system.” Community of Interest A CoI may be a “A collaborative group of users who for privacy data class of users in exchange information in pursuit of the privacy fabric their shared goals, interests, missions, (e.g., tribal, or business processes, and who disabled, genetic therefore must have a shared abnormalities, vocabulary for the information they high medical cost) exchange. The group exchanges information within and between systems to include security domains.” 106 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY Security and Term Sources Comments Privacy Fabric Community risk for Add – privacy “Probability that a particular privacy fabric vulnerability will be exploited within an interacting population and adversely impact some members of that population.” Compartmentalization “A nonhierarchical grouping of (see DHHS meaning) sensitive information used to control access to data more finely than with hierarchical security classification alone.” Compromise – As Especially re- “Disclosure of information to applied to privacy identification unauthorized persons, or a violation of the security policy of a system in which unauthorized intentional or unintentional disclosure, modification, destruction, or loss of an object may have occurred.” Compromising “Unintentional signals that, if Emanations (for intercepted and analyzed, would privacy data) disclose the information transmitted, received, handled, or otherwise processed by information systems equipment.” CND Different for privacy fabric? Confidentiality NIST SP 800-53, Traditional “Preserving authorized restrictions on NIST SP 800-53A, meaning for information access and disclosure, NIST SP 800-18, privacy embodied including means for protecting NIST SP 800-27, in numerous personal privacy and proprietary NIST SP 800-60, standards, despite information.” NIST SP 800-37, its problems. FIPS 200, FIPS 199, 44 U.S.C., Section 3542 Contamination Scenario: a de- “Type of incident involving the identified DB is introduction of data of one security placed into a classification or security category into system containing data of a lower security classification potentially re- or different security category.” identifying resources 107 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY Security and Term Sources Comments Privacy Fabric Continuous monitoring “The process implemented to maintain (of privacy fabric) a current security status for one or more information systems or for the entire suite of information systems on which the operational mission of the enterprise depends. The process includes: 1) the development of a strategy to regularly evaluate selected IA controls/metrics, 2) recording and evaluating IA relevant events and the effectiveness of the enterprise in dealing with those events, 3) recording changes to IA controls, or changes that affect IA risks, and 4) publishing the current security status to enable information-sharing decisions involving the enterprise.” Controlled interface Control at the “A boundary with a set of mechanisms NBDRA interface that enforces the security policies and for privacy fabric controls the flow of information (different?) between interconnected information systems.” Covert testing (of privacy fabric) Credential, credential “A trusted entity that issues or service provider registers Subscriber tokens and issues electronic credentials to Subscribers. The CSP may encompass Registration Authorities (RAs) and Verifiers that it operates. A CSP may be an independent third party, or may issue credentials for its own use.” Criticality, criticality Not all privacy level data elements or tools may be equal Cryptographic binding “Associating two or more related elements of information using cryptographic techniques.” Conformance to privacy fabric XXX Data integrity (privacy Mis-identification corruption) (e.g., TSA list) Default classification (for privacy data, or privacy tooling) 108 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY Security and Term Sources Comments Privacy Fabric Digital forensics As applied to privacy fabric: still emerging; check academic lit End-to-end privacy TBD XXX Ethics in Design IEEE P7000, IEEE Traceability of ethics and value chain P7002, IEEE P7007, are seen as no less feasible than ISO 27500 requirements tracing, but no more straightforward either. Event (privacy) CNSSI-4009 Subset of events “Any observable occurrence in a appropriate to system and/or network. Events privacy sometimes provide indication that an incident is occurring.” External provider, NIST SP 800-37, Critical for privacy “A provider of external information external network NIST SP 800-53 data/controls system services to an organization preservation in Big through a variety of consumer- Data across producer relationships, including but clouds, across not limited to: joint ventures; business organizations partnerships; outsourcing arrangements (i.e., through contracts, interagency agreements, lines of business arrangements); licensing agreements; and/or supply chain exchanges.” False Acceptance Mis-identification Biometric domain in 800-76 (?) Hacker – Identity hacker Health Information NIST IR 7497 Important as a de “A health information organization Exchange facto Big Data that brings together healthcare Variety source for stakeholders within a defined re-identification geographic area and governs health due to U.S. information exchange among them for ubiquity. See also the purpose of improving health and UnitedHealthCare care in that community.” Optum Identification NIST SP 800-47 TBD – Needs “The process of verifying the identity refinement of a user, process, or device, usually as a prerequisite for granting access to resources in an IT system.” 109 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY Security and Term Sources Comments Privacy Fabric Identifier FIPS 201, CNSSI- Identifiers can be “A data object - often, a printable, 4009 automated, e.g., non-blank character string - that biometric theft, or definitively represents a specific photo recognition identity of a system entity, distinguishing that identity from all others.” Identity Note: Review for “The set of attribute values (i.e., consistent usage. characteristics) by which an entity is recognizable and that, within the scope of an identity manager’s responsibility, is sufficient to distinguish that entity from any other entity.” Identity-based Security Policy Identity Binding Identity-based access control Identity proofing Identity token Identity validation Identity verification Impact, impact level, NIST SP 800-60, Same concepts but impact value CNSSI-4009, NIST mapped to privacy SP 800-34, NIST SP fabric 800-30 Incident Same meaning, “An occurrence that actually or covered under potentially jeopardizes the “confidentiality” confidentiality, integrity, or availability of an information system or the information the system processes, stores, or transmits or that constitutes a violation or imminent threat of violation of security policies, security procedures, or acceptable use policies.” Incident handling for Subset, but could privacy incidents be different from superset Indicator Recognized signal that an adversary might be attempting to compromise privacy fabric 110 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY Security and Term Sources Comments Privacy Fabric Information assurance “Measures that protect and defend for privacy information and information systems by ensuring their availability, integrity, authentication, confidentiality, and non-repudiation. These measures include providing for restoration of information systems by incorporating protection, detection, and reaction capabilities.” Information Domain Needs to be “A three-part concept for information enlarged for BD sharing, independent of, and across privacy fabric information systems and security domains that 1) identifies information sharing participants as individual members, 2) contains shared information objects, and 3) provides a security policy that identifies the roles and privileges of the members and the protections required for the information objects.” Information CNSSI-4009 “The integrated employment of the Operations (as applied core capabilities of electronic warfare, to identity disruption) computer network operations, psychological operations, military deception, and operations security, in concert with specified supporting and related capabilities, to influence, disrupt, corrupt, or usurp adversarial human and automated decision- making process, information, and information systems while protecting our own.” Information owner Information sharing Highlight as a “ISE in its broader application enables environment potential area for those in a trusted partnership to share, variety-enabled discover, and access controlled identification information.” Information Security NIST SP 800-39 Identifies design- Architect (sub: time role. privacy) Architecture refers to the design. Information Steward “An agency official with statutory or (for confidential data, operational authority for specified tools) information and responsibility for establishing the controls for its generation, collection, processing, dissemination, and disposal.” 111 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY Security and Term Sources Comments Privacy Fabric IS Resilience Does this notion apply to identity attacks specifically? IS Security Risks “Information system-related security (privacy subset) risks are those risks that arise through the loss of confidentiality, integrity, or availability of information or information systems and consider impacts to the organization (including assets, mission, functions, image, or reputation), individuals, other organizations, and the Nation.” Information Value “A qualitative measure of the importance of the information based upon factors such as: level of robustness of the Information Assurance controls allocated to the protection of information based upon: mission criticality, the sensitivity (e.g., classification and compartmentalization) of the information, releasability to other countries, perishability/longevity of the information (e.g., short-life data versus long-life intelligence source data), and potential impact of loss of confidentiality and integrity and/or availability of the information.” Insider threat for E.g., access to confidentiality personnel records, breaches authentication systems, ACLs Intellectual property Especially IP connected to or owned by a person, but also IP treated the same way as “privacy” data. Further study.i Interconnection NIST SP 800-47, Security Agreement CNSSI-4009 i IP protections, defenses, risks are similar but also different from individual human privacy. 112 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY Security and Term Sources Comments Privacy Fabric Interface Control Different for Document privacy? Internal network Use cases are privacy controls different IT privacy awareness and training program IT privacy policy NIST SP 800-12 Program policy; “1) Program Policy—high-level policy (three + types) issue (context used to create a Program policy - specific) policies; organization’s IT security program, system- or device- define its scope within the or app-specific organization, assign implementation policies responsibilities, establish strategic direction, and assign resources for implementation. 2) Issue-Specific Policies—address specific issues of concern to the organization, such as contingency planning, the use of a particular methodology for systems risk management, and implementation of new regulations or law. These policies are likely to require more frequent revision as changes in technology and related factors take place. 3) System-Specific Policies—address individual systems, such as establishing an access control list or in training users as to what system actions are permitted. These policies may vary from system to system within the same organization. In addition, policy may refer to entirely different matters, such as the specific managerial decisions setting an organization’s electronic mail (email) policy or fax security policy.” Key terminology: list, TBD—Map to See also utility domains, e.g., loader, management, confidentiality- ubiquitous O.S. logging, or packet logger, exchange, specific logging capture. escrow, etc. for a specific domain. Least trust Metrics needed for “The principal that a security trust components architecture should be designed in a & disclosed to way that minimizes 1) the number of originator/owner components that require trust, and 2) the extent to which each component is trusted.” 113 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY Security and Term Sources Comments Privacy Fabric Line-of-business OMB, NIST SP 800- Domain- or Lengthy discussion best framed privacy guidelines 60, OMB Business discipline-specific through HL7 FHR domain model use Reference Model privacy best case. FEA V2.3 practicesj List-oriented object CNSSI-4009 privacy protection Major / Minor OMB Circular A-130 What makes it application (for Appendix III, NIST major / minor in privacy) SP 800-18 the NBDRA? Not resolved in V2. Masquerading privacy NIST SP 800-19 data (see identity) Biometric match event FIPS 201, CNSSI- Possible paradigmatic event exemplar 4009 for Big Data Media (wearable, FDA, adapted from implanted digital NIST SP 800-53 device) Memorandum of Simple MOU was Critical for Big Data Variety Understanding for NIST SP 800-47 Privacy data (MOUP) Minor application NIST SP 800-18 Identify aspect of a larger application (susceptible to privacy that applies to privacy concerns) Mission/business NIST SP 800-30 Identify segment associated with segment* business processes that collect PII or other privacy data at risk Multilevel security (for CNSSI-4009 Applies MLS to privacy data subset privacy data) Mutual suspicion CNSSI-4009 As applicable to privacy data, e.g., consider privacy data across organizational boundaries National security FIPS 200 Use to identify possible exclusions or system (US) variations from otherwise universal guidelines or practices. Nation- specific. Need to know CNSSI-4009 Need to know for PII. determination Needs assessment for NIST SP 800-50 “The results of a needs assessment can privacy (policy, risk, provide justification to convince etc.) management to allocate adequate resources to meet the identified awareness and training needs.” j LOB or Domain-specific privacy. See also incidents, events, etc. Needs improved definition and examples. 114 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY Security and Term Sources Comments Privacy Fabric Privacy data resilience Adapted from CNSSI- Ability to sustain business operations 4009 after privacy data attack (e.g., partial leak) Non-organizational NIST SP 800-53 user Network sponsor (for CNSSI-4009 "Individual or organization responsible privacy components) for stating the security policy enforced by the network, designing the network security architecture to properly enforce that policy, and ensuring that the network is implemented in such a way that the policy is enforced." Non-repudiation (for CNSSI-4009 As applied to sender/recipient of PII PII) Operational controls NIST SP 800-53 "The security controls (i.e., safeguards (for PII) or countermeasures) for an information system that primarily are implemented and executed by people (as opposed to systems)." Operations Security CNSSI-4009 "Systematic and proven process by (OPSEC, for PII) which potential adversaries can be denied information about capabilities and intentions by identifying, controlling, and protecting generally unclassified evidence of the planning and execution of sensitive activities. The process involves five steps: identification of critical information, analysis of threats, analysis of vulnerabilities, assessment of risks, and application of appropriate countermeasures." Organizational NIST SP 800-137 "Ongoing monitoring sufficient to information security ensure and assure effectiveness of continuous monitoring security controls related to systems, networks, and cyberspace, by assessing security control implementation and organizational security status in accordance with organizational risk tolerance – and within a reporting structure designed to make real-time, data-driven risk management decisions." Organizational CNSSI-4009 "Entity within the PKI that Registration Authority authenticates the identity and the organizational affiliation of the users." 115 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY Security and Term Sources Comments Privacy Fabric Overt testing for NIST SP 800-115 “Security testing performed with the privacy knowledge and consent of the organization’s IT staff.” Partitioned security CNSSI-4009 "Information systems security mode of mode operation wherein all personnel have the clearance, but not necessarily formal access approval and need-to- know, for all information handled by an information system." Path histories NIST SP 800-19 "Maintaining an authenticatable record of the prior platforms visited by a mobile software agent, so that a newly visited platform can determine whether to process the agent and what resource constraints to apply." Pen testing (for variety NIST SP 800-53A Applies principles of pen testing to attacks) attempts to re-identify or identify PII Periods processing CNSSI-4009 "The processing of various levels of classified and unclassified information at distinctly different times. Under the concept of periods processing, the system must be purged of all information from one processing period before transitioning to the next." Personal Identity CNSSI-4009 Applies U.S. Federal ID standard to Verification other organizations Personal Identity See related definitions Person in an org responsible for Verification in FIPS 201 issuing identity credentials Authorization Official (role) PII "Information which can be used to distinguish or trace an individual's identity, such as their name, social security number, biometric records, etc., alone, or when combined with other personal or identifying information which is linked or linkable to a specific individual, such as date and place of birth, mother’s maiden name, etc." Personnel Registration “Management role that is responsible Manager (role) for registering human users.” 116 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY Security and Term Sources Comments Privacy Fabric PII Confidentiality NIST SP 800-122 "The PII confidentiality impact level— Impact Level low, moderate, or high—indicates the potential harm that could result to the subject individuals and/or the organization if PII were inappropriately accessed, used, or disclosed." Policy-based Access, Set of concepts Use broad framework to help Certifier, etc. around POA&M organizations identify responsibilities for managing PII policies associated with a system. Potential (privacy) CNSSI-4009 “"The loss of confidentiality, integrity, impact or availability that could be expected to have a limited (low) adverse effect, a serious (moderate) adverse effect, or a severe or catastrophic (high) adverse effect on organizational operations, organizational assets, or individuals.” Privacy NIST SP 800-32 "Restricting access to subscriber or Relying Party information in accordance with federal law and agency policy." Privacy Impact NIST SP 800-53 "An analysis of how information is Assessment handled: 1) to ensure handling conforms to applicable legal, regulatory, and policy requirements regarding privacy; 2) to determine the risks and effects of collecting, maintaining, and disseminating information in identifiable form in an electronic information system; and 3) to examine and evaluate protections and alternative processes for handling information to mitigate potential privacy risks." Privacy system CNSSI-4009 "Commercial encryption system that affords telecommunications limited protection to deter a casual listener, but cannot withstand a technically competent cryptanalytic attack." Privilege Management NIST IR 7657 "The definition and management of policies and processes that define the ways in which the user is provided access rights to enterprise systems. It governs the management of the data that constitutes the user’s privileges and other attributes, including the storage, organization and access to information in directories." 117 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY Security and Term Sources Comments Privacy Fabric Profiling (of people) NIST SP 800-61 "Measuring the characteristics of expected activity so that changes to it can be more easily identified." Proprietary "Material and information relating to information (owned by or associated with a company's people versus products, business, or activities, organizations) including but not limited to financial information; data or statements; trade secrets; product research and development; existing and future product designs and performance specifications; marketing plans or techniques; schematics; client lists; computer programs; processes; and know-how that has been clearly identified and properly marked by the company as proprietary information, trade secrets, or company confidential information. The information must have been developed by the company and not be available to the government or to the public without restriction from another source." Pseudonym NIST SP 800-63 “A name other than a legal name.” Residual risk (e.g., NIST SP 800-33 "The remaining potential risk after all after PII breach) IT security measures are applied. There is a residual risk associated with each threat." Risk NIST SP 800-53 "Information system-related security risks are those risks that arise from the loss of confidentiality, integrity, or availability of information or information systems and consider the adverse impacts to organizational operations (including mission, functions, image, or reputation), organizational assets, individuals, other organizations, and the Nation." Risk-Adaptable Access CNSSI-4009 Control Risk Analysis NIST SP 800-27 Risk Management NIST SP 800-30, Suite of risk-related taxonomy Framework, Risk NIST SP 800-53A, Model, Monitoring, NIST SP 800-37, Response, Response CNSSI-4009, FIPS Measure, Tolerance, 200, NIST SP 800-34, Executive NIST SP 800-82 118 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY Security and Term Sources Comments Privacy Fabric Risk Assessor NIST SP 800-30 "The individual, group, or organization responsible for conducting a risk assessment." Role NIST SP 800-95 "A group attribute that ties membership to function. When an entity assumes a role, the entity is given certain rights that belong to that role. When the entity leaves the role, those rights are removed. The rights given are consistent with the functionality that the entity needs to perform the expected tasks." Role-based Access NIST SP 800-95 Control (RBAC) Rule-Based Security NIST SP 800-33, “A security policy based on global (Privacy) Policy CNSSI-4009 rules imposed for all subjects. These rules usually rely on a comparison of the sensitivity of the objects being accessed and the possession of corresponding attributes by the subjects requesting access. Also known as discretionary access control (DAC).” Security Category FIPS 200, FIPS 199, "The characterization of information NIST SP 800-18 or an information system based on an assessment of the potential impact that a loss of confidentiality, integrity, or availability of such information or information system would have on organizational operations, organizational assets, individuals, other organizations, and the Nation." Security (Privacy) NIST SP 800-27 "A collection of entities to which Domain applies a single security policy executed by a single authority." – Concept modified to reflect privacy only. Security (Privacy) CNSSI-4009 Need to reconcile with Oasis standard Engineering Security (privacy) CNSSI-4009 "A secure subsystem of an information filter system that enforces security policy on the data passing through it." Security (privacy) Fabric-specific incident 119 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY Security and Term Sources Comments Privacy Fabric Security (privacy) NIST SP 800-53, Important for "A marking bound to a resource label FIPS 188 provenance (which may be a data unit) that names or designates the security attributes of that resource." Security (privacy) level FIPS 188 NBDRA "A hierarchical indicator of the degree adaptation of sensitivity to a certain threat. It implies, according to the security policy being enforced, a specific level of protection." Security (privacy) NIST SP 800-53 "Human-readable information affixed marking to information system components, removable media, or output indicating the distribution limitations, handling caveats, and applicable security markings." Security (privacy) plan NIST SP 800-53, "Formal document that provides an NIST SP 800-53A, overview of the security requirements NIST SP 800-37, for an information system or an NIST SP 800-18 information security program and describes the security controls in place or planned for meeting those requirements." Security (privacy) Needs to be “Set of criteria for the provision of policy greatly enlarged as security services.” it includes both practice and colloquial uses Security (privacy) CNSSI-4009 "The security status of an enterprise’s posture networks, information, and systems based on IA resources (e.g., people, hardware, software, policies) and capabilities in place to manage the defense of the enterprise and to react as the situation changes." Security (privacy) CNSSI-4009 impact analysis Security (privacy) CNSSI-4009 program plan Security (privacy) CNSSI-4009 “Highest and lowest security levels range that are permitted in or on an information system, system component, subsystem, or network.” 120 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY Security and Term Sources Comments Privacy Fabric Security (privacy)- CNSSI-4009 “Any change to a system’s relevant change or configuration, environment, event information content, functionality, or users which has the potential to change the risk imposed upon its continued operations.” Security (privacy) CNSSI-4009 Mandated privacy requirements requirements Security (privacy) CNSSI-4009 requirements traceability matrix Security (Privacy) CNSSI-4009 Safeguards Security (privacy) NIST SP 800-27 “A capability that supports one, or service many, of the security goals. Examples of security services are key management, access control, and authentication.” Security (privacy) tag FIPS 188 “Information unit containing a representation of certain security- related information (e.g., a restrictive attribute bit map).” Security (privacy) test, CNSSI-4009 evaluation, assess, etc. Sensitivity (for privacy CNSSI-4009 “Information representing elements of data) label the security label(s) of a subject and an object. Sensitivity labels are used by the trusted computing base (TCB) as the basis for mandatory access control decisions. See Security Label.” SLA for Privacy TBD Signed data (applied to CNSSI-4009 privacy) Privacy Spillage CNSSI-4009 “Security incident that results in the transfer of classified or CUI information onto an information system not accredited (i.e., authorized) for the appropriate security level.” Status (for privacy NIST SP 800-137 Person or s/w “Monitoring the information security components) agent metrics defined by the organization in monitoring the information security ISCM strategy.” 121 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY Security and Term Sources Comments Privacy Fabric Suppression measure CNSSI-4009 “Action, procedure, modification, or (applied to privacy) device that reduces the level of, or inhibits the generation of, compromising emanations in an information system.” Privacy Integrity NIST SP 800-27 Adapt from System Integrity? Privacy subsystem NIST SP 800-47, What contexts? Interconnect CNSSI-4009 System of Records NIST SP 800-122 “A group of any records under the control of any agency from which information is retrieved by the name of the individual or by some identifying number, symbol, or other identifying particular assigned to the individual.” Privacy System owner Adapt from “Person or organization having System Owner? responsibility for the development, procurement, integration, modification, operation and maintenance, and/or final disposition of an information system.” Technical Privacy CNSSI-4009 See also Technical “Security controls (i.e., safeguards or Security Controls Reference Model countermeasures) for an information adapted for system that are primarily implemented Privacy and executed by the information system through mechanisms contained in the hardware, software, or firmware components of the system.” Privacy – Threat NIST SP 800-27, definition, analysis, CNSSI-4009 assessment, event, scenario, source Tracking cookie NIST SP 800-83 Traffic Analysis NIST SP 800-24, Highly applicable “A form of passive attack in which an NIST SP 800-98 to privacy in IoT intruder observes information about calls (although not necessarily the contents of the messages) and makes inferences, e.g., from the source and destination numbers, or frequency and length of the messages.” Trusted Agent TBD See trusted Earliest or most identification responsible (TBD) forwarding and direct digital related terms connection to a person whose data is private 122 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY Security and Term Sources Comments Privacy Fabric Unauthorized FIPS 191 disclosure (privacy data) Privacy data not identified as such by a system User ID CNSSI-4009 User Registration NIST SP 800-57 User Representation Vulnerability assessment (for privacy) 2832 2833 123 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY Appendix C: Internal Security 2834 Considerations within Cloud 2835 Ecosystems 2836 2837 Many Big Data systems will be designed using cloud architectures. Any strategy to implement a mature 2838 security and privacy framework within a Big Data cloud ecosystem enterprise architecture must address 2839 the complexities associated with cloud-specific security requirements triggered by the cloud 2840 characteristics. These requirements could include the following: 2841 • Broad network access 2842 • Decreased visibility and control by consumer 2843 • Dynamic system boundaries and comingled roles/responsibilities between consumers and 2844 providers 2845 • Multi-tenancy 2846 • Data residency 2847 • Measured service 2848 • Order-of-magnitude increases in scale (on demand), dynamics (elasticity and cost optimization), 2849 and complexity (automation and virtualization) 2850 These cloud computing characteristics often present different security risks to an agency than the 2851 traditional information technology solutions, thereby altering the agency’s security posture. 2852 To preserve the security-level after the migration of their data to the cloud, organizations need to identify 2853 all cloud-specific, risk-adjusted security controls or components in advance. The organizations must also 2854 request from the cloud service providers, through contractual means and service-level agreements, to have 2855 all identified security components and controls fully and accurately implemented. 2856 The complexity of multiple interdependencies is best illustrated by Figure C-1 (Fang Liu, 2011). 2857 2858 Figure C-1: Composite Cloud Ecosystem Security Architecture 124 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 2859 When unraveling the complexity of multiple interdependencies, it is important to note that enterprise- 2860 wide access controls fall within the purview of a well thought out Big Data and cloud ecosystem risk 2861 management strategy for end-to-end enterprise access control and security (AC&S), via the following five 2862 constructs: 2863 1. Categorize the data value and criticality of information systems and the data custodian’s duties and 2864 responsibilities to the organization, demonstrated by the data custodian’s choice of either a 2865 discretionary access control policy or a mandatory access control policy that is more restrictive. The 2866 choice is determined by addressing the specific organizational requirements, such as, but not limited 2867 to the following: 2868 a. GRC; and 2869 b. Directives, policy guidelines, strategic goals and objectives, information security requirements, 2870 priorities, and resources available (filling in any gaps). 2871 2. Select the appropriate level of security controls required to protect data and to defend information 2872 systems. 2873 3. Implement access security controls and modify them upon analysis assessments. 2874 4. Authorize appropriate information systems. 2875 5. Monitor access security controls at a minimum of once a year. 2876 To meet GRC and CIA regulatory obligations required from the responsible data custodians—which are 2877 directly tied to demonstrating a valid, current, and up-to-date AC&S policy—one of the better strategies 2878 is to implement a layered approach to AC&S, comprised of multiple access control gates, including, but 2879 not limited to, the following infrastructure AC&S via: 2880 • Physical security/facility security, equipment location, power redundancy, barriers, security 2881 patrols, electronic surveillance, and physical authentication 2882 • Information Security and residual risk management 2883 • Human resources (HR) security, including, but not limited to, employee codes of conduct, roles 2884 and responsibilities, job descriptions, and employee terminations 2885 • Database, end point, and cloud monitoring 2886 • Authentication services management/monitoring 2887 • Privilege usage management/monitoring 2888 • Identify management/monitoring 2889 • Security management/monitoring 2890 • Asset management/monitoring 2891 Despite the fact that cloud computing is driving innovation in technologies that support Big Data, some 2892 Big Data projects are not in the cloud. However, because of the resurgence of the cloud, considerable 2893 work has been invested in developing cloud standards to alleviate concerns over its use. A number of 2894 organizations, including NIST, are diligently engaged in standards work around cloud computing. Central 2895 among these for Big Data Security and Privacy is NIST SP 800-144 (Jansen & Grance, 2011), which 2896 included a then-current list of related standards and guides, which is reproduced in Table C-1. 2897 Table C-1: Standards and Guides Relevant to Cloud Computing Publication Title FIPS 199 Standards for Security Categorization of Federal Information and Information Systems FIPS 200 Minimum Security Requirements for Federal Information and Information Systems NIST SP 800-18, Revision Guide for Developing Security Plans for Federal Information Systems 1 125 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY Publication Title NIST SP 800-34, Revision Contingency Planning Guide for Federal Information Systems 1 NIST SP 800-37, Revision Guide for Applying the Risk Management Framework to Federal Information 1 Systems: A Security Life Cycle Approach NIST SP 800-39 Managing Information Security Risk: Organization, Mission, and Information System View NIST SP 800-53, Revision Recommended Security Controls for Federal Information Systems and 4 Organizations NIST SP 800-53, Appendix Privacy Control Catalog J NIST SP 800-53A, Guide for Assessing the Security Controls in Federal Information Systems Revision 4 NIST SP 800-60, Revision Guide for Mapping Types of Information and Information Systems to Security 1 Categories NIST SP 800-61, Revision Computer Security Incident Handling Guide 2 NIST SP 800-64, Revision Security Considerations in the System Development Life Cycle 2 NIST SP 800-86 Guide to Integrating Forensic Techniques into Incident Response NIST SP 800-88, Revision Guidelines for Media Sanitization 1 NIST SP 800-115 Technical Guide to Information Security Testing and Assessment NIST SP 800-122 Guide to Protecting the Confidentiality of Personally Identifiable Information (PII) NIST SP 800-137 Information Security Continuous Monitoring for Federal Information Systems and Organizations 2898 The following section revisits the traditional access control framework. The traditional framework 2899 identifies a standard set of attack surfaces, roles, and trade-offs. These principles appear in some existing 2900 best practices guidelines. For instance, they are an important part of the Certified Information Systems 2901 Security Professional (CISSP) body of knowledge.k 2902 Access Control 2903 Access control is one of the most important areas of Big Data. There are multiple factors, such as 2904 mandates, policies, and laws that govern the access of data. One overarching rule is that the highest 2905 classification of any data element or string governs the protection of the data. In addition, access should 2906 be granted only on a need-to-know/-use basis that is reviewed periodically in order to control the access. 2907 Access control for Big Data covers more than accessing data. Data can be accessed via multiple channels, 2908 networks, and platforms—including laptops, cell phones, smartphones, tablets, and even fax machines— 2909 that are connected to internal networks, mobile devices, the Internet, or all of the above. With this reality 2910 in mind, the same data may be accessed by a user, administrator, another system, etc., and it may be k CISSP is a professional computer security certification administered by (ISC)).2. (https://www.isc2.org/cissp/default.aspx) 126 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 2911 accessed via a remote connection/access point as well as internally. Therefore, visibility as to who is 2912 accessing the data is critical in protecting the data. The trade-offs between strict data access control versus 2913 conducting business requires answers to questions such as the following. 2914 • How important/critical is the data to the lifeblood and sustainability of the organization? 2915 • What is the organization responsible for (e.g., all nodes, components, boxes, and machines within 2916 the Big Data/cloud ecosystem)? 2917 • Where are the resources and data located? 2918 • Who should have access to the resources and data? 2919 • Have GRC considerations been given due attention? 2920 Very restrictive measures to control accounts are difficult to implement, so this strategy can be considered 2921 impractical in most cases. However, there are best practices, such as protection based on classification of 2922 the data, least privilege, (Anderson, 2011) and separation of duties that can help reduce the risks. 2923 The following measures are often included in Best Practices lists for security and privacy. Some, and 2924 perhaps all, of the measures require adaptation or expansion for Big Data systems. 2925 • Least privilege—access to data within a Big Data/cloud ecosystem environment should be based 2926 on providing an individual with the minimum access rights and privileges to perform their job. 2927 • If one of the data elements is protected because of its classification (e.g., PII, HIPAA, PCI), then 2928 all the data that it is sent with it inherits that classification, retaining the original data’s security 2929 classification. If the data is joined to and/or associated with other data that may cause a privacy 2930 issue, then all data should be protected. This requires due diligence on the part of the data 2931 custodian(s) to ensure that this secure and protected state remains throughout the entire end-to- 2932 end data flow. Variations on this theme may be required for domain-specific combinations of 2933 public and private data hosted by Big Data applications. 2934 • If data is accessed from, transferred to, or transmitted to the cloud, Internet, or another external 2935 entity, then the data should be protected based on its classification. 2936 • There should be an indicator/disclaimer on the display of the user if private or sensitive data is 2937 being accessed or viewed. Openness, trust, and transparency considerations may require more 2938 specific actions, depending on GRC or other broad considerations of how the Big Data system is 2939 being used. 2940 • All system roles (i.e., accounts) should be subjected to periodic meaningful audits to check that 2941 they are still required. 2942 • All accounts (except for system-related accounts) that have not been used within 180 days should 2943 be deactivated. 2944 • Access to PII data should be logged. Role-based access to Big Data should be enforced. Each role 2945 should be assigned the fewest privileges needed to perform the functions of that role. 2946 • Roles should be reviewed periodically to check that they are still valid and that the accounts 2947 assigned to them are still appropriate. 2948 User Access Controls 2949 • Each user should have their personal account. Shared accounts should not be the default practice 2950 in most settings. 2951 • A user role should match the system capabilities for which it was intended. For example, a user 2952 account intended only for information access or to manage an Orchestrator should not be used as 2953 an administrative account or to run unrelated production jobs. 127 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 2954 System Access Controls 2955 • There should not be shared accounts in cases of system-to-system access. “Meta-accounts” that 2956 operate across systems may be an emerging Big Data concern. 2957 • Access for a system that contains Big Data needs to be approved by the data owner or their 2958 representative. The representative should not be infrastructure support personnel (e.g., a system 2959 administrator), because that may cause a separation of duties issue. 2960 • Ideally, the same type of data stored on different systems should use the same classifications and 2961 rules for access controls to provide the same level of protection. In practice, Big Data systems 2962 may not follow this practice, and different techniques may be needed to map roles across related 2963 but dissimilar components or even across Big Data systems. 2964 Administrative Account Controls 2965 • System administrators should maintain a separate user account that is not used for administrative 2966 purposes. In addition, an administrative account should not be used as a user account. 2967 • The same administrative account should not be used for access to the production and non- 2968 production (e.g., test, development, and quality assurance) systems. 128 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY Appendix D: Big Data Actors and 2969 Roles—Adaptation to Big Data 2970 Scenarios 2971 2972 SOAs were a widely discussed paradigm through the early 2000s. While the concept is employed less 2973 often, SOA has influenced systems analysis processes, and perhaps to a lesser extent, systems design. As 2974 noted by Patig and Lopez-Sanz et al., actors and roles were incorporated into Unified Modeling Language 2975 so that these concepts could be represented within as well as across services. (Patig, 2008) (M. López- 2976 Sanz, 2008) Big Data calls for further adaptation of these concepts. While actor/role concepts have not 2977 been fully integrated into the proposed security fabric, the Subgroup felt it important to emphasize to Big 2978 Data system designers how these concepts may need to be adapted from legacy and SOA usage. 2979 Similar adaptations from Business Process Execution Language, Business Process Model and Notation 2980 frameworks offer additional patterns for Big Data security and privacy fabric standards. Ardagna et al. 2981  suggest how adaptations might proceed from SOA, but Big Data systems offer somewhat different 2982 challenges. 2983 Big Data systems can comprise simple machine-to-machine actors, or complex combinations of persons 2984 and machines that are systems of systems. 2985 A common meaning of actor assigns roles to a person in a system. From a citizen’s perspective, a person 2986 can have relationships with many applications and sources of information in a Big Data system. 2987 The following list describes a number of roles, as well as how roles can shift over time. For some 2988 systems, roles are only valid for a specified point in time. Reconsidering temporal aspects of actor 2989 security is salient for Big Data systems, as some will be architected without explicit archive or deletion 2990 policies. 2991 • A retail organization refers to a person as a consumer or prospect before a purchase; afterwards, 2992 the consumer becomes a customer. 2993 • A person has a customer relationship with a financial organization for banking services. 2994 • A person may have a car loan with a different organization or the same financial institution. 2995 • A person may have a home loan with a different bank or the same bank. 2996 • A person may be the insured on health, life, auto, homeowners, or renters insurance. 2997 • A person may be the beneficiary or future insured person by a payroll deduction in the private 2998 sector, or via the employment development department in the public sector. 2999 • A person may have attended one or more public or private schools. 3000 • A person may be an employee, temporary worker, contractor, or third-party employee for one or 3001 more private or public enterprises. 3002 • A person may be underage and have special legal or other protections. 3003 • One or more of these roles may apply concurrently. 3004 For each of these roles, system owners should ask themselves whether users could achieve the following: 3005 • Identify which systems their PII has entered; 3006 • Identify how, when, and what type of de-identification process was applied; 3007 • Verify integrity of their own data and correct errors, omissions, and inaccuracies; 129 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 3008 • Request to have information purged and have an automated mechanism to report and verify 3009 removal; 3010 • Participate in multilevel opt-out systems, such as will occur when Big Data systems are federated; 3011 and 3012 • Verify that data has not crossed regulatory (e.g., age-related), governmental (e.g., a state or 3013 nation), or expired (“I am no longer a customer”) boundaries. 3014 OPT-IN REVISITED 3015 While standards organizations grapple with frameworks, such as the one developed here, and until an 3016 individual's privacy and security can be fully protected using such a framework, some observers believe 3017 that the following two simple protocols ought to govern PII Big Data collection in the meantime. 3018 Suggested Protocol One: An individual can only decide to opt-in for inclusion of their personal data 3019 manually, and it is a decision that they can revoke at any time. 3020 Suggested Protocol Two: The individual's privacy and security opt-in process should enable each 3021 individual to modify their choice at any time, to access and review log files and reports, and to establish a 3022 self-destruct timeline (similar to the EU’s right to be forgotten). 3023 130 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY Appendix E: Mapping Use Cases to 3024 NBDRA 3025 3026 In this section, the security- and privacy-related use cases presented in Section 3 are mapped to the 3027 NBDRA components and interfaces explored in Figure 7, Notional Security and Privacy Fabric Overlay 3028 to the NBDRA. E.1 Retail/Marketing 3029 3030 E.1.1 Consumer Digital Media Use 3031 Content owners license data for use by consumers through presentation portals. The use of consumer 3032 digital media generates Big Data, including both demographics at the user level and patterns of use such 3033 as play sequence, recommendations, and content navigation. 3034 Table E-1: Mapping Consumer Digital Media Usage to the Reference Architecture NBDRA Security and Privacy Topic Use Case Mapping Component and Interfaces Data Provider → End-point input validation Varies and is vendor-dependent. Spoofing is Application possible. For example, protections afforded by Provider securing Microsoft Rights Management Services . Secure/Multipurpose Internet Mail Extensions (S/MIME) Real-time security monitoring Content creation security Data discovery and classification Discovery/classification is possible across media, populations, and channels. Secure data aggregation Vendor-supplied aggregation services—security practices are opaque. Application Privacy-preserving data analytics Aggregate reporting to content owners Provider → Data Compliance with regulations PII disclosure issues abound Consumer Government access to data and Various issues; for example, playing terrorist freedom of expression concerns podcast and illegal playback Data Provider ↔ Data-centric security such as Unknown Framework identity/policy-based encryption Provider Policy management for access User, playback administrator, library control maintenance, and auditor Computing on the encrypted data: Unknown searching/ filtering/ deduplicate/ FHE Audits Audit DRM usage for royalties Framework Securing data storage and Unknown Provider transaction logs Key management Unknown 131 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY NBDRA Security and Privacy Topic Use Case Mapping Component and Interfaces Security best practices for non- Unknown relational data stores Security against DoS attacks N/A Data provenance Traceability to data owners, producers, consumers is preserved Fabric Analytics for security intelligence Machine intelligence for unsanctioned use/access Event detection “Playback” granularity defined Forensics Subpoena of playback records in legal disputes 3035 3036 E.1.2 Nielsen Homescan: Project Apollo 3037 Nielsen Homescan involves family-level retail transactions and associated media exposure using a 3038 statistically valid national sample. A general description  is provided by the vendor. This project 3039 description is based on a 2006 Project Apollo architecture (Project Apollo did not emerge from its 3040 prototype status). 3041 Table E-2: Mapping Nielsen Homescan to the Reference Architecture NBDRA Security and Privacy Topic Use Case Mapping Component and Interfaces Data Provider → End-point input validation Device-specific keys from digital sources; Application receipt sources scanned internally and Provider reconciled to family ID (Role issues) Real-time security monitoring None Data discovery and classification Classifications based on data sources (e.g., retail outlets, devices, and paper sources) Secure data aggregation Aggregated into demographic crosstabs. Internal analysts had access to PII. Application Privacy-preserving data analytics Aggregated to (sometimes) product-specific, Provider → Data statistically valid independent variables Consumer Compliance with regulations Panel data rights secured in advance and enforced through organizational controls. Government access to data and N/A freedom of expression concerns Data Provider ↔ Data-centric security such as Encryption not employed in place; only for data- Framework identity/policy-based encryption center-to-data-center transfers. XML cube Provider security mapped to Sybase IQ and reporting tools Policy management for access Extensive role-based controls control Computing on the encrypted data: N/A searching/filtering/deduplicate/ FHE Audits Schematron and process step audits 132 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY NBDRA Security and Privacy Topic Use Case Mapping Component and Interfaces Framework Securing data storage and Project-specific audits secured by infrastructure Provider transaction logs team. Key management Managed by project chief security officer (CSO). Separate key pairs issued for customers and internal users. Security best practices for non- Regular data integrity checks via XML schema relational data stores validation Security against DoS attacks Industry-standard webhost protection provided for query subsystem. Data provenance Unique Fabric Analytics for security intelligence No project-specific initiatives Event detection N/A Forensics Usage, cube-creation, and device merge audit records were retained for forensics and billing 3042 3043 E.1.3 Web Traffic Analytics 3044 Visit-level webserver logs are of high granularity and voluminous. Web logs are correlated with other 3045 sources, including page content (buttons, text, and navigation events) and marketing events such as 3046 campaigns and media classification. 3047 Table E-3: Mapping Web Traffic Analytics to the Reference Architecture NBDRA Security and Privacy Topic Use Case Mapping Component and Interfaces Data Provider → End-point input validation Device-dependent. Spoofing is often easy Application Real-time security monitoring Web server monitoring Provider Data discovery and classification Some geospatial attribution Secure data aggregation Aggregation to device, visitor, button, web event, and others Application Privacy-preserving data analytics IP anonymizing and time stamp degrading. Provider → Data Content-specific opt-out Consumer Compliance with regulations Anonymization may be required for EU compliance. Opt-out honoring Government access to data and Yes freedom of expression concerns Data Provider ↔ Data-centric security such as Varies depending on archivist Framework identity/policy-based encryption Provider Policy management for access System- and application-level access controls control Computing on the encrypted data: Unknown searching/filtering/deduplicate/ FHE Audits Customer audits for accuracy and integrity are supported 133 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY NBDRA Security and Privacy Topic Use Case Mapping Component and Interfaces Framework Securing data storage and Storage archiving—this is a big issue Provider transaction logs Key management CSO and applications Security best practices for non- Unknown relational data stores Security against DoS attacks Standard Data provenance Server, application, IP-like identity, page point- in-time Document Object Model (DOM), and point-in-time marketing events Fabric Analytics for security intelligence Access to web logs often requires privilege elevation. Event detection Can infer; for example, numerous sales, marketing, and overall web health events Forensics See the SIEM use case 3048 E.2 Healthcare 3049 3050 E.2.1 Health Information Exchange 3051 Health information exchange (HIE) data is aggregated from various data providers, which might include 3052 covered entities such as hospitals and contract research organizations (CROs) identifying participation in 3053 clinical trials. The data consumers would include emergency room personnel, the CDC, and other 3054 authorized health (or other) organizations. Because any city or region might implement its own HIE, these 3055 exchanges might also serve as data consumers and data providers for each other. 3056 Table E-4: Mapping HIE to the Reference Architecture NBDRA Security and Privacy Topic Use Case Mapping Component and Interfaces Data Provider → End-point input validation  Strong authentication, perhaps through X.509v3 Application certificates, potential leverage of SAFE Provider (Signatures & Authentication for Everything ) bridge in lieu of general PKI Real-time security monitoring Validation of incoming records to assure integrity through signature validation and to assure HIPAA privacy through ensuring PHI is encrypted. May need to check for evidence of informed consent. Data discovery and classification Leverage Health Level Seven (HL7) and other standard formats opportunistically, but avoid attempts at schema normalization. Some columns will be strongly encrypted while others will be specially encrypted (or associated with cryptographic metadata) for enabling discovery and classification. May need to perform column 134 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY NBDRA Security and Privacy Topic Use Case Mapping Component and Interfaces filtering based on the policies of the data source or the HIE service provider. Secure data aggregation Combining deduplication with encryption is desirable. Deduplication improves bandwidth and storage availability, but when used in conjunction with encryption, presents particular challenges (Reference here). Other columns may require cryptographic metadata for facilitating aggregation and deduplication. The HL7 standards organization is currently studying this set of related use cases. (Weida, 2014) Application Privacy-preserving data analytics Searching on encrypted data and proofs of data Provider → Data possession. Identification of potential adverse Consumer experience due to clinical trial participation. Identification of potential professional patients. Trends and epidemics, and co-relations of these to environmental and other effects. Determination of whether the drug to be administered will generate an adverse reaction, without breaking the double blind. Patients will need to be provided with detailed accounting of accesses to, and uses of, their EHR data. Compliance with regulations HIPAA security and privacy will require detailed accounting of access to EHR data. Facilitating this, and the logging and alerts, will require federated identity integration with data consumers. Where applicable, compliance with U.S. FDA CFR Title 21 Part 56 on Institutional Review Boards is mandated. Government access to data and CDC, law enforcement, subpoenas and warrants. freedom of expression concerns Access may be toggled based on occurrence of a pandemic (e.g., CDC) or receipt of a warrant (e.g., law enforcement). Data Provider ↔ Data-centric security such as Row-level and column-level access control Framework identity/policy-based encryption Provider Policy management for access Role-based and claim-based. Defined for PHI control cells Computing on the encrypted data: Privacy-preserving access to relevant events, searching/filtering/deduplicate/ anomalies, and trends for CDC and other FHE relevant health organizations Audits Facilitate HIPAA readiness and HHS audits Framework Securing data storage and Need to be protected for integrity and privacy, Provider transaction logs but also for establishing completeness, with an emphasis on availability. Key management Federated across covered entities, with the need to manage key life cycles across multiple covered entities that are data sources 135 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY NBDRA Security and Privacy Topic Use Case Mapping Component and Interfaces Security best practices for non- End-to-end encryption, with scenario-specific relational data stores schemes that respect min-entropy to provide richer query operations without compromising patient privacy Security against distributed denial A mandatory requirement: systems must survive of service (DDoS) attacks DDoS attacks Data provenance Completeness and integrity of data with records of all accesses and modifications. This information could be as sensitive as the data and is subject to commensurate access policies. Fabric Analytics for security intelligence Monitoring of informed patient consent, authorized and unauthorized transfers, and accesses and modifications Event detection Transfer of record custody, addition/modification of record (or cell), authorized queries, unauthorized queries, and modification attempts Forensics Tamper-resistant logs, with evidence of tampering events. Ability to identify record- level transfers of custody and cell-level access or modification 3057 3058 3059 E.2.2 Pharmaceutical Clinical Trial Data Sharing 3060 Under an industry trade group proposal, clinical trial data for new drugs will be shared outside intra- 3061 enterprise warehouses. 3062 Table E-5: Mapping Pharmaceutical Clinical Trial Data Sharing to the Reference Architecture NBDRA Security & Privacy Topic Use Case Mapping Component and Interfaces Data Provider → End-point input validation Opaque—company-specific Application Real-time security monitoring None Provider Data discovery and classification Opaque—company-specific Secure data aggregation Third-party aggregator Application Privacy-preserving data analytics Data to be reported in aggregate but preserving Provider → Data potentially small-cell demographics Consumer Compliance with regulations Responsible developer and third-party custodian Government access to data and Limited use in research community, but there freedom of expression concerns are possible future public health data concerns. Clinical study reports only, but possibly selectively at the study- and patient-levels Data Provider ↔ Data-centric security such as TBD identity/policy-based encryption 136 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY NBDRA Security & Privacy Topic Use Case Mapping Component and Interfaces Framework Policy management for access Internal roles; third-party custodian roles; Provider control researcher roles; participating patients’ physicians Computing on the encrypted data: TBD searching/filtering/deduplicate/ FHE Audits Release audit by a third party Framework Securing data storage and TBD Provider transaction logs Key management Internal varies by firm; external TBD Security best practices for non- TBD relational data stores Security against DoS attacks Unlikely to become public Data provenance TBD—critical issue Fabric Analytics for security intelligence TBD Event detection TBD Forensics 3063 E.3 Cybersecurity 3064 3065 E.3.1 Network Protection 3066 SIEM is a family of tools used to defend and maintain networks. 3067 Table E-6: Mapping Network Protection to the Reference Architecture NBDRA Security and Privacy Topic Use Case Mapping Component and Interfaces Data Provider → End-point input validation Software-supplier specific; refer to Application commercially available end point validation Provider . Real-time security monitoring --- Data discovery and classification Varies by tool, but classified based on security semantics and sources Secure data aggregation Aggregates by subnet, workstation, and server Application Privacy-preserving data analytics Platform-specific Provider → Data Compliance with regulations Applicable, but regulated events are not readily Consumer visible to analysts Government access to data and Ensure that access by law enforcement, state or freedom of expression concerns local agencies, such as for child protection, or to aid locating missing persons, is lawful. Data Provider ↔ Data-centric security such as Usually a feature of the operating system Framework identity/policy-based encryption Provider Policy management for access For example, a group policy for an event log control 137 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY NBDRA Security and Privacy Topic Use Case Mapping Component and Interfaces Computing on the encrypted data: Vendor and platform-specific searching/filtering/deduplicate/ FHE Audits Complex—audits are possible throughout Framework Securing data storage and Vendor and platform-specific Provider transaction logs Key management Chief Security Officer and SIEM product keys Security best practices for non- TBD relational data stores Security against DDoS attacks Big Data application layer DDoS attacks can be mitigated using combinations of traffic analytics, correlation analysis. Data provenance For example, how to know an intrusion record was actually associated with a specific workstation. Fabric Analytics for security intelligence Feature of current SIEMs Event detection Feature of current SIEMs Forensics Feature of current SIEMs 3068 E.4 Government 3069 3070 E.4.1 Unmanned Vehicle Sensor Data 3071 Unmanned vehicles (drones) and their onboard sensors (e.g., streamed video) can produce petabytes of 3072 data that should be stored in nonstandard formats. The U.S. government is pursuing capabilities to expand 3073 storage capabilities for Big Data such as streamed video. 3074 Table E-7: Mapping Military Unmanned Vehicle Sensor Data to the Reference Architecture NBDRA Security and Privacy Topic Use Case Mapping Component and Interfaces Data Provider → End-point input validation Need to secure the sensor (e.g., camera) to Application prevent spoofing/stolen sensor streams. There Provider are new transceivers and protocols in the pipeline and elsewhere in federal data systems. Sensor streams will include smartphone and tablet sources. Real-time security monitoring Onboard and control station secondary sensor security monitoring Data discovery and classification Varies from media-specific encoding to sophisticated situation-awareness enhancing fusion schemes Secure data aggregation Fusion challenges range from simple to complex. Video streams may be used  unsecured or unaggregated. 138 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY NBDRA Security and Privacy Topic Use Case Mapping Component and Interfaces Application Privacy-preserving data analytics Geospatial constraints: cannot surveil beyond Provider → Data Universal Transverse Mercator (UTM). Secrecy: Consumer target and point of origin privacy Compliance with regulations Numerous. There are also standards issues. Government access to data and For example, the Google lawsuit over Street freedom of expression concerns View Data Provider ↔ Data-centric security such as Policy-based encryption, often dictated by Framework identity/policy-based encryption legacy channel capacity/type Provider Policy management for access Transformations tend to be made within control contractor-devised system schemes Computing on the encrypted data: Sometimes performed within vendor-supplied searching/filtering/deduplicate/ architectures, or by image-processing parallel FHE architectures Audits CSO and Inspector General (IG) audits Framework Securing data storage and The usual, plus data center security levels are Provider transaction logs tightly managed (e.g., field vs. battalion vs. headquarters) Key management CSO—chain of command Security best practices for non- Not handled differently at present; this is relational data stores changing, e.g., see the DoD Cloud Computing Strategy . Security against DoS attacks Anti-jamming e-measures Data provenance Must track to sensor point in time configuration and metadata Fabric Analytics for security intelligence Security software intelligence—event driven and monitoring—that is often remote Event detection For example, target identification in a video stream infers height of target from shadow. Fuse data from satellite infrared with separate sensor stream . Forensics Used for after action review (AAR)—desirable to have full playback of sensor streams 3075 3076 E.4.2 Education: Common Core Student Performance Reporting 3077 Cradle-to-grave student performance metrics for every student are now possible—at least within the K-12 3078 community, and probably beyond. This could include every test result ever administered. 3079 Table E-8: Mapping Common Core K–12 Student Reporting to the Reference Architecture NBDRA Security and Privacy Topic Use Case Mapping Component and Interfaces Data Provider → End-point input validation Application-dependent. Spoofing is possible Application Real-time security monitoring Vendor-specific monitoring of tests, test-takers, Provider administrators, and data Data discovery and classification Unknown 139 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY NBDRA Security and Privacy Topic Use Case Mapping Component and Interfaces Secure data aggregation Typical: Classroom-level Application Privacy-preserving data analytics Various: For example, teacher-level analytics Provider → Data across all same-grade classrooms Consumer Compliance with regulations Parent, student, and taxpayer disclosure and privacy rules apply. Government access to data and Yes. May be required for grants, funding, freedom of expression concerns performance metrics for teachers, administrators, and districts. Data Provider ↔ Data-centric security such as Support both individual access (student) and Framework identity/policy-based encryption partitioned aggregate Provider Policy management for access Vendor (e.g., Pearson) controls, state-level control policies, federal-level policies; probably 20-50 different roles are spelled out at present. Computing on the encrypted data: Proposed  searching/filtering/deduplicate/ FHE Audits Support both internal and third-party audits by unions, state agencies, responses to subpoenas Framework Securing data storage and Large enterprise security, transaction-level Provider transaction logs controls—classroom to the federal government Key management CSOs from the classroom level to the national level Security best practices for non- --- relational data stores Security against DDoS attacks Standard Data provenance Traceability to measurement event requires capturing tests at a point in time, which may itself require a Big Data platform. Fabric Analytics for security intelligence Various commercial security applications Event detection Various commercial security applications Forensics Various commercial security applications 3080 3081 E.5 Transportation 3082 3083 E.5.1 Cargo Shipping 3084 This use case provides an overview of a Big Data application related to the shipping industry for which 3085 standards may emerge in the near future. 140 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 3086 Table E-9: Mapping Cargo Shipping to the Reference Architecture NBDRA Security and Privacy Topic Use Case Mapping Component and Interfaces Data Provider → End-point input validation Ensuring integrity of data collected from sensors Application Real-time security monitoring Sensors can detect abnormal Provider temperature/environmental conditions for packages with special requirements. They can also detect leaks/radiation. Data discovery and classification --- Secure data aggregation Securely aggregating data from sensors Application Privacy-preserving data analytics Sensor-collected data can be private and can Provider → Data reveal information about the package and geo- Consumer information. The revealing of such information needs to preserve privacy. Compliance with regulations --- Government access to data and The U.S. Department of Homeland Security freedom of expression concerns may monitor suspicious packages moving into/out of the country . Data Provider ↔ Data-centric security such as --- Framework identity/policy-based encryption Provider Policy management for access Private, sensitive sensor data and package data control should only be available to authorized individuals. Third-party commercial offerings may implement low-level access to the data. Computing on the encrypted data: See above section on “Transformation.” searching/filtering/deduplicate/ FHE Audits --- Framework Securing data storage and Logging sensor data is essential for tracking Provider transaction logs packages. Sensor data at rest should be kept in secure data stores. Key management For encrypted data Security best practices for non- The diversity of sensor types and data types may relational data stores necessitate the use of non-relational data stores Security against DoS attacks --- Data provenance Metadata should be cryptographically attached to the collected data so that the integrity of origin and progress can be assured. Complete preservation of provenance will sometimes mandate a separate Big Data application. Fabric Analytics for security intelligence Anomalies in sensor data can indicate tampering/fraudulent insertion of data traffic. Event detection Abnormal events such as cargo moving out of the way or being stationary for unwarranted periods can be detected. Forensics Analysis of logged data can reveal details of incidents after they occur. 3087 141 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY Appendix F: Version 2 Changes 3088 and New Topics 3089 3090 The current version of the NBDIF: Volume 4, Security and Privacy document reflects changes in the 3091 technology environment (e.g., as well as ongoing work within the NBD-PWG). For Version 2, the 3092 Security and Privacy Subgroup considered the following topics: 3093 1. See Cryptographic Technologies for Data Transformations. The latest document is updated to 3094 reflect recent cryptology practices. 3095 2. The NBD-SPSL is introduced, suitable for use by unaffiliated citizens, Big Data software 3096 architects, and IT managers. (Refer to related IEC standards 61508, 61671, 62046, SC22 WG 23.) 3097 3. Provided levels of conformance to Big Data security and privacy practices. Low, medium and 3098 high conformance levels were added. (See related work in “Conformity Assessment” of the 3099 “NIST Roadmap for Improving Critical Infrastructure Cybersecurity.”) The approach taken is 3100 similar to NIST 800-53. 3101 4. Improved descriptions of security and privacy dependency frameworks that interoperate across 3102 enterprises, applications, and infrastructure are cited in the NBD-SPSL. 3103 5. The current version reflects the growing importance of security and privacy aspects to the API- 3104 first and microservices design pattern. 3105 6. The NBD-SPSL directly addresses security and privacy issues with geospatial and mobile data 3106 . 3107 7. The NBD-SPSL includes security hardening through software-defined networks and other virtual 3108 network security concepts, as in IEEE P1915.1 and NIST 800-125B . 3109 8. This document now provides references to third-party references on risks, verifiability, and 3110 provenance for analytics that affect security and privacy. 3111 142 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY Appendix G: Acronyms 3112 3113 AAR After Action Review 3114 ABAC Attribute Based Access Control 3115 ABE Attribute-Based Encryption 3116 AC&S Access Control and Security 3117 ACL Access Control List 3118 ACM Association for Computing Machinery 3119 AI Artificial Intelligence 3120 API Application Programming Interface 3121 ARM Application Release Management 3122 AuthN/AuthZ Authentication/Authorization 3123 BAA Business Associate Agreement 3124 BYOD Bring Your Own Device 3125 CADF Cloud Auditing Data Federation 3126 CAT SEC Consolidated Audit Trail 3127 CDC U.S. Centers for Disease Control and Prevention 3128 CEP Complex Event Processing 3129 CFR Code of Federal Regulations 3130 CIA Confidentiality, Integrity, and Availability 3131 CIO Chief Information Officer 3132 CISSP Certified Information Systems Security Professional 3133 CM Configuration Management 3134 COPPA Children’s Online Privacy Protection Act 3135 CPE Common Platform Enumeration 3136 CPS Cyber-Physical System 3137 CPU Central Processing Unit 3138 CSA BDWG Cloud Security Alliance Big Data Working Group 3139 CSP Cloud Service Provider 3140 DevOps a clipped compound of software DEVelopment and information technology OPerationS 3141 DevSecOps Security and Safety Engineering in DevOps 3142 DHHS U.S. Department of Health and Human Services 3143 DISA Defense Information Systems Agency 3144 DoD U.S. Department of Defense 3145 DoS Denial of Service 3146 DR Disaster Recovery 3147 DRM Digital Rights Management 3148 EDM Enterprise Data Management 3149 EFPIA European Federation of Pharmaceutical Industries and Associations 3150 EHR Electronic Health Record 3151 EPA Explicit role-permission Assignments 3152 ETSI European Telecommunications Standards Institute 3153 EU European Union 3154 FAA Federal Aviation Administration 3155 FDA U.S. Food and Drug Administration 3156 FERPA Family Educational Rights and Privacy Act 3157 FHE Fully Homomorphic Encryption 143 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 3158 FHIR Fast Healthcare Interoperability Resources 3159 FIBO Financial Industry Business Ontology 3160 FTC Federal Trade Commission 3161 GPS Global Positioning System 3162 GRC Governance, Risk management, and Compliance 3163 HCI Human Computer Interaction 3164 HIE Health Information Exchange 3165 HIPAA Health Insurance Portability and Accountability Act 3166 HPC High Performance Computing 3167 HR Human Resources 3168 HTML HyperText Markup Language 3169 IA Information Assurance 3170 IaaS Infrastructure as a Service 3171 IAM Identity Access Management 3172 IBE Identity-Based Encryption 3173 IDE Integrated Development Environment 3174 IdP Identity provider 3175 IEEE Institute of Electrical and Electronics Engineers 3176 INCITS International Committee for Information Technology Standards 3177 IoT Internet of Things 3178 ISO International Organization for Standardization 3179 ISSEA International Systems Security Engineering Association 3180 IT Information Technology 3181 ITL Information Technology Laboratory at NIST 3182 KMS Key Management Systems 3183 M2M Machine to Machine 3184 MAC Media Access Control 3185 MBSE Model-based Systems Engineering 3186 MIFE Multi-input Functional Encryption 3187 ModSim Modeling and Simulation 3188 MPC Multi-party Computations 3189 NBDIF NIST Big Data Interoperability Framework 3190 NBD-PWG NIST Big Data Public Working Group 3191 NBDRA NIST Big Data Reference Architecture 3192 NBD-SPSL NIST Big Data Security and Privacy Safety Levels 3193 NSTIC National Strategy for Trusted Identities in Cyberspace 3194 OASIS Organization for the Advancement of Structured Information Standards 3195 OECD Organisation for Economic Co-Operation and Development 3196 OMG Object Management Group 3197 OSS Operations Support Systems 3198 PaaS Platform as a Service 3199 PCI Payment Card Industry 3200 PCI-DSS Payment Card Industry Data Security Standard 3201 PHI Protected Health Information 3202 PhRMA Pharmaceutical Research and Manufacturers of America 3203 PII Personally Identifiable Information 3204 PKI Public Key Infrastructure 3205 PMML Predictive Model Markup Language 3206 PMRM Privacy Management Reference Model 3207 RBAC Role-based Access Control 3208 RDF Resource Description Framework 144 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 3209 RPAS Remotely Piloted Aircraft System 3210 RPV Remotely Piloted Vehicle 3211 SaaS Software as a Service 3212 SAML Security Assertion Markup Language 3213 SCAP Security Content Automation Protocol 3214 SDLC Systems Development Life Cycle 3215 SDL-IT Secure Development Life Cycle 3216 SDN Software-Defined Network 3217 SEC U.S. Securities and Exchange Commission 3218 SGX Software Guard Extensions 3219 SIEM Security Information and Event Management 3220 SKOS Simple Knowledge Organization System 3221 SKUs Stock Keeping Units 3222 SOA Service-oriented architectures 3223 SON Self-Organizing Networks 3224 S-SDLC Secure-SDLC 3225 SSE Searchable Symmetric Encryption 3226 SSE-CMM Systems Security Engineering Capability Maturity Model 3227 SSL Secure Sockets Layer 3228 STS Security Token Service 3229 SWID Software Identification 3230 TCB Trusted Computing Base 3231 TCP/IP Transmission Control Protocol/Internet Protocol 3232 TLS Transport Layer Security 3233 TOSCA Topology and Orchestration Specification for Cloud Applications 3234 TPM Trusted Platform Module 3235 TSA Transportation Security Administration 3236 UAS Unmanned Aerial Systems 3237 UAV Unmanned Aerial Vehicle 3238 UDP User Datagram Protocol 3239 US¬CERT U.S. Computer Emergency Readiness Team 3240 VC3 Verifiable Confidential Cloud Computing 3241 VM Virtual Machine 3242 VPN Virtual Private Network 3243 XACML eXtensible Access Control Markup Language 3244 XML eXtensible Markup Language 3245 XMPP Extensible Messaging and Presence Protocol 3246 145 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY Appendix H: Bibliography 3247 3248  W. L. Chang (Co-Chair), N. Grady (Subgroup Co-chair), and NIST Big Data Public Working 3249 Group, “NIST Big Data Interoperability Framework: Volume 1, Big Data Definitions (NIST SP 3250 1500-1 VERSION 3),” Gaithersburg MD, Sep. 2019 [Online]. Available: 3251 https://doi.org/10.6028/NIST.SP.1500-1r2 3252  W. L. Chang (Co-Chair), N. Grady (Subgroup Co-chair), and NIST Big Data Public Working 3253 Group, “NIST Big Data Interoperability Framework: Volume 2, Big Data Taxonomies (NIST SP 3254 1500-2 VERSION 3),” Gaithersburg, MD, Sep. 2019 [Online]. Available: 3255 https://doi.org/10.6028/NIST.SP.1500-2r2 3256  W. L. Chang (Co-Chair), G. Fox (Subgroup Co-chair), and NIST Big Data Public Working Group, 3257 “NIST Big Data Interoperability Framework: Volume 3, Big Data Use Cases and General 3258 Requirements (NIST SP 1500-3 VERSION 3),” Gaithersburg, MD, Sep. 2019 [Online]. Available: 3259 https://doi.org/10.6028/NIST.SP.1500-3r2 3260  W. Chang and NIST Big Data Public Working Group, “NIST Big Data Interoperability 3261 Framework: Volume 5, Architectures White Paper Survey (SP1500-5),” 2015 [Online]. Available: 3262 https://www.nist.gov/publications/nist-big-data-interoperability-framework-volume-5- 3263 architectures-white-paper-survey 3264  W. L. Chang (Co-Chair), D. Boyd (Subgroup Co-chair), O. Levin (Version 1 Subgroup Co-Chair), 3265 and NIST Big Data Public Working Group, “NIST Big Data Interoperability Framework: Volume 3266 6, Big Data Reference Architecture (NIST SP 1500-6 VERSION 3),” Gaithersburg MD, Sep. 2019 3267 [Online]. Available: https://doi.org/10.6028/NIST.SP.1500-6r2 3268  W. L. Chang (Co-Chair), R. Reinsch (Subgroup Co-chair), D. Boyd (Version 1 Subgroup Co- 3269 chair), C. Buffington (Version 1 Subgroup Co-chair), and NIST Big Data Public Working Group, 3270 “NIST Big Data Interoperability Framework: Volume 7, Big Data Standards Roadmap (NIST SP 3271 1500-7 VERSION 3),” Gaithersburg, MD, Sep. 2019 [Online]. Available: 3272 https://doi.org/10.6028/NIST.SP.1500-7r2 3273  W. L. Chang (Co-Chair), G. von Laszewski (Editor), and NIST Big Data Public Working Group, 3274 “NIST Big Data Interoperability Framework: Volume 8, Big Data Reference Architecture 3275 Interfaces (NIST SP 1500-9 VERSION 2),” Gaithersburg, MD, Sep. 2019 [Online]. Available: 3276 https://doi.org/10.6028/NIST.SP.1500-9r1 3277  W. L. Chang (Co-Chair), R. Reinsch (Subgroup Co-chair), C. Austin (Editor), and NIST Big Data 3278 Public Working Group, “NIST Big Data Interoperability Framework: Volume 9, Adoption and 3279 Modernization (NIST SP 1500-10 VERSION 2),” Gaithersburg, MD, Sep. 2019 [Online]. 3280 Available: https://doi.org/10.6028/NIST.SP.1500-10r1 3281  T. White House Office of Science and Technology Policy, “Big Data is a Big Deal,” OSTP Blog, 3282 2012. [Online]. Available: http://www.whitehouse.gov/blog/2012/03/29/big-data-big-deal. 146 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 3283 [Accessed: 21-Feb-2014] 3284  V. Hu et al., “NIST SP 800-162: Guide to Attribute Based Access Control (ABAC) Definition and 3285 Considerations,” NIST Spec. Publ. 800-162, vol. 800, no. 162, 2014 [Online]. Available: 3286 https://csrc.nist.gov/publications/detail/sp/800-162/final 3287  M. Abramson et al., “Data Residency Challenges: A Joint Paper with the Object Management 3288 Group,” Cloud Standards Customer Council, Needham Heights, MA OR - Cloud Standards 3289 Customer Council, May 2017 [Online]. Available: citeulike-article-id:14395964 3290  Cloud Security Alliance, “Expanded Top Ten Big Data Security and Privacy Challenges,” Cloud 3291 Security Alliance, 2013. [Online]. Available: 3292 https://downloads.cloudsecurityalliance.org/initiatives/bdwg/Expanded_Top_Ten_Big_Data_Secu 3293 rity_and_Privacy_Challenges.pdf 3294  “IBM, Subgroup correspondence with James G Kobielus.” 2014. 3295  D. J. Weitzner, H. Abelson, T. Berners-Lee, J. Feigenbaum, J. Hendler, and G. J. Sussman, 3296 “Information accountability,” Commun. ACM, vol. 51, no. 6, pp. 82–87, 2008 [Online]. Available: 3297 http://dl.acm.org/ft_gateway.cfm?id=1349043&type=html 3298  M. Altman, D. O’Brien, S. Vadhan, and A. Wood, “Can You Have Privacy and Big Data Too? — 3299 Comments for the White House,” MIT Libraries: Program on Information Science, 2014. 3300 [Online]. Available: http://informatics.mit.edu/blog/2014/03/can-you-have-privacy-and-big-data- 3301 too-—-comments-white-house 3302  Cloud Security Alliance Big Data Working Group, “Top 10 Challenges in Big Data Security and 3303 Privacy,” 2012 [Online]. Available: 3304 https://downloads.cloudsecurityalliance.org/initiatives/bdwg/Big_Data_Top_Ten_v1.pdf 3305  B. C. M. Fung, K. Wang, R. Chen, and P. S. Yu, “Privacy-preserving data publishing: A Survey of 3306 Recent Developments,” ACM Comput. Surv., vol. 42, no. 4, pp. 1–53, 2010 [Online]. Available: 3307 http://portal.acm.org/citation.cfm?doid=1749603.1749605 3308  C. Dwork, “Differential privacy,” Proc. 33rd Int. Colloq. Autom. Lang. Program., pp. 1–12, 2006. 3309  L. SWEENEY, “k-ANONYMITY: A MODEL FOR PROTECTING PRIVACY,” Int. J. 3310 Uncertainty, Fuzziness Knowledge-Based Syst., vol. 10, no. 05, pp. 557–570, 2002 [Online]. 3311 Available: http://www.worldscientific.com/doi/abs/10.1142/S0218488502001648 3312  A. Narayanan and V. Shmatikov, “Robust de-anonymization of large sparse datasets,” in 3313 Proceedings - IEEE Symposium on Security and Privacy, 2008, pp. 111–125. 3314  J. Wang, D. Crawl, S. Purawat, M. Nguyen, and I. Altintas, “Big data provenance: Challenges, 3315 state of the art and opportunities,” in 2015 IEEE International Conference on Big Data (Big Data), 3316 2015, pp. 2509–2516. 3317  S. S. Sahoo, A. Sheth, and C. Henson, “Semantic provenance for eScience: Managing the deluge 3318 of scientific data,” IEEE Internet Comput., vol. 12, no. 4, pp. 46–54, 2008. 147 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 3319  ISO 16759:2013 Graphic technology — Quantification and communication for calculating the 3320 carbon footprint of print media products. International Organization for Standardization, 2013 3321 [Online]. Available: https://www.iso.org/standard/57615.html 3322  G. O’Malley, “Click Fraud Costs Marketers $11B, IAB Issues Key Report,” MediaPost, Jan. 3323 2014. 3324  R. Shields, “AppNexus CTO On The Fight Against Ad Fraud,” Exch. Wire, vol. October, no. 29, 3325 2014 [Online]. Available: https://www.exchangewire.com/blog/2014/10/29/appnexus-cto-on-the- 3326 fight-against-ad-fraud/ 3327  D. Lazer, R. Kennedy, G. King, and A. Vespignani, “The Parable of Google Flu: Traps in Big 3328 Data Analysis,” Science (80-. )., vol. 343, no. 6176, pp. 1203–1205, 2014 [Online]. Available: 3329 http://www.sciencemag.org/cgi/doi/10.1126/science.1248506 3330  P. Chen, B. Plale, and M. S. Aktas, “Temporal representation for mining scientific data 3331 provenance,” Futur. Gener. Comput. Syst., vol. 36, pp. 363–378, 2014. 3332  W. Jansen and T. Grance, “NIST SP 800–144: Guidelines on Security and Privacy in Public Cloud 3333 Computing,” Dec. 2011 [Online]. Available: http://csrc.nist.gov/publications/nistpubs/800- 3334 144/SP800-144.pdf 3335  ETSI, “Cloud Standards Coordination. Final Report.,” 2013 [Online]. Available: 3336 http://www.etsi.org/images/files/Events/2013/2013_CSC_Delivery_WS/CSC-Final_report-013- 3337 CSC_Final_report_v1_0_PDF_format-.PDF%5Cnhttps://ec.europa.eu/digital-single- 3338 market/news/etsi-delivers-report-cloud-computing-standards 3339  DISA, “Department of Defense (DoD) Cloud Computing Security Requirements Guide (SRG),” 3340 Fort Meade, MD, 2015 [Online]. Available: http://iase.disa.mil/cloud_security/Documents/u- 3341 cloud_computing_srg_v1r1_final.pdf 3342  CIO Council, “Recommendations for Standardized Implementation of Digital Privacy Controls,” 3343 Washington, DC, 2012 [Online]. Available: https://cio.gov/wp- 3344 content/uploads/downloads/2012/12/Standardized_Digital_Privacy_Controls.pdf 3345  J. Draeger, “A roadmap to a unified treatment of safety and security,” in 10th IET System Safety 3346 and Cyber-Security Conference 2015, 2015, pp. 1–6 [Online]. Available: citeulike-article- 3347 id:14395992 3348  M. Finnegan, “Boeing 787s to create half a terabyte of data per flight, says Virgin Atlantic,” 3349 Comput. UK, Mar. 2013 [Online]. Available: citeulike-article-id:14396257 3350  T. Larsen, “Cross-platform aviation analytics using big-data methods,” in 2013 Integrated 3351 Communications, Navigation and Surveillance Conference (ICNS), 2013, pp. 1–9. 3352  L. Piètre-Cambacédès and M. Bouissou, “Cross-fertilization between safety and security 3353 engineering,” Reliab. Eng. Syst. Saf., vol. 110, pp. 110–126, Feb. 2013. 3354  J. Voas, “NIST SP 800-183: Networks of ‘Things,’” NIST Special Publication 800-183. 2016. 148 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 3355  K. Stouffer, J. Falco, and K. Scarfone, “Guide to Industrial Control Systems (ICS) Security (NIST 3356 SP 800-82),” May 2015 [Online]. Available: 3357 http://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-82r2.pdf 3358  International Electrotechnical Commission and ISA, IEC 62443x: Industrial Automation and 3359 Control Systems Security. International Electrotechnical Commission. 3360  P. K. Das, A. Joshi, and T. Finin, “Capturing policies for fine-grained access control on mobile 3361 devices,” in Proceedings - 2016 IEEE 2nd International Conference on Collaboration and 3362 Internet Computing, IEEE CIC 2016, 2017, pp. 54–63. 3363  K. Lenz and A. Oberweis, “Inter-organizational business process management with XML nets,” 3364 Lect. Notes Comput. Sci. (including Subser. Lect. Notes Artif. Intell. Lect. Notes Bioinformatics), 3365 vol. 2472, pp. 243–263, 2003. 3366  I. Hickson, “HTML Microdata,” W3C Work. Gr. Note 29, pp. 1–29, 2013 [Online]. Available: 3367 https://www.w3.org/TR/microdata/ 3368  I. Hickson, G. Kellogg, J. Tenisson, and I. Herman, “Microdata to RDF – Second Edition,” W3C, 3369 2014. [Online]. Available: http://www.w3.org/TR/microdata-rdf/ 3370  R. Ross, M. McEvilley, and J. C. Oren, “NIST SP 800-160: Systems Security Engineering,” NIST 3371 Special Publication, Gaithersburg MD, p. 245, Sep-2016 [Online]. Available: 3372 https://csrc.nist.gov/csrc/media/publications/sp/800-160/archive/2016-09- 3373 22/documents/sp800_160_final-draft.pdf 3374  ISO/IEC/IEEE 15288:2015 Systems and software engineering — System life cycle processes. 3375 International Organization for Standardization / International Electrotechnical Commission / 3376 Institute of Electrical and Electronics Engineers, 2015 [Online]. Available: 3377 https://www.iso.org/standard/63711.html 3378  ISO 27500:2016 The human-centred organization — Rationale and general principles. 3379 International Organization for Standardization, 2016 [Online]. Available: 3380 https://www.iso.org/standard/64239.html 3381  IEEE P7000 - Model Process for Addressing Ethical Concerns During System Design. IEEE, 2016 3382 [Online]. Available: https://standards.ieee.org/project/7000.html 3383  IEEE P7002 - Data Privacy Process. IEEE, 2016 [Online]. Available: 3384 https://standards.ieee.org/project/7002.html 3385  IEEE P7003 - Algorithmic Bias Considerations. IEEE, 2017 [Online]. Available: 3386 https://standards.ieee.org/project/7003.html 3387  IEEE P7007 - Ontological Standard for Ethically Driven Robotics and Automation Systems. IEEE, 3388 2017 [Online]. Available: https://standards.ieee.org/project/7007.html 3389  Z. Khayyat et al., “BigDansing: A System for Big Data Cleansing,” in Proceedings of the 2015 3390 ACM SIGMOD International Conference on Management of Data SE - SIGMOD ’15, 2015, pp. 149 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 3391 1215–1230 [Online]. Available: citeulike-article-id:14396286 3392  L. A. Pachano, T. M. Khoshgoftaar, and R. Wald, “Survey of Data Cleansing and Monitoring for 3393 Large-Scale Battery Backup Installations,” in 2013 12th International Conference on Machine 3394 Learning and Applications, 2013, vol. 2, pp. 478–484 [Online]. Available: citeulike-article- 3395 id:14396282 3396  M. Fazio and A. Puliafito, “Virtual Resource Management Based on Software Transactional 3397 Memory,” in 2011 First International Symposium on Network Cloud Computing and Applications, 3398 2011, pp. 1–8 [Online]. Available: http://www.scopus.com/inward/record.url?eid=2-s2.0- 3399 84856349781&partnerID=tZOtx3y1 3400  A. Celesti, M. Fazio, and M. Villari, “SE CLEVER: A secure message oriented Middleware for 3401 Cloud federation,” in Proceedings - International Symposium on Computers and Communications, 3402 2013, pp. 35–40. 3403  W. Jun, Z. Di, L. Meng, X. Fang, S. Hu-Lin, and Y. Shu-Feng, “Discussion of Society Fire- 3404 Fighting Safety Management Internet of Things Technology System,” in 2014 Fifth International 3405 Conference on Intelligent Systems Design and Engineering Applications, 2014, pp. 422–425. 3406  K. Liu, Y. Yao, and D. Guo, “On Managing Geospatial Big-data in Emergency Management: 3407 Some Perspectives,” in Proceedings of the 1st ACM SIGSPATIAL International Workshop on the 3408 Use of GIS in Emergency Management SE - EM-GIS ’15, 2015 [Online]. Available: citeulike- 3409 article-id:14394474 3410  International Organization for Standardization, “ISO/IEC 27001 Information security management 3411 (ISO/IEC 27000 series webpage),” 2019. [Online]. Available: https://www.iso.org/isoiec-27001- 3412 information-security.html 3413  NIST, “NIST Cybersecurity Framework.” [Online]. Available: 3414 https://www.nist.gov/cyberframework 3415  NIST, “Draft NIST SP 800-53: Security and Privacy Controls forInformation Systems and 3416 Organizations (Rev. 5),” Aug. 2017 [Online]. Available: 3417 https://csrc.nist.gov/CSRC/media//Publications/sp/800-53/rev-5/draft/documents/sp800-53r5- 3418 draft.pdf 3419  B. Knijnenburg, “Privacy Support for the Total Learning Architecture: Operational 3420 Characteristics.” 2017. 3421  A. Ballestero, “Transparency,” in The International Encyclopedia of Anthropology, American 3422 Cancer Society, 2018, pp. 1–4 [Online]. Available: 3423 https://onlinelibrary.wiley.com/doi/abs/10.1002/9781118924396.wbiea1505 3424  O. Seizov, A. J. Wulf, and J. Luzak, “The Transparent Trap: A Multidisciplinary Perspective on 3425 the Design of Transparent Online Disclosures in the EU,” J. Consum. Policy, vol. 42, no. 1, pp. 3426 149–173, Mar. 2019 [Online]. Available: https://doi.org/10.1007/s10603-018-9393-0 3427  Fair Credit Reporting Act, 15 U.S.C. § 1681 et seq. [Online]. Available: 150 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 3428 https://www.ftc.gov/enforcement/rules/rulemaking-regulatory-reform-proceedings/fair-credit- 3429 reporting-act 3430  NIST, “NIST SP 800-37: Risk Management Framework for Information Systems and 3431 Organizations: A System Life Cycle Approach for Security and Privacy,” Dec. 2018 [Online]. 3432 Available: https://csrc.nist.gov/publications/detail/sp/800-37/rev-2/final 3433  X. Zhang and R. J. (editor), “A Survey of Digital Rights Management Technologies,” 2015. 3434 [Online]. Available: http://www.cse.wustl.edu/~jain/cse571-11/ftp/drm/. [Accessed: 09-Jan-2015] 3435  V. Bael, “European Union: ECJ Confirms that IP Addresses are Personal Data,” Mondaq, 2012. 3436 [Online]. Available: 3437 http://www.mondaq.com/x/162538/Copyright/ECJ+Confirms+That+IP+Addresses+Are+Personal 3438 +Data 3439  Personal Correspondence, “Cloud homomorphic encryption service.” 2015. 3440  Pharma and European Federation of Pharmaceutical Industries and Associations, “Principles for 3441 Responsible Clinical Trial Data Sharing,” 2013 [Online]. Available: http://phrma- 3442 docs.phrma.org/sites/default/files/pdf/PhRMAPrinciplesForResponsibleClinicalTrialDataSharing. 3443 pdf 3444  P. Wood, “How to tackle big data from a security point of view,” ComputerWeekly.com, 2013. 3445 [Online]. Available: http://www.computerweekly.com/feature/How-to-tackle-big-data-from-a- 3446 security-point-of-view 3447  B. Rossi, “Big security: big data and the end of SIEM,” Information Age, 29-May-2014. [Online]. 3448 Available: http://www.information-age.com/big-security-big-data-and-end-siem-123458055/ 3449  D. Gunderson, “Drone patrol: Unmanned craft find key role in U.S. border security,” Minnesota 3450 Public Radio News, Grand Forks, ND, 19-Feb-2015 [Online]. Available: 3451 https://www.mprnews.org/story/2015/02/19/predator-drone 3452  Deputy Under Secretary of the Navy, “Naval security enterprise,” Nav. Secur. Enterp., vol. 2nd 3453 Quarte, p. 11, 2015 [Online]. Available: 3454 http://www.secnav.navy.mil/dusnp/Security/news/Documents/NavalSecurityEnterpriseNewsletter 3455 2ndFY15.pdf 3456  U.S. Department of Justice, “Guidance on Domestic Use of Unmanned Aircraft Systems.” 3457 [Online]. Available: https://www.justice.gov/file/441266/download 3458  Data Quality Campaign, “Roadmap to Safeguarding Student Data,” 2015 [Online]. Available: 3459 https://dataqualitycampaign.org/resource/roadmap-safeguarding-student-data/ 3460  J. Campbell, “Cuomo panel: State should cut ties with inBloom,” Albany Bureau, Iohud, 2014 3461 [Online]. Available: http://www.lohud.com/story/news/education/2014/03/10/cuomo-panel-wants- 3462 cut-ties-inbloom/6279081/ 3463  L. Fleisher, “Before Tougher State Tests, Officials Prepare Parents,” Wall Str. J., vol. April 15, 151 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 3464 2013 [Online]. Available: https://blogs.wsj.com/metropolis/2013/04/15/before-tougher-state-tests- 3465 officials-prepare-parents/ 3466  R. D. Crick, P. Broadfoot, and G. Claxton, “Developing an Effective Lifelong Learning Inventory: 3467 the ELLI Project,” Assess. Educ. Princ. Policy Pract., vol. 11, no. 3, pp. 247–272, 2004 [Online]. 3468 Available: http://www.tandfonline.com/doi/abs/10.1080/0969594042000304582 3469  R. Ferguson, “Learning analytics: drivers, developments and challenges,” Int. J. Technol. Enhanc. 3470 Learn., vol. 4, no. 5/6, p. 304, 2012 [Online]. Available: 3471 http://www.inderscience.com/link.php?id=51816 3472  D. Donston-Miller, “Common Core Meets Aging Education Technology,” InformationWeek, vol. 3473 July 22, 2013 [Online]. Available: https://www.informationweek.com/policy/common-core-meets- 3474 aging-education-technology/d/d-id/1110849? 3475  Civitas Learning, “About,” 2016. [Online]. Available: https://www.civitaslearning.com/about/ 3476  ISO/IEC 29161:2016 Information technology — Data structure — Unique identification for the 3477 Internet of Things. International Organization for Standardization / International Electrotechnical 3478 Commission, 2016 [Online]. Available: https://www.iso.org/standard/45240.html 3479  Consolidated Audit Trail, “Consolidated Audit Trail Home Page,” 2019. [Online]. Available: 3480 https://www.catnmsplan.com/ 3481  U.S. Securities and Exchange Commission, “Rule 613 (Consolidated Audit Trail),” 2019. 3482 [Online]. Available: https://www.sec.gov/divisions/marketreg/rule613-info.htm 3483  Consolidated Audit Trail LLC, “High Level CAT Security Requirements Summary” [Online]. 3484 Available: https://www.catnmsplan.com/wp- 3485 content/uploads/2017/03/cat_nms_security_requirements_032416.pdf 3486  M. Alam, S. Katsikas, O. Beltramello, and S. Hadjiefthymiades, “Augmented and virtual reality 3487 based monitoring and safety system: A prototype IoT platform,” J. Netw. Comput. Appl., vol. 89, 3488 pp. 109–119, 2017 [Online]. Available: citeulike-article-id:14395975 3489  M. StJohn-Green, R. Piggin, J. A. McDermid, and R. Oates, “Combined security and safety risk 3490 assessment #x2014; What needs to be done for ICS and the IoT,” in 10th IET System Safety and 3491 Cyber-Security Conference 2015, 2015, pp. 1–7 [Online]. Available: citeulike-article-id:14395989 3492  Kauffman_Foundation, “Welcome to EdWise - Education Data for Missouri.” Kauffman 3493 Foundation, Kansas City, MO, Sep-2016 [Online]. Available: citeulike-article-id:14169722 3494  D. Boneh, A. Sahai, and B. Waters, “Functional Encryption: Definitions and Challenges,” in 3495 Theory of Cryptography: 8th Theory of Cryptography Conference, TCC 2011, Providence, RI, 3496 USA, March 28-30, 2011. Proceedings, Y. Ishai, Ed. Berlin, Heidelberg: Springer Berlin 3497 Heidelberg, 2011, pp. 253–273. 3498  R. Chandramouli, M. Iorga, and S. Chokhani, “NIST IR 7956: Cryptographic key management 3499 issues & challenges in cloud services,” 2013 [Online]. Available: 152 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 3500 http://dx.doi.org/10.6028/NIST.IR.7956 3501  P. Mell and T. Grance, “NIST SP 800-145: The NIST Definition of Cloud Computing,” 2011 3502 [Online]. Available: http://www.mendeley.com/research/the-nist-definition-about-cloud- 3503 computing/ 3504  Anonymous, “Summary of the Amazon S3 Service Disruption in the Northern Virginia (US- 3505 EAST-1) Region,” Amaz. Web Serv. Blog, Mar. 2017 [Online]. Available: citeulike-article- 3506 id:14313016 3507  Association for Computing Machinery, “The 2012 ACM Computing Classification System.” 3508 Association for Computing Machinery, 2012 [Online]. Available: 3509 http://www.acm.org/publications/class-2012 3510  NIST, “NIST SP 800-37: Guide for Applying the Risk Management Framework to Federal 3511 Information Systems,” 2010. 3512  S. Brooks, M. Garcia, N. Lefkovitz, S. Lightman, and E. Nadeau, “NIST IR 8062: An Introduction 3513 to Privacy Engineering and Risk Management in Federal Systems,” 2017 [Online]. Available: 3514 https://csrc.nist.gov/publications/detail/nistir/8062/final 3515  ISACA, “The Risk IT Framework,” 2009 [Online]. Available: http://www.isaca.org/Knowledge- 3516 Center/Research/ResearchDeliverables/Pages/The-Risk-IT-Framework.aspx 3517  NIST, “Framework for Improving Critical Infrastructure Cybersecurity,” 2014 [Online]. 3518 Available: http://www.nist.gov/cyberframework/upload/cybersecurity-framework-021214- 3519 final.pdf 3520  OASIS, “SAML V2.0 Standard,” SAML Wiki, 2005. [Online]. Available: https://wiki.oasis- 3521 open.org/security/FrontPage#SAML_V2.0_Standard. [Accessed: 09-Jan-2015] 3522  J. J. Cebula and L. R. Young, “A Taxonomy of Operational Cyber Security Risks,” Carnegie- 3523 Mellon Univ Pittsburgh Pa Softw. Eng. Inst, no. December, pp. 1–47, 2010 [Online]. Available: 3524 https://resources.sei.cmu.edu/asset_files/TechnicalNote/2010_004_001_15200.pdf 3525  H.-C. Kum and S. Ahalt, “Privacy-by-Design: Understanding Data Access Models for Secondary 3526 Data.,” AMIA Jt. Summits Transl. Sci. Proc. AMIA Summit Transl. Sci., vol. 2013, pp. 126–30, 3527 Jan. 2013. 3528  J. Rawls, “Justice as Fairness: Political not Metaphysical,” Philos. Public Aff., vol. 14, no. 3, pp. 3529 223–251, 1985 [Online]. Available: http://philosophyfaculty.ucsd.edu/faculty/rarneson/Philosophy 3530 167/Rawlsjusticeasfairness.pdf 3531  ETSI, “Smart Cards: Secure channel between a UICC and an end-point terminal (Release 7),” 3532 2007 [Online]. Available: 3533 http://www.etsi.org/deliver/etsi_ts/102400_102499/102484/07.00.00_60/ts_102484v070000p.pdf 3534  U.S. Department of Health & Human Services, “New rule protects patient privacy, secures health 3535 information,” 17-Jan-2013 [Online]. Available: 153 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 3536 http://www.hhs.gov/news/press/2013pres/01/20130117b.html 3537  D. F. Sittig and H. Singh, “Legal, Ethical, and Financial Dilemmas in Electronic Health Record 3538 Adoption and Use,” Pediatrics, vol. 127, no. 4, pp. e1042–e1047, 2011 [Online]. Available: 3539 http://pediatrics.aappublications.org/cgi/doi/10.1542/peds.2010-2184 3540  US-CERT, “About US-CERT,” 2015. [Online]. Available: https://www.us-cert.gov/about-us. 3541 [Accessed: 01-Jan-2015] 3542  U.S. Federal Trade Commission, “Protecting Your Child’s Privacy Online,” Consumer 3543 Information, Jul-2013. [Online]. Available: https://www.consumer.ftc.gov/articles/0031- 3544 protecting-your-childs-privacy-online 3545  U.S. Department of Health & Human Services, “Health Information Privacy, Security, and your 3546 EHR,” HealthIT.gov, Privacy and Security, 13-Apr-2015. . 3547  U.S. Food and Drug Administration, “Medical Device Safety Network (MedSun),” Medical 3548 Device Safety, 08-May-2017. [Online]. Available: 3549 https://www.fda.gov/medicaldevices/safety/medsunmedicalproductsafetynetwork/default.htm 3550  B. Mirkin, S. Nascimento, and L. M. Pereira, “Representing a computer science research 3551 organization on the ACM computing classification system,” in CEUR Workshop Proceedings, 3552 2008, vol. 354, pp. 57–65. 3553  X. Lin, M. Zhang, H. Zhao, and J. Buzydlowski, “Multi-view of the ACM classification system,” 3554 in Proceedings of the 12th ACM/IEEE-CS joint conference on Digital Libraries - JCDL ’12, 2012, 3555 p. 397 [Online]. Available: http://dl.acm.org/citation.cfm?doid=2232817.2232909 3556  A. Miles and S. Bechhofer, “SKOS Simple Knowledge Organization System Reference,” W3C 3557 Recommendation 18 August 2009. pp. 1–40, 2009 [Online]. Available: 3558 http://www.w3.org/TR/2009/REC-skos-reference- 3559 20090818/#concepts%5Cnpapers2://publication/uuid/67B635A0-CD7E-48A0-8730- 3560 EC86DB6CC3A1 3561  L. Obrst, P. Chase, and R. Markeloff, “Developing an Ontology of the Cyber Security Domain,” in 3562 Proceedings of the Seventh International Conference on Semantic Technologies for Intelligence, 3563 Defense, and Security, 2012, pp. 49–56. 3564  D. Waltermire and B. A. Cheikes, “NIST IR8085: Forming Common Platform Enumeration (CPE) 3565 Names from Software Identification (SWID) Tags,” NIST Special Publication, Gaithersburg, MD, 3566 Dec-2015 [Online]. Available: 3567 https://csrc.nist.gov/csrc/media/publications/nistir/8085/draft/documents/nistir_8085_draft.pdf 3568  D. Inoue, M. Eto, K. Suzuki, M. Suzuki, and K. Nakao, “DAEDALUS-VIZ: Novel Real-time 3D 3569 Visualization for Darknet Monitoring-based Alert System,” in Proceedings of the Ninth 3570 International Symposium on Visualization for Cyber Security SE - VizSec ’12, 2012, pp. 72–79 3571 [Online]. Available: citeulike-article-id:14395580 3572  A. Shabtai, D. Klimov, Y. Shahar, and Y. Elovici, “An intelligent, interactive tool for exploration 154 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 3573 and visualization of time-oriented security data,” in VizSEC ’06: Proceedings of the 3rd 3574 international workshop on Visualization for computer security, 2006, pp. 15–22 [Online]. 3575 Available: citeulike-article-id:7801543 3576  T. Takahashi, Y. Kadobayashi, and H. Fujiwara, “Ontological Approach Toward Cybersecurity in 3577 Cloud Computing,” in Proceedings of the 3rd International Conference on Security of Information 3578 and Networks SE - SIN ’10, 2010, pp. 100–109 [Online]. Available: citeulike-article-id:14395578 3579  G. Yee, “Visualization for privacy compliance,” in VizSEC ’06: Proceedings of the 3rd 3580 international workshop on Visualization for computer security, 2006, pp. 117–122 [Online]. 3581 Available: citeulike-article-id:2883612 3582  C. Brodie, C.-M. Karat, J. Karat, and J. Feng, “Usable Security and Privacy: A Case Study of 3583 Developing Privacy Management Tools,” in Proceedings of the 2005 symposium on Usable 3584 privacy and security - SOUPS ’05, 2005, pp. 35–43 [Online]. Available: 3585 http://dl.acm.org/citation.cfm?id=1073001.1073005%5Cnhttp://portal.acm.org/citation.cfm?doid= 3586 1073001.1073005 3587  W. Carey, J. Nilsson, and S. Mitchell, “Persistent security, privacy, and governance for healthcare 3588 information,” in Proceedings of the 2nd USENIX Conference on Health Security and Privacy, 3589 2011 [Online]. Available: 3590 https://www.usenix.org/legacy/events/healthsec11/tech/final_files/carey-healthsec11.pdf 3591  P. Dunphy et al., “Understanding the Experience-Centeredness of Privacy and Security 3592 Technologies,” in Proceedings of the 2014 workshop on New Security Paradigms Workshop - 3593 NSPW ’14, 2014, pp. 83–94 [Online]. Available: 3594 http://dl.acm.org/citation.cfm?doid=2683467.2683475 3595  E. A. Oladimeji, L. Chung, H. T. Jung, and J. Kim, “Managing security and privacy in ubiquitous 3596 eHealth information interchange,” in Proceedings of the 5th International Confernece on 3597 Ubiquitous Information Management and Communication - ICUIMC ’11, 2011, p. 1 [Online]. 3598 Available: http://portal.acm.org/citation.cfm?doid=1968613.1968645 3599  B. Obama, “National Strategy for Trusted Identities in Cyberspace,” The White House, p. 25, 2011 3600 [Online]. Available: 3601 https://www.whitehouse.gov/sites/default/files/rss_viewer/NSTICstrategy_041511.pdf%5Cnhttp:// 3602 www.whitehouse.gov/sites/default/files/rss_viewer/international_strategy_for_cyberspace.pdf 3603  National Institute of Standards and Technology (NIST), “NIST Cloud Computing Security 3604 Reference Architecture,” Spec. Publ. 500-299, 2013 [Online]. Available: 3605 https://csrc.nist.gov/publications/detail/sp/500-299/draft 3606  J.-S. Li, Y.-F. Zhang, and Y. Tian, “Medical Big Data Analysis in Hospital Information System,” 3607 in Big Data on Real-World Applications, 2016 [Online]. Available: 3608 http://www.intechopen.com/books/big-data-on-real-world-applications/medical-big-data-analysis- 3609 in-hospital-information-system 3610  O. Niakšu, “CRISP Data Mining Methodology Extension for Medical Domain,” Balt. J. Mod. 155 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 3611 Comput., vol. 3, no. 2, pp. 92–109, 2015. 3612  J. Schaffer, H. Tobias, D. Jones, and J. O. Donovan, “Getting the Message ? A Study of 3613 Explanation Interfaces for Microblog Data Analysis,” IUI 2015 Proc. 20th Int. Conf. Intell. User 3614 Interfaces, pp. 345–356, 2015. 3615  Cloud Security Alliance, “CSA Big Data Security and Privacy Handbook,” 2016 [Online]. 3616 Available: https://downloads.cloudsecurityalliance.org/assets/research/big- 3617 data/BigData_Security_and_Privacy_Handbook.pdf 3618  J. Loftus, A. May, N. P. Smart, and F. Vercauteren, “On CCA-secure somewhat homomorphic 3619 encryption,” in Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial 3620 Intelligence and Lecture Notes in Bioinformatics), 2012, vol. 7118 LNCS, pp. 55–72. 3621  C. Gentry, “A Fully Homomorphic Encryption Scheme,” Stanford University, Stanford, CA, USA, 3622 2009. 3623  D. Boneh, E.-J. Goh, and K. Nissim, “Evaluating 2-DNF Formulas on Ciphertexts,” in 3624 Proceedings of the Second International Conference on Theory of Cryptography SE - TCC’05, 3625 2005, pp. 325–341. 3626  M. Van Dijk, C. Gentry, S. Halevi, and V. Vaikuntanathan, “Fully homomorphic encryption over 3627 the integers,” Adv. Cryptology– EUROCRYPT ’10, pp. 24–43, 2010 [Online]. Available: 3628 http://link.springer.com/chapter/10.1007/978-3-642-13190-5_2 3629  J.-S. Coron, A. Mandal, D. Naccache, and M. Tibouchi, “Fully Homomorphic Encryption over the 3630 Integers with Shorter Public Keys,” in Advances in Cryptology -- CRYPTO 2011, 2011, pp. 487– 3631 504. 3632  C. Gentry, S. Halevi, and N. P. Smart, “Fully homomorphic encryption with polylog overhead,” in 3633 Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence 3634 and Lecture Notes in Bioinformatics), 2012, vol. 7237 LNCS, pp. 465–482. 3635  C. Gentry, S. Halevi, and N. P. Smart, “Homomorphic evaluation of the AES circuit,” in Lecture 3636 Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and 3637 Lecture Notes in Bioinformatics), 2012, vol. 7417 LNCS, pp. 850–867. 3638  M. Naehrig, K. Lauter, and V. Vaikuntanathan, “Can homomorphic encryption be practical?,” in 3639 Proceedings of the 3rd ACM workshop on Cloud computing security workshop - CCSW ’11, 2011, 3640 p. 113 [Online]. Available: http://dl.acm.org/citation.cfm?doid=2046660.2046682 3641  D. Boneh and B. Waters, “Conjunctive, Subset, and Range Queries on Encrypted Data,” TCC 3642 2007 Theory Cryptogr., vol. 4392, pp. 535–554, 2007 [Online]. Available: 3643 http://www.springerlink.com/content/370086k273w1587t/%5Cnhttp://eprint.iacr.org/2006/287 3644  D. Cash, S. Jarecki, C. Jutla, H. Krawczyk, M. C. Roşu, and M. Steiner, “Highly-scalable 3645 searchable symmetric encryption with support for Boolean queries,” in Lecture Notes in Computer 3646 Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in 3647 Bioinformatics), 2013, vol. 8042 LNCS, no. Advances in Cryptology-CRYPTO 2013, PART 1, 156 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 3648 pp. 353–373. 3649  P. Datta, R. Dutta, and S. Mukhopadhyay, “Functional encryption for inner product with full 3650 function privacy,” in Lecture Notes in Computer Science (including subseries Lecture Notes in 3651 Artificial Intelligence and Lecture Notes in Bioinformatics), 2016, vol. 9614, pp. 164–195. 3652  C. Percival, “Cache missing for fun and profit,” BSDCan 2005, pp. 1–13, 2005 [Online]. 3653 Available: http://pdos.csail.mit.edu/6.858/2011/readings/ht- 3654 cache.pdf%5Cnhttp://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.144.872 3655  J. Seifert, Ç. Koç, and O. Aciiçmez, “Predicting Secret Keys Via Branch Prediction,” in Ct-Rsa, 3656 2007, vol. 4377, no. October 2016, pp. 225–242. 3657  A. Shamir, “Identity-Based Cryptosystems and Signature Schemes,” in Lecture Notes in Computer 3658 Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in 3659 Bioinformatics), 1985, vol. 196 LNCS, pp. 47–53. 3660  D. Boneh and M. Franklin, “Identity-Based Encryption from the Weil Pairing,” SIAM J. Comput., 3661 vol. 32, no. 3, pp. 586–615, 2003 [Online]. Available: 3662 http://epubs.siam.org/doi/10.1137/S0097539701398521 3663  B. Waters, “Dual system encryption: Realizing fully secure IBE and HIBE under simple 3664 assumptions,” in Lecture Notes in Computer Science (including subseries Lecture Notes in 3665 Artificial Intelligence and Lecture Notes in Bioinformatics), 2009, vol. 5677 LNCS, pp. 619–636. 3666  J. Chen and H. Wee, “Fully, (almost) tightly secure IBE and dual system groups,” in Lecture Notes 3667 in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture 3668 Notes in Bioinformatics), 2013, vol. 8043 LNCS, no. PART 2, pp. 435–460. 3669  C. S. Jutla and A. Roy, “Shorter Quasi-Adaptive NIZK Proofs for Linear Subspaces,” in Part I of 3670 the Proceedings of the 19th International Conference on Advances in Cryptology - ASIACRYPT 3671 2013 - Volume 8269, 2013, pp. 1–20 [Online]. Available: http://dx.doi.org/10.1007/978-3-642- 3672 42033-7_1 3673  A. Sahai and B. Waters, “Fuzzy Identity Based Encryption,” Eurocrypt ’05, pp. 457–473, 2005 3674 [Online]. Available: http://eprint.iacr.org/2004/086 3675  V. Goyal, O. Pandey, A. Sahai, and B. Waters, “Attribute-based encryption for fine-grained access 3676 control of encrypted data,” in Proceedings of the 13th ACM conference on Computer and 3677 communications security - CCS ’06, 2006, p. 89 [Online]. Available: 3678 http://portal.acm.org/citation.cfm?doid=1180405.1180418 3679  J. Bethencourt, A. Sahai, and B. Waters, “Ciphertext-Policy Attribute-Based Encryption,” in 3680 Proceedings of the 2007 IEEE Symposium on Security and Privacy SE - SP ’07, 2007, pp. 321– 3681 334. 3682  B. Waters, “Ciphertext-policy attribute-based encryption: An expressive, efficient, and provably 3683 secure realization,” in Lecture Notes in Computer Science (including subseries Lecture Notes in 3684 Artificial Intelligence and Lecture Notes in Bioinformatics), 2011, vol. 6571 LNCS, pp. 53–70. 157 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 3685  A. C. Yao, “Protocols for secure computations,” in 23rd Annual Symposium on Foundations of 3686 Computer Science (sfcs 1982), 1982, pp. 160–164 [Online]. Available: 3687 http://ieeexplore.ieee.org/document/4568388/ 3688  J. Saia and M. Zamani, “Recent Results in Scalable Multi-Party Computation,” SOFSEM 2015 3689 Theory Pract. Comput. Sci., no. 8939, pp. 24–44, 2015 [Online]. Available: 3690 http://link.springer.com/10.1007/978-3-662-46078-8_3 3691  M. Zamani, “A Multi-Party Computation Library,” GitHub, 2015. [Online]. Available: 3692 https://github.com/mahdiz/mpclib 3693  IEEE, “‘Digital Inclusion, Identity, Trust, and Agency’ (DIITA) Industry Connections Program,” 3694 2019. [Online]. Available: https://standards.ieee.org/industry-connections/diita/index.html 3695  F. Schuster et al., “VC3 : Trustworthy Data Analytics in the Cloud,” Mar. 2015 [Online]. 3696 Available: https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/vc3-MSR-TR- 3697 2014-39.pdf 3698  PCI Security Standards Council, “The Prioritized Approach to Pursue PCI DSS Compliance,” PCI 3699 DSS Prioritized Approach PCI DSS 3.2, 2016 [Online]. Available: 3700 https://www.pcisecuritystandards.org/documents/Prioritized-Approach-for-PCI_DSS-v3_2.pdf 3701  E. Barker, “Recommendation for Key Management – Part 1: General (Revision 4), NIST Special 3702 Publication 800-57,” Jan. 2016 [Online]. Available: 3703 http://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-57pt1r4.pdf 3704  R. Brown and J. Burrows, “FIPS PUB 140-2 Security Requirements For Cryptographic Modules,” 3705 Change, vol. 46, no. 2, p. 69, 2001 [Online]. Available: 3706 http://csrc.nist.gov/publications/fips/fips140- 3707 2/fips1402.pdf%5Cnhttp://ukpmc.ac.uk/abstract/CIT/148081 3708  NIST, “NIST SP 800-39, Managing Information Security Risk Organization, Mission, and 3709 Information System View,” 2011 [Online]. Available: 3710 http://csrc.nist.gov/publications/nistpubs/800-39/SP800-39-final.pdf 3711  T. Pasquier and D. Eyers, “Information Flow Audit for Transparency and Compliance in the 3712 Handling of Personal Data,” in 2016 IEEE International Conference on Cloud Engineering 3713 Workshop (IC2EW), 2016, pp. 112–117 [Online]. Available: 3714 http://dx.doi.org/10.1109/IC2EW.2016.29 3715  L. Dabbish, C. Stuart, J. Tsay, and J. Herbsleb, “Leveraging Transparency,” IEEE Softw., vol. 30, 3716 no. 1, pp. 37–43, Jan. 2013. 3717  K. Benjamin, C. Cappelli, and G. Santos, “Organizational Transparency Maturity Assessment 3718 Method,” in Proceedings of the 18th Annual International Conference on Digital Government 3719 Research SE - dg.o ’17, 2017, pp. 477–484 [Online]. Available: citeulike-article-id:14396325 3720  E. Theodoridis, G. Mylonas, and I. Chatzigiannakis, “Developing an IoT Smart City framework,” 3721 in IISA 2013, 2013, pp. 1–6. 158 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 3722  P. T. Grogan, K. Ho, A. Golkar, and O. L. de Weck, “Multi-Actor Value Modeling for Federated 3723 Systems,” IEEE Syst. J., vol. PP, no. 99, pp. 1–10, 2017. 3724  G. Ballard et al., “How to Make Shared Risk and Reward Sustainable,” 23rd Annu. Conf. Int. Gr. 3725 Lean Constr., 2015. 3726  D. M. Nicol, “Modeling and simulation in security evaluation,” Secur. Privacy, IEEE, vol. 3, no. 3727 5, pp. 71–74, 2005 [Online]. Available: http://dx.doi.org/10.1109/msp.2005.129 3728  V. Volovoi, “Simulation of maintenance processes in the Big Data era,” in 2016 Winter Simulation 3729 Conference (WSC), 2016, pp. 1872–1883 [Online]. Available: citeulike-article-id:14396317 3730  R. G. Lang, Silva, and R. A. F. Romero, “Development of Distributed Control Architecture for 3731 Multi-robot Systems,” in 2014 Joint Conference on Robotics: SBR-LARS Robotics Symposium and 3732 Robocontrol, 2014, pp. 163–168 [Online]. Available: citeulike-article-id:14396321 3733  D. Dudenhoeffer, M. Permann, and E. Sussman, “General methodology 3: a parallel simulation 3734 framework for infrastructure modeling and analysis,” in WSC ’02: Proceedings of the 34th 3735 conference on Winter simulation, 2002, pp. 1971–1977. 3736  I. Paik, “Situation awareness based on big data analysis,” in 2016 International Conference on 3737 Machine Learning and Cybernetics (ICMLC), 2016, vol. 2, pp. 911–916. 3738  J. Ryoo, R. Kazman, and P. Anand, “Architectural analysis for security,” IEEE Secur. Priv., vol. 3739 13, no. 6, pp. 52–59, 2015. 3740  G. Lea, “Notes from YOW! 2014: Scott Shaw on ‘Avoiding Speedbumps on the Road to 3741 Microservices.’” Graham Lea, p. 1, 02-Mar-2015 [Online]. Available: citeulike-article- 3742 id:14169875 3743  R. Dhall, “Performance Patterns in Microservices based Integrations,” Comput. Now, 2016 3744 [Online]. Available: citeulike-article-id:14166626%5Cnhttps://www.computer.org/web/the-clear- 3745 cloud/content?g=7477973&#38%5Cntype=blogpost&%2338%5CnurlTitle=performance-patterns- 3746 in-microservices-based-integrations 3747  G. Landers, A. Dayley, and J. Corriveau, “Magic Quadrant for Structured Data Archiving and 3748 Application Retirement,” Gartner.com, 2016. [Online]. Available: 3749 https://www.gartner.com/doc/reprints?id=1-39B7753&ct=160613&st=sb 3750  K. Ruan and J. Carthy, “Cloud Forensic Maturity Model,” in Digital Forensics and Cyber Crime, 3751 M. Rogers and K. C. Seigfried-Spellar, Eds. Berlin, Heidelberg: Springer Berlin Heidelberg, 2013, 3752 pp. 22–41 [Online]. Available: http://link.springer.com/chapter/10.1007/978-3-642-39891-9_2 3753  P. Franková, M. Drahošová, and P. Balco, “Agile Project Management Approach and its Use in 3754 Big Data Management,” Procedia Comput. Sci., vol. 83, pp. 576–583, 2016. 3755  E. Burger, Flexible views for view-based model-driven development. Karlsruhe. Deutschland: KIT 3756 Scientific Publishing, 2014 [Online]. Available: https://www.scopus.com/inward/record.uri?eid=2- 3757 s2.0-84958701302&partnerID=40&md5=52a94f4dba6d117f5bbc7a5cf105cf68 159 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 3758  K. Kent and M. Souppaya, “NIST SP 800-92: Guide to Computer Security Log Management,” 3759 Natl. Inst. Stand. Technol., pp. 1–72, 2006 [Online]. Available: 3760 http://logrhythm.com/Portals/0/resources/NIST Guide Log Mgmt SP800- 3761 92.pdf%5Cnhttp://m.sagedatasecurity.com/pdfs/SP800-92-NIST-Guide-to-Log-Management.pdf 3762  K. Kent, S. Chevalier, T. Grance, and H. Dang, “NIST SP 800-86: Guide to Integrating Forensic 3763 Techniques Into Incident Response,” NIST, Gaithersburg MD OR - NIST, Sep. 2006 [Online]. 3764 Available: http://nvlpubs.nist.gov/nistpubs/Legacy/SP/nistspecialpublication800-86.pdf 3765  S. Zareian, M. Fokaefs, H. Khazaei, M. Litoiu, and X. Zhang, “A Big Data Framework for Cloud 3766 Monitoring,” in Proceedings of the 2Nd International Workshop on BIG Data Software 3767 Engineering SE - BIGDSE ’16, 2016, pp. 58–64. 3768  E. Chabrow, “NIST Plans Cybersecurity Framework Update - GovInfoSecurity,” Government 3769 Information Security, 2016. [Online]. Available: http://www.govinfosecurity.com/interviews/nist- 3770 considers-cybersecurity-framework-update-i-3199#.V1jIbRyMY7E.twitter 3771  DHS, “Critical Infrastructure Cyber Community or C3 Voluntary Program,” US-CERT, 2014. 3772 [Online]. Available: https://www.us-cert.gov/ccubedvp. [Accessed: 14-Aug-2016] 3773  E. Gonzalez, “SENC Project: SABSA Enhanced NIST Cybersecurity Framework,” SABSA, 2015. 3774 [Online]. Available: http://www.sabsa.org/node/176. [Accessed: 15-Aug-2015] 3775  S. Zurier, “6 Things To Know For Securing Amazon Web Services,” Dark Read., Aug. 2016 3776 [Online]. Available: citeulike-article-id:14396487 3777  A. Textor, R. Kroeger, and K. Geihs, “Semantic models for bridging domains in automated IT 3778 management: Lessons learned,” in 2017 International Conference on Networked Systems (NetSys), 3779 2017, pp. 1–8. 3780  NIST, “NIST SP 800-190: Application Container Security Guide,” Sep. 2017 [Online]. Available: 3781 https://csrc.nist.gov/publications/detail/sp/800-190/final 3782  E. G. Aydal, R. F. Paige, H. Chivers, and P. J. Brooke, “Security Planning and Refactoring in 3783 Extreme Programming,” in Extreme Programming and Agile Processes in Software Engineering: 3784 7th International Conference, XP 2006, Oulu, Finland, June 17-22, 2006. Proceedings, P. 3785 Abrahamsson, M. Marchesi, and G. Succi, Eds. Berlin, Heidelberg: Springer Berlin Heidelberg, 3786 2006, pp. 154–163 [Online]. Available: https://doi.org/10.1007/11774129_16 3787  M. Iqbal and M. Rizwan, “Application of 80/20 rule in Software Engineering Waterfall Model,” in 3788 Information and Communication Technologies, 2009. ICICT ’09. International Conference on, 3789 2009 [Online]. Available: http://ieeexplore.ieee.org/document/5267186/ 3790  B. Boehm, J. A. Lane, S. Koolmanojwong, and R. Turner, The Incremental Commitment Spiral 3791 Model: Principles and Practices for Successful Systems and Software, 1st ed. Addison-Wesley 3792 Professional, 2014. 3793  N. MacDonald and I. Head, “DevSecOps: How to Seamlessly Integrate Security Into DevOps SE - 3794 G00315283,” Gartner Group, Stamford CT OR - Gartner Group, Sep. 2016. 160 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 3795  A. Cockroft, “Evolution of Microservices (video presentation),” ACM. Association for Computing 3796 Machinery, New York, NY, 20-Jul-2016 [Online]. Available: citeulike-article-id:14337247 3797  J. Roche, “Adopting DevOps practices in quality assurance,” Commun. ACM, vol. 56, no. 11, pp. 3798 38–43, 2013 [Online]. Available: http://dl.acm.org/citation.cfm?doid=2524713.2524721 3799  Tom Nolle, “Infrastructure as code complicates hybrid, multiple cloud management (Part 2 of 2),” 3800 Search Cloud Computing, 2016 [Online]. Available: 3801 http://searchcloudcomputing.techtarget.com/tip/Infrastructure-as-code-complicates-hybrid- 3802 multiple-cloud-management 3803  J. Steer and A. Popli, “Building secure business applications at Microsoft,” Inf. Secur. Tech. Rep., 3804 vol. 13, no. 2, pp. 105–110, May 2008 [Online]. Available: 3805 http://dx.doi.org/10.1016/j.istr.2008.04.001 3806  Tom Nolle, “Separating DevOps from the future-driven cloud orchestration,” Search Cloud 3807 Computing, 2016. [Online]. Available: 3808 http://searchcloudcomputing.techtarget.com/tip/Separating-DevOps-from-the-future-driven-cloud- 3809 orchestration 3810  R. Qasha, J. Cala, and P. Watson, “Towards Automated Workflow Deployment in the Cloud 3811 Using TOSCA,” in Proceedings - 2015 IEEE 8th International Conference on Cloud Computing, 3812 CLOUD 2015, 2015, pp. 1037–1040. 3813  P. Chambakara, “API-First Design: Dawn Of New Era In App Development,” Digital Doughnut. 3814 2015 [Online]. Available: citeulike-article- 3815 id:14074448%5Cnhttps://www.digitaldoughnut.com/articles/2015/november/api-first-design- 3816 dawn-of-new-era-in-app-developme 3817  ISO/IEC 33001:2015 Information technology — Process assessment — Concepts and terminology. 3818 International Organization for Standardization / International Electrotechnical Commission, 2015 3819 [Online]. Available: https://www.iso.org/standard/54175.html 3820  G. Chen and Y. Luo, “A BIM and ontology-based intelligent application framework,” in 2016 3821 IEEE Advanced Information Management, Communicates, Electronic and Automation Control 3822 Conference (IMCEC), 2016, pp. 494–497 [Online]. Available: citeulike-article-id:14396492 3823  C. Atkinson, D. Stoll, and P. Bostan, “Orthographic software modeling: A practical approach to 3824 view-based development,” in Communications in Computer and Information Science, 2010, vol. 3825 69 CCIS, pp. 206–219. 3826  A. Barth, A. Datta, J. Mitchell, and H. Nissenbaum, “Privacy and Contextual Integrity: Framework 3827 and Applications,” in Proceedings of the 2006 IEEE Symposium on Security and Privacy SE - SP 3828 ’06, 2006, pp. 184–198. 3829  P. Lam, J. Mitchell, A. Scedrov, S. Sundaram, and F. Wang, “Declarative privacy policy: finite 3830 models and attribute-based encryption,” in Proceedings of the 2nd ACM SIGHIT International 3831 Health Informatics Symposium SE - IHI ’12, 2012, pp. 323–332. 161 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 3832  J. Wilson, “THE CLOUD, REGULATIONS, AND PII,” Iconic, Jan-2016 [Online]. Available: 3833 https://www.ionic.com/blog/the-cloud-regulations-and-pii/ 3834  R. Nelson, “Big data analytics becomes strategic test tool,” Eval. Eng., Dec. 2015 [Online]. 3835 Available: citeulike-article-id:14169892 3836  A. Karmel, R. Chandramouli, and M. Iorga, “DRAFT Special Publication 800-180, NIST 3837 Definition of Microservices, Application Containers and System Virtual Machines,” NIST Spec. 3838 Publ. 800-180, vol. 800180, 2016 [Online]. Available: http://csrc.nist.gov/publications/drafts/800- 3839 180/sp800-180_draft.pdf 3840  S. Newman, “Building microservices : designing fine-grained systems.” O’Reilly Media, 3841 Sebastopol CA, 2015 [Online]. Available: http://www.worldcat.org/isbn/9781491950357 3842  A. Versteden, E. Pauwels, and A. Papantoniou, “An Ecosystem of User-facing Microservices 3843 supported by Semantic Models,” USEWOD-PROFILES@ESWC, vol. 1362, pp. 12–21, 2015. 3844  American National Standards Institute, “ANSI INCITS 359-2004 Role Based Access Control 3845 Information Technology Industry Council,” 2004 [Online]. Available: 3846 http://profsandhu.com/journals/tissec/ANSI+INCITS+359-2004.pdf 3847  D. R. Kuhn, E. J. Coyne, and T. R. Weil, “Adding attributes to role-based access control,” 3848 Computer (Long. Beach. Calif)., vol. 43, no. 6, pp. 79–81, 2010. 3849  D. F. Ferraiolo, G. J. Ahn, R. Chandramouli, and S. I. Gavrila, “The role control center: Features 3850 and case studies,” in Proceedings of ACM Symposium on Access Control Models and 3851 Technologies (SACMAT 2002), 2003, pp. 12–20. 3852  E. Bertino and B. Catania, “GEO-RBAC: a spatially aware RBAC,” Proc. tenth ACM Symp. 3853 Access Control Model. Technol., pp. 29–37, 2005 [Online]. Available: 3854 http://dl.acm.org/citation.cfm?id=1063985 3855  R. Ferrini and E. Bertino, “Supporting RBAC with XACML+OWL,” in Proceedings of the 14th 3856 ACM symposium on Access control models and technologies SE - SACMAT ’09, 2009, pp. 145– 3857 154. 3858  Y. Sun, X. Meng, S. Liu, and P. Pan, “An approach for flexible RBAC workflow system,” in 3859 Computer Supported Cooperative Work in Design, 2005. Proceedings of the Ninth International 3860 Conference on, 2005, vol. 1, pp. 524-529 Vol. 1 [Online]. Available: citeulike-article- 3861 id:1204995%5Cnhttp://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1504134 3862  NIST, “NIST SP 800-137: Information Security Continuous Monitoring (ISCM) for Federal 3863 Information Systems and Organizations,” Sep. 2011 [Online]. Available: 3864 https://nvlpubs.nist.gov/nistpubs/Legacy/SP/nistspecialpublication800-137.pdf 3865  M. Underwood, “Big Data Complex Event Processing for Internet of Things Provenance: Benefits 3866 for Audit, Forensics and Safety,” in Cyber-Assurance for the Internet of Things, T. Brooks, Ed. 3867 Hoboken NJ: Wiley, 2016. 162 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 3868  M. Underwood et al., “Internet of things: Toward smart networked systems and societies,” Appl. 3869 Ontol., vol. 10, no. 3–4, pp. 355–365, Sep. 2015. 3870  J. Turnbull, The Art of Monitoring. New York, NY: James Turnbull, 2016 [Online]. Available: 3871 citeulike-article-id:14395588 3872  International Organization for Standardization, “ISO Home Page,” 2019. [Online]. Available: 3873 https://www.iso.org/home.html 3874  T. Stewart, “Human after all,” IoSH Mag., Jun. 2016 [Online]. Available: citeulike-article- 3875 id:14396478 3876  M. Wilkinson et al., “The FAIR Guiding Principles for scientific data management and 3877 stewardship,” Sci. Data, vol. 3, p. 160018, Mar. 2016 [Online]. Available: 3878 http://dx.doi.org/10.1038/sdata.2016.18 3879  C. J. Hoofnagle, “How the Fair Credit Reporting Act Regulates Big Data,” pp. 1–6, Sep. 2013. 3880  R. Chandramouli, “NIST SP 800-125B: Secure Virtual Network Configuration for Virtual 3881 Machine (VM) Protection,” NIST Spec. Publ., vol. 800, no. 125B, p. 23, 2016 [Online]. Available: 3882 http://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-125B.pdf 3883  PCI Security Standards Council, “PCI DSS Virtualization Guidelines,” 2011 [Online]. Available: 3884 https://www.pcisecuritystandards.org/documents/Virtualization_InfoSupp_v2.pdf 3885  IEEE P1915.1 - Standard for Software Defined Networking and Network Function Virtualization 3886 Security. IEEE, 2015 [Online]. Available: https://standards.ieee.org/project/1915_1.html 3887  B. Keshavamurthy and M. Ashraf, “Conceptual design of proactive SONs based on the Big Data 3888 framework for 5G cellular networks: A novel Machine Learning perspective facilitating a shift in 3889 the SON paradigm,” in 2016 International Conference System Modeling Advancement in Research 3890 Trends (SMART), 2016, pp. 298–304. 3891  IEEE 2413-2019 - IEEE Approved Draft Standard for an Architectural Framework for the 3892 Internet of Things (IoT). IEEE, 2019 [Online]. Available: https://standards.ieee.org/content/ieee- 3893 standards/en/standard/2413-2019.html 3894  D. Ardagna, L. Baresi, S. Comai, M. Comuzzi, and B. Pernici, “A service-based framework for 3895 flexible business processes,” IEEE Softw., vol. 28, no. 2, pp. 61–67, 2011. 3896  Microsoft, “Deploying Windows Rights Management Services at Microsoft,” 2013. [Online]. 3897 Available: http://technet.microsoft.com/en-us/library/dd277323.aspx 3898  The Nielsen Company, “Consumer Panel and Retail Measurement,” 2015. [Online]. Available: 3899 www.nielsen.com/us/en/nielsen-solutions/nielsen-measurement/nielsen-retail-measurement.html 3900  SAFE-BioPharma Association, “Welcome to SAFE-BioPharma.” [Online]. Available: 3901 http://www.safe-biopharma.org/ 3902  Microsoft, “How to set event log security locally or by using Group Policy in Windows Server 163 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2NIST BIG DATA INTEROPERABILITY FRAMEWORK: VOLUME 4, SECURITY AND PRIVACY 3903 2003,” 07-Jan-2017. [Online]. Available: http://support.microsoft.com/kb/323076 3904  DefenseSystems, “UAV video encryption remains unfinished job,” 31-Oct-2012. [Online]. 3905 Available: http://defensesystems.com/articles/2012/10/31/agg-drone-video-encryption-lags.aspx 3906  Department of Defense Memorandum from DoD CIO, “Department of Defense Cloud Computing 3907 Strategy,” Jul. 2012 [Online]. Available: http://1.usa.gov/1E0UTXT 3908  A. Sanna and F. Lamberti, “Advances in target detection and tracking in forward-looking infrared 3909 (FLIR) imagery,” Sensors (Switzerland), vol. 14, no. 11, pp. 20297–20303, 2014. 3910  K. A. G. Fisher et al., “Quantum computing on encrypted data,” Nat. Commun., vol. 5, 2014. 3911  J. Cartledge, “US Lawmakers Pledge to Close Air Cargo Security ‘Loophole,’” Post and Parcel, 3912 01-Nov-2010. [Online]. Available: http://postandparcel.info/35115/news/us-lawmakers-pledge-to- 3913 close-air-cargo-security-“loophole”/ 3914  S. Captain, “With Mapbox Deal, IBM Watson Will Learn A Lot More About Where Things Are 3915 Happening | Fast Company | Business + Innovation,” Fast Company, 2016. [Online]. Available: 3916 http://www.fastcompany.com/3062635/with-mapbox-deal-ibm-watson-will-know-where-things- 3917 are-happening 3918  R. Chandramouli, “Secure Virtual Network Configuration for Virtual Machine (VM) Protection 3919 (NIST SP 800-125B),” 2016 [Online]. Available: 3920 http://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-125B.pdf 3921 164 This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.1500-4r2