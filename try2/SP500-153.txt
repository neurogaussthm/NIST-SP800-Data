Computer Science All102789139 and Technology Ol A11105 7flT13T NBS Special Publication 500-153 Guide to Auditing for Controls Nes and Security: PUBLICATIONS A System Development Life Cycle Approach 100 .U57 #500-153 1988T m he National Bureau of Standards' was established by an act of Congress on March 3, 1901. The Bureau's overall goal is to strengthen and advance the nation's science and technology and facilitate their effective application for public benefit. To this end, the Bureau conducts research to assure international competitiveness and leadership of U.S. industry, science arid technology. NBS work involves development and transfer of measurements, standards and related science and technology, in support of continually improving U.S. productivity, product quality and reliability, innovation and underlying science and engineering. The Bureau's technical work is performed by the National Measurement Laboratory, the National Engineering Laboratory, the Institute for Computer Sciences and Technology, and the Institute for Materials Science and Engineering. The National Measurement Laboratory Provides the national system of physical and chemical measurement; • Basic Standards^ coordinates the system with measurement systems of other nations and • Radiation Research furnishes essential services leading to accurate and uniform physical and • Chemical Physics chemical measurement throughout the Nation's scientific community, • Analytical Chemistry industry, and commerce; provides advisory and research services to other Government agencies; conducts physical and chemical research; develops, produces, and distributes Standard Reference Materials; provides calibration services; and manages the National Standard Reference Data System. The Laboratory consists of the following centers: The National Engineering Laboratory Provides technology and technical services to the public and private sectors • Applied Mathematics to address national needs and to solve national problems; conducts research • Electronics and Electrical in engineering and applied science in support of these efforts; builds and Engineering^ maintains competence in the necessary disciplines required to carry out this • Manufacturing Engineering research and technical service; develops engineering data and measurement • Building Technology capabilities; provides engineering measurement traceability services; • Fire Research develops test methods and proposes engineering standards and code • Chemical Engineering^ changes; develops and proposes new engineering practices; and develops and improves mechanisms to transfer results of its research to the ultimate user. The Laboratory consists of the following centers: The Institute for Computer Sciences and Technology Conducts research and provides scientific and technical services to aid Information Systems Engineering Federal agencies in the selection, acquisition, application, and use of Systems and Software computer technology to improve effectiveness and economy in Government Technology operations in accordance with Public Law 89-306 (40 U.S.C. 759), Computer Security relevant Executive Orders, and other directives; carries out this mission by Systems and Network managing the Federal Information Processing Standards Program, Architecture developing Federal ADP standards guidelines, cind managing Federal Advanced Computer Systems ADP participation in voluntary standardization activities; provides scientific and technological advisory services and assistance to Federal agencies; and provides the technical foundation for computer-related policies of the Federal Government. The Institute consists of the following divisions: The Institute for Materials Science and Engineering Conducts research and provides measurements, data, standards, reference • Ceramics materials, quantitative understanding and other technical information • Fracture and Deformation^ fundamental to the processing, structure, properties and performance of • Polymers materials; addresses the scientific basis for new advanced materials • Metallurgy technologies; plans research around cross-cutting scientific themes such as • Reactor Radiation nondestructive evaluation and phase diagram development; oversees Bureau-wide technical programs in nuclear reactor radiation research and nondestructive evaluation; and broadly disseminates generic technical information resulting from its programs. The Institute consists of the following Divisions: 'Headquarters and Laboratories at Gaithersburg, MD, unless otherwise noted; mailing address MD Gaithersburg, 20899. ^Some divisions within the center are located at Boulder, CO 80303. ^Located at Boulder, CO, with some elements at Gaithersburg, MDComputer Science and Technology NBS Special Publication 500-153 Guide to Auditing for Controls and Security: A System Development Life Cycle Approach Editors/Authors: Zella G. Ruthberg Bonnie T. Fisher William E„ Perry John W. Lainhart SV James G. Cox ' Mark Gillen Douglas B. Hunt Co-Sponsored by: President's Council on Integrity and Efficiency and Institute for Computer Sciences and Technology National Bureau of Standards MD Gaithersburg, 20899 Research Information Center National Bureau of Standards April 1988 Gaithersburg, Maryland 20899 DEPARTMENT OF COMMERCE U.S. C. William Verity, Secretary National Bureau of Standards Ernest Ambler, DirectorReports on Computer Science and Technology The National Bureau of Standards has a special responsibilitywithin the Federal Government for com- puter science and technology activities. The programs of the NBS Institute for Computer Sciences and Technology are designed to provide ADP standards, guidelines, and technical advisory services to im- prove the effectiveness of computer utilization in the Federal sector, and to perform appropriate research and development efforts asfoundation for such activities and programs.This publication serieswill report these NBS efforts to the Federal computer communityaswell asto Interested specialists inthe academic and private sectors. Those wishing to receive notices of publications in this series should complete and return the form at the end of this publication. Library of Congress Catalog Card Number: 88-600518 National Bureau of Standards Special Publication 500-153 Natl. Bur. Stand. (U.S.), Spec. Publ. 500-153, 266 pages (Apr. 1988) CODEN: XNBSAV U.S. GOVERNMENT PRINTING OFFICE WASHINGTON: 1988 For sale by the Superintendent of Documents, U.S. Government Printing Office, Washington DC 20402Table ofContents EXECUTIVE SUMMARY xiii CHAPTER 1 GENERALADP AUDIT ISSUES 1 INTRODUCTION 1.1 1 1.1.1 Scope ofthe Audit Guide 1 1.1.2 How to Use the Audit Guide 2 1.1.3 Auditor Skills Needed 2 1.1.4 Auditing in a Computerized Environment 3 1.1.4.1 The Need 3 1.1.4.2 The Scope ofAudit in a Computerized Environment 3 1.1.4.3 Relationship Between Systems Development Audits and Operational Audits ofAutomated Information Systems (AISs) 4 1.1.5 Relevant Laws and Regulations 4 1.1.5.1 Requirements for Audit Involvement 4 1.1.5.2 Requirements for Internal Control 5 ^ 1.2 RISKS GENERATED BY COMPUTER TECHNOLOGY 6 1.2.1 Overview ofRisks 6 1.2.1.1 Definitions 7 1.2.1.2 Vulnerability/Risk Related Requirements 7 1.2.2 Risks in a Computerized Environment 8 1.2.2.1 Additional Risks Present in a Computerized Environment 8 1.2.2.2 Assessing Vulnerabilities Through the Audit Process 9 1.3 CONTROL OBJECTIVES AND STANDARDS IN A COMPUTER ENVIRONMENT 10 1.3.1 Impact ofthe Computer on Controls 10 1.3.2 Internal Control and Computer Security Review Policy 11 1.4 EVIDENCE IN AUTOMATED SYSTEMS 14 1.5 AIS AUDITABILITY 15 CHAPTER 2 AIS LIFE CYCLE CONSIDERATIONS 16 iiiBACKGROUND 2.1 16 ( 2.1.1 PCIE - EDP Systems Review and Security Work Group 16 2.1.2 System Development Life Cycle 16 OPERATING ENVIRONMENT 2.2 17 2.2.1 IRM Planning and Implementation ofPolicy Guidelines 17 IRM 2.2.1.1 Planning 17 2.2.1.2 Using Policy/Procedures/Standards 18 2.2.1.2.1 References Used by the Life Cycle Matrix 19 GSA 2.2.1.2.2 Major References 21 2.2.2 AIS Development Methodologies 21 2.2.3 Project Administration and Control 23 2.2.4 AIS Life Cycle Matrix 24 2.3 LIFE CYCLE PHASES 26 2.3.1 Initiation - Phase I 27 2.3.2 Definition - Phase II 27 2.3.3 System Design - Phase III 27 2.3.4 Programming and Training - Phase IV 28 V 2.3.5 Evaluation and Acceptance - Phase 28 2.3.6 Installation and Operation - Phase VI 29 ^ 2.4 RESPONSIBLE PARTICIPANTS AND THEIR FUNCTION INTHE AIS LIFE CYCLE 29 2.4.1 Policy/Oversight Participants 29 2.4.1.1 Information Resources Management (IRM) Official 29 2.4.1.2 System Security Officer (SSO) 30 2.4.1.3 Internal Control Officer (ICO) 30 2.4.2 Functional/Operational Participants 30 2.4.2.1 Sponsor/User 30 2.4.2.2 Project Manager/Contracting Officer's Technical Representative (COTR) 30 2.4.2.3 System Security Specialist (SSS) 31 2.4.2.4 Internal Control Specialist (ICS) 31 2.4.2.5 Contracting Officer 31 2.4.2.6 ADP Manager 32 2.4.2.7 QuaHty Assurance (QA) Specialist 32 2.5 USE OF EXTERNALDEVELOPMENl^ SERVICES 32 2.5.1 Contractor Services 32 2.5,1.1 Differences from the AIS Life Cycle Matrix 33 ivp 2.5.1.2 Differences in Audit Approach 34 2.5.2 Off-The-ShelfSoftwareATurnkey Systems 35 2.5.2.1 Differences from the AIS Life Cycle Matrix 36 2.5.2.2 Differences in Audit Approach 37 2.6 AIS LIFE CYCLE DOCUMENTATION 37 2.6.1 Needs Statement 38 2.6.2 Feasibility Study Document 38 2.6.3 Risk Analysis 38 2.6.4 Cost/Benefit Analysis 40 2.6.5 System Decision Paper 40 2.6.6 Audit Plan 40 2.6.7 Project Plan 41 2.6.8 Requirements Documents 41 2.6.8.1 Functional Requirements Document 41 2.6.8.2 Functional Security and Internal Control Requirements Document 42 2.6.8.3 Data Requirements Document 42 2.6.8.4 Data Sensitivity/Criticality Description 42 2.6.9 Specifications Documents 42 2.6.9.1 System/Subsystem, Program and Data Base Specifications 42 9 2.6.9.2 Security and Internal Control Related Specifications 43 2.6.10 Validation, Verification and Testing Plan and Specifications 43 2.6.11 User Manual 44 2.6.12 Operations/Maintenance Manual 44 2.6.13 Installation and Conversion Plan 44 2.6.14 Test Analysis and Security Evaluation Report 44 2.7 DOCUMENT PHASING AND INTERRELATIONSHIPS 45 2.7.1 Need for Flexibility 45 2.7.2 Notation Conventions in Figure 2 46 CHAPTER 3 A WORK PRIORITY SCHEME FORTHE ADP AUDITOR 47 3.1 INTRODUCTION 47 3.1.1 The Work Priority Scheme in Perspective 47 3.1.2 BriefOverview ofthe Scheme 47 3.2 THE NEED FOR THE SCHEME 48 3.2.1 ADP Audits/Security Reviews - A Form ofControl 48 I V^ 3.2.2 Size ofReviewTask 49 i BACKGROUND ON THE METHODOLOGY 3.3 49 3.3.1 The Invitational Workshop 49 3.3.2 Workshop Points ofAgreement 49 A WORK PRIORITY SCHEME FOR THE ADP AUDITOR 3.4 50 3.4.1 Assumptions and Caveats 50 3.4.2 Audit Planning/Prioritization Process 51 3.4.3 Non-Discretionary Audits 51 3.4.4 Risk Evaluation Levels and Dimensions 53 3.4.5 Two Level Work Priority Dimensions/Characteristics 54 3.4.5.1 Level I: .....55 3.4.5.1.1 Mission Impact/Strategic Value/Organization (Business) Criticality and Sensitivity Factors 55 3.4.5.2 Level II: 56 3.4.5.2.1 System Size/Scale/Complexity 56 3.4.5.2.2 System Environment/Stability 57 3.4.5.2.3 Reliability/Integrity 58 3.4.5.2.4 Technology Integration 59 RISK SCORING APPLICATION OFTHE WORK PRIORITY 3.5 -- ^ SCHEME 59 3.5.1 Implementation ofthe Scheme 59 A 3.5.2 Simple Scoring Approach 60 A 3.5.3 Detailed Scoring Approach 60 3.5.4 Discretionary Audits 60 3.6 USES OFTHE WORK PRIORITY SCHEME 62 3.7 PROBLEMS WITH AND SOLUTIONS TO USE OF SCHEME 63 3.7.1 Potential Difficulties in Utilization 63 3.7.2 Methods for Overcoming Difficulties 64 3.8 NEXT STEPS 65 3.8.1 The Audit Organization 65 3.8.2 The ADP Auditor 65 CHAPTER 4 AIS DEVELOPMENTALAUDITS 67 ( viSDLCCONTROLOBJECTIVES AND AUDIT CONCERNS I 4.1 67 4.1.1 Control Objectives 67 4.1.2 Auditors' Control Concerns 68 4.1.2.1 Legal Requirements 68 4.1.2.2 Management Policies 68 4.1.2.3 Internal Controls 69 4.1.2.4 Audit Trails 69 4.1.2.5 Documentation 69 4.1.2.6 Economy and Efficiency 70 APPROACH FOR SYSTEMS UNDER DEVELOPMENT 4.2 70 4.2.1 Introduction 70 4.2.2 Preliminary Review ofthe SDLC Methodology 71 4.2.2.1 Review the SDLC Methodology to be Used in Developing the AIS Under Review 72 4.2.2.2 Compare Organization's SDLC Methodology to Audit Guide SDLC Methodology 74 4.2.3 AIS Development Impact on Audit Scope 75 4.2.4 The Effect ofa Quality Assurance (QA) Function on the ADP Auditor's Role in the SDLC 76 ^ 4.3 AUDITPARTICIPATION DURING THE INITIATION PHASE - PHASE I 77 4.3.1 Primary Audit Objective ofthe Initiation Phase 77 4.3.2 Overview ofthe Initiation Phase 77 4.3.2.1 Participants and Their Tasks 78 4.3.2.2 System Initiation Phase Documents 79 4.3.3 Audit Survey 80 4.3.3.1 Study the Initiation Phase Environment 80 4.3.3.2 Review Initiation Phase Plans 81 4.3.3.3 Gather Information on the Initiation Phase Status 81 4.3.3.4 Verify Information on Initiation Phase Status 81 4.3.3.4.1 Review Documents 81 4.3.3.4.2 Interview Key Participants 82 4.3.4 Customize Audit Objectives 83 4.3.4.1 SDLC Methodology Audit Considerations 83 4.3.4.2 Contracting/Purchase Audit Considerations 85 4.3.5 Detailed AuditTesting 86 4.3.5.1 Introduction 86 4.3.5.2 Systems Initiation Phase Audit Tests Program 86 4.3.5.3 Survey Questionnaire - Initiation Phase 86 vii4.3.6 Audit Results/Reporting 88 4.3.6.1 Potential Deficiencies 88 4.3.6.2 Potential Effects ofDeficiencies on Meeting System Mission ... 89 4.3.7 Reassess Audit Strategy 89 AUDIT PARTICIPATION IN THE DEFINITION PHASE - PHASE II .... 100 4.4.1 Primary Audit Objective ofthe Definition Phase 100 4.4.2 Overview ofthe Definition Phase 100 4.4.2.1 Participants and Their Tasks 101 4.4.2.2 System Definition Phase Documents 102 4.4.3 Audit Survey 103 4.4.3.1 Review Initiation Phase Outputs 104 4.4.3.2 Review Definition Phase Plans 104 4.4.3.3 Gather Information on Definition Phase Status 104 4.4.3.4 Verify Information on Definition Phase Status 105 4.4.3.4.1 Review Documents 105 4.4.3.4.2 Interview Key Participants 106 4.4.4 Customize Audit Objectives 108 4.4.4.1 SDLC Methodology Audit Considerations 108 4.4.4.2 Contracting/Purchase Audit Considerations 108 4.4.5 Detailed Audit Testing 109 4.4.5.1 Introduction 109 4.4.5.2 Definition Phase Audit Tests 109 4.4.5.3 Survey Questionnaire-Definition Phase 110 4.4.6 Audit Results/Reporting Ill 4.4.6.1 Potential Deficiencies Ill 4.4.6.2 Potential Effects ofDeficiencies on Meeting System Mission 112 . . 4.4.7 Reassess Audit Strategy 113 AUDIT PARTICIPATION IN THE SYSTEM DESIGN PHASE - PHASE III 121 4.5.1 Primary Audit Objective ofthe System Design Phase 121 4.5.2 Overview ofthe System Design Phase 121 4.5.2.1 Participants and Their Tasks 122 4.5.2.2 System Design Phase Documents 123 4.5.3 Audit Survey 124 4.5.3.1 Review Definition Phase Outputs 124 4.5.3.2 Review Design Phase Plans 124 4.5.3.3 Gather Information on Design Phase Status 125 4.5.3.4 Verify Information on Design Phase Status 125 4.5.3.4.1 Review Documents 125 viii4.5.3.4.2 Interview the Participants 126 4.5.4 Customize Audit Objectives 127 4.5.4.1 Design Methodology Audit Considerations 128 4.5.4.2 Contracting/Purchase Audit Considerations 129 4.5.5 Detailed Audit Testing 130 4.5.5.1 Introduction 130 4.5.5.2 System Design Phase Audit Test Program 130 4.5.5.3 Survey Questionnaire-Design Phase 131 4.5.6 Audit Results/Reporting 132 4.5.6.1 Potential Deficiencies 132 4.5.6.2 Potential Effects ofDeficiencies on Meeting System Mission .. 133 4.5.7 Reassess Audit Strategy 134 4.6 AUDIT PARTICIPATION IN THE PROGRAMMING AND TRAINING PHASE - PHASE IV 141 4.6.1 Primary Audit Objective ofthe Programming and Training Phase .... 141 4.6.2 Overview ofthe Programming and Training Phase 141 4.6.2.1 Participants and Their Tasks 142 4.6.2.2 Programming and Training Phase Documents 143 4.6.3 Audit Survey 144 ^ 4.6.3.1 Review System Design Phase Outputs 144 4.6.3.2 Review Programming and Training Phase Plans 145 4.6.3.3 Gather Information on Programming and Training Phase Status 145 4.6.3.4 Verify Information on Programming and Testing Phase Status 146 . 4.6.3.4.1 Review Documents 146 4.6.3.4.2 Interview Key Participants 149 4.6.4 Customize Audit Objectives 151 4.6.4.1 Design Methodology Audit Considerations 151 4.6.4.2 Contracting/Purchase Audit Considerations 152 4.6.5 Detailed Audit Testing 153 4.6.5.1 Introduction 154 4.6.5.2 Programming and Training Phase Audit Tests 154 4.6.6 Audit Results/Reporting 154 4.6.6.1 Potential Deficiencies 155 4.6.6.2 Potential Effects ofDeficiencies on Meeting System Mission 155 . , 4.6.7 Reassess Audit Strategy 156 4.7 AUDIT PARTICIPATION IN THE EVALUATION AND ACCEPTANCE PHASE -PHASE V 163 4.7.1 Primary Audit Objective ofthe Evaluation and Acceptance Phase 163 ix4.7.2 Overview ofthe Evaluation and Acceptance Phase 164 4J.2.1 Participants and Their Tasks 164 4.7.2.2 Evaluation and Acceptance Phase Document 166 4.7.3 Audit Survey 166 4.7.3.1 Review Programming and Training Phase Outputs 166 4.7.3.2 Review Evaluation and Acceptance Phase Plans 166 4.7.3.3 Gather Information on Evaluation and Acceptance Phase Status 167 4.7.3.4 Verify Information on the Evaluation and Acceptance Phase Status 167 4.7.3.4.1 Review Documents 168 4.7.3.4.2 Interview Key Participants 168 4.7.4 Customize Audit Objectives 171 4.7.4.1 Evaluation and Acceptance Phase Methodology Audit Considerations 171 4.7.4.2 Contracting/Purchase Audit Considerations 172 4.7.5 Detailed Audit Testing 173 4.7.5.1 Introduction 173 4.7.5.2 Evaluation and Acceptance Phase Audit Tests 174 4.7.6 Audit Results/Reporting 174 4.7.6.1 Potential Deficiencies 174 4.7.6.2 Potential Effects ofDeficiencies on Meeting System Mission .. 175 4.7.7 Reassess Audit Results/Plans 175 Appendix A - PCIE Work Group on EDP Systems Review and Security A-1 Appendix B - Laws and Regulations B-1 Appendix C - Key Computer Security and Audit Definitions C-1 D Appendix - Additional Risks in a Computerized Environment D-1 Appendix E - Vulnerabilities in a Computerized Environment E-1 Appendix F - Evidence Provided by Computer Technology F-1 G Appendix - Key References - Annotated G-1 H Appendix - Bibliography H-1 Appendix I - PCIE/NBS Invitational Workshop - Discussion Groups Membership I-l Appendix J - Two Risk Scoring Methods J-1 i XLIST OF FIGURES Figure Page 1. Automated Information System (AIS) - Life-Cycle Matrix 25 2. System Life-Cycle Documentation Flow Chart 39 3. Audit Planning/Prioritization Process 52 4. Audit Areas ofConcern 61 5. Flow ofEvaluation Work 169 F.l Audit Impact Matrix F-7 F.2 Comparison ofOld and New Forms ofEvidence F-8 J.l System Risk Scoring - Simplified Method J-2 J.2 Practice Template for Risk Scoring ofan AIS J-8 LIST OF TABLES Table Page 4.1 Initiation Phase Audit Tests 91 4.2 Definition Phase Audit Tests 114 4.3 System Design Phase Audit Tests 155 4.4 Programming and Training Phase Audit Tests 157 4.5 Evaluation and Acceptance Phase Audit Tests 176 J.l System Risk Scoring - Simplified Method Example J-3 J.2 Dimension Risk Scores and System Risk Scores for AIS 1 J-9 J.3 Dimension Risk Scores and System Risk Scores for AIS 2 J-10 xiLIST OFACRONYMS ADP Automated Data Processing AIS Automated Information System CFR Code ofFederal Regulations COTR Contracting Officer's Technical Representative DP Data Processing EDP Electronic Data Processing FAR Federal Acquisition Regulation FIRMR Federal Information Resources Management Regulation FPR Federal Procurement Regulation FPMR Federal Property Management Regulation GAO General Accounting Office GSA General Services Administration ICS Internal Control Specialist OIG Office ofInspector General OMB Office ofManagement and Budget NBS National Bureau ofStandards PCIE President's Council on Integrity and Efficiency PCMI President's Council on Management Improvement PM Project Manager QA Quality Assurance RFP Request for Proposal SDLC System Development Life Cycle SDM System Development Methodology SLC System Life Cycle sss System Security Specialist W&T Verification, Validation, and Testing xiiEXECUTIVE SUMMARY This guide addresses auditing the system development hfe cycle (SDLC) process for an automated information system (AIS), to ensure that controls and security are designed and built into the system. The guide also presents a process for deciding which system to audit among an organization's universe of systems. It is directed toward mid-level ADP auditors having a minimum oftwo years experience in ADP auditing, but can also be used by security ADP reviewers, quaHty assurance personnel, and as a training tool for less experienced ADP auditors. managers and system developers will also find it useful guidance on security and control issues. The guide is designed to provide audit/review programs for each major phase of the SDLC process and assumes a large sensitive system. The reader is expected to make appropriate modifications for small less sensitive systems. The guide represents the results of the past four years of activities by the Electronic Data Processing (EDP) Systems Review and Security Work Group of the Computer Security Project within the President's A Council on Integrity and Efficiency (PCIE). (See Appendix for more information on the Work Group.) This guide can be used in any ofthe followingways: 1. Understandingthe needforandplanningforauditorreviewinvolvementinAISs under development - Chapters 1 and 2 are designed to assist the auditor inplan- ning an audit for such systems under development. These chapters explain the neworincreased risks inAISs, the types ofcontrolsused inthose systems, aswell as a conceptual model for systems development. 2. Identifying systems for audit/review involvement - Chapter 3 provides a risk as- sessment approach to help identify an agency's high-risk systems. These are the systems most needing audit/review coverage. 3. Creatinga phase-by-phaseprogramforauditors orsecurityreviewersinvolved in areviewofAISsunderdevelopment-Chapter4providesacompleteaudit/review program designed for each of the five major phases of the system development process. Throughout thisdocument, the systemdevelopment Ufe cycle (SDLC) isdefmedas amajorsubset ofthe systemlifecycle (SLC).TheSLC consistsofthefive phases intheSDLCplus the sixth phase, Installation and Operation. xiiiIn order to provide a rich background ofmaterials for the user ofthe guide, the relevant laws and regulations are cited and described (Section 1.1.5 andAppendixB) and the mostuse- ful references are cited with many ofthem described (Sections 2.2.1,2.1 and 2.2.1.2.2, Appen- dices G and H). The relevant laws regulations, and standards promulgated by Congress, the Office ofManagement and Budget (OMB), and the U.S. General Accounting Office (GAO) have been divided into two sets: 1) those that require audit involvement in AISs and 2) those thatrequire internal control inAISs. Chapter 1 also contains adiscussion ofthe related issues ofcomputer generated risk, control objectives and standards in a computer environment, the audit/review evidence found in automated systems, and AIS auditability. The references ap- pearinginChapter2 ofthe guide are also divided into two sets: 1) those NBS and DOD docu- ments that formed the basis for the Life Cycle Matrix of Figure 1 and 2) the major related General Services Administration (GSA) references on software improvement and software G engineering. Appendix contains descriptions ofkey references relating to all the materials H in this guide while Appendix contains a more general listing of related references, with no descriptions. - The model arrived at for describing the phases and functional roles in the AIS life cycle is presented inthe Life Cycle Matrix in Figure 1 and described atlength inChapter 2.The ac- companying flow of documents, as the system progresses through the Hfe cycle phases ofIn- itiation, Definition, Design, Programming and Training, Evaluation and Acceptance, and Installation and Operation, are shown in Figure 2 and described in Section 2.6. The activities to be conducted by the functional roles (i.e.. Information Resources Management Official, System Security Officer/Internal Control Officer, Auditor, Sponsor/User, Project Manager/ContractingOfficer'sTechnical Representative, SystemSecuritySpeciahst, Internal ADP Control Specialist, Contracting Officer, Manager, and QuahtyAssurance Specialist) ap- pear in abbreviated form in the Life Cycle Matrix ofFigure 1 and are described more fully in Section 2.4. Changes in these activities that result from the use of external development ser- vices (contract or off-the-shelf) are discussed in Section 2.5. ADP Since auditorsecurityreviewscanbeverytime consumingand, therefore,canplace a tremendous drain on an organization's audit/review resources, the Work Group developed a work priority scheme in March of 1986, using the input generated by a small invitational workshop on the subject. This scheme was published as an internal report by the National Bureau ofStandards in August of 1986, NBSIR86-3386, and appears in this guide as Chapter 3. The scheme is in the form ofa high level risk assessment which employs a two-level review of the major areas of concern (or dimensions). Level I looks at the dimension called Criticality/Mission Impact while Level II looks at four dimensions (namely, Size/Scale/Com- plexity, Environment/Stability, Reliability/Integrity, and Technology Integration). The result ofapplying the scheme is to rank the audit/reviewwork in order ofdegree ofrisk posed to the organizationbythe variousAISs. Information from existing risk analyses andvulnerability as- sessments may be used to reduce the costs ofthis risk assessment. xivChapter 4 presents an audit/review program for each of the five phases of the system development process (SDLC). The control objectives used as the basis for each phase audit/review are divided into six categories (i.e., Legal Requirements, Management PoUcies, Internal Controls, Audit Trails, Documentation, and Economy and Efficiency) and are taken fromtheU.S.GAO"YellowBook"onstandardsforauditinthe Federalgovernment [GAOS 1- 1].Thecontents ofeachphase audit/reviewprogramare drivenbythe listingofactivitiesfound in the Life Cycle Matrix ofFigure L The first step in the audit/review program is to evaluate the life cycle methodology currently being used by the organization, to ensure that it encom- passes the bestparts/documents ofthe methodology described in Chapter2. The audit/review coverageineachphase ispresentedinaparallelmannerforconsistency andequalcomprehen- siveness. Each phase audit/review effort is presented in terms ofthe same eight components: 1) briefintroduction to the phase and appropriate audit participation, 2) primary audit objec- tives, 3) overview ofthe phase, 4) initial background audit survey, 5) customized audit objec- tives, 6) detailed audittesting, 7) assessmentofauditresults, and 8) questionnairesormatrices for obtaining information (the audit program), found inTables 4.1 to 4.5. Although quality assurance is not heavily implemented in the Federal agencies at this time, the quality assurance functional role was included because use of this activity, in early systemdevelopment particularly, cangreatly reduce costly errors and omissions aswell as the ADP agency's audit burden. Given the relatively limited amount of resources available for ADP reviews and the time consuming nature of systems development work, auditors should focus heavily on 1) the effectiveness ofthe process fordesigning and developing internal con- trolsinautomatedsystemsand2)thesubstance ofthoseinternalcontrols.Thesereviewswould result in large cost savings for the organizations. Any rigid application of the SDLC process presented here would be unrealistic in the rapidly changing computer environments that may now include such elements as distributed databases, expert systems, protyping, and computer-aided systems engineering. The reader is urged to be flexible and to followthe spirit ofthis document insuch instances, rather than ad- here bhndly to the details in this guide. Although operational audits are also important, they are not addressed because there is alreadymuchpublicliteratureonthatsubject.Forcontrolassessmentinthe operationalphase, the GAO "Black Book" [GA081-3] has a particularly thorough treatment. The main reasons for choosing to address SDLC audit are 1) there is a tremendous pay-off available to an or- ganizationwhen systems are developed with controls and security from the start and 2) there is currently very little comprehensive guidance available on SDLC audits for the Federal government. The Work Group hopes this document helps to fill this need. XVACKNOWLEDGEMENTS This documentrepresentsthe efforts ofmanypeople.TheHstofeditors/authors citesthe individualswho contributedmost to the final contents. BonnieT. Fisherwasprimarilyrespon- sible for the Life-Cycle Matrix described in Chapter 2 and co-authored, with Zella G. Ruth- berg, the Work Priority Scheme found in Chapter 3. William E. Perry wrote the initial draft ofthe bodyofthe document, undercontractto the Institute for Computer Sciences andTech- nology(ICST) atthe NationalBureauofStandards (NBS) andthe Office ofInspectorGeneral (OIG) ofthe Department ofHealth and Human Services (HHS). Still under contract, he also wrotetheseconddraft,usingextensiverevisionsrecommendedbyJohnW. LainhartIV,James G. Cox, MarkGillen, andDouglas B. Huntaswell as BonnieT. Fisher andZellaG.Ruthberg. The third and final draftwas the result ofmany hours spent by this subcommittee ofthe EDP Systems Review and Security Work Group (the editors/authors minus W. E. Perry). During the latter half of this project, Gail Shelton and James G. Cox were the project leaders ofthe EDP Systems Review and Security Work Group under Richard Kusserow, In- spectorGeneral ofHHS. Ms. Sheltonvery ablyplanned and carried out the manyadministra- tive details ofthis complex undertakingwhile Mr. Cox handled the technical component. We would like to thank them both for their efforts in these capacities. Finally, James E. Lebo, a Co-operative Education student with ICST/NBS converted the document into a desk top We publishing format and produced the very professional looking printing ofthe text. would like to thank him for his resourcefulness in accomplishing this in a conscientious and timely manner. Zella G. Ruthberg Computer Scientist, ICST/NBS October 30, 1987 xviCHAPTER 1 GENERALADPAUDIT ISSUES INTRODUCTION 1.1 1.1.1 Scope oftheAudit Guide Auditing in a computerized environment covers a broad spectrum of activities. The ac- tivities range fromusingreportsproduced by computerized applications, to assessing the ade- quacies ofcontrols in sophisticatedinformationsystems, to evaluatingautomated information systems (AISs) under development. The range ofskills needed to audit successfully ina com- puterized environmentvaries as greatly as the activities audited. This guide covers auditing the system development life cycle (SDLC)^process for a sys- tem, to ensure that controls and security are designed into the system.The guide also presents a process for deciding which system to audit among an organization's universe of systems. It isdirectedtowardmid-levelADP'^auditorshavingaminimumoftwoyearsexperience inADP auditing,butcanalsobeusedbysecurityreviewers, qualityassurancepersonnel, andasatrain- ADP ADP ing tool for auditors with less experience in auditing. managers and system developerswillalsofinditusefulguidanceonsecurityandcontrolissues.Theguideisdesigned to provide audit/reviewprograms for each majorphase ofthe SDLC and assumes a large sen- sitive system. The reader is expected to make appropriate modifications for a small less sen- sitive system. Section 2.3 of this guide defines an SDLC that encompasses generally accepted phases used in many Federal agencies. Each phase ofthis life cycle is defined there. The roles ofthe participants, including the auditor^, are also defined. The audit role for each life cycle phase is supportedby an auditprogram inChapter 4, including questionnaires foruse bythe auditor duringthatphase.TheGAO "BlackBook" [GAOS 1-3]providesacontrolassessmentapproach for evaluating general and application controls in an operational computer-based environ- ment. 1 Throughout this document, the system developmentHfecycle (SDLC) isdefined as amajor subset ofthe systemlife cycle (SLC).TheSLCconsists ofthe five phasesin theSDLC plus the sixth phase, Installation andOperation. 2 ElectronicDataProcessing(EDP) is the term commonlyusedintheprivatesector. However, since the Federalgovernment usesthebroadertermAutomaticDataProcessing (ADP) instead ofEDP, and since thisdocument isbeingproducedbythe Federalgovernment, thisdocumentwillconformtoFederalusage anduseADPwhenever thereisachoice. 3 Theterms'auditor' and'audit' areused throughout this documentwithout the quahfiers 'internal' or 'external' sincethisguide canbe usedbybothtypes. 11.1.2 How to Use theAudit Guide This audit guide is designed to be used as an audit program for auditing AISs under development. It can be used in any ofthe followingways: 1. Understanding the need for and planning for audit involvement in AISs under development - Chapters 1 and 2 are designed to assist the auditor inplanning an audit for such systemsunderdevelopment. These chapters explain the neworin- creased risks inAISs, the types ofcontrolsused inthose systems, aswell as acon- ceptual model for systems development. 2. Identifyingsystems for audit involvement- Chapter3 provides arisk assess-ment approach to help identify an agency's high-risk systems. These are the systems most needing audit coverage. 3. Creating a phase-by-phase program for auditors involved in a review of AISs under development - Chapter 4 provides a complete audit program designed for each ofthe five major phases ofthe system development process. 1.1.3 Auditor Skills Needed Auditsofsystemsunderdevelopmentrequireskillsbeyondthoseneededtoconductnon- ADP audits oflesser scope. Because the system is underdevelopment, the auditormust often assess howwell a project is being managed, the adequacy ofplanning, or the standards being followed. To do this, the auditor must have knowledge and experience in such areas as: 1. System development methodologies; 2. Standards for system documentation and software engineering; 3. Systems planning and project management methods; and 4. Methods,procedures, orstandardsfordeveloping, documenting, andtestingcon- trols. These skills have beenlaid out asjob core dimensions bythe EDP Auditors Foundation, Inc."^, The skills are also those needed for certification as an information system auditor (CISA). Generally, auditors who l)have mastered the CISAjob core dimensions, 2)have met 4 See ExhibitI in "InformationSystemsAuditProcess,"byS. R. Vallabhaneni [VALLS831 for aconcise picture ofthejob dimensionsfor aCertifiedInformationSystemsAuditor (CISA) andtheirrelationtothe informationsystems audit function. SeeAppendixG formoreinformationonthe document.the prerequisites for the CISA, and 3)have continued their education program then have the skills needed for auditing systems under development. Where particular skills are lacking, it is still possible to do useful ADP audit work. The scope ofthe audit, however, should probably be restricted (e.g., ifskills in controls are strong but skills in systems management are weak, the audit might be properly restricted to control issues). An alternative is to team up such an auditor with a person in the organization having the missing skills and not involved in the system under review. 1.1.4 Auditing in a Computerized Environment 1.1.4.1 The Need -The computer has substantially altered the methodsbywhichproces- ses, such as payroll and accounts receivable, operate and are controlled and audited. The op- portunities for personal review and clerical checking have declined as the collection and subsequent uses ofdata are changed. The changes are the result ofmoving from manual pro- cedures performed by individuals famiHar with both the data and the accounting process, to highvolume, automated techniques performed by individuals unfamiUar with either the data or the accounting practices. Computerization has substantially reduced the time available for the review of transac- tions before their entry into the automated system's records. As a result, in poorly controlled systems the opportunity for discovering errors or fraud before they have an impact on opera- tions may be reduced, especially in the case of real-time and data base systems. This has in- creased the importance ofinternal control/securityprocedures. Thus, it is imperative that the auditorreviewthese systems as theyare being developed, to insure that adequate controls and security are designed into the system from the outset. 1.1.4.2 The Scope ofAudit in a Computerized Environment - Auditing in a com- puterized environment can be divided into two broad areas. First is the audit of operational computer systems, and second is the audit ofsystems under development. These two types of audits require significantly different approaches. The auditofoperationalsystems evaluates theresults ofoperations. Itis normallyadata- oriented audit, looking at processed transactions. Controls canbe evaluated byexamining the results ofoperation. In a developmental audit, there is no operational system or data. The auditor evaluates controls without the benefit of observing processing results. In addition, in a developmental audittheauditoris concernedwith ensuringthat the developmental procedures and standards havebeenproperlyfollowed.Asstatedearlier,thisguide addressesdevelopmentalauditsonly.1.1.4.3 Relationship Between Systems Development Audits and Operationa l Audits of Automated Information Systems (ALSs) - The operational audit can identify AIS vul- nerabilities, but these may not be correctable after development because of the associated costs. Studies have shown that it costs approximately 50-100 times more to correct an opera- tional system as itwould have cost to build in the necessary control during development. Ifthe auditorcanidentifypotentialvulnerabilities duringdevelopment, theycanbemore easily and economically corrected than after the AIS is installed and operational. Thus, it be- comes imperative to evaluate the adequacy ofthe developer's approach to controls, i.e., how controlsare addressed, implemented, and documented. When anadequate systemofcontrols is built in during development, it can be fine-tuned through operational audits, as necessary. The developmental audit team should define operational audit programs, areas for review during operations, and recommend specific audit tools and techniques for use during operational audits. The developmental audit team can, therefore, play a significant role in making operational audits ofsystems more effective, efficient, and economical. 1.1.5 Relevant Laws and Regulations Congress and Federal regulatory agencies have grown increasingly concerned about the integrity of Federal computerized systems. This concern also covers the security and privacy ofdata stored by Federal computer systems. The relevant laws, regulations, and standards in- clude the following: (Note that longer descriptions can be found in Appendix B.) 1.1.5.1 Requirements for Audit Involvement - The laws, regulations, and guidance per- tainingto theperformance oftheauditfunction,particularlyasrelatedtoAISaudits, arebrief- ly described below: 1. Inspector General Act of 1978 (PL95-452) [IGA78] - Establishes the Offices of Inspector General in many major Federal agencies and specifies their audit and investigative responsibilities. 2. Standards For Audit ofGovernmental Organizations, Programs, Activities, and Functions, by U.S. General Accounting Office (GAO), 1981 [GA081-1] - Defines the standards for the conduct ofFederal audits. 3. QualityStandardsforFederal OfficesofInspectorGeneral,byPresident'sCoun- cil on Integrity and Efficiency (PCIE), 1986 [PCIE86] - Provides quality stand- ardsformanagement, operation, and conduct ofthe Federal Offices ofInspector General.4. BudgetandAccountingProceduresActof1950(PL8 1-784) [BA? A50] -Specifies GAO detailed audit objectives for conducted audits. 1.1.5.2 Requirements for Internal Control -The laws, regulations, andguidance describ- ingcontrolrequiredforagenciesandsystems,includingtheresponsibilityforcontrol, arelisted and briefly described below: 1. Budget and Accounting Procedures Act of 1950 (PL81-784) [BAPA50] - Re- quiresthat agencyheads establishand maintaineffective systemsofinternal con- trol. 2. BrooksAct (PL89-306), 1965 [BRA65] - Providesforthe"economicandefficient purchase, lease, maintenance, operation, and utilization of automatic data processing equipment by Federal departments and agencies." 3. Freedom of Information Act (PL93-502), 1974 [FIAA74] - Establishes proce- dures under which an individual can obtain records in the possession of the Federal government while enabling the government to protect records that re- quire confidential treatment. 4. PrivacyAct of 1974 (PL93-579) [PYA74] - Establishes standards and safeguards for the collection, maintenance, or disclosure of an individual's personal infor- mation by Federal agencies, and grants an individual access to the records con- cerning him/her maintained by Federal agencies. 5. FederalRecords ManagementActs (PL81-754, PL94-575), 1950 [FRMA50] and 1976 [FRMA76] - Require establishment ofstandards and procedures to ensure effective records creation, use, maintenance, and disposal. 6. Paperwork Reduction Act (PL96-511), 1980 [PRA80] - Defines the process to reduce paperwork and enhance the economy and efficiency of the Government and private sector by improving Federal information policy-making. 7. Federal Managers' Financial Integrity Act (PL97-255), 1982 [FMFIA82] - Re- quires that agency internal controlsystemsbe periodically evaluated and that the heads ofexecutive agencies report annually on their systems' status. 8. StandardsforInternal Controlsinthe FederalGovernment, byU.S. GeneralAc- countingOffice, 1983 [GA083] -Presents the internal controlstandardstobe fol-lowed by executive agencies, covering both the program management as well as the traditional financial management areas. 9. OMB CircularA-123, 1981 [OMB123] & A-123R, 1983 [OMBR123] - Prescribes the policies and standards to be followed by executive agencies in establishing and maintaininginternal controls in theirprograms and administrative activities. 10. OMB CircularA-127, 1984 [OMB 127] - Prescribespolicies andprocedures tobe followed by executive agencies in developing, operating, evaluating, and report- ing on financial management systems. 11. OMB Circular A-130, 1985 [OMB 130] - Establishes policy for the management of Federal information resources as well as procedures for information system security. RISKS GENERATED BYCOMPUTER TECHNOLOGY 1.2 1.2.1 Overview ofRisks Organizationsassume risksinthe conduct oftheiractivities.Theserisks representpoten- tial damaging events occurring that canproduce losses. Controls or safeguards are installed to reduce these risks. Ifcontrols are insufficient, specific opportunities for loss remainwhich are too large. The two elements that generate the risks in a computerized environment are its unique A vulnerabilities and its unique set of threats. vulnerability is a weakness or flaw in a com- puter-based system that may be exploited by a threat to cause destruction or misuse ofits as- sets or resources. Threats can be physical (e.g., fire, water damage, earthquakes, and hurricanes) orpeople-oriented (e.g., errors, omissions,intentionalacts ofviolence, andfraud). When athreatmaterializes andtakes advantage ofasystem'svulnerabilities, adamagingevent occurs that causes a loss. The riskofdamaging events cannotbe totallyeliminated, butthe use of controls onvulnerabilities and/or threats can reduce such risks to an acceptable level. The purposes ofa risk analysis of a computerized environment are (1) to search out its vulnerabilities and the probabilities of threats materializing to exploit these vulnerabilities, and (2) to calculate the damage or loss to its assets that could be produced by the resulting damaging events.^ Auditors should assess a computerized environment's vulnerabilities and 5 There is no consensusonthe definitionofrisk analysis. Somepeople add athird component, "tomake control orsafeguardrecommendationsthat will reduce the damages or loss to an acceptable level, throughthe use ofacost/benefit analysis." Othersin the field, however, consider thatthisadditionmakes the activityarisk management program.setofthreatstoarriveatsomeestimateofpossibledamagingevents. Suchanassessmentwould also necessarily include reviewing the strength ofexisting controls. 1.2.1.1 Definitions -Someusefuldefinitionsinthecontextofcomputersecurityandaudit follow. Appendix C contains definitions ofadditional relevant terms as well as the following. A 1. Vulnerabihty: vulnerabilityisadesign, implementation, oroperationsflawthat may be exploited by a threat, to cause the computer system or application to operate in a fashion different from its published specifications and to result in destruction or misuse ofequipment or data [NBS SP 500-57, p.A-2]. 2. Vulnerability assessment: The process of (1) identifying flaws and the controls associated with those flaws in order to evaluate the adequacy of the control to reduce the risks to an acceptable level, and (2) identifying those flaws requiring management action, where risks are found to be too high. 3. Computer Generated Risk: Computer generated risk is the potential loss or damage to an organization that results from the use or misuse of its computer [adaptedfromNBSSP500-57,p.A-2].Thismayinvolveunauthorized disclosure, unauthorized modification, and/or loss of information resources as well as the authorized but incorrect use of a computer. Risk can be measured to some ex- tent byperforming a risk analysis. 4. Riskanalysis: Risk analysisis an analysis ofan organization's informationresour- ces,its existingcontrols, and itsremainingorganizationandcomputersystemvul- nerabilities [NBS SP 500-57, p. A-3]. It combines the loss potential for each resource orcombination ofresourceswith anestimated rate ofoccurrence to es- tablish a potential level of damage to assets or resources in terms of dollars or other assets. 1.2.1.2 Vulnerability/Risk Related Requirements - Government-wide mandates/direc- tives as well as agency-specific regulations require Federal agencies to conduct vulnerability OMB A assessments. These requirements are found in Circulars A-123, A-127, and A-130. vulnerability assessment is conducted using part of a risk analysis. The vulnerability assess- ment is a major assessment ofthe adequacy ofan agency's controls and uses many tools to ac- complish it, e.g., risk analysis. The Federal agencies must first identify vulnerabiHties and threats, and then determine whether controls are adequate to reduce the resulting risks to an acceptable level. Ifnot, vulnerabihties will have been identified which need to be corrected, andthreatswill havebeenidentifiedwhich need tobe guarded against bythose Federal agen- cies. 71.2.2 Risks in a Computerized Environment The risks in a computerized environment include both the risks thatwould bepresent in manual processing, plus some risks that are unique or increased in a computerized environ- ment. The auditor should identify these risks, estimate the severity of the risks, and then develop audit tests to substantiate the impact of the risks on the application. For example, if the auditor felt that erroneous processing was a very high risk for a specific application, then the auditor should devise tests to substantiate the correctness or incorrectness ofprocessing. This could be accomplished in avariety ofways. Onewayto verifyprocessing accuracywould be to use Computer Assisted Audit Techniques (CAATs). 1.2.2.1 Additional Risks Present in a Computerized Environment - The use of a com- puter introduces additional risks into the system environment. Thus, besides the traditional risks, the auditor needs to assess the impact of these additional risks. The auditor should be aware ofthesespecial risksbecausetheypose threatswhicharenotpresentatallorarepresent to a lesser degree in non-computerized environments. These additional risks include problems associated with: • Improperuse oftechnology; • Inability to control technology; « Inability to translate user needs into technical requirements; © Illogical processing; • Inability to react quickly; • Cascading oferrors; 9 Repetition oferrors; ® Incorrect entry ofdata; • Concentration ofdata; • Inability to substantiate processing; and • Concentration ofresponsibilities. 8Each ofthese risks is discussed individually in Appendix D, including many ofthe con- ditions that cause the risks to occur. 1.2.2.2 Assessing Vulnerabilities Through the Audit Process -Theobjectiveofcontrolis to reduce risk. In an ideal environment, everything would be processed correctly, and there would be no need for control. Unfortunately, that environment does not exist, and risks are present which may introduce damaging events into the processing environment. Controls reduce the number and/or severity ofdamaging events to an acceptable level. In order to evaluate the effectiveness of controls, the auditor must determine the vul- nerabihties present in the computerized environment and the resulting risks. Until the risks areunderstood,the effectivenessofcontrolsinreducingthose riskscannotbe evaluated.Thus, if the auditor is going to place reliance on controls, the auditor must both identify the vul- nerabilities and determine the severity ofthose risks in the operating environment. It will be useful for auditors, as they consider application system and data file risks, to be aware of the manyundesirable events which can have serious consequences. The National Bureau ofStandards' FIPS PUB 65 [FIPS65] provides the auditor and sys- tems developer a list of negative situations to which application systems are vulnerable, grouped according to common system organizational structures. Those vulnerability lists are reprinted in Appendix E of this guide for the reader's convenience. While they are not in- tended to be all inclusive, they are suggestive of the various kinds ofvulnerabilities that may exist in every system. The list ofpotential vulnerabilities helps identify the additional risks in a computerized environment. Due to their value to the ADP auditor, as a tool in the identification ofunique risks, abriefdescriptionofthetypesofvulnerabilitiesfoundinFIPSPUB 65isrepeatedbelow, 1. Erroneous or Falsified Data Input - Erroneous or falsified input data is the simplest and most common cause ofundesirable performanceby anapplications system. Vulnerabilities occurwherever data is collected, manually processed, or prepared for entry to the computer. 2. Misuse by Authorized End Users - End users are the people who are served by the ADP system. The system is designed for theiruse, but they can also misuse it forundesirable purposes. Itis oftenvery difficult to determinewhether their use ofthe system is in accordance with the legitimate performance oftheirjob. 3. Uncontrolled System Access - Organizations expose themselves to unnecessary risk ifthey fail to establish controls over who can enter the ADP area, who canuse the ADP system, and who can access the information contained in the sys- tem. 4. IneffectiveSecurityPracticesfortheAppHcation-Inadequatemanualchecksand ADP controls to ensure correct processingby the system, or negligence by those responsible for carrying out these checks, result in many vulnerabilities. ADP 5. Procedural Errors Within the Facility - Both errors and intentional acts committed by the ADP operations staffmay result inimproper operational pro- cedures, lapsed controls, and losses in storage media and output. 6. ProgramErrors -Applicationsprogramsshould be developedinanenvironment that requires and supports complete, correct, and consistent program design, good programming practices, adequate testing, review, and documentation, and proper maintenance procedures. Although programs developed in such an en- vironment may still contain undetected errors, programs not developed in this manner will probably be rife with errors. Additionally, programmers can deliberately modify programs to produce undesirable side effects or they can misuse the programs they are in charge of. 7. Operating SystemFlaws - Design and implementation errors, system generation and maintenance problems, and deliberate penetrations resulting in modifica- tions to the operating system can produce undesirable effects in the application system. Flaws in the operating system are often difficult to prevent and detect. 8. Communications System Failure - Information being routed from one location to another over communication lines is vulnerable to accidental failures and to intentional interception and modification by unauthorized parties. Both management and auditors conduct vulnerability assessments. Management does OMB the review as required by Circular A-123, while the auditor does it as an independent assessment. The auditor looks both at management's performance of the review and at tests for inadequacies in management's system ofinternal controls. 1.3 CONTROL OBJECTIVES AND STANDARDS IN A COMPUTER ENVIRONMENT 1.3.1 Impact ofthe Computer on Controls The objectives ofcontrol do not change ina computerized environment. The controlob- jectives that are applicable to a manual system are equally applicable to a computerized sys- tem. What changes are the control techniques used to achieve the control objectives. 10The new control complexities introduced by the computer require that, in addition to controllingthetraditionalprocesses, newcontroltechniquesbeintroduced.Thesewouldcover the automated processes themselves, as well as the interface between the manual and automated processes (an area where control problems often occur). Examples of the new types of controls that exist within the computer processes include controls to ensure that: • Properversions ofprograms are in operation; • Data integrity is maintained as it is passed between programs; and • Access to the system is limited to only authorized individuals. Examples ofthe newtypes ofcontrols introduced as aresult ofthe interface betweenthe manual and automated processes include controls to ensure that: • All data to be entered for computer processing is, in fact, input for processing; • Only correctly entered data is accepted for computer processing; and • Rejected data is maintained on an automated suspense file until corrected. Thus, new control techniques must be used to reduce the new, unique risks introduced by the computerized environment. 1.3.2 Internal Control and Computer Security Review Policy The U.S. General Accounting Office (GAO), as required by the Federal Managers' Financial Integrity Act of 1982 [FMFIA82], has defined the internal control standards [GA083,p. 9] to be followed by executive agencies in establishing and maintaining systems of GAO internal control. This document on internal control standards provides guidance for agenciesin developingsystems ofinternal control forAISs. It is through those control systems that Federal managers fulfill their control responsibihties. Thepurposeofsystemsofinternalcontrolistoreasonablyensurethatthefollowinggoals are achieved: 1. Obligations and cost complywith applicable law. 112. All assets are safeguarded against waste, loss, unauthorized use, and misap- propriation. 3. Revenues andexpenditures applicable to agencyoperations are recorded and ac- countedforproperlyso that accounts and reliable financialand statisticalreports may be prepared and accountability ofthese assets may be maintained. TheFederal Managers' Financial IntegrityAct directs the heads ofexecutive agencies to conduct armual evaluations of their internal control systems using guidelines established by the Office of Management and Budget. These guidelines are incorporated into the audit programs included in later sections of this manual. Controls not built into systems under developmentwillprobably notbe added inthe operational system.As has beendiscussed ear- nerinSection 1.1.4,3, modification ofoperationalsystems is extremelydifficultand costly. Ex- cessivecostandprogrammaticrequirementsfrequentlyprohibitbuildingcontrolsintosystems once operational. The Comptroller General has defined the minimal level ofquality acceptable for inter- nal control systems in operation [GA083]. They constitute the criteria against which systems ofinternal control are to be evaluated in the Federal government. The minimum level ofin- ternal control is divided into the following three categories: 1. General standards (a) Reasonable assurance: Internalcontrolsystems aretoprovide reasonable • assurance that the objectives ofthe systems will be accompHshed. (b) Supportive attitude: Managers and employees are to maintain and demonstrate apositive andsupportive attitude towardinternalcontrols at all times. (c) Competentpersonnel: Managers and employees are to havepersonal and professional integrity and are to maintain a level of competence that al- lows them to accomplish their assigned duties, as well as understand the importance ofdeveloping and implementing good internal controls. (d) Control objectives: Internal control objectives are to be identified or developed for each agency activity and are to be logical, applicable, and reasonably complete. (e) Control techniques: Internal controltechniques are tobe effective andef- ficient in accomplishing their internal control objectives. 12specific standards (a) Documentation: Internal control systems and all transactions and other significant events are tobe clearly documented, and the documentation is to be readily available for examination. (b) Recording oftransactions and events: Transactions and other significant events are to be promptly recorded and properly classified. (c) Execution of transactions and events: Transactions and other significant events are tobe authorizedandexecutedonlybypersonsactingwithinthe scope oftheir authority. (d) Separation of duties: Key duties and responsibilities in authorizing, processing, recording, and reviewing transactions should be separated among individuals. (e) Supervision: Qualified andcontinuous supervisionistobeprovidedto en- sure that internal control objectives are achieved. (f) Access to and accountability for resources: Access to resources and records is to be limited to authorized individuals, and accountability for thecustodyanduseofresourcesistobeassignedandmaintained.Periodic comparison shall be made between the resources and the recorded ac- countability to determine whether the two agree. The frequency of the comparison shall be a function ofthe vulnerability ofthe asset. Audit resolution standard When auditors identify potential control weaknesses, managers are re- quired to promptly resolve these audit findings. Specifically, managers are to: (a) Promptly evaluate findings and recommendations reported by auditors. (b) Determineproperactionsinresponseto auditfindingsand recommenda- tions. (c) Complete,withinestablishedtimeframes,allactionsthatcorrectorother- wise resolve the matters brought to management's attention. 13The audit resolution standard requires managers to take prompt, responsive action on allfindings and recommendationsmadebyauditors.A responsive actionisonewhichcorrects identified deficiencies. Where audit findings identify opportunities for improvement rather than merely cite deficiencies, responsive action is considered to be that which produces im- provements. The audit resolution process begins when the results ofan audit are reported to management, and is completed only after action has been taken that (1) corrects identified deficiencies, (2) produces improvements, or (3) demonstrates the audit findings and recom- mendations are either invalid or do not warrant management action. Auditors are responsible for following up on audit findings and recommendations to as- certainthatresolution hasbeen achieved. Auditors' findings and recommendations shouldbe monitored through the resolution and follow-up processes. Top management should be kept informed through periodic reports so it can assure the quality and timeliness of individual resolution decisions. 1.4 EVIDENCE IN AUTOMATED SYSTEMS The evidence collected to support findings in an automated system may differ drastical- ly from traditional audit evidence. For example: 1. Transactions might be entered with no hard-copy equivalent. The "evidence" might have to be obtained from a data base management system. 2. Authorizations might be entirely electronic, through use of a password, with no written signature available to examine. 3. Procedures might not be found in a written manual but rather in coded instruc- tions in a programwhich directs operations through terminal screen prompts or instructions. 4. The audit trail which supports a transaction process in an automated system, is itself automated. Rather than a paper trail, the trail might reside on computer tapes or disk files or other electronic media. In Appendix F, other changes in audit evidence are enumerated along with three brief examples describing where evidence changed due to automation. Auditors must anticipate evidence needed during AIS development to insure proper consideration is given to related controls. 14AIS AUDITABILITY 1.5 Auditability should be a management concern and relates to management control responsibilities.Auditabilityrelatestothesubstantialevidentialmatterproduced and retained by AISs, and the abihty to locate and reconstruct processing. Auditability also encompasses the system ofinternal controls which assures the integrity ofprocessing and the protection of evidential matter. Auditability takes on greater importance in AISs because many of these systems have eliminated the traditional source documents. Transactions are originated electronically, and thus auditability is dependent upon the ability of the system to substantiate the integrity of those input transactions. This integrity is assured through an adequate system ofinternal con- trols. The concept of auditability requires audit involvement in the development of AISs. Retrofitting controls in AISs is expensive and difficult on an after-the-fact basis. Therefore, the auditability and effective controls allowing for managerial and audit oversight must be designed and incorporated into AISs as those systems are developed. 15CHAPTER! AIS LIFE CYCLE CONSIDERATIONS BACKGROUND 2.1 2.1.1 PCIE - EDP Systems Review and Security WorkGroup In October 1983, the President's Council on Integrity and Efficiency (PCIE) established aworking group on Electronic Data Processing (EDP) Systems Review and Security^ under the leadership of the Inspector General of the Department of Health and Human Services. Includedunder the umbrella ofthe Computer Security Project, the Work Group was charged withexploringwaystofacilitateandimproveOfficeofInspectorGeneralreviewsofautomated information systems (AISs), particularly those systems under development. Its objective was toimprovethelikelihoodthat auditable andproperlycontrolledsystems aredeveloped.While the Work Group looked at automated systems throughout the entire system life cycle (SLC), the clearfocuswas onthe system development life cycle (SDLC) and the auditor's role inthat process. 2.1.2 System Development Life Cycle Whilethe conceptofaSDLC isnotanewone,linkingitandthegenerallyacceptedphase activitiesto otherAIS andInformationResourcesManagement (IRM) standards andrequire- ments has not heretofore been successfully accomplished. Similarly, despite the growth of ADP auditunitsinthe OIGs, and recognitionofthe significantbenefits tobegainedfrompro- active reviews (i.e., those conducted during the system development process), few develop- mental audits have been conducted. One of the key deterrents appears to be the confusion that exists regarding the actual role ofthe auditor during the SDLC. To achieve their objective, and to clarify the role of the OIG/auditor, the PCIE Work Group drewuponthe Department ofDefense life cycle approach to the managementofauto- mated systems and the National Bureau of Standards/Institute for Computer Sciences and Technology's Federal Information Processing Standards Publications (FIPS PUBS) and Spe- cialPublications.Usingthisinformation,theWorkGroupdevelopedanSLCfunctionalmatrix forAISs.The matrix, structured around criticalAIS documentationrequirements, is intended ADP to clarify the functions of the auditor vis-a-vis other key participants in the planning, design, implementation, and review processes. With the matrix as a conceptual framework, this audit guide is intended to facilitate the successful fulfillment ofthat role, focusing on sys- tems under development and major modifications to existing systems. 6 SeeAppendixA formoreinformationonthe activities ofthisgroup. 16OPERATING ENVIRONMENT 2.2 The AIS life cycle used to develop systems will not be the same in every agency. In addi- tion, the operating environment for the life cycle is a function of the agency in which it exists and also varies from agency to agency. There is no single standard SDLC for the Federal government. This chapter describes good practice for the SDLC and its operating environ- ment.The use by Federal agencies oftheseAIS life cyclepractices shouldresult inawell-con- trolled and auditable AIS. Managementestablishestheenvironmentinwhichsystemsaredeveloped.Iftheenviron- ment is structured, the probability ofawell-defined life cycle and compliance to it increases. A loose management style leads to free-formsystem developmentwhich may result in serious omissions. The operating environment reflects the adequacy ofthe general controls over sys- tem development, operations, and maintenance. 2.2.1 IRM Planning and Implementation ofPolicy Guidelines Agencies need to perform overall long-range IRM planning. The purpose of this plan- ning is to determine which AIS projects are to be implemented, the priority and schedule for their implementation, the individual(s) responsible for implementation, and the amount of resources to be allocated to each project. Inadditionto formal IRM planning, organizations must identifyand followpolicies/pro- cedures/standards for developing AISs. These policies/procedures/standards shouldbe estab- lished andpromulgatedwithinthe organization, based onguidance providedby such agencies as the National Bureau ofStandards and the General Services Administration. Each ofthese two major considerations is discussed in some detail below. 2.2.1.1 IRM Planning -IRM planningisameans ofselecting, prioritizing,budgeting, and assigning projects to individuals and groups to implement. Many organizations have adopted the concept using a management steering committee, an IRM planning committee, or an ex- IRM ecutive committee. The following are the desirable characteristics ofsuch an IRM planning committee: (a) Is comprised ofsenior managers -The IRM committee should be chaired by the seniormanagerofthe agency, andbe comprisedofthe directsubordinates ofthat senior manager. 17(b) Hasrepresentativesfromallmajoragencydatausers-Itisimportantthatallusers ofinformation processing services are represented on the IRM committee. This ADP committee will establish priorities ofwork, which require that all users of serviceshave avoice inhowthose resources are allocated. Inaddition, userssuch as budgeting, legal, andADP audit should also be represented on the IRM com- mittee. (c) Meets on a regular basis - For most agencies, quarterly is sufficient. (d) Establishes AIS implementation priorities - The IRM committee determines which systems are implemented, and inwhat sequence. Note that the IRM com- mittee may also determine other dataprocessingpriorities, such as implementa- tion ofmajor software packages (e.g., data base management systems). (e) IdentifiesandassignsprojectstoaSponsor-The Sponsor istheindividualrespon- sible for implementing the AIS. For many systems, multiple entities will be in- volved. Thus, it is important for the IRM committee to identifywho is in charge, and thenensure that thatindividual has adequate resources at his/her disposal to successfully implement the project. (f) Monitors status ofprojects - The IRM committee must retain responsibility for projects, and therefore should be receiving regular status reports on approved AIS projects. Ifprojects fall behind schedule, or encounter other problems, the IRM committee should take appropriate action. 2.2.1.2 Using Policy/Procedures/Standards - Although there is nouniformSDLC for the Federalgovernment,thereareavarietyofpolicies,procedures, andstandardswhichhavebeen issued relating to the development ofAISs. Many ofthese have been issued by the National BureauofStandards, the General ServicesAdministration's Office ofSoftware Development, the Office of Management and Budget (OMB), and the U.S. General Accounting Office (GAO). The objective ofthese policies/procedures/standards is to increase the probability of success for the AIS. Some of the more pertinent publications that system development projects should fol- G H low are listed below and can be found in Appendix and (annotated with an asterisk). Auditors involved in the system development process should study these publications to en- sure that they follow the guidance. 182.2.1.2.1 References Used by the Life Cycle Matrix - The following references are cited in the Life Cycle Matrix in Figure 1. FIPSPUB38 GUIDELINES FOR DOCUMENTATION OF COMPUTER 1. PROGRAMSANDAUTOMATED DATASYSTEMS, 1976 February 15 [FIPS38]. Providesbasicguidanceforthepreparationoftendocumenttypesthat areusedinthe developmentofcomputersoftware. Canbe used as acheck- list for the planning and evaluation ofsoftware documentation practices. FIPSPUB64 GUIDELINES FOR DOCUMENTATION OF COMPUTER 2. PROGRAMS AND AUTOMATED DATA SYSTEMS FOR THE IN- mATION PHASE, 1979 August 1 [FIPS64]. Providesguidanceindeterminingthe contentandextentofdocumen- tationneededforinitiationphaseofthe software lifecycle. Coversprepara- tion of project requests, feasibility studies, and cost/benefit analysis documents. 3.FIPSPUB65 GUIDELINE FOR AUTOMATIC DATA PROCESSING RISK ANALYSIS, 1979 August 1 [FIPS65]. ADP Presents a technique for conducting a risk analysis on an facility andrelatedassets. Providesguidanceoncollecting, quantifying, and analyz- ing data related to the frequency ofoccurrence and the damage caused by adverse events. 4. FIPSPUB 73 GUIDELINES FOR SECURITY OF COMPUTER APPLICATIONS, 1980 June 30 [FIPS73]. Describesthe differentsecurityobjectivesforacomputerapplication, explains the control measures that canbe used, and identifies the decisions that should be made at each stage in the life cycle of a sensitive computer application. For use in planning, developing, and operating computer sys- tems which require protection. 5. FIPSPUB 101 GUIDELINE FOR LIFECYCLE VALIDATION, VERIFICATION, AND TESTING OF COMPUTER SOFTWARE, 1983 June 6 [FIPSlOl]. Presents an integrated approach to validation, verification, and test- (W&T) ing thatshouldbeused throughout the software lifecycle. Also in- cluded is a glossary of technical terms and a list of supporting NBS W&T pubhcations. An appendix provides an outline for formulating a plan. 196. FIPSPUB 102 GUIDELINE FOR COMPUTER SECURITY CERTIFICATION AND ACCREDITATION, 1983 September 27 [FIPS102]. Describeshow to establish andhowto carryoutacertification and ac- creditationprogramfor computer security. Certification consists ofa tech- nical evaluation of a sensitive system to see how well it meets its security requirements. Accreditation is the official management authori zation for the operation ofthe system and is based on the certification process. Also included is a glossary ofterms. 7. FIPSPUB 105 GUIDELINE FOR SOFTWARE DOCUMENTATION MANAGE- MENT, 1984 June 6 [FIPS105]. Provides explicit advice on managing the planning, development, and production of computer software documentation. Includes several check- lists, references to relevant standards and guidelines, and a glossary of terms. NBS SPEC PLANNINGFORSOFTWAREVALIDATION,VERIFICATION,AND 8. PUB 500-98 TESTING, Patricia B. Powell, Editor, November 1982 [NBS98]. Presents a guide for managers, programmers, and analysts to aid in VV&T developingplansforsoftware andinselectingappropriatepractices, techniques, and tools. In explaining the fundamental concepts, this report provides information to help in establishing organizational policies for W&T. NBS SPEC GUIDE TO SOFTWARE CONVERSION MANAGEMENT, Mark 9. PUB 500-105 Skall, Editor, October 1983 [NBS105]. Describes explicit steps for carrying out software conversionprojects. This guide was developed to help managers avoid the common problems associatedwith software conversion. It includes anextensive reference list, case studies, and a glossary ofterms. 10. DOD7920.2 MAJOR AIS APPROVAL PROCESS, DOD INSTRUCTION, October 20, 1978 [DOD78-2]. Establishes the review and decision process and procedures for the development ofmajor AISs. It implements DOD's life cycle management directive 7920.1. 202.2.1.2.2 Major GSA References - The following are major references by GSA on this subject area. Other GSA references can be found in Appendices G and H. Also cited in Ap- pendk G are the definitions offour classes ofGSA regulations that are pertinent to this sub- ject area. 1. SOFTWARE IMPROVEMENT - A NEEDED PROCESS IN THE FEDERAL GOVERNMENT, June 1981 [GSA81-1]. An easy-to-read introduction to the concepts of software improve- mentandhowthese concepts canbe used to effectivelymodernize Govern- ment software. GUIDELINES FOR PLANNING AND IMPLEMENTING A SOFTWAREIMPROVE- 2. MENT PROGRAM (SIP), May 1983 [GSA83-3]. Serves as a starting point for establishing, planning, and implement- ing a SIP. Emphasizes the top-down incremental approach to software improvement and explains what needs to be done to set up a SIP in an organization. THE SOFTWAREIMPROVEMENTPROCESS-ITS PHASESANDTASKS (PARTS 3. 1 & 2), July 1983 [GSA83-5]. A companion for the "Guidelines" described above, this report goes into greater detail discussing the phases and tasks needed for planning and implementing a SIP. 4. ESTABLISHING A SOFTWARE ENGINEERING TECHNOLOGY (SET), June 1983 [GSA83-4]. Software engineering is an approach to managing software develop- ment and maintenance by using standards, procedures, and automated tools. This book serves as a starting point for implementing a SET inyour organization. 2.2.2 AIS Development Methodologies In the past, few structural restrictions were placed on the system designer. The project teamwas given a mission and resources to accomplish that mission. The methods they chose forbuildingtheAISwere leftto theirdiscretion. As aresult, manysystemswere installed late, followed no standards, were significantly over budget, and often failed to meet user needs. This unstructured design approach offered minimal opportunities for management, let alone the auditor, to identify problems during development. It was not until installation that problems became apparent. The solution to this management dilemma was to develop a for- 21malized method for developing automated systems. These methodologies are alternately called system development methodologies (SDMs), system development life cycle (SDLC), or system life cycle (SLC) methodologies. The following are generally accepted as the desirable practices of a good SDLC methodology: 1. Predefined documents/deliverables -All ofthe products/deliverables tobe developed during the creation of an automated system need to be defined. In the better design methodologies, these products/documents are standardized. They will either be preprinted forms, or screens available to the designer on computer terminals. The sequence inwhich the products are created is also determined. In most instances, the outputfromoneproductorset ofproducts is needed before the next product can be developed. 2. Life cycle phases or checkpoints - The life cycle should be divided into segments defined by activities and outcomes or deliverables. Each segment encompasses some part of the developmental process. The purpose of having distinct phases or checkpoints is to allow decisions to be made regarding completion ofthe project, changes in direction, cancellation of the project, and authorization for use of more resources on the project at these points in time. Note that management in many organizations only authorizes work (i.e., resources) on anAIS project through the next management checkpoint. This is done to assure that manage- mentcancontinuallyevaluateprojectstatus and makethe appropriatemanagementdecisions. 3. Completion ofproducts/documents are tied to life cycle phase checkpoints - At each checkpoint, specifiedwork is to be completed. This work is normally expressed as documents to be produced. Thus, when someone reviews a project at a checkpoint they know which products/documents are to be delivered at that point in time. This also helps ensure that the project is on schedule and within budget. It is through the examination ofthese products that the status ofwork can be determined. 4. Reviews are product/document reviews - Reviews of the status of projects are per- formed by reviewing the products/documents produced by the project team. Therefore, it is important that these products/documents be produced in a standardized format. The Nation- al Bureau of Standards, through its various FIPS publications, has issued standards for most of the documents produced during the developmental process [FIPS38, FIPS64]. These reviews must be signed off on upon completion, indicating satisfactory completion of the product/document, and life cycle phase. 5. Training is tied to products/documents - The training program for people associated with developmental projects is centered around the products/documents to be produced. Auditorsinvolvedinthe developmentalprocess shouldbecomefamiliarwiththedevelopmen- 22. tal products/documents in order to properly review that project. While the auditor need not know how to develop the products, the auditor should understand the meaning of the infor- mation contained in those documents, and how the documents tie together in the SDLC organization's process. 2.2.3 ProjectAdministration and Control Project administration and control are the tools of management to monitor and direct the project during implementation. The life cycle methodology, and the developmental products, are designed to create a secure, accurate, and cost-effective system to meet user needs. Project administrationand controlproduce documentswhich are usedbymanagement inadministering the project. The developmental products are normally retained as part ofthe system documentation and become input to maintenance of the system. Project administra- tion and control documents generally have a limited Hfe, and are not retained for the life of the system but through the SDLC. Theproject administrationand controldocuments canbe usedby the auditorto evaluate the status ofprojects and to evaluate the performance ofproject management. Project status is evaluated by the products that relate actual work to scheduled/budgeted work. Project management is evaluated on its ability to produce the specified work products in accordance with the project management plan. The products/documents used for project administration and control include: 1. Budgeting/budget status reports - The funds allocated for development ofAISs and the internal budgetary reporting systems stating the use of funds against budgets. 2. Scheduling/schedule status reports - The division of system development tasks into phases/deliverables, and relating those phases/deliverables to specific time frames.The status report indicateswhether or notthe deliverables have beenac- complished within the stated time frames. 3. Development project status reports - Reports prepared by the individual project members indicating the status of deliverables under their responsibility. To be effective,thesestatusreportsmustbeabletodefinitivelystatethepercentofwork done, as opposed to the amount ofresources consumed. 4. Checkpoint reviewstatus report -The results ofaformal analysisbywhich anin- dependent group evaluates the completeness ofwork or product deliverables at specific system development checkpoints. 235. Resource utilization report - Status reports produced by computer operations. These reports are normally generated automatically from statistical information collected about resources consumed during the development project. One such package is IBM's job accounting system called System Management Facility (SMF). 6. Projectmanagementsoftware system- OrganizationsutiHze avariety ofmanage- A ment software systems to controlprojects. commonlyused software package is PAC II, which is a scheduling and status reporting system. 7. Automated software development environments -Complete and self-contained software development, documentation, and testtools and techniques for systems analysts, programmers, and reviewers. In general, such environments will automatically generate all the reports and code, and provide mapping back to high level specifications. In most AIS projects, more emphasis is placed on system development than project management. Thus, the auditoris more apt to find well-defined developmental products than tofindwell-developedproject administrationand control documents. Manyofthe administra- tive documents are more quantitative in nature (e.g., stating the amount ofresourcesused) as opposed to qualitative in nature (e.g., indicating percentage ofproject completion in relation to the developmental work products). 2.2.4 AIS Life Cycle Matrix Auditorscannotcomprehensivelyreviewasystemunderdevelopmentuntil there issome structure to the development process. Without structure, the auditor will be unable to deter- mine what deliverables are to be produced at what time. On the other hand, it is recognized that different agencies within the Federal government use different system development methodologies. As a basis for structuring the review proposed by this guide, the PCIE Work Group on EDP SystemsReviewand Security^defined arecormnendedAIS life cycle process inthe form ofa Life Cycle Matrix (see Figure 1). This life cycle matrixwas developed based on the more 7 SeeAppendixA for a description ofthe PCIEWorkGroup anditsefforts in producingthis life cycle matrix. 24PART VI INSTALLATION & OPERATION Informmce approvesfinal installationofsystem; accreditsall Officalid systemsdetermined tobeofcritical sensitivityor importance to theDept.; directsperiodic reviews perP.L. 96-511 forcontinued need System;port • conductsperiodicreviewsperOMB CircularsA- Contro & 123,A-127,andA-130; feedingintolong-range AISplanningprocess Auditojstaiia- • conductsperiodicreviewsperOMBA-130& urity GAO auditstandards; updatesAudit Planand Programasneeded SponscCon- • overseestraining; directsperiodicreviewsofsensi- tiveapplicationsforrecertification; identifies ition needforchangestosystemand revisesProject Plan accordingly Project • directsimplementation andupdates UserManual Techni tern & Operations/Maintenance Manualasneeded duringimplementation andoperation Plan SystemU • conductsperiodic reviewsperOMB CircularsA- Special 123,A-127, andA-130 stal- Contra • ifappropriate,continuestoassurecontractcom- pliance ADPr,, • conductsperiodicreviewsperOMB CircularA- 130; provides technicalassistance; maintainssys- ical tem documentation Qualitj ad- • reviewschangestosoftwaresystem;summarizes, ent analyzesand reportson defectstoresponsible participants hinthephaseorFigure1. AUTOMATEDINFORMATIONSYSTEM(AIS)-LIFE-CYCLEMATRIX  LIFE-CYCLE DEVELOPMENT PHASES III PARTICIPANTS OPERATINGENVIRONMENT SYSTEMDESIGN PROGRAMMING&TRAINING EVALUATION&ACCEPTANCE INSTALLATION&OPERATION I q s« liu yi si sa hr tb ee e sl m mi pes rpn lh ot a cM s n e,s n dy r i us e n ri c g ee oi sarn d n bsl d yif m wde a he- c ic ny i cac s hl g ie oe Onp m Ir e pi Gn rn oc t ii c sp epl s noe sl os i ; i, c iwy fd , i lo i c&c h du oOm l foe Inn aGg lt l-a e st r s ii a t gno -abgn -ere- IapprovesNeedsSlBtcmer a APp h Dp a Pr so ev MIe aIs , ni aS ny gs c et o rne sm (u olD cte cac ut ri i ss oi n bo ewn tiP wta ehp eSe npr o Pn ht so ae sa r ed sAv )Ja sn |c 3c r |e al no d a t A top cDp mPr Pho ia nv Ms te ae os n DI au I cp I g p,d tea i 'rn st .e (cd oo fcn oS cs ruy u mrls astt lae btm sei ytoD sn we te ec w e mi i sns t 'i h Po ihSn nap vsP o eea n nsp s t)e o o.r rr & yAt Jo s ea nci v s Pa a hop n arp c s/n e eUv i )ee o rs P au h np a dd sa e Ate DId V P.S i My ns act noe anm gsu eD l re tc a (i t ts xii roo cnn urw sP ia t bhp ee tSr wp eot eo n n-ad a l Aop Dp P Pr ho av Mse aes nV au ,p gd eia n rt ce (o od n csS cu uy l rs t sat te bim eo tnD we w ec i ei t ns hi Po S hn p aoP sn ea s sp o )e rr /Ul so ea rdv ai nn dce a s i py mp es pp rt or Pe ro .m tv s Lae ns d 9ce 6f eti -n e 5ta r 1ol m 1ti i hn fns e oet rda Dl tel l p oa to mt .bi i;o e nn d uo io ef rf dec cs r nty i s ets i et pce da em l r; is oea dnc isc i cr te i rd v ei i vt t is y ewa ol ;i nificantnews>-sicnisors>-stcmsmodifLcations »e p dos elt via ecb lyl , oi ps p sh ee r ps oO lD ie M cp yt B. peC ri i tm r acc ium nla ia nl r gsc tAo on -t 1 pr 2 ro 3 il v, aa A cn y-d 1 r2 ec 7 qo , um i&p ru eAt m-e e1r n3 t0s se ;c ou a fr li st oy sRiskAnalysis;helpsIt m i iio cnS naS il sO R D/ e oI q cC u uiO mr ec e nmo tem snp ,to sn oe nDn o at cs su eo m lf ee cnP tr to bsj ae s&c it sDP al ta an, R •r P tie r ov noi ,e g Vw m es m nS fS a in cO ad/ tI iDC oa nO ta ac no B dam sp Teo esn S te p in e nct gis f Pio lcf a at nS iy o as n nst d,em a S/ pnS edu cib V fs a iy l cs ait tde ia om - n, : •r O Ce opv nei nmer ric so iS n osS n/O M/ Pa lI i aC nn ,O le ac n no a dm np rco ee vn ie M sn a et n ds uWao lf &,U TIs ne str Pa llM ala nan t au io na n dl, and a Cr oe nv ndi vSe ew S rs sO iT /e oIs nCt POA ln aca nol my psi os nea nn td sS oe fcu rr ei vt iy seE dva Il nu sa tat li lo an tiR oe np &ort •c Amo I.n Sdu A pc l-t a1s n2 n7p i,e nr a gi no pdd ri oAc c- er 1 se 3 sv 0i ;e fws eep de ir ngO iM ntB olC oi nr gc -u rl aa nrs geA- agencyrecordsanddata,perPrivacyActof1974 Speciicaiions kd a f mue o ed rv nie p ttl rso i ip oo mrs f pi rA a i ou UD i vt nP eo g mma ea su nt yd s tei t sdt ems [g s 4yu ),si td aee nm; ds,c ro t en i pd a ou s rc c tdt ss o ons nel e ne sc ett eai b dv l ee i dsr he mev adi ne c aw r gis t eeo -rr i: ' r S t sle ceuv omdi pye eD,w es ocR/ fiie ssv fika uol tA n uu n ra a P et l ae y ips s neiN vrs oe ,, le b vCd a eos s ms e eS t d nt / ta B ut e pe n om ce nrn ut rt, AnF ae la ys si ib si ,li aty ndSys- > P R i Pr l he e ra ev q on ii u g, re i rw dF r as eu e/ mvne m ecv e lta n oil t pou sn ma at eDle nos tcR ,S uey q m as su et i n ne r t em e s cm e,D see sanc anti rdss yi ;D po ao pn r rc tP eu ia pm cp aiee rpnr a et, t ss eP As,r uio dD nj iae ttc at i Sr B Py re as ov s. ji e ce D cw Se ls pc/ ei Pe cs lv s ai .a no ,l ;nu Wa uPt pae & dps aeT t& r e, sp PSo l Ays as us n. di / ib aSl tnuy db Psi rS)n op^p eu gcPt rss r a,o mt g ao r nR a di ms Rk & evA iDn sa a el ty dasis, t Mr D i ae e ov nci n uLe s isn . lbs U ,n/ se aePv r na a dl p Mu e a Ia r n nt , sue ts ar ale lr ,v le i av s tOi ie ps od ee nd rW a &P t&r i Co oj oT ne nsc vt /P eMl rP aa sl ina inn oa t, nn eS d n Py a lSs anpt nce ;e eem i uf pi -ca- t Fr i ve o Bv ni le u&w as l/ C ie o ov n na vl Reu cra s pt ie os o nn ;re P uv li pas dne , ad ta eP n sr do Aj T ue e dc s it t tP Al Pna rn a o, l gyr s re i av s mis &ed SI ei tK ut ra il tlS y' •c G Po rAn od O gu rc aat u ms di ap t ser s ni t eo a ed ni ddc ea drr de sv ;ie uw ps dp ae tr esO AM udB itA- Pl1 a3 n0 aA t] Be & rs et vaa ipb epl wri sosh v &e as l rm epa r cn o oca meg mse es nm f de o an r tt iAI ol S ne s« s;l poi erm ngp aal ine nim ize nen s gt a ta ot fi Aoo r Dn ma Plgu eqi fud fa oe l rl i ti t sn yes * i m C Pd o ace s pnn t eit / r;i B ;f d ei sie n es r e le f e& c i ct t tsv sAa Fl n aei aa Pd lsa ryit osbe jiis esl c;in t te dye e MSd v at; e nu ld ad oye gp,v ese R rl Sio ysp sks tA eN n mae le Dyd ess ci isS , sl iaa ol n ne d- (a mp ep nr to sve Ds ocP ur mo eje nc tt s,Pl aa nn dan ud pdF au tn ec st Sio yn sa tl emRe Dq eu ci ir se i- on » Sa D V pp ae ep lc ci ii it ds fi ai iv to ce in as o tnPr i,ae opv nVei ses r r (e ; i ad f li lrP ce br aa ao tsj sise o eec ns dt s ae oP ns nl dRa Oin Ts e Aa k sn t rAd in ena cu gl op y mPd s cla i a nt s n de ; as aa tnS p idpy ors not sve )em s a ua t pp enp dndr aao n iSl t t^- e sc fs Si M yc ar sae n tv t ui ei as mo le nd Ds & e.P cr IU io nj ss se ie tc oart nllMP Paal t ana i pn u o, ena rlr &,e iv nO Ci ips o te e n id ar v ta eW et r si s& uo i sn o eT s n r/ PM tP la rl a aia innn n;- - > sa v eep erp ssr io tov rn ae is P nl ir a ne n gv ; ;i us ae p cd cd eaP ptr teo ssje (Sc ayt cs cP t rl ee da m in tD sa e )n cd si ysI i sn o ts n eta mPll faa opt rei r oo ; pn co& iv teC tr io - on n- *o l n Piv leve aeer nds a ape f cpe o cls r oi cc rtr a dha t iai i nnn o ggi n len s yg s; f tod orir sre yec sct tes enp mie lr aii e nso dtd ii roc en v;r ie siv d ei e sne Ptw ris f oi jo e ef s cs ien 'd S tee l ruv nde yl D,o ep cRs ii sso ikr oA no nv a Pe l ar y ps se eie rss ,d Ce ov se tl /o Bp em ne cn rt uo Anf aP lc ya ss ii sb ,il ai nl dy S ku P Vep r rd o ia g ft r ie cas am tP i&r oo nj De aac ntt daP Tl B ea a sn s t; e id nSe gpv e Pe c ll i ao f np is c aa nS ty dios n St s pe , em c&/ iS fiu V cb a als tiy ids oat nt se im o I vu S t epp i red o sca n iit s ofe / ncs Ma PatP liir ano no tn ;j s ee ; n raa ed n se cP pvl e oea nMn l s; o a ip n br s u le a ev Ui ls fs , oe e rs ar n pW M d ra& on I gnuT rsa t al a m, lP mll aO ia tpn nie goa r nn aa &d n- dCon- ' sA lu en ep ca nd ul aa ry nit s t ce i y cs ;s MP & r ar eo nvj S uie e s ac c e lt su ,rP Ui al st na y en dr; Ev IMs a nau l sp n. tp auR lo a ler l apt , tos ir O o& t npc aao r nnv a de d tr i Cs c oe oe nr ne st vs i A ef lT i rae e sss i iI ni o-y ns Pl lc am n dd &i ur rOe ipc nt e gs ra ii i mm i pp o ll n ee s mm A ec nfn tat aio tnt iti oco nnn a aa n nn c dd e ou M pp a ed n ra u at a te ils oa nU sse nr eeM da en dual • pe b Ars -at o 1sa c 2eb e 7dl s ,i s os e *nh se Ds Af e -op pr 1o Ll 3ii , 0nc dy r gi uevi i iqm d dup u ail a nre l cem s eme y en s nt t ta e st mi ao d nn e dvg Oeu li Md oe p Bl mi e Cn n ie t rs cc& uf lf ap o il r sa un A,n -i 1r I pp m Dor e oo n n cv e t ui n s md t ee s Ds noo tc cf so un P ms r eu ol njt e ta c st ti aPo nln a dn& , Dar F te u av ni c Re tw ei qoo n uf a ilS rS eR mO e eq/ nuI tiC srO e-c. »r tP ie r ov o ni .ge rw Va es rmS ifS a inO cd/ atI D iC oa nO ta ac no B dam sp Teo esn S te p in e nct gis f Pio lcf a at nS iy o as n ni s de ,m a S/ pnS cdu cb iVs fay ll cs ait tdt Cr O oe pv nei vrc eaB rtS si iS o oS n nsO / P/ M lI a aC ni ,O nt ac e nno dam np rco ee vn ie M sn a et n ds uWao lf &,U TIs ne str aa nlM dla an t Su i po ea n cl i, & fica- Ir S M lae aS tv nO ii u o/e naw I ls aC . nT O dOe ps i Ct em orp nA aa vn tca eitl roey snds isi o/ds nMo& ac Piu lnmS atee nc enu ntr aai ntt ciy eoE nv Ma aul np. uda aR t le e ,p s ao t nn o da U In l nd e str al- ConiractingOfficcr/CotilratiAuditor GSA/Depts .p po nli ac cy uri cm mp el nem te pn ot la it ci yonguidelinesbasedO ADPMotiagcr I tl ie oa nlp do el vi ec ly oi pm mp el ne tm ,en pt u, t .appropriate,unlessthisof- Ir D cae a lv ti sae uw pRs pe oqP r.r to Dj te o oc ct ' Ps rP ; ol ja a en s c, taF p Mu pn arc o nt p ari gio ean t ra el , &R pe Srq po. v oi nD d so ec es^ rs /t. Ue. sch en ri- » pr D rc av oti pac ri iv B as a tesW ,e& pS rp oT e vc isc d., eo sm &p to eWn che& nn it cT as lo P sf l uaS pny ps oa7 rnS tu db tSs opy es Pc. rs, o; jP ear cso tg a, p-i Ir O &e pv Cei oie idw vi xW o rsn& is o/ nT Ma Pi lc n ao t nm e ;np a po rnn oce ven it M ds ea sno uf ta eU cl hs ne a ir n cd aM la I sn ns uu t pa a pl l ol, a ri tio ti ( Id R li ier npe uoc ert sts , tt oe as pnt rds; ovIr n ie s dv t ei ale tlw eas ct hiT noe in cs at a lnA d sn ua C pl o py ons rvi tes ;r& s mi aoS ye nc du Pr oli at n ty ; ecE c hv o ni iil c-. al ManagerandSponsor/UserindevelopingSpecs. P Dr Poj te na inM ia nn gagerandSponsor/User;mayconduci evaluationforcertification. Oualily/Vssuratice(OA)Specialist a i ab c pl mi rss oh cme ees se sa t in nd r geu pqt u ri i ol ri cz e ee m ds e unp rtr eso s,ce is ns ce ls udt io nm gs cu or mc pla ip ap i Ir pe rv oi ce ew ss sis ny gst ste am nd de as ri dg sn,W&Tcomponentsand ' d dr eoe scv iui gme new n atp nar dto i dg o ar n ta , am a pd n ne d xf ei tn sri sat iii n no in gn, g s,p tr af no o drg ar c ra o dm m spc lo id ae n, celo ' \ or i fe sv Nei s ee ew r ds es sT pe o Ss n tt s ai tA b en l ma el ey npas tri ts i& cipS ae nc tu sri ot ny sE yv sal t, emR ae cp ho ir et vea mn ed na td- a pr anc rav tli iye czu ies ps ac nah tna sdng re es pot ro ts so of ntw da er fe ecs ty sst le om: res su pm cm nsa ir bi lz ees |1]Matrixintendedtoreflect,primarily,roles&documentsforlarge,in-houseAISleielopmentorredesignefforts.Alternativeapproachesarcdiscusse. |2|IRMi ln ifb eo rd sy loof 'sr ie np go lr et. offical*asidentifiedunderPL96-S11andOMBCircularA130,Forsmallersystems,however,approvalauthoritiescommonly |3|Relatd ie ol ne sg ha it ped a, ma os ngpr Iov Ri Mde Od fff io cr iab ly ,D Spe op na sr ot rme an nt dpAolDicPy, Managermaybeformal,a;inthecaseofanestablishedAISapprovalbody,orinformaladhoc body,dependingupontheorganizationandparticularsystem. AllauditinvolvementinAISlifecycleshouldbebasedonanassessmentofnce<!andpotentialrisk/cirposure.andiKrformedonaselectbasis,noton | (5 61 1I In ns so oa m mll e es ccy iis rrt cce uum mms ss tto aar nn ccp eeh ssa ,,se s ss o o. m me eo of ft th he es se ef fu un nc ct ti io on ns sa ar re eh haa nn dd ll ee ddb by ya aCC oO ntT rR acr te. As up do in tsb irit ret so pt oh ne siP br lo ej te oct thM ean Ca og ne lr ta. ctingOfficer, 25commonly recognized deliverables produced in Federal AIS projects, and a comprehensive surveyofsystem developmentpractices in over 100 offices ofapproximately 76 Federal agen- cies and inselectedprivate sector companies.This life cycle matrix should beusedby auditors as a basis for understanding how to review systems under development. Actual reviews must be tied to the particular development methodologyused. The AIS life cycle matrix is designed to be used by the auditor in the following manner: 1. As a training tool - The matrix defines the major phases in the development of an AIS in terms of key activities to be performed and products delivered. This matrixcanbeused toorient the auditorto the developmentalprocess byexplain- ing: (a) The phases/activities ofthe system development process; (b) The participants in the developmental process; (c) The responsibilities assigned to individual participants ("participants" refers to functional responsibilities for development rather thanjob titles or full-time positions); and (d) The products/deliverables to be produced. 2. As a basis for understanding a proposed review methodology - Because the specific development methodology ofvarious Federal agencies may differ, it is onlypossible toprovide ageneralizedauditreviewmethodology.The framework for describing this methodology is the AIS life cycle matrix provided here. 3. Forcustomization ofthe auditmethodology to aspecificFederal agency andAIS -The auditormay need to customize the reviewmethodology in this guide to the specific AIS project under review. This can be accomplished by relating the deliverables/responsibilities in the agency to the AIS under review. 4. In the absence of having a formal methodology or using one, this matrix can be used by auditors as criteria for evaluating AISs under development. LIFE CYCLE PHASES 2.3 The auditor should not expect that systems will be developed in accordance with this specific SDLC methodology. The life cycle phases described in this guide are intended to clarify the broad functions or activities which should occur during the development of an 26automated system. The six phases cover activities commonly performed, so that whatever developmentmethodology the auditorencounters, the followingsix phases encompass the ac- tivities likely to be found, and thus could be customized to a specific audit (see Figure 1, Automated Information System (AIS) - Life Cycle Matrix). 2.3.1 Initiation - Phase I DOD Consistentwith the "MissionAnalysis"and"ConceptDevelopment"Phases, the in- itiationphasebeginswiththerecognitionofaproblemandthe identificationofaneed. During thisphase, theneed isvalidated, andtheexplorationofalternativefunctionalconceptsto satis- fy the need is recommended and approved. The decision to pursue a solution must be based uponaclearunderstandingoftheproblem, apreliminaryinvestigationofalternativesolutions, includingnon-computer-basedsolutions, andacomparisonofthe expectedbenefitsversusthe cost (including design, construction, operation, and potential risks) of the solution. At this stagethe risk/sensitivityofthe dataorinformationin orresourcescontrolled bytheAIS under consideration should be evaluated. 2.3.2 Definition - Phase II In this phase, the functional requirements are defined, and detailed planning for the development of an operable AIS is begun. Functional requirements and processes to be automated are documented and approved by an appropriate senior management official before anAIS development effort is started. Requirements identification is iterative, as is the analysis ofpotential risk, and involves those who identify and solve problems. It is critical that internal control and specificsecurityrequirements be identified during thisprocess. Require- ments may be, and commonly are, modified in later phases as a better understanding of the problem is gained. Also, duringPhase II, aProjectPlan specifyinga strategyformanagingAIS development, certification, andaccreditationisprepared. Itdefinesthegoals and activities for all subsequent phases, and includes resource estimates during each phase, intermediate mile- stones, as well as methods for design, documentation, problem reporting, and change control. W&T Resourceplanningfor shouldbe includedhere [FIPSlOl]. Inessence, the Project Plan describes the unique SDLC methodology to be used during the life ofthe particular project. During this phase, the Audit Plan is also prepared so that the newAIS will be auditable from the start. 2.3.3 System Design - Phase III The activities performed during this phase result in a specification ofthe problem solu- tion. The solution provides a specific high-level definition including information aggregates, informationflows and logical processing steps, as well as all major interfaces and their inputs and outputs. The purpose is to refine, resolve deficiencies in, define additional details in, and 27package the solution. The detailed design specifications describe the physical solution (algo- rithms and data structures) in such a way that it can be implemented in code with little or no needfor additional analysis. Agencies should define and approve security specifications prior to acquiring or starting formal development ofthe applications. The validation, verification, W&T) and testing ( goals are also identified during this phase, and aplan for achievingthese goals is developed (See National Bureau of Standards FIPS PUB 101). The Project Plan (schedules,budgets, deliverables, etc.) andRiskAnalysis arereviewed andrevisedasrequired given the scope and complexity of the solution formulated. These activities are coordinated with the Certification Plan components. 23.4 Programming and Training - Phase FV This phase results in programs which are ready for testing, evaluation, certification, and installation. Programming is the process of implementing the detailed design specifications VV&T into code. Completed code will then undergo unit testing, as described in the revised Planin this phase, and integration and system testingin Phase V. In addition to Programming andTrainingManuals, User and Maintenance Manuals are prepared duringthe fourth phase, as is a preliminary Installation Plan which specifies the approach to and details of the instal- lation ofthe AIS. 23.5 Evaluation and Acceptance - PhaseV o Inthis phase integration and system testing ofthe AIS occurs. Forvalidationpurposes, , the system should be executed on test data, and the AIS field tested in one or more repre- sentative operational sites. Using actualfunctional transactiondata, ifdesignated a"sensitive" system, the system should be certified for technical adequacy in meeting its security require- mentsbyanappropriate authority,prior to accreditationand installation. Beforecertification, W&T all test resultswould be documented and a comparison ofactual and expected results made. OMB Circular A-130 and NBS FIPS PUB 102 security evaluation should be part ofthe broader testresults/test evaluationreport.The accreditationstatement, the last keyactivity of the phase, will be a statement from the responsible accrediting official (e.g., Sponsor/User) 8 Development Phase-TheInstitute forComputerSciences andTechnologyat theNationalBureauof Standards (ICST/NBS), in structuringaframeworkwithin which the development ofsoftwarecouldbe discussed, identified aDevelopmentPhaseincludingfourstages —definition, design, programming, and testing.These are representedbyPhasesII-V describedabove. Duringthe DevelopmentPhasethe requirements for software are determinedandthesoftware is then defined, specified, programmed, and tested. Documentationispreparedwithinthis phase toprovide an adequate record ofthetechnical informationdeveloped. ThePCIEWork Group'sphasesareintendedtocovernot onlysoftwcu-ebut also hardware, telecommunications, etc., i.e., allthe components ofan automatedinformationsystem 28that the system is operating effectively and is ready to be installed. Any caveats or restrictions should be provided at this time. 23.6 Installation and Operation - PhaseVI Comparable to DOD's "Deployment and Operation" phase, and encompassing both NBS'"Installation"subphaseand "Operationand Maintenance"phase, thepurposeofthis final life cycle phase is to: (a) implementthe approved operational plan, includingextension/instal- lationatothersites; (b) continue approved operations; (c) budget adequately; and (d) control all changes and maintain/modify the AIS duringits remaining life. Problem reporting, change requests, andotherchange controlmechanismsare used tofacilitate the systematiccorrection and evolution ofthe AIS. In addition, periodic performance measurement and evaluation ac- tivities are performed to ensure that the system continues to meet its requirements in a cost- effective manner in the context of a changing system environment. These reviews may be conducted by either or both the quality assurance (QA) staffor the audit unit. 2.4 RESPONSIBLE PARTICIPANTS AND THEIR FUNCTION IN THE AIS LIFE CYCLE The auditor must recognize that organizational structures vary significantlyfrom agency to agency. The functions described in this section are described as "job title related" functions so thatorganizations can look at them as specificjob titles, if they have an equivalentjob, or as functions which must be performed whether or not the specific job exists. The list is not meant to be all-inclusive, nor does it preclude smaller agencies or organizational units from combining participants or roles. Therationalefordescribingtheparticipantsistoidentifythe role ofeachkeyparticipant. In the audit program, the auditor will be asked to verify that the respective AIS participants A haveeachperformedtheir appropriaterole. briefdescriptionofall oftheparticipants listed in the AIS life cycle matrix follows, with the exception ofthe auditor, whose role constitutes the bulk of this guide and is found in Chapter 4. (Note that these functions are divided into poHcy/oversightparticipants and the functional/operationalparticipants, based onthe level of the agency at which they operate.^) 2.4.1 Policy/Oversight Participants 2.4.1.1 Information Resources Management (IRM^ Official - This individual is respon- sible for developing uniformpolicies and procedures to ensure that an agency effectively and 9 Policy/oversightparticipantstendtofunction at the department level, settingand/or overseeing implementationofinternalcontrol andsecuritypolicyguidance. Functional/operationalparticipants are locatedinprogramorlinelevelandimplementdepartment policyorguidance 29efficiently manages its records/information and its information resources. The IRM official is responsible for approving the development or acquisition of all information systems, though this responsibility may be shared with an approval body, or for some systems, delegated out- side that position. The IRM function, that of a "single official," is called for in PL96-511 OMB [PRA80] and in Circular A-130 [OMB130]. 2.4.1.2 System Security Officer (SSO) - At the department level, the SSO is responsible for the development, implementation, and operation of an agency's computer security IRM program. Designated by the official, that individual is expected to define and approve overall security specifications of new systems or changes to existing systems, whether developed in-house or acquired from an outside source. The SSO is also responsible for con- ducting or overseeing the conduct ofrisk analyses prior to the development ofany major sys- OMB tem. The function is identified in Circular A-130. 2.4.1.3 Internal Control Officer (ICQ) -At the department level, the ICO is responsible for seeing that an agency's financial management information systems are identified, devel- oped, maintained, reviewed, and improved as necessary. The ICO is responsible for the con- ductofvulnerabilityassessmentsofthesefinancialmanagementinformationsystems,andtheir OMB internal control points. The ICO responsibihty is derived from Circular A-123 [OMB 123].TheICOdoesnotperformthereviewsperse,butestablishespolicyfordetermina- tion of the internal control points, and oversees the scheduling and conduct of reviews per- formed at the operational or program level. 2.4.2 Functional/Operational Participants 2.4.2.1 Sponsor/User -The Sponsor/User is responsible for initially identifying the need that has to be met by an AIS. The Sponsor/User has to identify various alternative solutions to the problem, and determine the feasibilityand cost/benefit ofthe various alternatives.The Sponsor/UseralsohastoconductoroverseetheconductofaRiskAnalysis,toassessthepoten- tialvulnerabiHtiesofthesystemorappHcationbeingdeveloped.Thatanalysismustbecontinu- ally updated or revised during the SDLC to assure the inclusion of appropriate internal controls andsecuritysafeguards.TheSponsor/Userisultimatelyresponsible foraccepting(ac- crediting) the systemas being complete, meeting its requirements, and beingready foropera- tional use. Depending on the particular system, the Sponsor/User may be located at various OMB levels in the agency. Under Circular A-130, the Sponsor/User, as the official whose program an information system supports, should be responsible and accountable for the products ofthat system. 2.4.2.2 Project Manager/Contracting O fficer's Technical Representative (COTR) - The Project Manager is the individual responsible for seeing that a system is properly designed to meetthe Sponsor/User's needs, and is developed onschedule.TheProject Manager isrespon- 30sible for seeing that all system documentation is prepared as the system is being developed. If the systemis developed either in-house orby acontractor, the Project Manager is responsible for certifying that the delivered system meets all technical specifications, including security, ADP obtaining technical assistance from the Manager as necessary. If a different individual, COTR the should report to the Project Manager appraisals oftechnical adequacy of the AIS beingdevelopedbythe contractor. The ProjectManager is designated by the Sponsoror chief User and is responsible to the same. 2.4.2.3 System Security Specialist (SSS)^^-This individual is responsible, at the program or operational level, for seeing that a system complies with the agency's computer/system securitypoHcy.The SSS approves designreviews, to assure that (l)the design meets approved securityspecifications and system tests, and (2)administrative, physical and technical require- OMB ments areadequateprior to installationofthe system.Thefunctionis referenced in Cir- OMB cularA-130, and must be coordinatedwith internal control review requirements under A-123. 2.4.2.4 Internal Control Specialist- This individual is responsible, at the operational level, for seeing that a system complies with the agency's internal control policy. The ICS as- suresthatasystemmeetsbasicstandardsfor documentation, recordingoftransactions, execu- tion of transactions, separation of duties, access to resources, and all other internal control OMB requirements. The function is referenced in CircularA-123, and should be coordinated OMB with security review requirements under Circular A-130. 2.4.2.5 Contracting Officer - The Contracting Officer is responsible for awarding and managing contracts to a vendor to provide part or all ofthe system development activity that is not performed by a unit within the operating agency. The contract might also provide for the procurement of system software required by a new application. The Contracting Officer in either case, is responsible for seeing that thevendor or contractor complies with the terms of the contract and that the deliverables are provided on time. Responsibilities are clearly statedinthe existingregulations (i.e., FIRMR, FPMR, FAR andFPR). He/sheworkswiththe PM and COTR and, possibly, the Sponsor/Userto assure that the request forproposal (RFP) and the final contract clearly reflects user needs and critical internal control and security fea- tures. 10 ThetitleofSystemSecuritySpecialist, orSSS, isusedin placeofSystemSecurityOfficer (SSO) to differentiate thefunction and responsibilityofthe department's securityofficefromthat at the program or operational level.The same distinctionapplies to theInternalControlSpecialistversustheInternal ControlOfficer. 31(Contract Auditor - If requested by the Contracting Officer, the Contract Auditor is responsibleforreviewing acontractor'sperformance onaspecified contract. Otherwise, com- pHance with the contract would fall under the purview ofthe Auditor.) 2.4.2.6 ADP Manager -TheADP Manager isthe technical individualresponsibleforthe ADP installations and operations of an agency's programs (i.e., he/she is responsible for the operation ofthe dataprocessingcenter and the management ofthe system analysts, program- mers, etc.). The data processing (DP) branch may actually develop parts of the AIS or may provide technical support to the Project Manager and Sponsor/User during the system's life cycle. Dependent upon the particular system/application under development, the ADP Manager might serve with the Sponsor/User on a system review/approval board, QA 2.4.2.7 Quality Assurance (QA) Specialist -The operationslevel staffis responsible for assuring the Sponsor/User that an application system is developed in accordance with the system's stated objectives, contains the needed internal controls and security toproduce con- sistentlyreliable results, and operates in conformance with requirements and dataprocessing procedures. Quality assurance, as defined in the AIS life cycle matrix, is the function that es- tablishes the responsibilities and methods used to ensure quality in data processing products. The Quality Assurance Speciahst may or may notbe personally involved in establishing these responsibilities and methods. QA QA The charter should allow for independent reviews. staff should actively par- ticipate in reviewing the development of new systems or appHcations and the significant VV&T modification ofexisting systems. (Coordinationwith security/audit and participants is QA essential to avoid duplication ofeffort.) In addition, the staffshould ensure data integrity QA ofsystems. The presence and effective functioning of the staffwill determine the nature and extent ofaudit involvement, in that they commonly perform similar functions. USE OF EXTERNAL DEVELOPMENT SERVICES 2.5 2.5.1 Contractor Services Differencesinthe SLCwhich resultfromtheuse ofcontractorservicesinlieuofin-house staff, are described briefly below. At least two points are key: 1. The term "contractor" applies to both private sector enterprises and activities of the Federalgovernment.Thislattercategoryincludes, forexample. General Ser- vices Administration, Defense and non-Defense laboratories, and the National Bureau ofStandards. 322. Contractors can be used in every phase and activity in the SLC. There are, however,restrictionsonthe typeofworkwhichcontractorsshoulddo (e.g., poHcy formulationand managementofgovernmentemployees), andways inwhich they should not be employed (e.g., personal services). These restrictions are stated in the Code ofFederal Regulations (CFR). Regardless of whether these services are performed in-house or contracted out, the operating environment and project management must make adequate provision for control over the system development process (e.g., requiring compliance with standards and subject- ing deliverables to VV&T). Only items at variance with functions and activities specified in theAISLife Cycle Matrixare identified, and are described inthe life cyclephase inwhich they wouldoccur.Differencesinthe auditapproach,however, occasionedbythechangeindevelop- ment circumstances, are presented following Phase VI. 2.5.1.1 Differences from the ATS Life Cycle Matrix Operating Environment 1. • InformationResources Management (IRM) Official- Establishes guidelines on the use of contractor services, e.g., issuing design specifications for competitive award rather than automatically letting the same contractor design and develop a particular software application. • ContractingOfficer-Establishes guidelines, rules andprocedures fortheuse ofcontractor services. 2. Initiation - Phase I • Sponsor/User - In coordination with the Project Manager, incorporates a preliminary assessment ofthe need for contractor services in the Feasibility Study, Risk Analysis, and Cost/Benefit Analysis, where possible and as appropriate. (Minimally, the acquisition ofcontractor services can require a long lead time. Therefore, the impact on the project schedule must be recognized and identified.) • Project Manager/Contracting Officer's Technical Representative (COTR) - Supports the Sponsor/User in project initiation and the assessment of government personnel and contractor resource needs. (No other change is required. The typical use ofthe contractor is in support of the Project Manager/COTR. However, contractors can also be used, for 33example, by the ADP Manager to provide consultation, by the Sponsor/User to develop the Needs Statement, or by the Auditor to review/evaluate the Feasibility Study. In all cases, the government's interests must be protected by a rigorous definition of what the contractor is expected to do. It is the Contracting Officer's responsibility to ensure that the interests of the ADP government are met. Contracting for resources is discussed in GSA's 41 CFR 201-32, and is referenced in 41 CFR 210-20.003, Requirements Analysis.) 3. Definition - Phase II • ProjectManager/COTR -Incorporatestheprovisionofcontractorresources, as appropriate, into the Project Plan to ensure that: (1) resource acquisition schedules are meaningful; (2) the role of the contractor(s) is identified and proper; and (3) objectivity controls are provided. (No other particular change is required. Contractors may participate in any activity unless otherwise precluded by Federal statute or Departmental policy.) 4. System Design - Phase III • Information Resources Management (IRM) Official- Oversees project to ensure objectivity ofdesign with respect to requirements. 5. Programming & Training, Evaluation & Acceptance, and Installation & Opera- tion - Phases IV, V, and VI No particular change is required. Contractors may participate in any activity un- less otherwise precluded by Federal statute or Departmental policy. 2.5.1.2 Differences in Audit Approach -The impactonauditofusingcontractorservices at key points in the SDLC, will vary with the degree ofresponsibility assigned to the contrac- tor, and number of contractors involved. For example, at one extreme, contracts may be awarded which incorporate all major phases of the project, from feasibihty study through installation and operation, into a single contract. At the other extreme, contracts may be in- corporatedintotheprojectwhichcallforlimitedresponsibility,suchasdevelopmentofasingle subsystem, or system documentation, orTraining/User Manuals. Care should be taken that the objective integrity ofthe approach is not compromised by allowing a contractor, without proper management, to define the requirements and design a 34system responsive to the requirements. Without this management, there is no incentive for a contractor to seek cost-effective design approaches. Each ofthe possible permutations ofcontractor involvement has unique characteristics which will require modification of the audit approach to specifically address the situation. There are, however, common areas which will need to be considered. The degree ofaudit ef- fort directed to these areas is, ofcourse, dependent on the nature and scope ofthe contractor involvement. The areas to be considered are: • Project Plan-The overall Project Plan should include specific delineation ofcontrac- tor responsibilities vis-a-vis the other "responsible participants." Particular attention should be paid to the vaHdation, verification, testing, and certification of contractor produced products. • Requirements Specifications - The requirements description should be as complete as possible, identifying the tasks to be completed and deliverable items, in as much detail as necessary to ensure that all documentation and decision points reflected in the AIS Life Cycle Matrix are adequately addressed, and that all relevant system development standards and guidelines are incorporated. • ContractMonitoring-Proceduresandpracticesrelatingtothemonitoringandevalua- tion ofworkunder the contract should be sufficient to ensure compliance by the con- tractorwith the SDLC documentation and decision level requirements. The audit approach to systems development activities involving contractor support remains focused on the requirements specified in the AIS Life Cycle Matrix. The use ofcon- tractors in the development process, however, does introduce additional elements for con- sideration in developing the overall Audit Plan. For example, the contractor should not be substituted for user involvement, project management, standards, and documentation. 2.5.2 Off-The-ShelfSoftware/Turnkey Systems The acquisition and installation of off-the-shelf software or turnkey systems, in lieu of customizingamajor systemdevelopment effort, alsorequires modificationofthe functions or rolesidentifiedin theAIS Life Cycle Matrix.The differences inthe systemlife cycle are as fol- lows. (It should be kept in mind that many of the changes identified are required for the procurement ofcontractor services as well as software.) 35Differences from the AIS Life Cycle Matrix & Operating Environment. Initiation (Phase TV and Programming Training (Phase IV^ No particular change is required. Definition - Phase II • Project Manager - Prepares Functional Requirements Document to serve as the basis ofprocurement action. Design - Phase III • Sponsor/User - Reviews proposed procurement for sufficiency. • Project Manager - Identifies and appoints technical evaluation panel to review technical competency ofbids/offers. • ADP Manager - Reviews requirements documents and provides technical assistance to Contracting Officer relative to development of procurement action. V Testing - Phase • Sponsor/User - Reviews results ofall pre-award test procedures. Concurs in any customizing and award. • ProjectManager -Overseescompletionof"livetestdemonstration"andother pre-award test procedures. Defines/approves required customizing. (If customizing is required, that process should be done by returning to a sub-process identical, if abbreviated, to that for full systems development Phases II-IV). Approves award to selected bidder/offeror. • ADP Manager - Provides technical assistance in evaluating "live test demonstration" and other pre-award test procedures. Also oversees installation ofsoftware at the test site. 36& 5. Installation Operation - Phase VI • Sponsor/User - Identifies and initiates request for additional modifications by manufacturer. • Project Manager - Reviews system updates and ensures revisions to documentation and manuals, and initiates required training. ADP • Manager - Installs licensed systemupdates. 2.5.2.2 Differences in Audit Approach -The majordifferences forthe auditorinreview- ingthe selectionand installation ofoff-the-shelfsoftware willbe that little to no attentionwill be paid to the actual coding process unless substantial customizing was required. Normally, off-the-shelfsoftware is considered reliable unless problems are found. However, more often than not, off-the-shelf software or turnkey systems are found to need modification to be responsive to user requirements. Any such modification may impact the agency's ability to hold the vendor accountable for problems encountered or future upgrades or maintenance. Modification to such software or to its operating environment should, therefore, be a consideration for the auditor in any of the affected life cycle phases, VV&T particularly with regard to implications. 2.6 AIS LIFE CYCLE DOCUMENTATION Audits ofsystems under development are not practical unless well-defined documenta- tion exists. System documentation requirements are a classic problem associated with the developmentofanyautomatedsystem.Themanyaudit reportsofthe GeneralAccountingOf- fice (GAO) support this assertion. The individual findings of PCIE Work Group members tendto corroboratethe problemand theidentified need. Much carewas takenin the develop- ment ofthe documentation set presented here. Managersmayfinditappropriatetoeitherconsolidate severalrequirementsinto asingle document, move documentation requirements to an earlier phase, or make other changes whichtheydeemnecessary forthe efficientand effective management oftheirprogram. What iscriticalisthatthepurpose andfunctionsofthedocumentselaborated onbeloware achieved. The purpose and general content of each of the named documents or document types identified in the AIS matrix are defined in the following paragraphs. Figure 2, System Life 11 The referencesaftereach documenttypecontaintherequirements orjustificationfor thatdocument. (Note:NBS HPS PUBS applyequallytosoftware and the fullAIS). 37Cycle (SLC) Documentation Flowchart, describes the flow of documents as an AIS project proceeds through its SLC. It uses a single letter for identification ofeach document. 2.6.1 Needs Statement (FIPS PUB 64, DOD 7920.1, FIRMR 201-30.007) A Needs Statement should be prepared to describe, in written form, deficiencies in ex- isting capabilities, new or changed program requirements, or opportunities for increased economy and efficiency. It should justify the exploration of alternative solutions (including automation) to the deficiencies. An adaptation of the document should be used for systems not designated as major systems.The need forAIS security should be identified, based on an- ticipated system's sensitivity/criticality. Since the Needs Statement is a management docu- ment, it normally should not exceed four to six pages in length. 2.6.2 Feasibility Study (FIPS PUB 64, FIRMR 201-30.007) The purpose of the FeasibiHty Study is to provide: (1) an analysis of the objectives, re- quirements and system concepts; (2) an evaluation of alternative approaches for reasonably achievingthe objectives; and (3) identificationofaproposed approach.This study, inconjunc- tion with the Cost/Benefit Analysis should provide management with adequate information to make decisions to initiate or continue the development, procurement, or modification of software or other ADP-related services. The Feasibility Study may be supplemented with an appendix containing details ofa Cost/Benefit Analysis, or may be considered with a separate Cost/Benefit Analysis. 2.6.3 RiskAnalysis (FIPS PUBS 65, 87, and 102, OMB A-130) The purposes of the Risk Analysis are to identify internal control and security vul- nerabilities of an AIS, determine the nature and magnitude ofassociated threats to data and assets, determine the resulting potential for loss, and provide managers, designers, systems security specialists and auditors with recommended safeguards. These would be included during the Design, Development and Installation/Operation Phases ofanew and/or modified AIS to reduce the potential loss. It should be reviewed and revised, as necessary, during each phase of the SDLC to as- sure that appropriate security measures are installed. The findings and recommendations of the RiskAnalysis shouldbe usedbythe reviewteams duringthe AIS securityand certification reviews.Itshouldbepreparedandmaintainedasaseparate document, andshouldbereviewed and updated as necessary, when a modification is made to the operational system. 38— • Z Z o o OO OO OO < < cb uo CC Q_ LaLI OO X CL CO CD CO CO O CO 3 CO CD (Z/^ LL —I CL CD CO ZO3 o CL t Co D L <— =O > -—a -3 z L OU 00 0- OO o z <»3 ^o rot C C—O L CQ O- a CO. ZC C DO D 0o 0 D< a. CC DO •— 0 o0 C CO D C CL O. ot= c<r >< U o <oJ S00 tZ Q QD _. Ca" 0O 0> -7-; C - sO a z o Go Q S D_ " — < a>r 1 >t > o LU GQ ^ a> 'oo CO 00 a. CC < aoy >o O "rt o tj o Z a CO S- i'co 00 o _ L zLl 2 2- Zz 1c:I^<0 i0 > ^£ rt —C oC 2 k OJ o < E = ,O £O c qI H o ^ oa> coz Qo E o z 00 Q ^ a> a gs o ^ > Ca O> LU ^ — D 11 CO >a> 5 00 O Z o 3 cr C £O = CO < <E1> Q <i> a> otJ CC CO u _ ou l -2L QU 0 CI5 S <tJ C0 O0 Co O > 3<1> O^CD"^ C^ I0 -0 "o 2 Z O > o- _i HLU LU >- LKU OO a<3 c >o - gI O OOO tn Lo CD Q O C3 O C a3 >- ey> coco^ c:i = z O OO CO o u. CD uo L QU C_ O Z CD L ZlD Q ZDQ ^CD L to^C QO _ C CO L qI 03 iZ CD OO TS OO CL CL I n a> CD s CD= C> J^L^ i0 _= < ^n £J = C £OL = C QO _ i ^ O ^ a> CO s00 ^^^ tJ CO ^ <n — < CO CD Ed. o i ag " EE -t ao a> o a> Z o < o li! a: CO Qlif CO <cDOciujLi_c:!z:x 392.6.4 Cost/Benefit Analysis (FIPS PUB 64, OMB A-130, OMB A-123, FIRMR 201- 30.007) The purpose of the Cost/Benefit Analysis is to provide managers, users, designers, sys- tems security speciaHsts, and auditors with adequate cost and benefit information, including the impact of security, privacy, and internal control requirements on that information, to analyze and evaluate alternative approaches to meeting mission deficiencies. This document, in conjunctionwith the Feasibility Study, should provide the information for management to make decisions to initiate or continue the development, procurement, or modification of software or other AlS-related components. The Cost/Benefit Analysis may be prepared as a separate document, ordetails ofthe Cost/BenefitAnalysismaybe appended to theFeasibility Study. 2.6.5 System Decision Paper (FIPS PUB 64, DOD 7920.2, OMB A-130, OMB A-123) The System Decision Paper provides the information and framework critical to the departmental and operating divisions' decision-makingprocess duringthe development ofan AIS. It is the principal document for recording the essential information on the AIS, such as missionneed, milestones, thresholds, issues and risks (including security, privacy and internal controls), alternatives, cost/benefits, managementplan, supportingrationale for decisions, af- fordability in terms ofprojected budget and out-year funding, and the decisions made by the agency's Office ofthe Secretary. The SystemDecision Paper remains in existence throughout the life ofa majorAIS. It mustbe approved at the appropriate level whenmilestones foreach life cycle phase are achieved. The final iteration of the System Decision Paper, prior to the system's installation and operation, should include an accreditation statement by the responsible accrediting official, thatthe AIS is operatingeffectively. Any caveats on its operationneed tobe mentioned atthis time. 2.6.6 AuditPlan (PublicLawsEstablishingOIGs,GAO AuditStandards,OMB A-130, OMB A-123, OMBA-73) Audit Plans are developed encompassing all agency system activities. Systems under development may be selected for review based on several factors, including the sensitivity or criticalityofthe systemor theeffectiveness ofinternal agencyADPmanagement control (e.g., averificationandvalidation group, a formalized testingprocess, a quality assurance function, or a risk management function). Forthosesystemsselectedforauditreview, adetailedAISspecificauditplanisprepared. The plan clarifies audit involvement, which may range from audit review of completed work 40productsateachdevelopmentstage to active reviewparticipationineach system development ADP phase. Inanycase, theoverall objective is toassess the adequacy ofinternal controls and GAO provide the "reasonable assurances" to management spelled out in Appendix 1 of the Audit Standards [GA081-1]. 2.6.7 Project Plan (FIPS PUBS 102 & 105, NBS SP 500-98, OMB A-130, OMB A-123) The Project Plan specifies the strategy for managing the software/AIS development. It defines the goals and activities for all phases and sub-phases. It includes resource estimates overthe durationofsystem developmentandintermediate milestones includingmanagement and technical reviews (i.e., those for security, privacy, and internal controls requirements). In addition, it defines methods for design, documentation, problem reporting, and change con- trol. It also specifies supporting techniques and tools. While the focus or emphasis of the Project Plan is on the developmental phases of an AIS, the plan cannot omit consideration of the system's installation and operation, most particularlythe certificationprocess the systemmustgo throughpriorto entering thefinal life A cycle phase. formal Certification Plan should be included as a routine subsection of the ProjectPlans forall systemsdesignated as "sensitive."Thatsubsection contains clarification of responsibilities, security requirements andevaluationapproach, evaluationschedule and sup- portrequired, aswell as identification ofthe evaluationproducts. Just as the remainder ofthe Project Plan is to be reviewed and modified during each phase, so the Certification Plan is to be revised as needed, commonly based on the updated Risk Analysis. 2.6.8 Requirements Documents 2.6.8.1 Functional Requirements Document (FIPS PUBS 38, 64, 87, & 124, DOD-STD- 7935, OMB A-130, OMB A-123, GSA 41, CFR 201-20) - The purpose ofthe Functional Re- quirements Document is to provide a basis for the mutual understanding between users and designers ofthe initial definition of the software/AIS, including the requirements, operating environment, and development plan. It should include, in the overview, the proposed methods and procedures, a summary of improvements, a summary of impacts, security, privacy, and internal control considerations, cost considerations and alternatives. The requirements section should state the functions re- quiredofthesoftware inquantitative andqualitative terms, and howthese functionswill satis- fy the performance objectives. It should also specify the performance requirements vis-a-vis accuracy,validation,timing,andflexibility.Inputs/outputsneedtobeexplained, aswell as data characteristics. Finally, the Requirements Document needs to describe the Operating En- vironment and provide or make reference to a development plan. 412.6.8.2 Functional Security and Internal Control Requirements Document (FIPS PUBS 38, 64, 73, 87, & 102, DOD-STD-7935, OMB A-130, OMB A-123) - The purpose of the Security and Internal Control Requirements Document is to focus attention of the user and system designer on the security/internal control needs of the system, based both on vul- nerabilitiesidentified duringthe RiskAnalysis andestablishedinternalcontrol/securitystand- GAO NBS ards (e.g., guidance, guidance). Included should be requirements for general controls (i.e., management and environ- mental controls) at the computer installation, if additional ones are needed, and automated application controls. All security requirements need to be defined and approved prior to ac- quiring or starting formal development ofthe applications. 2.6.8.3 Data Requirements Document (FIPS PUB 38, DOD-STD-7935, OMB A-130, OMB A-123) - The purpose of the Data Requirements Document is to provide, during the definition stage of software development, data descriptions and technical information about data collection requirements. The datadescriptions need to be separated into two categories- -static and dynamic data. Dataelements in each category should be arranged inlogical group- ings, such as functions, subjects, or other groupings which are most relevant to their use. The document should also describe the type ofinformation required to document the characteris- tics of each data element, and specify information to be collected by the user and that to be collectedby the developer. Finally, procedures fordatacollection, and the impacts ofthe data requirements need to be discussed. 2.6.8.4 Data Sensitivity/Criticality Description (FIPS PUBS 65 and 102) - In the Data Sensitivity/Criticality Description, specific types of sensitive data and assets should be iden- tified. Once sensitive/critical data have been identified, it may be necessary to determine the degree and nature of sensitivity within the general grouping. Categories of sensitivity and criticahty will be agency dependent. The importance of this determination is that data sen- sitivity/criticality assessments need to be known before the nature and magnitude of threats can be postulated. 2.6.9 Specifications Documents 2.6.9.1 System/Subsystem. Program andDataBaseSpecifications (FIPSPUBS 38,DOD- OMB OMB STD-7935, A-123, A-130)^^- The purpose of the System/Subsystem Specifica- tions is to describe for analysts and programmers the requirements, operating environment, design characteristics, and program specifications (ifdesired) for a system or subsystem. The purpose of the Program Specifications is to describe for programmers, the requirements, operating environment, and design characteristics of a computer program. Both the Sys- 12 Note: These specifications areusuallyfound inthree separate documents. 42tem/SubsystemandProgramSpecificationsshould havesectionsdescribingfunctionsandper- formancerequirements, interms ofaccuracy,validation, timingand flexibility, and the operat- ingenvironment.ThepurposeoftheDataBaseSpecificationsistodescribethenature, logical, and physical characteristics of a particular data base. The section on physical characteristics needs to address storage and design considerations. 2.6.9.2 Securityand Internal Control Related Specifications (FIPS PUB 73 & 102, OMB OMB A-123, A-130) - By separating security and internal control specifications from the broader specifications papers, added weight is given to their importance. The details may be includedas a separate,but clearly identifiable subsectionofthe otherspecification papers. Its purpose is to set forth security and internal control specifications to meet the functional security and internal control requirements detailed in Section 2.6.8.2. All specifications should be sufficiently precise to allow tests to be designed which will tell whether the requirement is satisfied. The security specifications should be kept current throughout the entire Hfe cycle ofthe AIS. No changes to the system should be permitted un- lessthey either do not affect the security specifications or have been approved and entered as anofficial modification to the document. Security specifications should be reviewed by all or- ganizations involved in the use or operation ofthe application. For any sensitive application, they must be reviewed and approved by the party responsible for security and by the organization's auditors. 2.6.10 Validation,VerificationandTestingPlanandSpecifications (FIPSPUBS38and 101, NBS SP 500-98, OMB A-130, A-123, DOD-STD-7935) W&T 13 The purpose ofthe Plan is to plan for the evaluation ofquality and correctness W&T ofsoftware, includingrequirements anddesigndocumentation.The Planalsoprovides plansforthetestingofsoftware,includingdetailedspecifications,descriptions,andprocedures W&T A foralltests, aswell astestdatareductionand evaluationcriteria. planisadocument, W&T orgroupofdocuments, specifyingaproject's requirementsandtheproceduresneeded W&T to achieve them. Because the general system planning drives the planning, in turn W&T providingfeedbacktothe overalldevelopment, the generalprojectplanningand plan- ning are closely integrated. Once the overall background, goals, and requirements ofthe AIS W&T are clearlyunderstood, planning may begin. W&T 13 Note: The PlanandSpecificationsmaybetwoseparatedocuments. 432.6.11 User Manual (FIPS PUB 38, DOD-STD-7935, OMB Circular A-130, OMB A- 123) The purpose of the User Manual is to sufficiently describe the functions performed by the software in non-ADP terminology, such that the user organization can determine its ap- plicability, as well as when and how to use it. It should serve as a reference document for in- itiationprocedures,preparationofinputdataandparameters, andforinterpretationofresults. Inadditiontogeneralinformation, the manualshouldprovide afull descriptionoftheapplica- tion as well as a section on procedures and requirements, including those related to security, privacyand internal controls. Itshould also describe error, recovery, andfile queryprocedures and requirements. 2.6.12 Operations/MaintenanceManual (FIPS PUBS 38 & 106, DOD-STD-7935,OMB OMB A-130, A-123) Two separate manuals may be necessary. The purpose of the Operations Manual is to provide computer operations personnelwith a description ofthe software and the operation- al environment so that the software can be run. It includes an overview of the software or- ganization, program inventory and file inventory, as well as a description of the runs and sections on non-routine procedures, remote operations, and security requirements. ThepurposeoftheMaintenanceManual istoprovidethemaintenanceprogrammerwith the information and source code necessary to understand the programs, their operating environment, and their maintenance procedures and security requirements. 2.6.13 Installationand ConversionPlan ("ImplementationProcedures (IP)"DOD-STD 7935, OMB A-130, NBS SP 500-105) TheInstallationand ConversionPlanis a tool fordirecting the installationorimplemen- tationofanAIS at locations otherthan the test site, after testingofthe AIS, includingsecurity features,has been completed. It may also be used to direct the implementation of major modifications or enhancements of an AIS which have already been installed. Those parts of the document directed toward users should be presented in suitably non-technical language. Those parts directed toward computer operations personnel should be presented in suitably technical terminology. 2.6.14 Test Analysis and Security Evaluation Report (FIPS PUBS 38 & 102, NBS SP OMB OMB 500-98, DOD-STD-7935 "TestAnalysis Report," A-130, A-123) The purpose ofthe Test Analysis Report is to: (1) document the test analysis results and findings; (2) present the demonstrated capabilities and deficiencies, including the security 44evaluation report needed for certification of the AIS; and (3) provide a basis for preparing a statement ofAlS/software readiness forimplementation. Since it presents the deficiencies for review by staff and management personnel (i.e., users), the document should be prepared in non-technical language. The Security Evaluation Report, which should be a large subsection of the document, should end with a certification transmittal letter and contain a suggested accreditation state- ment for the responsible Accrediting Official. That statement would authorize installation of the AIS, possiblywith qualifications or exceptions. Agencies should conduct periodic reviews of sensitive applications, once they are operational, and recertify the adequacy of security safeguards. DOCUMENT PHASING AND INTERRELATIONSHIPS 2.7 Figure 2 depicts the time-phasing of the documents identified and summarized in Sec- tion 2.6. Two factors are particularly worthy of note. First, each life cycle phase requires the development of certain documentation. In general, the documents are representative of the activities carried out during that phase, and are usually a prerequisite for moving to the next phase. Second, the set of documentation demonstrates multiple interrelationships. That is, they feed into other documents and/or require updating as the project moves from one life cycle phase to another. It should also be noted that Section2.6 and Figure 2 do not depict all ofthe documenta- tion needed to assure a project's success. Workbooks, memoranda, letters, electronic mail notes, telephone logs, etc. are allpart ofthe documentationset required forsuccessfulproject communication and control. The documentation set presented here should be viewed as deliverable products resulting from the activities within a particular life cycle phase. The following discussion should enable the auditor to better interpret Figure 2, when using it in the audit programs for the various phases. 2.7.1 Need for Flexibility Flexibilityinthe interpretationofthe Life Cycle Matrix isboth desirable and insome in- stances necessary. That is, some changes to the life cycle discussed in this chapter would be appropriate ifthe subject to be addressed is a major modification to a system rather than the development of a new one. Similarly, modification of documentation needs might be ap- propriate ifthe system is small and uncomplicated rather than large and complex. However, thedisciplineandattributesinherentinthelife cyclephases,participants, and documentsneed to be considered throughout any system development effort. Two examples illustrate this. 451. For small systems, project managers may not need a separate Validation, Verification, andTestingPlan, andmayfinditconvenienttointegratetheactivity into the Project Plan, particularly during the early phases ofa system's life cycle. However, the need to continually assess the user's needs (validation) and to en- sure the conceptual integrity ofthe design (verification) are not arguable. 2. Project managers may find it efficient to integrate the results of a Feasibility Study, Cost/Benefit Analysis, and Risk Analysis into a System Decision Paper. However, the need to address the feasibility of a project, its risks, and its costs and benefits, is essential, even ifthe system is required by law. Notation Conventions in Figure 2 The letter/number conventions and other notations used in Figure 2 reflect the follow- 1. Subscripts indicate updates of a particular document based upon new informa- tioneitherwithin aparticularphase, orwhenmoving from one phase to another. Updates may not always be required, e.g., the User Manual developed in Phase IV (ProgrammingandTraining), may remainunchanged intoPhase VI (Installa- tion and Operation). This is, however, an unlikely situation for large systems. 2. The Project Plan should be updated at the beginning ofeach phase to serve as a coordinatingmediumthroughoutthephase.ExperienceindicatesthattheProject Planandthe otherdocumentationaswell, are oftenupdatedseveraltimes during a phase for large projects where, for example, the System Design Phase is 12 to 18 months in duration. 3. Selected documentation usually feeds into others. For example, System/Subsys- tem Specifications (Section 2.6.9.1) are a necessary input to the development of both the Validation, Verification and Testing (VV&T) Plan and VV&T Specifications (Section2.6.10). Other relationships exist beyond those identified inFigure2.These relationshipsshouldbe clearlydefinedbytheProjectManager when the program for documentation management is undertaken. 46CHAPTERS AWORK PRIORITY SCHEME FOR THEADP AUDITOR INTRODUCTION 3.1 3.1.1 TheWork Priority Scheme in Perspective InSpring 1985, the PCIEWork Group (see AppendixA) co-sponsored, with ICST/NBS, a public/private sector workshop of ADP auditors, senior ADP managers, and computer security speciaHsts who explored the criteria for assessing risk in computerized systems. (See Appendix I for participant Hst.) Recognizing the common problem of limitations on audit resources, the participants and their respective organizations donated two and one half days oftheir time to determine the most productive way to assign those resources. An NBS Inter- nal Report No. 86-3386, released August 1986, presented the results ofthat workshop. That report and this Chapter describe a high level risk analysis forAISs that can be used ADP bycomputersecurityreviewersand auditorstoprioritizetheirnon-discretionaryand dis- cretionary review activities for AISs. It divides the risk analysis problem into five areas ofrisk concern (called dimensions)with each area definedby aset ofcharacteristics. Alsopresented are two possible risk scoring schemes, one simple and intuitive, the other method more ADP detailed. Finally, an approach for deriving an audit plan, using these scores is provided. ADP auditors areurged touse existingRiskAnalyseswhere possible, to reduce the auditbur- den. The identification and risk rating of sensitive systems by ADP auditors and security reviewers should takeplace attheveryearliestpointpossible sothat the control requirements are identified and provided for early in the SDLC. 3.1.2 BriefOverview ofthe Scheme The Scheme described in this Chapter enables its user to systematically perform a risk- ADP basedevaluationofthesubjectsfor audit (orsecurityreview)withinanorganization(i.e., the universe of its AISs), and to arrive at a risk measurement for each AIS. This final risk measure (or score) is based on an analysis of risk in key areas of concern (dimensions for describng risk) in that system. These scores enable the user to rank the systems by determin- ingwhichAISs offerthe highestlevels ofriskto the organization andwhich dimensionswithin each AIS contribute most to this high level of risk. Based on this analysis, the user can then drawup anADP audit orsecurityreviewworkplanforthe organizationin question. Thework plan would include annual coverage along with a basis for formulating the scope of specific AISreviews. Consideringthegeneralityofthe dimensions andtheirassociated characteristics, the scheme is equally appropriate for public and private sector internal audit organizations. 47The scheme employs a two-level review and the characteristics associated with the five dimensions. The levels and their dimensions are: Level I Criticality/Mission Impact Level II Size/Scale/Complexity Environment/Stability Reliability/Integrity Technology Integration Each dimensionis definedbya related set ofcharacteristicswhich are used to estimate orcal- A culate the amountofriskposedbythat dimensionto the failure ofthe system. LevelIreview looks at Criticahty/Mission Impact of the system to the organization (see Section 3.4.5.1 for Level I characteristics)and develops a risk score for each AIS with respect to this dimension. Since this dimension is the most important of the five risk areas, it can be used as a first es- timate ofthe system riskscore.The AISs can thenbe placed in sequence fromhigh to lowrisk andthelowrisksystemseliminatedfromfurtherreviewconsideration. Organizationswithvery limited resources could stop at a Level I review and plan theirworkbased on these results. It should be noted that some of this information may be available from already existing Risk Analyses and vulnerability assessments within the organization, and should be used so as to lower costs. To refine the risk scores further, the high criticality risk AISs are reviewed at Level II. Risk scores are obtained for the four remaining dimensions for each high criticality risk AIS. These four dimension risk scores are summed and added to the Level I risk score to yield the system risk score for that AIS. The AISs reviewed at Level II can then again be placed in se- quence from high to lowrisk and thus enable the reviewer or auditunit toprioritize thework. THE NEED FOR THE SCHEME 3.2 3.2,1 ADP Audits/Security Reviews - A Form ofControl Inthepasttenyears there hasbeen a slowlygrowingrecognition ofthe need for controls in the Federal Government's automated systems. Although there often is resistance among programsponsors oruser management to employing internal controls withinAISsbecause of the cost, time, and overhead that such controls can introduce, the interest in and use of con- OMB trolsinAISs iscontinuingto grow.Thisgrowthis augmentedbytheincreasingemphasis has placed on internal controls since the passage ofPL97-255, the Federal Managers' Finan- cial Integrity Act of 1982 [FMFIA82], and the completion and revision of their own Circular 48A-123.The GeneralAccountingOffice (GAO), atCongressionalrequest, hascloselyfollowed the Federal agencies' implementation of A-123, and, thus far, has been dissatisfied with agencies' compliance—especially in the area ofinternal controls in AISs. Audit organizations, whose activities existed well before the computer age, have long recognized and stressed the need for internal controls in manual (primarily financial) systems and the need for independent audits as a critical component of the oversight of an organization's systems. With the advent of computerized AISs, career fields specializing in ADP audit (generally found in audit organizations) and security review (often found in data processing departments or management) have developed. Recognition and revision of their role in the review ofautomated systems is increasing rapidly. 3.2.2 Size ofReview Task A major imphcation of the enormous numbers of computers/systems and our depend- ence onthem, is thatthe universe ofAISs thatneeds reviewing is also enormous. The number ADP oftrained auditors and securityreviewers to do thisjob, however, has not kept pacewith A thatgrowing universe. consistent methodology for obtaining a risk score for anAIS is seen asamajortoolforcullingthroughthereviewworkthatneedstobedoneand assigningrelevant aswell as realisticworkloads to the review staffavailable within an organization. BACKGROUND ON THE METHODOLOGY 3.3 3.3.1 The Invitational Workshop The PCIE Work Group, in the course of its activities, decided that an essential com- ponentoftheirfinalproduct. Guideto AuditingforControlsand Security: A System Develop- ADP ment Life Cycle Approach (this document), was a methodology for prioritizing the auditor's work. Rather than rely exclusively on the experience and background of the Work Group members, it was decided to hold an invitational workshop on the subject and use the ideas generated during the course ofthe workshop to develop a workpriority scheme. 3.3.2 Workshop Points ofAgreement Although eachgroup came upwith asomewhat different setofmajoraudit/securitycon- cerns (dimensions) for the scheme, there was universal agreement on four underlying premises: 491. The entire ADP Audit Plan must first give consideration to non-discretionary audits (mandated by law, regulation, and/or the agency/organization manage- ment). These are reflected in the front-end qualifiers (see Section 3.4.3 for list). ADP Only if there are remaining resources for audit would the scheme be used as originally intended. 2. The risk-basedprioritizing evaluationneeds tobe performed attwo levels, Level I and Level II (ifsufficient resources are available). 3. The firstlevel ofinquiry (foritsLevel I dimension) should concernitselfwiththe criticality of the AIS to the agency/organization mission. Only critical systems shouldbereviewedfurther(foritsLevelIIdimensions)andgivenamoredetailed risk score. 4. The ranking and rating ofthe risk characteristics of each dimension is program and agency/organization specific. Only the risk scoring method is applicable across the board. AWORK PRIORITY SCHEME FOR THEADP AUDITOR 3.4 3.4.1 Assumptions and Caveats The use ofthe proposed work prioritizing scheme is based on certain ideal assumptions and caveats. These include: • An inventoryofall computersystems (AISs)—operational,underdevelopment, orun- dergoing major change— is maintained by the organization, to establish the audit universe. • The above inventory may not be complete due to user development or system chan- ges made outside the system development process. • Touse thepriorityscheme, certainminimal informationis requiredorthe assessment ofthe system may not be valid. • The fullpriorityschemewouldmosteasilybeperformedbyADP auditgroupsinorder to enlist multiple perspectives, especiallywhere resources are known tobe a concern. 14 It shouldbeunderstood that thetermsADP audit andsecurityreviewmaybeusedinterchangeably throughout the scheme. 50• Auditors in the organization must agree that risk qsilbe evaluated by a standardized scheme. • Users should always be consulted in the risk evaluation conducted by the auditor to ensure appropriate assumptions and to assure maximum effectiveness. • Auditorjudgement is still needed! Within this framework of assumptions and caveats the entire ADP audit work plan can then be developed. To the degree these assumptions differ from the reality of the organization's SDLC environment, the work planning methodology should be adjusted. 3.4.2 Audit Planning/Prioritization Process The risk evaluation performed as part ofthe work priority scheme must be done within the context ofthe entire audit planning process. There are elements of the process that need to be considered prior to the risk evaluation (such as non-discretionary audit requirements), and other elements that require consideration afterwards (such as resource constraints). The following sections contain a suggested model for the entire prioritization process. 3.4.3 Non-DiscretionaryAudits As canbe seenfrom the model inFigure 3, the audit planningandprioritizationprocess startswithfront-endqualifiersthatmustbeconsideredbytheauditorpriortomakingdecisions with respect to which system(s) should be audited. These front-end qualifiers consist ofnon- discretionary factors which are beyond the auditor's control. These nondiscretionary factors include, but are not limited to the following: OMB • External directives (e.g., laws, regulations, circulars, and audit standards); • Internaldirectivesandpriorities (e.g.,contractualrequirements; requirements, stand- ards, and policies of audit and data processing organizations; upper management directives); • Business/organizational environment unique to the organization (e.g., effect of economyonorganization,budget oforganization, and technology available to orused by organization); • Organizational unique factors (e.g., presence and strength of quality assurance and security functions, management and control philosophy, structure, and policies); 51Front-End Qualifiers Discretionery Non-Discretionary Audits Audits Risk Evaluation Back-End Audit Qualifiers Implementation Figure 3. Audit Planning-Prioritization Process 52• Geo-political environment (e.g., public concern and politics); • Resource constraints/economic health (e.g., dollars, time, expertise, training, tools, and techniques); • Knownproblemswiththe system,from currentlogs orpreviousevaluationsand audits (e.g., nature and magnitude ofproblems); • Evaluations and audits planned by management; and • Auditor's institutional knowledge oforganization's universe ofsystems. After all ofthe front-end qualifiers have been considered, it may be thatthe entire audit planis dictated by the non-discretionarywork. That is, external directives, internal directives, business environment, unique organization/responsibilities, and/or resource constraints may requirethatcertainauditsbeperformedandtheserequiredauditsmayuseuptheHmitedaudit resources available. In this case, the priority scheme may still be useful for determining audit approaches and where and when to focus efforts. If, on the other hand, additional audit resources are available for discretionary audits, the risk evaluation ofthe workpriority scheme canbe used to identify and rank the systems in greatest need of audit coverage. Ultimately, back-end qualifiers may need to be considered for the discretionary audits, as described in Section 3.5. 3.4.4 RiskEvaluation Levels and Dimensions As stated on pages 45 and 46, the work priority scheme expresses the risk concerns in terms of two levels and five dimensions. The risk concerns in Level I are reviewed first and those inLevelII are reviewed second. Level I has one dimension andLevel II has four dimen- sions. Each dimension is defined as a related set of characteristics which can estimate or measure the amount ofriskposed by that dimension to a failure ofthe system. The chiefcon- cern ofeach dimension canbe stated in the form ofa question as follows: 1. What is the Impact/Criticality ofthe system to the organization? A poorly developed or controlled system that is mission critical could jeopardize an organization's basic operational or programmatic effectiveness; therefore, an impact/critical system commands audit attention. The larger the impact, the more important it is to audit. 2. How Complex is the system? (This includes size considerations.) 53The morecomplex thesystem, the more difficuhis communicationandcontrol, andcon- sequently, the higher the risk of failure. The greater the chance for failure, the more impor- tant it is to audit the system. 3. How Stable is the system internally (structure) and externally (environment)? The less stable the system, the more difficult it is to develop procedures for communica- tion and control, the greater the chance for failure, and the greater the need to audit. 4. How Reliable is the system and the information it processes and generates (i.e., what is the chance ofthe system failing or the data beingwrong)? The answerto this questionis obtainedbylookingat the controls inthe system (integrity controls) and prior audit experience. The less reliable, the more chance for failure and the need to audit. 5. How well is the Technology Integrated into the organization? ; The poorer the system technology is integrated with the skills ofthe staffand the stand- ards and procedures ofthe organization, the more chance forfailure and the greater the need to audit. These questions serve as thebasis for the five dimensions itemized onpage 46, and their associated characteristics developed for the work prioritization scheme. 3.4.5 Two Level Work Priority Dimensions/Characteristics The two level work priority scheme permits a high amount of flexibility since it can be applied in any degree of detail required. For example, the results of Level I ranking may be adequate toprioritize all auditwork, based onavailabletime andresources. Ifadditionalrank- ing characteristics are necessary, the more detailed Level II can be used to further prioritize A auditwork. two level review, additionally, enables the auditor to purge from consideration those systems which will definitely not be reviewed for any number of reasons. Environment and resource issues enter in here. The two level work priority scheme follows in outline form, identifying the five dimen- sions and their related characteristics. [Note: The same characteristic may be used in more than one dimension. The question asked in each will, however, be different.] 543.4.5.1 T^vel T: 3.4.5.1.1 Mission Impact/Strategic Value/Organization (Business) Criticality and Sen sitivity Factors • criticality ofsystem to organization mission • criticality/sensitivityofsystemtowellbeing,safetyorinterestofgeneralpublic/clients /consumers • criticality/sensitivity ofdata and information -competitive advantage -confidence ofpublic in program/department -privacy/confidentiality/security issues • materiality ofresources controlled by system • fraud potential • life cycle costs ofsystem (people and dollars) -development cost budget • people • dollars hardware software facilities -operating cost budget • people dataprocessing/systems (including training) users (including training) • dollars hardware (CPU, peripherals, terminals, telecommunications, etc.) -acquisition -operation software -acquisition -maintenance supplies facilities configuration change control 55• degree ofdependence on AIS • criticality ofinterfaces with other systems and external organizations A Level I review, outHned above, provides a "firstcut" at the total audituniverse.This in- itial review will identify critical systems that require audit coverage. The additional dimen- sions tobe reviewedinLevel IIshouldbe usedtorankthese criticalsystems tofindthose most deserving ofdiscretionary audit coverage. 3.4.5.2 Level IL 3.4.5.2.1 System^^ Size/Scale/Complexity • size ofuser area impacted • number/complexity ofinterfaces/relationships with other projects or systems . :: • complexity ofAIS technology (e.g., network size, communication needs, system con- figuration, degree of centralization, nature of transaction coupling mechanisms, na- ture ofsecurity) • size/complexity ofsystem -size ofsystem budget • development costs • maintenance/operation costs -number/complexity ofdifferent inputs -number/complexity ofunique files -number/complexity ofunique outputs -number/complexity oflogical files (views) systemwill access -number/complexity ofmajor types ofon-line inquiry -number ofsource documents maintained/retained -number/complexity ofcomputer programs -complexity ofprogramming language -complexity ofsystem configuration -number ofhuman elements interfacing the system -number ofdecision levels -number offunctions by devices -number, types, and complexity oftransactions -number ofexternal organizations impacted 15 The term"system" is usedinplace of"project" to signifythe entireAIS lifecycle andthepossibilityof auditingat einypoint inthe development processor operations. 56• nature ofinteractions with external organizations .2.2 System Environment/Stability • organizational breadth (interfaces, dependencies, system configuration) • management involvement/commitment • project management approach and structure -configuration management program -management efficiency and effectiveness • specificity of, agreement on, and support for user requirements • confidence in estimates—both cost and time—premising make-or-buy decisions, ven dor selection, system testing/validation, etc. • number ofvendors/contractors involved • newness offunction/process to user • problems associatedwith current systemperformance and/orsystemdevelopment ef fort • existence/scope ofdata processing standards, policies and procedures, especially sys tems development life cycle methodology and documentation requirements • availability of evidence - document and report preparation and maintenance for en tiresystemslife cycle (e.g., test/validation/certificationresults, operationsmanual, sys tem specifications, audit trails, exception reporting) • quality and completeness ofdocumentation • general controls -physical access controls -environmental controls -communication controls -management controls environment -document controls -system change and test/validation/certification controls 57• on-going concern issues/organizationeffect (will mission objectives be met in a time- ly manner?) -interruption tolerance -ability to maintain performance -unsatisfactory system performance (adverse consequences from degradation or failure) -unsatisfactor>' system development completion -unsatisfactory conversion • labor relations (e.g., salary parity, hours, fringe benefits, etc.) • project team (management and staffeffectiveness and training) • organizational and personnel changes (frequency, magnitude, and number) • functional requirements changes (frequency, number, and magnitude) • technical changes (e.g., frequency, magnitude, and number) • factors affecting cost/economic/budget climate • availability and adequacy ofback-up and recoveryprocedures .2.3 Reliability/Integrity • hazards/risks to information system (data, hardware, communications, facilities) • general controls -environmental (e.g., physical access controls, natural hazards controls) -management • applications controls • availability and adequacy ofaudit trails • quality and quantity ofautomated error detection/correction procedures • availability and adequacy ofback-up and recovery procedures • completeness, currency and accuracy ofdocumentation for audit 58• prior reviews (e.g., A-123, A-i27, A-130, audits-internal, CPA, QA--IRM triennial reviews) • auditorjudgement (intuitively obvious) 3.4.5.2.4 Technology Integration • make-up of project team in relation to technology used (number, training, and ex- perience) • applicability ofthe data processing design methodologies and standards to the tech- nology in use • pioneering aspects (newness of technology and/or technological approaches used in this information system for application and organization) • technical complexity ofinformation system (interrelationships oftasks) • user knowledge ofDP technology • margin for error (i.e., is there reasonable time to make adjustments, corrections or perform analyses before the transaction is completed?) • utilization ofequipment (tolerance for expansion) • availability ofautomated error detection/correction procedures • completeness, currency, and accuracy of documentation for implementation- /maintenance/operation (e.g., operations/maintenance manuals). • amount ofhardcopy evidence RISK SCORING APPLICATION OF THE WORK PRIORITY SCHEME 3.5 -- 3.5.1 Implementation ofthe Scheme ADP For the scheme to be of use to the auditor, an analysis approach for risk scoring must be employed using the dimensions and characteristics. Two possible approaches for ar- riving at asystemrisk score are suggested here and described in Appendix J. The first scoring method is a simple intuitive approach based on a minimal collection of information on the AIS, while the second one is more elaborate and based on more detailed information on the 59AIS. Userexperiencewillundoubtedlyleadtomodificationsandimprovementsinthe applica- tion of the scheme and the risk scoring methods. If the ADP reviewer for some reason does notwishtouse ascoringmethodology, he/she couldstill keep the dimensionsandtheircharac- teristics in mind when performing a less formal review. 3.5.2 A Simple ScoringApproach The simple approach assigns a weight and a risk level to each dimension, based on a qualitative judgement with respect to the characteristics associated with each dimension. Criticality/ Mission Impact is always assigned the highest weight. The product of the weight and risk level of a dimension is the risk score for that dimension. The Criticality/Mission Im- pact risk score is then the Level I system risk score. To obtain the Level II system risk score, the sum ofthe dimension risk scores over the four Level II dimensions is added to the Level I system risk score. (See AppendixJ for details.) 3.5.3 A Detailed ScoringApproach The more detailed approach looks in depth at the characteristics associated with each dimension. Each dimension is defined by a set of characteristics which are used to calculate the amount ofriskposed by that dimension to the failure ofthe system. Each characteristic is givenaweightandarisklevel.Theproductofthesetwonumbers istheriskscoreofthecharac- teristic, andthe sum overthe riskscores ofthe characteristics ofadimensionyieldsthe dimen- sionrisk score. Again, the Criticality/Mission Impactrisk score is theLevel Isystemriskscore. Similarly, to obtain the Level II system risk score, the sum of the dimension risk scores over the four Level II dimensions is added to the Level I system risk score. (See Appendix J for details.) 3.5.4 Discretionary Audits After the systems have been identified and ranked, using the risk based evaluation, several back-end qualifiers must be considered by the auditor in determining how many dis- cretionaryaudits canbe added to the auditplan (See Figure 3). These back-end qualifiers can be categorized in two areas: - Audit Types and Objectives - Audit Resource Constraints Figure 4 identifies thf different audit methodologies that can be used and the different audit objectivesthat canbe accomplished inperformingADP audits.The auditormust considerthe auditmethodologyto be performed and the audit objective to be accomplished indecidingon 60' c E o O o c E c O <1> c ><D L1 J1 U= LU ^ LU CO 2~^ E o <^ L>ll <i> Io- o LU > o —> <i> 1o11 CD z O o o O < i2. LU u O < 00 ^ Q- c: x: H o <i> o =3 Q E = D = o < CO CO i3 CO CO ^ ll-J <1> o ^ o> >o c: o E V) 'j—l <1> CO i3 CO LJJ O > Q2 l 00 E 0>^•C'-^ to C CoO O Q<1> a u> If E <^ i; aC m> 0^) o o o £ O J C>1— O0 ^.<1> O1O C5 L1 QCO— .O/ ^ ^ HO QC3 C CO O -O O > < Q . . 61thenumber ofadditional (i.e., discretionary) audits that canbeperfomed. Furthermore, these issues mustbe considered inHght ofthe audit resource constraints (e.g., people, time, dollars, expertise) that exist. For example, to perform a system under development audit which looks at security, confidentiality, and privacy issues requires substantially more resources than an operational system audit which looks at only data reliability issues. Thus, the mix of audit methodologiestobeperformed,andtheexistingauditresourceconstraintsmustbeconsidered whendecidingonthe numberofdiscretionaryaudits that canbe added tothe auditplan. After theseback-endqualifiershavebeenconsidered,theauditplancanthenbefinalized,andaudits conducted. USES OF THEWORK PRIORITY SCHEME 3.6 Theriskscores developed duringthe risk-basedevaluationcanbeusedforbothdevelop- mentalandoperationalsystems.Themajordifferencebetweenrisk-basedevaluations ofthese twoclassesofsystemsisthat(1)therankingofcharacteristicsmaychange,and (2) somecharac- teristics may not be applicable to both. The following is abriefenumeration ofsome possible uses ofthe Work Priority Scheme. A 1) To determine relative risk between applications - risk score of one application is compared to scores developed for other applications in the same department.Thus, riskscor- ing is used to determine relative risk among applications. The score is not used to determine an absolute measure ofrisk. 2) To create an audit risk profile - An audit risk profile is a pictorial representation of the various risk characteristics measured. While the audit risk score shows audit risk for the entireAIS,the riskprofile showsthe relationalriskamong thevarious risk characteristics.The objective of the risk profile is to graphically illustrate what characteristics contribute to the total risk, and inwhat proportion. 3) To modify the characteristics contributing to audit risk - Both the auditor and data processing management can use the audit risk scheme to identify those characteristics which may cause the information system to be less successful thanproposed. For example, ifthe ap- plicationprojectpersonnel do notunderstand the computer technologybeingused, the prob- ability of success of the information system being developed diminishes. Once the characteristics that may cause the system to be less successful than desired are known, those characteristics can be altered such that the probability ofsystem success increases. 4) To help allocate audit resources - The information gathered during the audit risk analysis can be used as a basis for allocating audit resources to review application systems and/or review specific aspects of those systems. For example, high-risk information systems may receive extensive reviews, medium-risk cursory reviews, and low-risk no reviews. For 62those systems reviewed, the area ofreview can be selected based on the high-risk characteris- tics. For example, ifcomputer technology is a high-risk characteristic, the auditors may want to expend time reviewing how effectively the project team is using that technology. 5) To develop a data base of risk characteristics - The information gathered during this process should be saved and used for two purposes. The first use is to improve the audit risk prioritization scheme to make it more predictive ofaudit risk; the second use is to assist data processingmanagementin structuringandplanningprojects such thatthose projectswill have the highest probability ofsuccess. PROBLEMS WITH AND SOLUTIONS TO USE OF SCHEME 3.7 Potentialdifficultiesinusingtheworkpriorityschemeandmethodsforovercomingthese difficultieswere discussed by the PCIE Work Group participants in order to facilitate the use ofthe scheme. These follow in outline form. 3.7.1 Potential DifTiculties in Utilization • Time and resources are needed for sufficient data collection. • Organization data processing planning is often inadequate. • There is a need to establish an understanding of and agreement on related issues on a consistent basis by all affected parties (auditors/systems developers/users/etc). • There is a need to convince affected management (audit and operations) as to the credibilityofthe scheme and its impact on audit coverage, given a finite level ofaudit resources. • Initial time and resources are needed to adapt the work priority scheme to the or- ganization. • Therankingrepresentsasnapshotatagivenpointintimewhichrequiresmaintenance and updating to ensure its continued validity. • Audit planning needs to be separate from and sensitive to data processing and busi- ness cycle planning processes. • Integrated skill knowledge is required that includes relevant expertise in pertinent speciaHty areas. 63• Work priority scheme is just another tool for audit management to consider in its decision-making process. ADP • audit resources are still likely to be insufficient to provide coverage suggested by the scheme. • An up-to-date and complete inventory ofAISs is required—all thosewhichare opera- tional, developmental, and undergoing change. ,7.2 Methods for Overcoming Difficulties • Make the underlying questionnaire and datagathering methods as simple aspossible for administering it. • Refine data collection methods through experience and learning curve. • Educate users (including DP community) regarding needs for standards, planning, etc.. DP • Audit recommendations should emphasize necessary improvements to and busi- ness executives. • Encourage early participation and collective editing to reach consensus on data col- lection instrument. • Apply scheme retroactively to existing systems to demonstrate the risks that audit coverage would have addressed. • Emphasize that initial commitment would have long-term benefits and that, once es- tablished, maintenance would be considerably less costly. • Analyze dynamics ofthe organizationand the audit componentwithinitto determine the frequency ofthe "snapshot". Workload mixand control attributes maybe affected accordingly. • Develop a means for staying atuned to planning cycles. ADP • Consider supplementing audit resources with financial and generalist auditors for areas not requiring specific technical expertise. They may even be more relevant for business and institutional knowledge. 64• ADP audit resources maybe supplemented with consultants forareas requiring high- ly skilled data processing knowledge. NEXT STEPS 3.8 Recognizing both the significant benefits and limitations that accompany the work prioritization scheme discussed above, what then should the ADP auditor expect to do next? 3.8.1 The Audit Organization The NBS/PCIE workshop attendees came up with a number of recommendations for ADP A furtheractivityby Audit/ComputerSecurityOrganizations. briefenumerationofthese follows. 1) The work priority scheme described here should be tested within organizations by apply- ADP ingit to the planning considerations ofaprioryear'sworkload universe.This might help ascertain how ADP audit resources may have been allocated differently and whether that al- location may have better assisted management in identifying and overcoming resultant con- trol deficiencies in the systems. 2) Feedback should be captured on institutional knowledge of why and how systems have ADP failed so that one could determine whether the draft scheme would have targeted audit resources on the most vulnerable systems. A 3) prototype needs to be developed which would include a survey questionnaire, a weight- ing and scoring system, a testing process, a methodology for evaluating results and modifying theprototype, a method for the selectionoftesting sites, and a method ofquantifying qualita- tive issues that would facilitate a comprehensive cost-benefit evaluation of the work priority scheme. 3.8.2 TheADP Auditor Hopefully, theADP auditorwillhavethe opportunity toprioritize his orherworkbefore jumping in. Whether or not the formal scheme and ranking methodology is used, however, considerationofthe dimensions andtheir associated characteristics is stronglyrecommended. That review will, at the least, enable the auditor to place emphasis on those areas most vul- nerable and in need ofattention. Thenext chapterprovides detailed auditprogramsfor eachphase ofthe systemdevelop- ment life cycle (SDLC) described in Chapter2. Dependingon the results ofthe prioritization process, the auditor might choose to emphasize one phase over another or select aspects of 65each phase. The programs presented are for large critical systems that will undoubtedly re- quire a comprehensive review. The programs can be adapted and shortened, however, for smaller sensitive systems. 66CHAPTER 4 AIS DEVELOPMENTALAUDITS SDLC CONTROL OBJECTIVES AND AUDIT CONCERNS 4.1 4,1.1 Control Objectives Computer dataprocessing should produce accurate, complete, and authorized informa- tionwhich is supportable and timely. In a computerized environment, this is accomplished by a combination of controls in the computer application, and controls in the environment in which the computer application operates. Controls are divided into general and application controls. General controls can be fur- ther divided into management and environmental controls. Management controls deal with organizations, policies, procedures, and planning. Environmental controls are the operation- al controls primarily administered through the computer center/computer operations group. As computerized systems become more sophisticated, there is a general shift from ap- plicationcontrolstogeneral controls.Thisshiftis duetothefactthatsome ofthe controlfunc- ADP tionsperformedbythe applicationare shifted to the environment. For example, the edit andvalidation dataprocedures may move from the application to the environmentwhen data base concepts are used. Although the adequacy of controls over the computerized environ- ment is growing in importance, the organization still cannot ignore the application controls areabecause there will always be important application controls. Thisauditguideconcentratesonapplicationcontrols.These controlsneedtobereviewed for each application, while general controls should be reviewed initially but not on every ap- plication. However, even general controls require periodic review as technology, personnel, or policies change. The GAO "Black Book" [GAOS 1-3] provides a control assessment for evaluating general and application controls in an operational computer-based environment. This auditguide specifically addressesthe process ofdesigning applicationcontrols into a new or modified system and evaluating the entire development process. To assist in this control evaluation, the control objectives can be divided into six categories.^^ These categories are: 1. Legal Requirements 2. Management Policies 3. Internal Controls 4. Audit Trails GAO 16 These controlobjectives come from the "YellowBook" [GA081-1]. Section4.1.2istakenalmost verbatimfrom that document. 67Documentation 5. 6, Economy and Efficiency 4.1.2 Auditors' Control Concerns The following material discusses the above six control objectives and the auditor con- cerns that they generate. 4.1.2.1 Legal Requirements -Toprovide reasonable assurancethat systems/applications conformwith legal requirements. Legal requirements applicable to systems and applications may originate from various sources. One such requirement is compliance with State and Federal privacy statutes, which restrictcollectionanduse ofcertaintypesofinformationaboutindividuals. Safeguards are ob- viously necessary in such systems. Conversely, organizations subject to the Freedom ofInfor- mation Act should have systems/apphcations designed so that appropriate and timely responses can be made to legitimate requests. The applicability of the Federal Information Processing Standards program [required by the Brooks Act [BRA65]] to the system involved should also be considered by the auditor. If such standards apply, they should be included in the auditor's review. Once again, auditor review of the design and development processes can help assure management that these requirements have been considered and satisfied. 4.L2.2 Management Policies - To provide reasonable assurance that systems/applica- tions carry out the policies management has prescribed for them. Pohciesonwhat isexpectedofautomatedsystems shouldbe establishedbymanagement, and the auditor should determine whether they are being adhered to in design. The auditor should ascertainwhether an appropriate approval process isbeing followed, both in develop- ing new systems and in modifying existing systems. The auditor should consider the need for approval of a system's design by data processing management, user groups, or other groups whose data and reports may be affected. Also, the auditor should review the provisions for security required by management, to protect data and programs against unauthorized access and modification. Ifmanagement's requirements are not being met, or have not been clearly articulated, the auditor must report such shortcomings to officials who can take corrective action. Fre- quently, in the past, efforts to make new systems/applications operational by scheduled dates have resulted in some elements or controls that were desired by management being set aside by designers for later consideration. Auditors, in retaining their independence during the design and developmentprocesses, should report such actions to top management for resolu- tion. 684.1.2.3 Internal Controls - To provide reasonable assurance to management that sys- tems/applications include the controls necessary to protect against loss or serious error. Thesystemdesign and developmentprocesses include: (1) definingthe processing tobe done by a computer; (2) designing the processing steps; (3) determining the data input and filesthatwillbe required; and (4) specifyingeach individualprogram's inputdata and output. Each area must be properly controlled, consistent with good management practices. The auditor's review ofthese matters is designed to provide reasonable assurance to management thatthesystems/applications,onceplacedinoperation,willbeprotectedagainstlossorserious error. Properlydesigned systems, with excellent control mechanisms built in, might have these controls bypassed or overridden by management direction. This has occurred in systems im- mediatelyafter theywere implemented andput into operation. Many times the designers and developers override such controls toget the system operationaland thenforgetto activate the controls after the system errors have been corrected. Almosteverysystemhas manual aspects (e.g., input origination, output disposition), and these, togetherwith the electronic data processing controls, are consideredwhen the auditor is reviewing system controls for adequacy. 4.1.2.4 AuditTrails -To provide reasonable assurance that systems/applicationsprovide the controls and audit trails needed for management, auditor, and operational review. Infinancialapplications, atransactionmustbe capable ofbeingtracedfrom itsinitiation, through all the intermediate processing steps, to the resulting financial statements. Similarly, information in the financial statements must be traceable to its origin. Such capability is referred to by various terms (e.g., audit trail, management trail, transaction trail) and is also essential innon-financial systems or applications. The reliability ofthe output can be proper- ly assessed when the transaction processing flow can be traced and the controls over it, both manual and automated, can be evaluated. During the design and development process, the auditor may recommend, through for- mal correspondence, audit trails or other controls to the design/development team. By doing so through formal correspondence, the auditorwill remain independent. Audit of the systems design and development processes can help assure management that this capability is in fact being built into the systems/applications. 4.1.2.5 Documentation - To provide reasonable assurance that systems/applications are documented in a manner that will provide the understanding ofthe system required for ap- propriate maintenance and auditing. 69The auditor should determine whether the design, development, and modification pro- cedures produce documentation sufficient to define: (1) the processing that must be done by programs in the system; (2) the data files to be processed: (3) the reports to be prepared: (4) the instructions to be used by computer operators; and (5) the instructions to user groups for preparationandcontrolofdata.Theauditorshouldalsoascertainwhethermanagementpolicy providesfor evaluation ofdocumentationand adequate testingofthe systembefore itis made operational These steps are taken to ensure that the system and its controls canbe relied on. 4.1.2.6 Economy and Efficiency -Toprovide reasonable assurance that systems/applica- tions will be efficient and economical in operation. Determiningwhether an organization is managing and using its resources (e.g., person- nel, property, space) efficiently and economically, and reporting on the causes of inefficien- cies or uneconomical practices, including inadequacies in management information systems, administrative procedures, or organizational structures, is considered here as a basic charac- teristic ofgovernment program audits. With the development ofcomplex systems or applica- tions, the auditor'sreviewshould also focusonwhetherthe systemhas beendevelopedinsuch a way that operations will produce desired results at minimum cost. For example, early in a system's development, the auditor should review the adequacy of the: (1) statement of mis- sion needs and system objectives; (2) Feasibility Study and evaluation of alternative designs to meet those needs and objectives; and (3) Cost/Benefit Analysis which attributes specific benefits and costs to system alternatives. APPROACH FOR SYSTEMS UNDER DEVELOPMENT 4.2 4.2.1 Introduction The mid-level ADP auditorispresumed to fullyunderstand thebasic SDLC process and SDLC to have a basic familiarity with the specific process utilized within the organization ADP under review. With this familiarity the auditor only needs to survey the organization's current SDLC process to ensure a complete and accurate understanding of the currently ex- istent procedures and responsibilities. The survey should be structured around the AIS Life Cycle Matrix (see Chapter 2) and may involve a "prehminary review ofthe SDLC methodol- ogy" (see Section4.2.2). Additionally, an audit survey foreach SDLCphase is incorporated in Sections 4.3 through 4.7 for consideration in developing the scope of review throughout the SDLC process. The survey scope is impactedby the effectiveness ofthe organization's quality assurance function aswell as itsutilization ofappropriate technologies, and its methodologies for software development and system installation. These impacts on the surveyscope are fur- ther discussed in Section 4.2.3. The rest of this chapter is designed primarily to assist the mid-level ADP auditor in designing and conducting audits ofthe development ofAISs that are in process. The chapter 70is divided into the SDLC phases as reflected in the AIS Life Cycle Matrix described in Chap- ter 2. It prescribes audit coverage for consideration throughout the AIS development cycle. The audit approach and considerations for each phase, however, are presented as separate modules foruse in reviewduring the AIS developmental phase, or at the completion ofapar- ticular phase. Each module within the rest of this chapter is presented in a parallel manner for a con- sistent and comprehensive description ofpotential audit coverage for each AIS developmen- tal phase. The modules each contain the following segments: 1. Audit participation - Briefintroduction ofthe phase and relevant audit involve- ment. 2. Primary audit objectives - Overall purpose for audit coverage during phase. 3. Overview - Description ofthe phase and its AIS life cycle matrix responsibilities and deliverables. 4. Audit survey - Initial background analysis and pertinent survey technique(s). 5. Customized audit objectives - AIS phase developments impacting scope of sub- sequent audit coverage. 6. Detailed audit testing - Specific audit objectives, tests, and techniques. 7. Assessment ofaudit results - Analyses for developing and reporting phase audit test results and planning future AIS audit coverage. 8. Questionnaires/Matrices - Tools for soliciting and assimilating pertinent phase information. 4.2.2 Preliminary Review ofthe SDLC Methodology^^ The SDLCmethodology described inthis auditguide is a conceptualmethodology. Itin- corporates good practices from many different methodologies into one approach. From an auditperspective, it defines the type ofdocumentationneeded to ensure the auditabilityofan AIS. Auditors involved in system development reviews should not expect to find the system developedprecisely according to the methodology described in this audit guide. The auditors shouldexpectthatthemethodologyusedbytheorganizationencompassesthebestparts/docu- ments ofthe methodology described herein. Ifthe development methodology is deficient, the auditor should recommend improvements inthat methodologyalong the lines ofthat defined in this audit guide. 17 ThissectionisbasedonworkdonebytheInternalAuditSteeringCommittee organized and chairedby Coopersand Lybrand, NewYork. Thematerial found here hasbeen incorporatedintheIIA pubhshed document"SystemDevelopmentAuditReviewGuide" [C&L86] thatresultedfromthis committee's efforts. 71The auditor has two tasks to performin reviewing the SDLC methodologybeingused to developthe systemthe auditor is reviewing. First, the auditormustmake apreliminaryreview ofthe system development methodology (SDM) for its adequacy in providing the discipline and control over the AIS development as prescribed in this guide. Second, the auditor must compare the SDLC being used for the AIS under review with this guide's methodology, for coverage ofits provisions and the adequacy ofthe control over the AIS development. 4.2.2.1 Reviewthe SDLCMethodologytoheUsedin Developingthe AISUnderReview - The following represents an audit program to review the organization-specific SDM. This program should be used for the following two purposes: 1. Priortoperforminganydevelopmentreview, the auditorshouldbecomefamiliar with the organization's SDM. The objective is to familiarize the auditorwith the processes that will be followed and documents produced, as the system is being developed. 2. Priortoeachdevelopmentphasereview,theauditorshouldreviewthemethodol- SDM ogy applicable to that phase. This review will help reconcile the used for the AIS under review, with the review program and documents described in this audit guide. The steps that the auditor needs to take to perform a preliminary SDM review ofa either the entire methodology or the methodology for a single phase ofthe development cycle, are: SDM 1) Obtain a copy of the used by the organization to develop and ' - monitor the development ofnewapplications orsystems. By interviewing agencypersonnel, determinewhetherrequirements are mandatoryor ad- visory in nature. 2) Determinewhether anyprior evaluations have beenperformed onthe methodology and review them for background information. 3)Throughobservation,interview,andreviewofavailableevidencedeter- mine whether: (a) The methodologyas documented isup todate, and applications or systems are being developed in compliance with it. (b) There are any known problems with the methodology as it exists. (c) Deviations from the formal methodology are permitted. 724) By reviewing documentation and interviewing key agency personnel, SDM evaluate the effectiveness ofthe as follows: (a) Is it formally structured into phases, each yielding a measurable end product? (b) Do identifiable closure points exist for each designated phase that require the completion offormalized documentation? 5) Is emphasis placed on the incorporation of security and internal con- trols (includingaudit and qualityassurance toolsandtechniques) into sys- temsbeingdeveloped, ensuringthattheyareconsistentwithmanagement objectives? 6) Are planning requirements for each subsequent phase clearly iden- tified? 7) Does the methodology allow for controlling changes in requirements over the life ofthe project? 8) Has anADP steeringcommittee been established to reviewthe system development process, assign priorities to projects, and resolve problems as they arise? Does it include senior departmental officials? SDM 9)Does the formallyrecognizeparticipationofthefollowinggroups or personnel in the development process: (a) Sponsor/User, (b) Project Manager, (c) Data Processing, (d) Quality Assurance, (e) System Security/Internal Control, and (f) Audit? 10) Have responsibilities for theparticipant groups in (9) abovebeenfor- mally established for each designated phase? 11) Arethe roles and responsibilities ofthe members ofthe data process- ingproject team orits equivalent clearlydefined (e.g., system analyst, sys- tem designer, programmer, data analyst, data base administrator)? 7312)To ensurethat theneeds ofusers and theorganization are metat each phase, does the methodology provide sufficient opportunities for com- munication between users and system developers? Do 13) well-defined written standards exist to facihtate adequate documentation? 14) Are the requirements for user, program, system and operations documentation for each phase adequate and clearly identified? 15) Do well-definedwritten standards exist for programming? 16) Has the methodology incorporated considerations for: (a) database environments, (b) telecommunications, (c) networking, (d) distributed processing, (e) end user programming (fourth generation), (f) prototyping, and packaged software selection and implementation? (g) 17) Are Project Managers authorized to make decisions on personnel, resources, scheduling, costs, budgets, and most technicalprojectmatters? 18) Are Project Managers sufficiently supported by top management to accomplish the system development project? 4.2.2.2 Compare O rganization's SDLC Methodology to Audit Guide SDLC Methodol- ogy - Once the auditor has reviewed and understood the SDLC methodology being used for the AIS under review, that methodology should be compared to the methodology described in this audit guide. This step involves the following tasks: 1. Compare the documents described in this audit guide to the documents in the SDLC methodology used for developing the AIS under review. The documents mayhave a different name, or they may be consolidated intofewer documents or split apart into more documents. The task involves determining if comparable documented information is contained in both methodologies. 742. IdentifydeficienciesintheSDLCmethodologyused indevelopingthe AIS under review. This Hst can include either documents, or attributes ofdocuments which are missing from the methodology. 3. Determine the audit importance of missing documents or document attributes. The auditor needs to determine whether the lack of those documents will have any significant impact on the AIS. This determination can be made by reading Sections 4.3 to 4.7 about the use and review of the information in those docu- ments. 4. If the missing documents or document attributes are significant, the auditor should recommend that the methodologybe corrected, particularlyfor this AIS, to provide that missing information. 4J23 AIS Development Impact on Audit Scope As reflected in Section 4.2.1, the mid-level ADP auditor's scope of audit coverage will beimpactedbytheorganization'sSDLC processaswell asthe characteristics oftheindividual AIS under development. During the preliminary review of the SDLC methodology and the specificAIS audit survey, the auditorswillbe identifying and assessingthevarious impacts on their audit scope, and correspondingly aligning the necessary resources and expertise to ex- ecute the appropriate audit coverage. The AIS impacts on or implications for the audit's scope may relate to the effectiveness ofcontrolswithinthe organization'sSDLCmethodologyorto the capabilitiesofthe organiza- tion to effectively incorporate available technologies and SDLC disciplines. For example, an effectively controlled SDLC methodology instituted in an organization, as evidenced by pre- vious AIS development audit coverage orthrough a preliminary SDLC review, may allow the auditors to confine their scope to a survey ofthe effective application ofthis methodology to the specificAISunder review. Furthermore, while the auditors are absolutely independent of thoseresponsiblefortheSDLC process, theauditors'scopecouldalsobecurtailedafterverify- ing the effectiveness ofquality assurance activity during the AIS development. Unfortunate- ly, a quality assurance function is a control within a SDLC process which has been formally ADP institutedinonlyafeworganizations. Itisdifferentiatedfrom auditwhichindependently assesses the whole SDLC process, including the quality assurance function's effectiveness. Other SDLC methodology implications could compel the auditors to expand their planned audit coverage or to supplement their assigned audit resources with specific exper- tise. Where historical audit coverage has evidenced SDLC controlweaknesses in a phase, ex- panded audit coverage may be needed. Examples of such weaknesses may include: a) 75introduction ofnew technologies without commensurate in-house expertise; b) utilization of system testing methods without adequately protecting the security or integrity of data; c) software development through purchased off-the-shelf applications without providing for necessary interfaces or customizing; and d) procurement of system design and development without adequate evaluation criteria or expertise to effectively oversee contractedwork. These and other AIS development implications should be evaluated for their potential impact on the AIS as well as their impact on the audit scope and corresponding audit resour- ces.The auditsun^eyshouldresultinauditobjectives customizedtoreflect these implications. Their impacts should also be reflected in the detailed audit tests and again considered when assessing audit results. Should the auditors be unable to properly complement their resources with the neces- sary expertise or should other constraints be placed on the audit coverage, the AIS develop- ment review report should be qualified accordingly. 4.2.4 The Effect ofa Quality Assurance (QA) Function on the ADP Auditor's Role in SDLC the QA The labels, definitions, and substance of canvary substantially among organizations. One or more ofthe following might applyto the organization's concept ofQA: designreview, independent testing, peer review, requirements review, walk-throughs, product assurance, standards compliance enforcement, code review, and data integrity review. QA The definition for purposes ofthis audit guide is: Any mechanism used by manage- ment which provides assurance that a quality product (requirements, design, code, etc.) is being developed. Ifmanagement has an effective QA function in one area, the ADP auditor can concentrate efforts on other more vulnerable areas. Unfortunately, the mechanism management has in place may be perfunctory and only give the illusion of quality, e.g., peer review might be a pro forma paper exercise with little analytical criticism and no corrective QA action. To determine the effectiveness of and its effect on audit activities, several steps should be taken at the start ofthe SDLC or during a phase. QA 1. Determine what mechanisms are in place. The question to be directed to : management is "How are you assured that products have quality (i.e., other than personal assurances from systems personnel)?" QA 2. Evaluate mechanisms (i.e., what physical evidence is there that the mechanisms actually work?). The evidence can be in the form of reports to management, documentation ofreviews or a prior audit ofthe process. 76QA 3. Modifyauditplanswhere is effective (e.g., ifit canbe established that stand- ards are effectivelyenforced, the auditormay not need to reviewthe adequacyof documentation). 4. On the other hand, if significant problems are identified with the QA function, the auditor should recommend strengthening the function, particularly for this AIS, to provide the needed oversight function. 43 AUDIT PARTICIPATION DURING THE INITIATION PHASE PHASE - I During the Initiation Phase, the need for a computerized solution to a problem is iden- tified and validated. Alternate methods for satisfying the need are explored and a functional recommendation is developed. The recommendation is presented to management, and ifap- proved the AIS project continues through the remaining phases ofsystems development. The primary audit objective duringthis phase is to ensure that the system need is estab- lishedand thatthe cost forsatisfyingthatneed isjustified.The auditorwill performthe review of the Initiation Phase by examining the documents produced during that phase, and inter- viewing the Initiation Phase participants and other involved parties. The result of the audit review of this phase becomes an input to management in determining whether or not to ap- prove the Initiation Phase recommendation. 43.1 PrimaryAudit Objective ofthe Initiation Phase The primary objective ofreviewing the Initiation Phase is to: "Ensure that the system need is established and that the cost to satisfy that need isjustified." The achievement ofthat audit objectivewill require the auditor to review the documentation produced during the Initiation Phase. The documentation is reviewed for two reasons: first, to ensure that the documentation is complete and in compliance with the organization's In- itiation Phase; and second, to ensure the accuracy and completeness of the established need and the reasonableness ofthe cost-justification for accomplishing that need. 43.2 Overview ofthe Initiation Phase ConsistentwiththeFIPSPUB 64"ProjectRequestDocument" [FIPS64] andDOD "Mis- sion Analysis" and "Concept Development" Phases [DOD78-2], the Initiation Phase begins withthe recognitionofaproblemand the identificationofaneed. Duringthisphase, the need isvalidated, andtheexplorationofalternativefunctionalconcepts to satisfythe need is recom- mended and approved. The decision to pursue a solution must be based upon a clear under- 77standingoftheproblem, apreliminaryinvestigationofalternative solutions, andacomparison ofthe expected benefitsversus costs (including design, construction, operation, andpotential risks) of the solution. At this stage the risk/sensitivity of the data or information in the AIS should be evaluated. During the Initiation Phase it is immaterial whether the solution will be in-house- developedsoftware, contracted software, or off-the-shelfsoftware.The objective ofthisphase is to lookat alternate functional solutions to the userneed. No particularchange to the SDLC methodology for this phase is needed regardless ofwhich ofthe three potential implementa- tion methods are selected later in the developmental process. Likewise, the audit approach remains unchanged during this phase,whether or not the systemis developed in-house or ob- tained through contracting or purchase. 4.3.2.1 Participants and TheirTasks -Listedbelowaretheresponsibleparticipantsinthe Initiation Phase with a brief description of their role during the phase, including the role of the auditor: L System Security Officer(SSO)/Internal Control Officer(ICO) - Oversees or con- ducts Risk Analysis; helps evaluate system sensitivity. 2. Auditor - Reviews/evaluates Needs Statement, FeasibiHty Study, Risk Analysis, and Cost/Benefit Analysis; based upon review determines scope offuture invol- vement. 3. SponsorAJser - Identifies and validates need; develops Needs Statement; directs Feasibility Study, Risk Analysis, and Cost/Benefit Analysis; selects a Project Manager. Ifallorpart ofthe SDLC effortwillbe contracted, the Sponsor/Userincoordina- tionwiththe Project Manager, incorporates apreliminaryassessmentoftheneed for contractor services in the Feasibility Study, Risk Analysis, and Cost/Benefit Analysis, where possible and as appropriate. (Minimally, the acquisition ofcon- tractor services canrequire a long lead time; therefore, the impacton theproject schedule must be recognized and identified.) 4. Project Manager/Contracting Officer's Technical Representative (COTR) - If appropriate, awards contract and assures contract compliance. The Project Manager/Contracting Officer's Technical Representative (COTR) supports the Sponsor/User in project initiation and the assessment ofgovernment personnel and contractor resource needs. 785. System Security Specialist(SSS)/Internal Control Specialist(ICS) - Provides con- sultations as appropriate. 6. Contracting Officer - Ifappropriate, awards contract. 7. Contract Auditor - Ifappropriate, assures contract compliance. 8. ADP Manager - Provides technical consultation as appropriate. 9. Quality Assurance (OA) Specialist - Provides consultation on quality attributes ofNeeds Statement. 4.3.2.2 System Initiation Phase Documents -The InitiationPhase auditwill focus on the documents produced during this phase. While the actual documents produced will vary from agency to agency dependingupontheir system development methodology, the more common documents produced during the Initiation Phase are: 1. Needs Statement (FIPS PUB 64, DOD 7920.2, FIMR 201-30.007) - A Needs Statementshouldbeprepared to describe inwrittenform deficiencies inexisting capabilities, new or changed program requirements, or opportunities for in- creased economy and efficiency. It should justify the exploration of alternative solutions. 2. Feasibility Study (FIPS PUB 64, FIRMR 201-30.007) - The purpose of the FeasibilityStudyis toprovide: (1) ananalysisofthe objectives, requirementsand system concepts; (2) an evaluation of alternative approaches for reasonably achieving the objectives; and (3) identification ofa proposed approach. 3. Risk Analysis (FIPS PUB 65 and 102, OMB A-130) The purpose of the Risk Analysis is to identify internal control and security vulnerabilities of an AIS, determine the nature and magnitude ofassociated threats to data and assets, and provide managers, designers, systems security specialists and auditors with recommendedsafeguards tobe includedduringthe design, development, andin- stallation/operationphases ofa new or modified AIS. 4. Cost/Benefit Analysis (FIPS PUB 64, OMB A-130, OMB A-123, FIRMR 201- 30.007) - The purpose of the Cost/Benefit Analysis document is to provide managers, users, designers, systems security specialists and auditors with ade- quate cost and benefit information, including the impact ofsecurity, privacy and internal control requirements on that information, to analyze and evaluate alter- native approaches to meeting mission deficiencies. 795. System Decision Paper (FIPS PUB 64, DOD 7920.2, OMB A-130, OMB A-123) - The System Decision Paper (SDP) provides the information and framework critical to the departmental and operating divisions' decision-making process during the development ofan AIS. 433 Audit Survey In preparing for the Initiation Phase review, the auditor needs to understand the work flow, gatherthe necessarydocumentation, and interviewthe responsibleparticipants. Mostof this background analysis can be done within the team established to implement the project. Thetasks thatneed tobe completed duringthe audit survey are to: (1) studythe environment inwhich the project will be initiated; (2) review Initiation Phase plans; (3) gather informa- tion on the Initiation Phase status; and (4) verify information on the Initiation Phase status. The four tasks are discussed individually below. 4.3.3.1 Study the Initiation Phase Environment - Prior to conducting the review of the Initiation Phase, the auditor should: 1. Become familiar with the developing organization's system development life cycle (SDLC) methodologywith particular emphasis on the methodology in the Initiation Phase. Specific review tasks should include: (a) DeterminewhetheranypriorevaluationsofthisSDLCmethodologyhave been made, and ifso how its effectiveness was evaluated. (b) Determine ifthe development team understands and supports the SDLC methodology. (c) Byinquiry and review ofdocumentation, evaluate the effectiveness ofthe SDLC methodology. (d) Compare the SDLC methodology to that defined in this audit guide and notedifferences,particularlywhereproblemsmightoccurduetodevelop- ment deficiencies. (e) Identify the documents produced by the SDLC methodology. (f) Determine through interview whether the project team has been ade- quately trained in the use ofthe SDLC methodology. 2. Become familiar with the organization's cost-justification process. 803, Become familiar with the appropriate regulations/poHcies relating to the area being considered for automation. 4.3.3.2 Review Initiation Phase Plans - The auditor should become familiar with the problem that has been recognized and the need to be satisfied. The plan to initiate the AIS shouldbe reviewed to ensure that itwill result in the type ofdocuments described in this sub- section. The auditor should also inquire about Initiation Phase participants to ensure that the participants identified in this subsection will in fact participate in the Initiation Phase. 4.3.3.3 Gather Information on the Initiation Phase Status - The auditor should obtain and review the following Initiation Phase documents: Needs Statement 1. 2. Feasibility Study 3. Risk Analysis 4. Cost/Benefit Analysis 5. System Decision Paper The auditor needs to determine status information in three areas. First is the status of the above five documents, i.e, whether theyhave beenprepared, and ifso, whether in accord- ancewiththe SDLCmethodology. Second isthe status oftheproject, i.e.,whether itisontime, andwhether the needed tasks have been completed, and ifnot, when their completion is ex- pected. Third, the auditor should identify any changes in the identified problem or need, and validate that those changes have been properly incorporated into the documents developed during this phase. 4.3.3.4 Verify Information on Initiation Phase Status - In fulfiUing this task, the auditor should review the documents produced during the Initiation Phase, and interview key par- ticipants about their role in the preparation ofthose documents. 4.3.3.4.1 Review Documents - The Initiation Phase produces five major documents. An AISprojectbeginswitha Needs Statement.This statement eitherincludes, orissupported by, a needs validation andjustification statement. The Sponsor/User of the system must in some manner be able to justify undertaking the AIS Initiation Phase. In previous system develop- ment audits it has been frequently noted that valid alternatives have not been considered during the Initiation Phase. Therefore, the auditor should be particularly sensitive to ensure that this has occurred for the system under review. 81TheNeeds StatementbecomesthebasisforaFeasibihtyStudyand aRiskAnalysisstudy. The objective ofthese parts ofthe Initiation Phase is to identify aproposed approach and the vulnerabihties associated with that approach. The RiskAnalysis provides additional input to supplement the Needs Statement so that a Cost/Benefit Analysis can be prepared. This document, in conjunction with the Feasibility Study document, provides the necessary information for management to make a decision to uiitiate or continue the development, or to take other appropriate actions. The actions of management will be included within a System Decision Paper. This becomes the principle document containing the essential information about the AIS. It becomes a basis for the sys- tem Definition Phase. Note that different SDLC methodologies may produce slightly different documents. In some organizations, the informationdefinedwithin these five documentsmaybe consolidated into fewer documents, or expanded into a greater number of documents. What is important fromanauditperspectiveisthattheinformationincludedinthesefivedocuments isdeveloped during the Initiation Phase. The documents to be completed during the Initiation Phase will be specified by the agency's SDLC methodology. The auditor, having gained a famiharitywith that methodology during the background step, can determine that all of the appropriate documents have been prepared.The auditorshouldensure the appropriate accumulationofinformationforthe Sys- tem Decision Paper, in order to verify the correctness ofthat document. 4.3.3.4.2 Interview Key Participants - The auditor should identify the responsible par- ticipants in the Initiation Phase, and interview them to determine that the needed Initiation A Phase tasks have beenperformed. list ofthe responsible participants and the questions that shouldbe asked ofthoseparticipants isprovided below. The objective ofthisbackground task is to ensure that the work necessary to properly prepare a System Decision Paper has been performed. Inspecificorganizations theparticipants mayhave differenttitlesthanthose listed below, or the tasks may be divided in a different manner. It is not as important that the tasks be performed by the indicated responsible participant as it is that the tasks are performed (by someone). 1. Sponsor/User tasks (a) Has the Sponsor/User developed a Needs Statement? (b) Has the SponsorAJser identified and vahdated the needs? (c) WhatdirectiondidtheSponsor/Userprovide forthepreparationofanAl- ternatives Analysis, a Feasibility Study, a Risk Analysis, a Cost/Benefit Analysis, and a System Decision Paper? (d) Has the Sponsor/User selected a Project Manager? 822. Project Manager/Contracting Officer's Technical Representative (COTR) (a) Has the Project Manager/COTR developed or overseen development of an Alternatives Analysis, a Feasibility Study, a Risk Analysis, a Cost/- Benefit Analysis, and a System Decision Paper? 3. System Security Specialist/Internal Control Specialist (a) Has the System Security Specialist/Internal Control Specialist provided security and/or internal control consultation as appropriate? 4. Contracting Officer (a) Has the Contracting Officer, ifappropriate, awarded the contract? 5. Contract Auditor (a) Has the Contract Auditor, ifappropriate, assured contract compliance? ADP Manager 6. (a) Has the ADP Manager provided Initiation Phase consultation as ap- propriate? 7. Quality Assurance Specialist (a) Has the QualityAssurance Specialist, ifthe functionexists, provided con- sultation on quality attributes ofthe Needs Statement? If the needed background information and/or the needed involvement by responsible participants has not occurred,the auditor should report that potential vulnerability in the In- itiation Phase audit report. The failure to perform these tasks may result in an incomplete and/or inaccurate System Decision Paper. 43.4 CustomizeAudit Objectives Unless the Initiation Phase is conducted in accordance with the process defined in this auditguide, the auditorwill need to customize the audit approach based onthe agency's par- ticular SDLCmethodology. Inaddition, ifthe software is to be contracted orpurchased there will be other considerations. 4.3.4.1 SDLC Methodology Aud it Considerations - The Initiation Phase is designed to produce information leading to an implementation decision. In many instances, the decision toimplementthe systemis made aftertheproblemhasbeenrecognized and theneed defined, and before any other information is collected and analyzed. In those instances, the project team may not prepare the types ofdocuments defined in this phase program. 83Ratherthanfourdistinctdocuments leading toadecisionpaper,some organizationsonly prepareasingledocumentwhichmaybecalleda"NeedsAnalysis"document.Withinthisdocu- ment they tend to incorporate all of the components of the five major documents described for this phase. The auditor should not be particularly concerned about the number of docu- ments prepared, but should concentrate on the information in those documents to ensure it contains the same type ofinformation as described inthe five documents inthisphase. Unless that information is prepared, the full facts needed for decision and later implementationwill not have been developed. In some instances the information may not be fully documented. Some installations prepareoralpresentationstoinitiateprojects,withthe documentedinformationonlyonvisual aids. Inthose instances, the auditor should attempt to sit inonthe presentation, orgo overthe presentationwith the presenters shortly thereafter. Duringthis phase or at its conclusion, the auditorwill be reviewing the established need and the cost-justification for implementing that need. In most Initiation Phase reviews, this will involve evaluating the proposed system in the context of the agency mission. However, there maybe nondiscretionaryfactorswhich could affectthe extent and scope ofthe Initiation Phase review. The factors thatwould affect the extent and scope ofthe Initiation Phase audit include: OMB 1. Laws, regulations, circulars, and other audit standards directing audit in- volvement in the program being computerized. 2. Requirements included incontractual provisions or otherrequirements defining audit role during systems development. A 3. business or organizational environment which because of its unique factors (e.g.,the size of the budget of the organization) warrants additional audit atten- tion. ADP 4. Presence or absence ofinternal assessment groups (e.g., quality assurance, or specialized staff groups, such as computer security officers) necessitating greater or lesser audit involvement. 5. Applications which are politically sensitive (e.g., environment related applica- tions). 6. Resource constraints on the audit organization (e.g., the lack of budget, exper- tise, or tools to do the appropriate audit function). 847. Pasthistoryoftheagency/appHcationwhich indicatesabnormal activity (e.g.,pre- GAO vious reports identifying agency/application vulnerabilities). Thepresence or absence ofthese types offactorsmayresultin changing the scope ofthe audit (e.g., lead to a more detailed evaluation ofthe need for the system, or identification of factorswhichcouldsignificantlychangetheeffort/resourcesneeded toimplementthesystem). 4.3.4.2 Contracting/Purchase Audit Considerations - Ifthe project may result in the ac- quisition and installation ofoff-the-shelfsoftware, in lieu ofcustomized software, there is no particular change required for the Initiation Phase. Changes in the developmental process would not occur until the next phase (i.e.. Definition - Phase II). There are additional considerationsifthere is aprobabilitythatthe softwarewillbe con- tractedto anindependentvendor.The typical use ofthe contractoris insupport ofthe Project Manager/COTR. Contractors can also be used, however, by the ADP Manager, to provide consultationtotheSponsor/UsertodeveloptheNeedsStatement,orbytheAuditor,toreview- /evaluate the Feasibility Study. In all cases, the government's interests must be protected by a rigorous definition of what the contractor is expected to do. It is the Contracting Officer's ADP responsibility to ensure that the interests of the government are met. Contracting for resources is discussed in GSA's 41 CFR 201-32, and is referenced in 41 CFR 201-20.003, Re- quirements Analysis. The decision to use a contractor resides with the Sponsor or User,in consultation with the Project Manager. The analysis to determine whether or not a contractor should be used would be included in the Alternatives Analysis, Feasibility Study, Risk Analysis, and Cost/Benefit Analysis. The conclusions drawn from these aspects of the Initiation Phase will indicate the desirability ofcontracting out the software development. Ifthe use ofoff-the-shelfsoftware or an independent contractor has not been included as an alternative, the auditor should investigate why these alternatives have not been con- sidered. Ifacontractor alternative is included, the auditorshould evaluatewhether ornotthat alternative has been given appropriate consideration, and that the alternative selected is reasonable. In systems that are to be completed through contract/purchase, the following concerns should be addressed by the auditor: 1. Has a COTR been assigned to the project? 2. Is it known whether this type ofsoftware can be purchased/contracted for in the public sector? 853. Are there any security considerations that might prevent this need from being satisfied through contract/purchase? 4. Are adequate funds available for contract/purchase? 5. Are there anystrongbusiness/organization reasons that mightpreclude thework being done by other than agency staff? 6. Is there adequate time to go through the purchasing/contracting procedure? 7. Willthesystemspecificationsbefirmenough atthepointofcontracting/purchas- ing to provide the vendor with sufficient information to develop an appropriate system? 43.5 Detailed Audit Testing 4.3.5.1 Introduction - The auditor should select those documents and criteria within documents, that have a significant effect on the management decision to proceed with the project. Those items should be tested through additional audit investigation and tests. The recommended tests for the InitiationPhase are included inthe Initiation Phase detailed test- ing program. (See Table 4.1) 4.3.5.2 Systems Initiation Phase Audit Tests Program - The program contained in this guide (see Table 4.1) indicates the audit objectives/indicators to be evaluated. For each audit objective/indicator, there are one or more audit tests to be performed. Where appropriate, toolsandtechniques arelistedto assistthe auditorinperformingthesetests.Note thatinsome instances the audit tool or technique consists of a general description, while in other instan- ces the programrefers to a specificproduct or document containing a specific audit approach for the indicated test. 4.3.5.3 Survey Questionnaire - Initiation Phase - The auditor has two verification tasks to perform. First, the auditor must ensure that the appropriate forms, worksheets, and docu- ments have beenprepared as specified by the system development methodology. Second, the auditor must verify that the information has been properly recorded on the documents. The extensiveness of these verification tests will be dependent upon the specific audit objectives selected. QA In organizations having a quality assurance (QA) function, normally performs this verification task. In those instances, the auditor need only test to determine whether or not the quality assurance review is in place and working effectively. 86The documents to be completed during the Initiation Phase will be specified by the agency's system development methodology. The auditor, having gained a familiaritywith that methodologyduringthebackgroundstep, candeterminethatalloftheappropriate documents have been prepared. The auditor should ensure the appropriate buildup of information into the System Decision Paper in order to verify the correctness ofthat document. The Needs Statement should include: 1. Expression ofneed in terms ofagency mission; 2. Deficiencies in existing capabilities; 3. New or changed program requirements needed; 4. Opportunities for increasing economy and efficiency ofuser operation; 5. The internal control/security needed for the AIS; and 6. Alternative solutions to solving the need with justification for the alternatives being proposed. The Feasibility Study should include: 1. An analysis ofthe objectives, requirements, and system concepts; 2. An evaluation ofalternative approaches for reasonably achieving the objectives; 3. Identification ofthe proposed approach; and 4. Sufficient information in the above three areas, or additional areas, to provide managementwith adequateinformationtomake decisions toinitiate orcontinue the development, procurement, or modification of software or other ADP-re- lated services. RiskAnalysis should contain: Identification ofinternal control and securityvulnerabilities; The nature andmagnitude ofassociated threats to data and assets coveredbythe proposed AIS; Recommended safeguards to be included in the design to address the identified risks; and A detailed review of all data and assets to be processed or accessed by the sys- tem, showing the value and sensitivity ofthat data or assets. The Cost/Benefit Analysis should include: 1. Costs to build the system; 2. Benefits to be derived from the system; 3. Impact ofthe AIS on security, privacy, and internal control requirements; 4. Analysis and evaluation of alternative approaches proposed in meeting the mis- sion deficiencies; and 5. Detailed Cost/Benefit Analysis ofthe proposed alternative. 87The System Decision Paper should include: 1. Information and framework critical to the decision-making process; 2. Mission need; 3. Milestones; 4. Thresholds; 5. T Issues andJ ri•s1ks; 6. Alternatives; 7. Cost/benefits; 8. Management plan supporting rationale for decisions; 9. Affordability in terms ofprojected budget and out-of-year funding; and 10. The decision made (alternative selected). Audit Results/Reporting Problems identified in the previous audit steps should result in audit recommendations, assumingthevarianceidentifiedissignificant.Theauditorshouldbeabletoidentifythepoten- tial impact of the variance prior to issuing an audit report recommending corrective action. The audit report should be released prior to management's decision on whether or not to proceed with the AIS (i.e., sign-offon the System Decision Paper). 4.3.6.1 Potential Deficiencies - The objective ofthe review is to determine whether the InitiationPhase contains deficiencies.Anysuch deficienciesshouldbe reported, togetherwith recommendations to overcome them. However, while specific deficiencies are unique to an individualAIS, experience hasshownthatcertaindeficiencies are moreprevalentthanothers. These problems are listed below as a basis for comparison against deficiencies identified in the review. They assist the auditor in assuring that these more common deficiencies have not been overlooked. 1. The Needs Statement will not be complete, and thus the possibility that the im- plemented systemwill not meet the true needs ofthe user. A 2. reasonable set ofalternatives will not be considered, and thus the alternative selected might not be the best alternative. 3. Therightindividuals fromusermanagementmightnotbeinvolved, orsufficient- ly involved, in the Initiation Phase, resulting in a decisionwhich may not be fully supported by user management. This is particularly true when two or more departments/agencies are involved in the same system. , 884. Allvulnerabilitiesmaynotbeidentified, orthemagnitudeofthosevulnerabilities maynotbe determined,which couldresultin extensive additional costs or opera- tional vulnerabilities. 5. The Cost/Benefit Analysis does not identify all of the costs, or the benefits may be overstated, resulting in a systembeing implemented which should not be. 6. The System Decision Paper may not include all important elements uncovered during the phase, resulting in an incorrect decision due to lack ofinformation. 7. The System Decision Paper may not be reviewed by a sufficient number of in- volved managers to have that paper adequately evaluated, resulting in the implementation ofa system which maybe deficient or overly costly. 4.3.6.2 Potential Effects ofDeficiencies on Meeting System Mission -The impact ofthe identifieddeficienciesoncompletingthesystemmissionmustbe determined.Inorderforuser management to make effective decisions on audit findings and recommendations, they need an assessment of the impact of those deficiencies on their mission. The auditor can use the strategies for determining the value ofan impact, as described in FIPS PUB 65, or canuse in- formation readily available and collected during the Initiation Phase review. 4.3.7 Reassess Audit Strategy The audit of the Initiation Phase should conclude with a determination of the audit strategy for the remaining developmental phases. The audit strategy should include: 1. Extent ofaudit involvement in the remaining system development phases. 2. Scheduleofaudittasks,tobecoordinatedwiththesystemdevelopmentschedule. 3. Specificauditorassignments. [Note: Itis advantageous tohave continuityin audit staffthroughout the entire developmentalprocess unless specialists are required for a single phase audit.] 4. Audit tools and techniques to be used. [Note: Some tools require unique skills and extended preparatory time.] The audit strategy will be affected by the auditor's analysis ofthe Initiation Phase work. The criteria which could extend or reduce the projected audit involvement in the remaining phases include: 89Outside directives impacting the scope and extent ofaudit involvement. Competencyand involvement ofotherinternalgroupsprovidinganindependent assessment ofthe AIS (e.g., the quality assurance function). The completeness and accuracy ofthe documentsproduced duringthe Initiation Phase. The apparent consensus ofinvolved parties regarding the correctness ofthe al- ternative selected. The assurancethat canbeplaced ontheCost/Benefit AnalysisandRiskAnalysis. 90S -S Qh <U 03 i-H O i-i ja a u c O -1-1 < o o .2 -a Cl O c m° 1/3 o 00 o fl s " Cl -S - 9 o 3 O to D a !3 = 1^ 13— * .Z2 o -c 2 Q o :2 d u o Xi u > 7 U3 3 (0 t 6f3 0 M HCi a, 3 )u>< 2^ IcSO 3 ta/i 60 •f=. O . .a2 .o C 2 ^3 ? o .3 2 3 O <u J3 CO 3s I-I T 3 n 33 3 T oO O3 w .3 H 3 3 H .„ >O>%^ "S 3 O a Q < .-3 U l3a U u .D a ( s.- DI 3 8 « ^ ;8 O S tm - QID ' Io 3 So - -( a < D X ( 1o I3 O 1O o -/ /U u U I3 3, ^ >O S S . . a6 3s 20 '~O <D 3 a u. o 3 60 3 O o 3 iui o3 O a o o3 03 ^ 00 3 .-a ^ 3 > o 60 WU3 ^UOi 3 t;o: 3 o 73 -a 0W:1 >> «5 S to W 3t/3 T3 "S ai c a OQ U 2Si 2 S - 2 H g « a Oj - ^S !/3 .3 D < t 1) ) t-i 3r 3 u D -S .5 91- 1 a, i (/3 ii cr I O U 3 .a u o a 3 I—I 'S uii .9 C/5 a " o .is o H d :^ .3 u a • a§ a o (-1 CO a 2 <u 5 'o o „ § a 2 W H o a 03 Q U ( >S a 0 " g a a " a 1*o- </: 1/5 -c CO Q .5 <u 2 > a 2 ^ < 1 S S ^ la 1/3 iS£ o I&- o ° ° a 13/2 60 -in C . zC : o H o ^ ;S 2 (U .1-1 3 D 2 § "S .9 5^ ci. .Si I ^ t3. 3 (N. 3 ) C- Ii , C G U l-H § 2 =0 a, a o o J3 < _ 3 U a I Q D ' -Da C DO T b C! O J^ 2 3 < 3 .a 3 O O o CO 1/3 .t; 92a I •i .a 9 3 'iJ o S S o a.^ § D _> O -a o o -C» W O * O » s o >_ "53 a -^=1 J3 'ii ^.2 a ^ 2i *-o*-» .a s a o o 13 2 i ^ ° O (/2 i .9 "I B -3 W B a o > 13 03 -r S ^ T3 *j O -53 " oC 'o-' 2 9 1) >0) J Oh H 2 D S «2 (U =^ S3 ^ 8 oWn •T3 9 (U ^ >• H o g to o bfi H CI 8 9 ° a D T3 2 " Q U "n ci D < J3 • .- Sa 2 g o a- o Co I, "(U - oa ^< oU r^O q -2 au 3 o « a ' d .a a a ^ " o o (3 g o 'S Uo >-§oo .a03 fl Sot < au o T T3 on U C/D -O CoQ 3 ^ z IQ— D 01/ 33 D (D X) 13 u "3 H a 93' 2 «O3 3 ' 5SD ^ "§ B ^ •5b•§ ^ ^ a o •£ c o -I 1-1 o O <D CO —c >a . (U H >(U .oa VO3 C33 PH HJ > d _ la oa _> -o O c egi d a-> -0 -t ^;a -50 2b3 O t)" Q D < W u .S £o - °5 "iD Da-i J3 =. 1o 3 ^o« .2 b ca J3 ."2 IoI! a o ^ to H -fl 3 8 1^ '-5 O O "5 1 o/3 I" S I s a ^ :^ a •5 o > P a o > ^ <u o «O CI, «3 s to Q -C C O3 S2 i-H (S w z 3 < d 8 94; • Sa 3 3 « l3i3 wO ^ (U U < oD - o6 o O ID 00 . Os C3 • ^^ I £D O ( OU O 8 (U t O §5£) 3 »3 ( 3 O o C5 O0 V3 -3 =^ .s 3 O -I 3D 3 O Ooo CO 3 O e _ </3 - ^ ID W H li -« oS3i ™O s =^ g ^ S C o O 3 ^ 3 O o 5S2 )"^ 5 •2 cN §3a ' J _io O3S 3 >o 5: 3 I S ID D - u HO , i T'^ s 3'S I3 ED ^< C C/ O O: Q D < " i a oS n e« -8 ^ ^^ gB 1 M -t 3i 3 o < O^ (D 11/3 1«i 1. . -3 5 -« u a. I ,D " t 3o nj -f S3 HU .£3 O Jo (50. O3 Jl-S l - o sn " " -o o O3S 3oo pI3 - IID DD j -I ( 2 T3 W- SD U OP O ID I o >D ( c0 > S OC 3 :r^ .C 33 23 " TC I c "3OO D D . I3 D ^O C3O 3 O . (73 u Doa Q D O < 3 3 =Sfc 95XI a. d 03 (U -a D u D -o '<C Ojn S D 2 o c o a u CU H HO O u u u lU 1a/i 3 Q u D a T d3 o 1 3) 5 u ^ c T3 _> o — 03 < D tS 3 s 6 o B wr-i x3 ; !U (0 U3 "t -! 3? T D3 „ C 73 - aa XJ 3 a 5 2 -2 El u -t3 G. O > M03 00 Q c i| - 31 c D 3 1 0W0 B 73 -JC3 2 "3 i: o 1 ^ a XI O "3 Q "3 D T U 33 a <u .1D -/ 33 -a S -2 5 .a a o o T5 96« S 2 .B .a s a a Q D > O o o a " •z: -c oti r( au « 1 o > CO 2 3 g 1"-1 " H § (<Uu 5 a ^ 3 <D O 2 "-I lD-c W -4— H </3 iOn o a « O I/O ?5 £^ -2 a T3 5 D, < .§ 2i oa G 3. CO oD P .9 O -C 5O 5 ft: i2 1o> £03 ! 8£ I I S a" > D, >(U 3 O ><U 13 3 o o a >" 3a 3 o -c .S CO O 00 T3 t/3 "2 .2 ao- "§ S2 (^/3 (U <; Q-i Q O D < U 3 IaD -a c/3 .s 3 O u u ^ i •1 in 971 ; o .S T3 o o 1 S 4^ ^- ^ S3 C>0 a_. g- fl o I (U J3 1/3 a •C o > a o -a a .2 00 U -O Oh U o oB O 8 a o o l| a, 9 O u 1) H 1 a CW/5 3 > o cr H c o H Q la 8 ^ Q D < J3 O ^(u Ju 3 *5 r! O IS 2 - -a c/2 > JJ 1) D, J (SO cn 'I CO U PQ o Q D u 3 a "3 o o 98( Oh > a .y o o B 3 .1 O a o .2 a U -1-1 a,.9 .a > o g a .9 -a H CW/3 H H IQ— ^ 9 «? D 00 F-\ I. o ?^ 994.4 AUDIT PARTICIPATION IN THE DEFINITION PHASE - PHASE II DuringtheDefinitionPhase, thefunctionalrequirements are defined, and detailedplan- ning for the development ofan operational AIS is begun. Experience has shown that it is dif- GAO ficult to obtain a good requirements definition, studies of AISs show inadequate requirements statements to be one ofthe major causes of defects in AISs. Because ofthe dif- ficultyin defining correct requirementsthe firsttime, requirementidentificationshould be an iterative process. The audit objectives duringthe DefinitionPhase are toensure thatuserneedshavebeen clearlydefined and translated into requirements statements, includingrequirements for a sys- tem ofinternal control designed to conformto established standards. This audit objective will beaccomplishedprimarilythroughanindependentanalysisoftheDefinitionPhasedocuments and the vaHdation ofthe information contained in those documents. 4.4.1 Primary Audit Objective oftiie Definition Phase The primary audit objective for the Definition Phase is: "To ensure thatusers' needshave been clearly defined and translated into requirements state- ments which incorporate adequate controls and conform to estabhshed standards." Inaccomplishingthisobjective, the auditorwillhave tounderstandtheneedsidentifiedduring the Initiation Phase. This is necessary to ensure that the Definition Phase properly translates those needs into appropriate requirements statements. In addition, many auditors emphasize internal control requirements because experience has shown that to be a major weakness in the Definition Phase. In order to perform this audit phase effectively, the auditor must become familiar with the Definition Phase ofthe agency's SDLC methodology. This will require an understanding ofthe DefinitionPhaseworkflowandthe documentsproduced duringthatphase.The auditor will also needto identify theparticipants in the DefinitionPhase, and determine theirspecific responsibilities. 4.4.2 Overview ofthe Definition Phase In the Definition Phase, the needs from the Initiation Phase are translated into a com- puter solution. The system designers must develop the logic which will permit user needs to be accomplished on a computer. This is achieved through the involvement ofindividuals from user and dataprocessing areas, and involved third parties such as internal control and security personnel. 100The Definition Phasewill produce the functional requirements and begin detailed plan- ning for development of an operable AIS. Functional requirements and processes to be automated are documented and approved by an appropriate senior management official before the AIS development effort is begun. Requirements identification is iterative, as is the analysis ofpotential risk, involving those who both identify and solve problems. It is critical that internal control and specific security requirements be identified during this process. Re- quirementsmaybemodifiedinlaterphasesasabetterunderstandingoftheproblem isgained. Also, during the Definition Phase, a Project Plan specifying a strategy for managing AIS development, certification, andaccreditationisprepared. Itdefinesthegoals and activities for allphases, and includes resource estimates duringeachphase and intermediate milestones, as well as methods for design, documentation, problem reporting, and change control. The physical number ofparticipants in this phase is normally greater than the Initiation Phase. Data processing personnel play a much more active role during the Definition Phase. Improperly defined requirements usually surface during definition. 4.4.2.1 Participants and Their Tasks - The responsible participants in the Definition Phase, togetherwith a briefdescription oftheir responsibilities follows: 1. Information Resources Management (IRM) Official - Approves Needs State- ment to advance to Phase II (Definition), in consultationwith Sponsor/User and ADP & Manager. (Note: This occurs betweenphases I II.) 2. System Security Officer (SSO)/Internal Control Officer (ICO) - Reviews SSO/- ICOcomponentsofProjectPlan, FunctionalRequirementsDocumentsandData Requirements Documents, on a selective basis. 3. Auditor(OIG) - Reviews/evaluates System Decision Paper, Project Plan, Func- tional Requirements Documents, Data Requirements Documents and par- ticipates intheir development, as necessary; identifies audit trail and auditability requirements, including quality assurance and audit tools and techniques, for in- corporation in requirements documents; prepares Audit Program. 4. Sponsor/User - Approves Project Plan and Functional and Data Requirements Documents, and updates System Decision Paper. 5. Project Manager/Contracting Officer's Technical Representative (COTR) - Develops Project Plan, Functional and Data Requirements Documents with Sponsor/User participation and audit consultation. 1016. SystemSecuritySpecialist/InternalControl Specialist-Providesconsultationand reviewofSSO/ICOcomponentsofProjectPlan,FunctionalRequirementsDocu- ments and Data Requirements Documents. 7. Contracting Officer - Ifappropriate, awards contract. 8. Contract Auditor - Ifappropriate, assures contract compliance. 9. ADP Manager - Reviews Validation, Verification and Testing components of Project Plan, Functional Requirements Documents, Data Requirements Docu- ments, as appropriate; provides technical support to Project Manager and Spon- sor/User. 10. Quality Assurance (QA) Specialist - Reviews project definition to ensure com- pliance with Needs Statement and data processing standards. 4.4.2.2 System Definition Phase Documents - The work performed during the Defini- tion Phase will be recorded on six major Definition Phase documents. In addition, the System Decision Paper will be updated as appropriate. Furthermore, each phase of the system life cycle provides an opportunity to reevaluate the risks, cost/benefit, and approach to be taken duringimplementation. Regardless ofthe developmental methodologyemployed, the auditor can expect to find approximately the same information produced. The sixmajor documents produced in thisphase and abriefdescription oftheircontents follow. Note that the major laws, regulations, and directives that require or recommend these documents are found in parentheses after each document name. GAO OMB 1. AuditPlan (PublicLawsEstablishingOIGs, Audit Standards, A-130, OMB A-123) The objective is to assess the adequacy of internal ADP controls andprovide the "reasonable assurances" to management spelled outinAppendix GAO 1 ofthe Audit Standards (Yellow Book). 2. ProjectPlan (FIPS PUBS 102& 105, NBS SP500-98, OMB A-130, OMB A-123) The Project Plan specifies the strategy for managing the software/AJS develop- ment. It defines the goals and activities for all phases and subphases. 3. Functional Requirements Document (FIPS PUBS 38, 64, & 124, DOD-STD- OMB OMB 7935, A-130, A-123) The purpose of the Functional Requirements Document is to provide a basis for the mutual understanding between users and designers ofthe initial definition ofthe AIS, includingthe requirements, operat- ing environment, and development plan. 1024. Functional Security and Internal Control Requirements Document (FIPS PUBS 38, 64, 73, & 102, DOD-STD-7935, OMB A-130, OMB A-123) The purpose of theFunctionalSecurityand InternalControlRequirementsDocument istofocus attention of the user and system designer on the security/internal control needs of the system, based both on vulnerabilities identified during the Risk Analysis and establishedinternal control standards. This document may be included as an appendix to the Functional Requirements Document. 5. Data Requirements Document (FIPS PUB 38, DOD-STD-7935, OMB A-130, OMB A-123) The purpose of the Data Requirements Document is to provide, during the definitionstage ofsoftware development, a data descriptionand tech- nical information about data collection requirements. 6. DataSensitivity/CriticalityDescription (FIPSPUBS 65 and 102, OMB A-123 and 130) Based on an assessment of sensitivity and/or criticality, provides a general statement ofthe nature and magnitude ofpotential threats for use in the formal Risk Analysis, and preliminary determination ofdata sensitivity. This document may be included as an appendix to the Data Requirements Document. In addition to the six major documents produced in this phase, one document, the Sys- tem Decision Paper, is updated. 4.4.3 Audit Survey The audit survey in this and following phases will primarily involve review of: (1) the documentsproduced inthepreviousphase; (2) appropriate auditworkpapersproduced in the previous phase; and (3) those documents produced in the present phase. The audit survey in the Initiation Phase required the auditors to look at the user area and appropriate policies, regulations, andthe SDLCmethodology.Thatinformationshouldbedocumented inthe audit workpapers from the Initiation Phase. The objective of the survey in this and the remaining phases is to bring the auditor "up to speed" in review activities. Ifthe phases were short in duration, the survey in this and later phasesmaynotbe necessary. However, inmostinstances, severalweeks ormonths mayelapse between the conclusion ofone phase and the point where the auditor re-enters the develop- ment process to conduct the review during the following phases. Eachsurveywillinvolvefoursteps. First, theauditorwillneedto reviewthe output docu- mentsproduced in the previousphase plus appropriate auditworkpapers. Second, the auditor must review and become familiar with the plans to complete this phase. Third, the auditor gathersthedocumentationproducedduringthisphaseandevaluatesthestatusofworkincom- 103parison to the plan. Lastly, the auditor verifies the documents produced during this phase through challenging and analyzing those documents, as well as interviewing the participants in the phase. Note that the specific work within these four tasks will be dependent upon the customized audit objectives selected for this phase (see Section 4.4.4). These four tasks are discussed individually in the following sections. 4.4.3.1 Review Tnitiation Phase Outputs - The auditor should review the following five Initiation Phase documents, or the equivalent documents produced by the developmental methodologyused for this AIS: 1. Needs Statement 2. Feasibility Study 3. Risk Analysis 4. Cost/Benefit Analysis 5. System Decision Paper The key document for review is the System Decision Paper. This will include a summa- tion ofmuch ofthe information in the other documents. The auditor should refer back to the other documents as appropriate to get more detailed information. The auditorshouldreviewtheauditworkpapersprepared duringthepreviousphase.The major concern here is to review the deficiencies uncovered during the Initiation Phase. The auditor, during this review, will want to ensure that those deficiencies have been adequately addressed during the Definition Phase. One ofthe major audit tasks in each review phase is to evaluate the adequacy ofthe actions taken on auditor-identified deficiencies from the pre- vious phase. 4.4.3.2 Review Definition Phase Plans - The System Decision Paper should provide the details of the plan for implementing each phase. However, the auditor should be aware that many organizations maintain their schedules and plans through automated scheduling and project management systems. In these instances, the auditor may need the outputs from the automatic scheduling system in order to review the plans. The key plans, from an audit perspective, are the tasks which will produce the needed documentation. Thus, the auditor should study the documents to be produced during the phase, andthenrelate those to theplans to ensure thattheywillbeproduced duringthephase. Ifitisuncertainthatalltheneededinformationwillbeproduced, the auditorshouldchallenge the adequacy ofthe plans. 4.4.3.3 Gather Information on Definition Phase Status - The auditor should monitor projectstatusperiodicallyto determinewhen reviews should occur.This canbe done through 104questioningproject management, or through querying automated project status systems. The auditor should not rely upon the project personnel to identify when a review is to occur, un- less management has imposed the restriction that the phase is not complete until it has been reviewed by audit. The auditor needs to determine the status ofthree aspects ofthe project. First is the ad- ministrative status of the project, which is a budget and schedule status. This is necessary to determine where the project stands and its availability for review. Second, the auditor needs to determine the status ofdocumentation. [Note:The fact that the administrative schedule in- dicates a document is complete does not necessarily indicate that all of the attributes ofthat documenthavebeencompleted.] Ifscheduleandbudgetaretight, theprojectteammaydecide to eliminate certainparts ofdocuments in orderto stayon schedule. Ifthis is done, the auditor should note those missing items as project deficiencies.Third, the auditorwants to determine the status of changes. If there have been significant changes to the project, the auditor will wantto ensure that the schedule and budget have been adjusted accordingly, and any changes needed to the documents produced inprevious phases have been made. 4.4.3.4 Verify Information on Definition Phase Status - This task involves reviewing documents produced during the Definition Phase and interviewing the key participants who produced those documents. 4.4.3.4.1 Review Documents - The construction of an AIS is performed in conjunction withdevelopmentofaseries ofdocuments thatbuildoneuponanother. The informationused forthe project's DefinitionPhase originates from the InitiationPhase System Decision Paper. This information is then supplemented and expanded upon through the processes which produce the Definition Phase documents. The document flow for the Definition Phase is determined by the SDLC methodology. The System DecisionPaper is the source document forboth the Project Plan and the updated System Decision Paper. [It is also the source document for the Audit Plan, but that will be prepared by the audit function, as opposed to the developmental group. See Section 4.4.7 on audit strategy for the tasks needed to develop the Audit Plan.] The Project Plan specifies the strategyfor managing the software development process. The Project Plan also indicates how the systemwill be certified prior to installation and operation. TheSystemDecisionPaperplus the ProjectPlanareused as thebasisfordevelopingthe Functional Requirements Document, the Functional Security and Internal Control Require- ments Document, the Data Requirements Document, and the Data Sensitivity/Criticality Description. The preparation of these documents requires extensive interaction among the responsibleparticipants. The interactionprimarily involves the responsible functional/opera- 105tionalparticipants, although the policy/oversightparticipantswillbe contributing expertise in their specialty areas. All ofthe documents developed during this phase, with the exclusion ofthe Audit Plan, are also utilized to update the System Decision Paper. The auditor wants to ensure that the System Decision Paper's currentness and completeness is maintained throughout the entire development process. It is at this point in the cycle that management again must make a decision regarding the continuation of the project. Management has the option to continue theproject through the nextphase, canceltheproject, orproposemodifications totheproject. This may cause parts or all ofthe Initiation and Definition Phase to be repeated. 4.4.3.4.2 Interview Key Participants - The auditor has two concerns regarding the par- ticipants responsible for the Definition Phase; first, that the appropriate individuals par- ticipate, and second, that they perform the proper functions. To do this, the auditor should identifywho isparticipatinginthe DefinitionPhase, andthe rolesand responsibilitiesofthose individuals. Listed below are the areas ofrecommended involvement: 1. Information Resources Management (IRM) Official (a) Has the IRM official approved Needs Statement prior to commencing Phase II (performed in consultation with Sponsor/User and ADP Man- ager)? Note that this occurs between the end of Phase I and the start of Phase II. 2. System Security Officer (SSO)/Internal Control Officer (ICO) (a) Has the SSO/ICO reviewed security/control components of the Project Plan? (b) Hasthe SSO/ICO reviewed security/controlcomponents oftheFunction- al Requirements Document? (c) Has the SSO/ICO reviewed the security/control components ofthe Data Requirements Document? [Note: This may be done on a select basis as deemed necessary by the SSO and ICO.] 3. Sponsor/User (a) Has the Sponsor/User approved the Project Plan? (b) Has the Sponsor/User approved the Functional Requirements Docu- ment? (c) Has the Sponsor/User approved the Data Requirements Document? (d) Has the Sponsor/User developed/modified the System Decision Paper prior to the completion ofthe phase? 1064. Project Manager(PM)/Contracting Officer's Technical Representative(COTR). (a) Has the PM/COTR developed a Project Plan? (b) Has the PM/COTR developed Functional Requirements Documents (with user participation)? (c) HasthePM/COTR developedaDataRequirementsDocument(withuser participation)? 5. System Security Specialist(SSS)/Internal Control Specialist(ICS). (a) Has the SSS/ICS provided consultation and review ofthe SSO/ICO com- ponents ofthe Project Plan? (b) Has the SSS/ICS provided consultation and reviewofthe SSO/ICO com- ponents ofthe Functional Requirements Document? (c) Has the SSS/ICS provided consultation and review ofthe SSO/ICO com- ponents ofthe Data Requirements Documents? 6. Contracting Officer (a) Has the Contracting Officer awarded the contract, ifappropriate? 7. Contract Auditor (a) Has the Contract Auditor assured contract compliance, ifappropriate? ADP Manager 8. (a) Has the ADP Manager reviewed the Project Plan? (b) Has the ADP Manager reviewed the Functional Requirements Docu- ment? (c) Has the ADP Manager reviewed the Data Requirements Document? (d) Has the ADP Managerprovided technical support, as appropriate, to the Project Manager? (e) Has the ADP Managerprovided technical support, as appropriate, to the Sponsor/User? 9. Quality Assurance (QA) Specialist QA (a) Has Specialist reviewed project definition to ensure compliance with Needs Statement? QA (b) Has Specialist reviewed project definition to ensure compliance with dataprocessing standards? Note that in some agencies, all ofthese positions will not exist; however, the tasks indi- cated for those responsible participants should be performed. The auditor should first ensure 107that they are performed, and then ensure that the individual performing them has the neces- sary skills and responsibility to perform them effectively. 4.4.4 CustomizeAudit Objectives Thepreviously statedauditobjectivesmustbemodified forthe specificAIS. The auditor mustidentifythe specificuserneeds thatmustbetracedto clearlydefined requirements state- ments, and the established standards to which controls must conform. This involves the crea- tion ofa set ofspecific audit objectives for the Definition Phase. The extentofauditinvolvementintheDefinitionPhasewillbepartiallydependentupon aseriesoffactorsthatcancausetheAIStohavegreaterimpactontheagency.Also,thegreater the number offactors that may negatively impact the success ofthe AIS, the greater the need for audit involvement during this phase. That involvement should be reflected in the cus- tomization ofaudit objectives. 4.4.4.1 SDLC Methodology Audit Considerations -The type ofdocuments andinforma- tion produced during the Definition Phase will be heavily dependent upon the prevailing managerial style and philosophy. For example, if the managerial style is to anticipate risks, muchemphasiswillbeplacedontheRiskAnalysis.Likewise,ifmanagement isveryconcerned about the Cost/Benefit Analysis, attention will be placed on creating that document. On the other hand, ifthese are areas oflittle interest to management, only cursory attention may be paid to these documents. Theauditormayalso encounterautomated SDLC methodologies. Inthoseinstances, the developers will enter the information electronically; the information may not be printed in hard-copyformat.Theauditorwilleitherneedtolearntousethesystemtoreviewtheinforma- tion, or have someone print the information for auditpurposes. 4.4.4.2 Contracting/Purchase Audit Considerations - There are minimal changes in the auditapproachduringtheDefinitionPhase,whethertheAIS isdevelopedin-house,purchased offthe shelf, or contracted for. However, two responsibilities are changed during the Defini- tion Phase, and these will require the auditor to verify that those added responsibiHties are performed during the background/survey audit step. These changes are: 1. Off-the-shelfsoftware change - Ifoff-the-shelfsoftwareisbeingconsidered, thentheProjectManager, inprepar- ingthefunctional requirements, mustprepare thatdocumenttoserve asthe basis for procurement action. 1082. Contracting difference - Ifit is expected that the software will be acquired through contract, the Project Manager/COTR must incorporate the provision of contractor resources, as ap- propriate, into the Project Plan to ensure that: (l)resource acquisition schedules are meaningful; (2)the role of the contractor(s) is identified and proper; and (3)controls are provided for contractor objectivity. No otherparticularchanges are required. Contractors mayparticipate in any activityun- less otherwise precluded by Federal statute or departmental policy. The specific contracting/purchase Definition Phase concerns that should be addressed by the auditor include: 1. Doesthephase define the type ofcontractors/vendors thatwillbe eligible toper- form this project? 2. Do benefits outweigh costs through the use ofpurchased/contracted software? 3. Willthe contractor/vendorbe able to dealwith the significance ofidentifiedvul- nerabilities/risks? 4. Has the COTR been sufficiently involved in the definition process to determine whether adequate information has been developed to begin the contracting or purchase? 5. Have measurement criteria been established which can be used to evaluate the product produced by a contractor/vendor? 4.4.5 Detailed Audit Testing 4.4.5.1 Tntroduction - The auditor has two document verification responsibilities. The first is to ensure that the documents are prepared in accordancewith the system development methodology. [Note: This may be done by another independent review group, for example, quality assurance, ormaybe done by the auditor on a test basis.] Second, the auditorwants to ensure that the same information is accurately transferred from document to document to document.The latter responsibility is one that requires the auditor to understand theproject, as well as the flow ofdocuments through the development process. 4.4.5.2 Definition Phase AuditTests -Theauditorshouldvalidatesufficientattributesof the documentation to enable reliance to be placed on them. At the end of this process, the auditor will need to develop an opinion as to whether or not there are deficiencies in the 109project, and to make recommendations. Testing independent sources will permit those recommendations to be developed. The validation should be performed using the Definition Phase detailed audit testing program. (SeeTable4.2)Thisprogramcontains asetofauditobjectives/indicators forevalua- tion. For each audit objective/indicatorthat the auditor selects, audit tests are recommended, together with the tools and techniques for performing those tests. The audit program is designed to help the auditor select those items requiringvalidation. 4.4.5.3 Survey Questionnaire Definition Phase - The documents and the key attributes to be included in each document that the auditor should verify follow. [Note: This informa- tion is needed, even if the developmental methodology has a slightly different set of docu- ments.] 1. Project Plan should contain: (a) Strategy for managing the software; (b) Goals and activities for all phases and subphases; (c) Resource estimates for the duration ofthe system development process; (d) Intermediate milestones, including management and technical reviews; (e) Methods for system development, documentation, problem reporting, and change control; and (f) Supporting techniques and tools. 2. Functional Requirements Document should contain: (a) The proposed methods and procedures; A (b) summary ofimprovements; A (c) summary ofimpacts, internal controls, security, and privacy considera- tions; (d) Cost considerations and alternatives; (e) The functions required of the software in quantitative and qualitative terms; (f) How the software functions will satisfy the performance objectives; (g) Performance requirements such as accuracy, validation, timing, and flex- ibility; (h) Explanation ofinputs/outputs; and (i) The operating environment. 3. Functional Security and Internal Control Requirements Document should con- tain: (a) Vulnerabilities identified during Risk Analysis; and 110(b) Established internal control standards, and general as well as application control requirements. 4. Data Requirements Document should contain: (a) Data collection requirements (both static and dynamic data); (b) Logical groupings ofdata; (c) The type ofinformation required to document the characteristics ofeach data element; (d) Specification ofthe information to be collected by the user; (e) Specification ofthe information to b^ collected by the developer; (f) Procedures for data collection; and Impacts ofthe data requirement needs, (g) 5. Data Sensitivity/Criticality Description should include: (a) Sensitive/critical types ofdata; (b) Sensitive/critical types ofassets; and (c) Degree ofsensitivity ofdata and assets. 4.4.6 Audit Results/Reporting Attheconclusionofaudittesting, theinformationneededtodevelopfindingsandrecom- mendations has been collected. At this point the auditorwillneed to determine anyvariances between actual and expected results. For each variance the auditor will need to determine whether thatvariance is significant, and ifso, to develop recommendations. 4.4.6.1 Potential Deficiencies - The objective ofthe review is to identify deficiencies in the Definition Phase. While the specific deficiencies will vary based on the AIS, there are deficiencies which are common to the Definition Phase. These are listed below in order to help the auditor assure that these deficiencies have not been overlooked in the review: 1. Theestimateforresourcesandtimerequiredtoimplementthesystemisunrealis- tic based on the requirements. The auditor might utilize an automated estimat- ing package in order to validate the reasonableness ofthe estimate. 2. The definition is inadequate to move to the next phase ofsystems development. Ifthe attributes specified inthe documentsfor thisphase are not complete, there is a high probability that extra resources will be required in the followingphases to compensate for this deficiency. 3. The input requirements are incomplete. The information needed forprocessing has not been fully specified, thus making design impractical. Ill4. Theneeded outputrequirementsare incomplete.Thelackofthese requirements will make system design impractical and uneconomical. 5. The processing specifications are incomplete. The definition does not indicate howinput requirementswillbe converted to output requirements.The netresult is that extra time will be required during design to develop this definition. 6. The systemfailures and/or impact ofthose failures will be inadequately defined. Thenetresultis thatthe appropriate recoveryprocedures maynotbe developed. 7. The level ofservice needed to achieve the processing objectives will not be ade- quately defined. The net result is that operations may not have the necessary processing capacity to handle the system requirements. 8. The security and internal control requirements maynot be fully defined.The net result is that the implemented system may lack adequate security and internal controls. 9. The assets requiring sensitivity/criticality controls may not be defined, resulting in operational problems due to inadequate handling ofthe asset. 4.4.6,2 Potential Effects ofDeficiencies on Meeting System Mission - Problems inade- quately addressed in the Definition Phasewill lead to escalating costs throughout the remain- der of the system development process. Dr. Barry Boehm in the book Software Economics [BOEMB81] estimated that the cost offking inadequate definitions in the operational phase ofan AIS could be 100 times as costly as addressing the same problem in definition. Thus, it is critical for the auditor to not only identify the deficiencies, but to estimate the impact of those deficiencies. The impact ofDefinition Phase deficiencies canbe estimated in one oftwoways. First is the actual cost ofthe deficiency itself. For example, the lack ofcontrols may result in the loss ofassets in the operational system. Second, the auditor should estimate the escalating cost of fixing definition problems. The rule ofthumb provided by Dr. Boehm is that for each unit of cost estimated as needed to fix a Definition Phase deficiency, it will cost ten times as much by the time the test phase occurs, and 100 times as much once the system is placed into opera- tion. 1124.4.7 Reassess Audit Strategy Ateachstepofthedevelopmentalprocess, theauditorsshouldreassess the auditstrategy and level ofeffort based upon the findings and recommendations during that phase. In addi- tion, during the Definition Phase, the auditors should establish the Audit Plan. The audit plan should be based upon accomplishing the six audit objectives outlined in GAO the "Yellow Book"[GA081-l]. These are: 1. Provide reasonable assurance that systems/applications carry out the policies management has prescribed for them. 2. Provide reasonable assurance that systems/applications provide the controls and audit trails needed for management, auditor, and operational review. 3. Provide reasonable assurance to management that systems/applications include the controls necessary to protect against loss or serious error. 4. Provide reasonable assurance that systems/applications will be efficient and economical in operation. 5. Provide reasonable assurance that systems/applications conform with legal re- quirements. 6. Provide reasonable assurance that systems/applications are documented in a manner that will provide the understanding of the system required for ap- propriate maintenance and auditing. 1132 2 i 1 .S u 3 T 33 Oh 13 (U § .3 J3 to o O -cs to - 3 a C/2 j Sa aa .^"S ^-5 1 ^ JS pL, CM a o O (U aj I i U o ID JS 2 re -O 3 §1 "ore 1 g3 (so re w ^ (/5 " O S. ^ c^2 s(u " r se H w .S o ^ca a» uH j aa , "u55 H H I 9 J E « g 3 o w Q = 2 a. §- - Oh2 g So < Hi o £« " >5 -s( aU r <e U 1( 3u JS u Jr Se Jr 3e ja o u a •S ^ .S =2 « ™ -—1 §1 •O Oh S 2 IS} -u- Qtj r Se U 1u/3 "K ^ Om i 5i ^ s I (/5 ^ 3 Jac " -2 a ^ r' e j^ U §d 1/3 -. <1 a- ^1 1 "3 3 (V) C(50 ^ c b «p CQ U JO eS ^>- 1 ^ S/3 • • u— a ie Pj . o' XZi o Q O -h h" a «^ c o I 0)T < ^ <0 ^ <D 9^. £ *<^£re .& Sfi < r Se w & 114X) -o S u u Oh C3 -a o .2 :2 2 2 o u o 3 CO o 2 - l 3-H (aU S u E 3 o .3 3 § O <4-< ii u O" a 3 W oa o ^ ' c3 r -o C3 3 o o ;63 31) lo-i •5 .g 2 S u .a o <U "2 « H a o 1-2 P D kw- u "-^ ju a Sa 2oa o^ W3 <u - •31a —' a re 3 O ti5 na O 0) D -a > T3 o <u S .• 2> (D 3 -oo cr s « <0 (SO o -a u § .s 3 3 •3 U2 .9 ^a S iP sHa o a -o w 3 ^ c Dr HB 10. 3 0*0O ID X) T3 0W0 t/3 "73 e S 2 « 9 U 2 9 OQ OS 3 O D < T (33 U 3 G.7§ 3 . a9 H «(aD o o , •- —, I (U (N f<5 115> re O < O 3 0) re 5 o C3 .2 o I^ — 8o D CQ ( re re ,s o a I a T3 I 3 (U 3 re J3 r3e X( )U X > r) e r OC2 3 3 . ro2 e o o o O a r2 Q r < b ae o O £D 3 ^ 3 a o o, . * ro a—2 e oa U, r a o oe o --rae^o s, o o ra e 1>) T ^3 o re •O za 3 . Voa - ^ 3 re r (Ue 5i-i a u o o c re S >S :r u Se ^ u & r o 3 rSe e O( aIU C3 a 3 /2 3 c 3 3 u3 o _ r Se c 60 re bc ID 2 o -3 -s s 3 •3 O o-^ ^ 3 3 re a .9 3 " 43—1 3 O o O 116•S a jo a «o "S .a O (U a 3 « >-5 > 4J U o o X u "• "c ( 5 ( I Oo:U U Br^ 5 „ XS o oi3 a - ^a in CO " <1 o o *2 j) <<^*o ^ o- i2 cH a Oj h1" 2O 9 D2 -" ^i" < ^« -• oC la a Cc -O Ol . - I .o ( 9D V D O 3 D o3 - . 33 C ( a 2U < - w H -Wo 1 D3 l(U <p. $ O «5 O > <*-! *^ a CO 1) .a - 9a Q a 3 o l-l p4 S 5 9 2 5 .9 > O "3 II J> «* ^i to <2 o S 2 S CX^ C coj O O 1ac o aa 1 ^ a o M1a o >3 T < O3 U ^VO 3, 1w O W3 5 a s I 3D t (/ U2 . O9 o (U <u s a 00 it •9 t1/ o2 3 ^ i a t( oU 2 .9 a u c |3 1o •%o%o t3 a in o a ^ 1 a 5 3 o a C/3 •O i3 (O a, c<3 W3 CO CO O ^2i 8 CO "is; w I (350 I3SO 3 ja o o o o 4 48) ) • oa 0. 73 CO CO J3 (50 o .t5a ja 2 § H u o oa g c C (O UX 0 <«0 £ 3 J 42 a3 ) Tw« C 3O H u 4> Q V-b Ol< o cx to ^ CJ j> C aO a o " 5 < *c j( U aD O u T MO3 6 i 4)0 T t3 > S3 CO C 2gO i an 1 i VDS .> O <o 3 _ -C c (4o —3 U1 Ooa 3 h ' I2 C ? 0 S)X ^g S( C u S0 O 5, T <a CC C au O O u4 a 33 a O T X3 4 3) )> ' <1 9o a r 12 a o;;; •a 2 c n3 )r g o 4a " ). ja -S ; 4) "O ts 3 " bO 9 a a 3 u o CX 3 CO 1- -2 § a o -4 o) 43) «C CO J Xi .a -O 'o "3 " O CXja 00 i« 117« < o 1o/3 1) e bx p ta-l " oo h ^ t« •i Oh .2 o u o lu-< a u ^ •-I a CI, o o "2 o ii i-i O U5 > S 2 .a 8 o o a I— I c c3 -a a sO ^ D O a o I > "< C/ S3 o k. O "to C aO & 3 a <u 3 U (D 4— » ^ •3S CuI 1/3 3 ° a .a u a H S a T3 !/3 1/3 ^ W H H IQ D— > a o o a X ( C « ol / O 53 .t > 1 6 a/o 3^ 0j: t a-l ^ g _r T, aja 1^ .£ « 2i o PO 3 o ( 1 a/0 3 < (SO ^ ^ ^ > o ci^ O 1/3 g ja U O3 M& u o o UH c o -•T6 S 3-l0 QSc a (D .o (V- /33^h - «a O 3 o " a o J3 1y, ^ a 3 ' 1*"o 35„ -o o o .a ^ 8 o 3 ~ z . .a r4 «3 1/3 ? .a .6 a 30 i3 O 3 ^ 3 (U 00 3 C o „ a < 8 1/3 a o u > o U3 IS s 8 iCl?. ^ z 8 t S ^ a 8 u 3 !_ t 2j a i «2 .a a u a 3 ^2 O o < a g a JH 3i <U 't33 1181 I t ( wU .( 3SO .a 2 a <tj ^.a u c ^ 1 8 •4-1 o > o s C>O 1) ^ a -a ••5 •a 73 T3 .a ° E 1 3 §^ 1) o </5 1/3 O cr o u t a> « ^ o 0O0 0r OH 0 . 22 oa 5 TJ o ™ o< < cr •5b2 u CI. > a o o o -a ^ Os Ti 13/ )j 0) — 5 2 pCo a uQ -4— 3«J O S t g/5 . O lD2 -c.,a 0U 1-) T1 >35 ^ (U O U5 t/5 b .p; On U "2 IT Sit «O T3 o O to a a u X) a t/5 •4-1 a u g (3T3 1 ja CO u S -4-1 ULi •T3 •P3 =3 u l-i a" 1 !/ 23 Vm3 3 -o wa a oa U 0 1/h ) 3 >O > a^ 3 (U . -- Sti i H => 3 T3 ID ^ 2a IQ— t U3 O "5 S < o w I) "d JS o -I tJ ;/3 T3 O I/: .i.f 2 e a a s :2 fs a o '4-> t/3 > -a .!3a cr i-i o - JJ ^ 3 fa ^ T 2j S .Si. G 11 .2 "5 CO s O o e 3 Uu 2 i 8 «3 1) .a « .a -§ CQ I t/3"?3 1W/33 8 l§l O o a O Q J O O a o o 2 «3 tua uT 3 c ur^— e D < > O 0) (D s 3 ^ a < a 33 D k 3i st/3 o 8 o y -3 H o I 3 crT3 -3 -O 00 On 1192 - S I o p •a -s J3 13 S 2 g 2 o. ^3 (U .9 o O E S3 i s a i-i C/3 8 .3 ^ .9 u < J3 S X) PLI 3 cr ra u I s o 3 ( oX .SuS • .2 o O H Q t/5 > a CW/5 e ^ H 3 H Q ,sr. <9 /5 '3 Ct // 53 --J D .o 2 a S < 1) y u •±3 ( (/D J T3 ,2 o •f 3 « -U O . u o§ _ U J3 M a a lU ( «U O a t 3ifi t3 " 3cS i^ 5Q:^ 5 § a ° c o C « a 5 ^ ^ " - § a; > oj -is Q J . S52 CtJ ^ U S ^ rS 3 3 o ^ • . 3 D .2 "S -o 3* u C/2 3 a a. o < c a . O ?^ Q a Q' (u —o a 60 D < § 2 a n O 3 O < 1204.5 AUDIT PARTICIPATION IN THE SYSTEM DESIGN PHASE - PHASE III The objective of this phase is to develop detailed design specifications which describe the physical solution to the system requirements developed during Phase II, the Definition Phase.The challenge ofthisphase is to determine howthe requirements canbe satisfiedusing the computer. It may also be necessary to resolve deficiencies and clarify particular require- ments in more detail so that the computer solution canbe finalized and documented. TheauditobjectiveduringthesystemDesignPhase istoensurethatsystemrequirements are adequatelyincorporated into the designspecifications. The auditorshould concentrate on the adequacy of controls in the design. The auditor also wants to ensure that the system is auditable, and to design the methods for auditing the system once it becomes operational. 4.5.1 Primary Audit Objective fo the System Design Phase The primary audit objective ofthe system Design Phase is: "To ensure that system requirements are adequately incorporated into design specifications, including controls that ensure auditability." The accomphshment of this objective necessitates that the auditor understand the system design process, as well as the application area and the controls needed to govern that area. 4.5.2 Overview ofthe System Design Phase The InitiationandDefinitionPhases are designedto clarifyand document Sponsor/User needs and requirements. The system Design Phase takes those requirements and converts them into specifications for a computerized system. The more specific the requirement specifications, the easier it becomes to develop a workable computer solution. On the other hand, if the requirements are not correctly or fully defined, additional work will need to be done during the Design Phase in order to produce the outputs required by the Sponsor/User to satisfy his/her needs. The third phase results in a technical specification oftheproblem solution. The solution provides a specific high-level definition, including information aggregates, information flows and logicalprocessing steps, aswell as majorinterfaces and theirinputs and outputs. The pur- pose is to refine the problem, resolve deficiencies, define additional details and package the solution.Thedetaileddesignspecificationsdescribe thephysicalsolution(algorithmsanddata structures) in such a way that it can be implemented in code with little or no need for addi- tional analysis. 121[Note: Agencies should define and approve internal control/securityspecifications prior to acquiring or starting formal development ofthe applications. This is advisable for generat- ing a suitable system since few dataprocessingprofessionals have extensive training in design principles and practices, and this weak area ofsystem development needs all the loiowledge- able input possible.] The validation, verification and testing (VV&T) goals are also identified during this phase, and aplanfor achieving these goals is developed (see FIPS PUB 101).The system tests should be able to verify that required administrative, technical, and physical safeguards are operationally adequate. The Project Plan (schedules, budgets, deliverables, etc.) and Risk Analysis are reviewed and revised as required, given the scope and complexity ofthe solution formulated. These activities are coordinated with the Certification Plan components. 4.5.2.1 Participants and Their Tasks -Listedbelowaretheresponsibleparticipantsinthe system Design Phase, with a briefdescription oftheir role during the phase: 1. InformationResources Management (IRM) Official- Approves updated System DecisionPapertoadvancetothesystemDesignPhase,inconsultationwithSpon- sor or User and ADP Manager (occurs between phases), and enters system into department's formal systems inventory. 2. System Security Officer (SSO)/1nternal Control Officer (ICO) - Reviews SSO/- ICO components of System/Subsystem, Program and Data Base Specifications, and Validation, Verification and Testing Plan and Specifications. 3. Auditor(OIG) - Reviews/evaluatesandpossiblyprovidesinputstoRiskAnalysis, System Decision Paper, System/Subsystem, Program and Data Base Specifi- VV&T cations, Plan and Specifications, and revised Project Plan; updates Audit Plan. 4. Sponsor/User - Approves revised Project Plan and updates System Decision Paper; reassesses Risk Analysis; approves Validation, Verification and Testing QA Plan and Specifications (all based on recommendations, where available). 5. Project Manager/Contracting Officer'sTechnical Representative (COTR) - Up- dates Project Plan; develops System/Subsystem, Program and Data Base Specif- ications, and Validation, Verification and Testing Plan and Specifications. 6. System Security Specialist/Internal Control Speciahst - Reviews SSO/ICO com- ponents of System/'Subsystem, Program and Data Base Specifications and Val- idation, Verification, and Testing Plan and Specifications. 1227. Contracting Officer - Ifappropriate, awards contract. 8. Contract Auditor - Ifappropriate, assures contract compliance. 9. ADPManager -ReviewsVV&T componentsofSystem/Subsystem, Programand VV&T Data Base Specifications, and Plan and Specifications; as appropriate, provides technical support to Project Manager and Sponsor/User. 10. QualityAssurance (QA) Specialist-Reviewssystemdesign, VV&T components, and documentation for compliance to definition and data processing standards. 4.5.2.2 System Design Phase Documents - During the system Design Phase, three new documents will be created and three documents will be updated, all based on the work done during the Design Phase. The three new documents are: 1. System/Subsystem, Program and Data Base Specifications (FIPS PUB 38) - The purpose of the System/Subsystem Specifications is to specify the requirements, operating enviroimient, design characteristics, and program specifications. The purpose of the Program Specifications is to specify the requirements, operating enviroimient, and design characteristics ofa computer program. The purpose of the DataBase Specifications is to specify the nature, logical and physical charac- teristics of a particular data base. [Note: These may actually be three separate documents.] 2. Security and Internal Control Related Specifications (FIPS PUBS 73 & 102) - Thepurposeisto setforthsecurityand internalcontrolspecifications to meetthe functional security and internal control requirements. This document maybe in- cluded as an appendix to System/Subsystem, Program and Data Base Specifica- tions document. PUB 3. Validation, Verification, and Testing Plan and Specifications (FIPS 101) - The purpose of the VV&T Plan is to plan for the evaluation of quality and cor- rectness ofthe software, includingrequirements and design documentation.The W&T Plan also contains plans for the testing of software, including detailed program specifications, descriptions, internal contols and securityspecifications, andprocedures for alltests, aswell as testdata reduction and evaluationcriteria. 123The three updated documents are: 1. Audit Plan 2. Project Plan 3. System Decision Paper 4.5,3 Audit Survey The extent of the background work to be performed by the auditor will depend upon his/her participation in the earlier phases, as well as the project status as perceived by the auditor at the conclusion ofthe previous phase. The better the understanding the auditor has of the system, or the better controlled the system, the less preparatory work the auditor will need to do for this phase. The four tasks that the auditorwill need to perform are: 1. Review Definition Phase outputs; 2. Review Design Phase plans; 3. Review information on Design Phase status; and 4. Verify information on Design Phase status. Note that the specific work within these four tasks will be dependent upon the customized audit objectives selected forthis phase (reference Section4.5.4). These four tasks are individ- ually discussed below: 4.5.3.1 Review Definition Phase Outputs -Priortobeginningthesurveyphase ofproject design, the auditor shouldstudythe results ofthe DefinitionPhase review. Thiswould include reviewing any workpapers and reports prepared by the audit review of the Definition Phase, plusthekeydocumentsproducedduringtheDefinitionPhase.Itisalsogoodpracticetoreread Section4.4 on Definition Phase audit before reviewing the results ofthe DefinitionPhase, to reorient the auditor to the documents that are normally produced during that phase, and the types of customized audit objectives and work programs that are performed by the auditor during the Definition Phase. 4.5.3.2 Review Design Phase Plans -The Project Manager should prepare and maintain a ProjectPlan. This documentwould contain aworkplan, schedule, budget, individual assign- ments, andwork tasks to be performed by the project team. The auditor should review this to determine what work products are to be produced during this phase, the sequence in which those work documents will be produced, to whom the task ofpreparing the documents have been assigned, and the schedule and effort associated with each ofthe work documents. This will enable the auditor to know the sequencing and scheduling ofwork documents so that the auditor can develop an appropriate audit work schedule. 1244.5.3.3 Gather Information on Design Phase Status -The auditor should gather the doc- uments appropriate to the design methodology. The type ofdocuments that the auditorneeds to obtain and review during the background step ofthe Design Phase audit are: 1. System/Subsystem, Program, and Data Base Specifications; 2. Security and Internal Control Specifications; 3. Validation, Verification, and Test Plan and Specifications; 4. Updated Risk Analysis; 5. System Decision Paper (including updated cost/benefit data and analysis); and 6. Updated Project Plan. Theauditorneedstogatherinformationaboutthestatusoftheabovedocuments.Specifi- cally, the auditor should determine: 1. Status ofdocument -Are they complete? Ifnot, is additionalworkplanned to be undertaken to complete the documents, and ifso, when will they be done? 2. Has the project proceeded according to the Project Plan? - Ifnot, what action is being taken to get the project back on target? 3. Have anychangesbeenmade to theproject's functionality or architecture? Ifso, the auditor needs to assess how they may impact the customized audit objectives for previous audit phases and this phase. 4.5.3.4 Verify Information on Design Phase Status - The work done to verify the infor- mation on Design Phase status will be based upon the customized audit objectives selected. 4.5.3.4.1 Review Documents - The flow of work will depend upon the specific system developmentmethodologybeingused.Figure2representsthe more traditionalflowofpaper- work in the SDLC and includes the Design Phase. This figure shows the input from the pre- vious phase, the documents and document updates produced during this phase, and the sequence inwhich they are produced. Formanydatabase systems,prototype systems, and skeletalcode systems, programming commences immediately after the Definition Phase. About the only parts of the identified Design Phase documents that the auditor could expect to find are: 1. Operating environment, design characteristics, and program specification parts ofthe System/Subsystem, Program and Data Base Specifications. 1252. Security specification part of the Security and Internal Control Related Spec- ifications. [Note: While internal controls are very important, they may not be in- cluded in this document because the control portionmay not have been deemed necessary in the initial prototype version. This decision to develop without con- trols contains serious risks since the subsequent inclusion of controls may intro- duce major alterations in system behavior and cost.] In the newer developmental methodologies, the Sponsor/User may do the testing him- self/herself by examining the output to determine if it meets needs. If, however, the system must fulfill a significantbusiness/organization function, thenthe auditorshould expectto find at least a minimal test plan, regardless ofthe type ofdevelopmental methodology. 4.5.3.4.2 Interview the Participants - The role of the responsible participants will also vary depending on the system development methodology. For example, in prototyping, the SponsorAJserhasaveryactiveroleinworkingwiththedevelopersthroughaniterativeprocess ofdesign and implementation. Theauditoris concernedfirstthattheproperresponsibleparticipants are includedinthe system Design Phase, and second that they perform their proper roles. Again, note that the names used for responsible participants may vary from agency to agency. What the auditor mustdo, ifthe individualslistedherearenotinvolved, is to determinewhetherornotthefunc- tionsareperformed, and ifso,isthereadequatedivisionofresponsibilitiestoensuretheneces- sary checks and balances for an effective system design. The questions that the auditors should ask ofthe responsible participants include: 1. Information Resources Management (IRM) Official (a) Has the System Decision Paper been approved? (b) Has the system been entered into the department's formal system inven- tory? 2. System Security Officer/Internal Control Officer (a) Have the SSO/ICO components ofthe system/subsystembeenreviewed? (b) Have the SSO/ICO components ofthe Program and DataBase Specifica- tions been reviewed? (c) Have the SSO/ICO components ofthe Validation, Verification, andTest- ing Plan and Specifications been reviewed? 3. Sponsor/User (a) HastherevisedProjectPlanandupdatedSystemDecisionPaperbeenap- proved? 126(b) Has the Risk Analysis been reassessed? (c) HastheValidation, Verification,andTestingPlanand Specificationsbeen approved? 4. Project Manager/Contracting Officer's Technical Representative (COTR) (a) Has the Project Plan been updated? (b) Have the System/Subsystem, Program and Data Base Specifications been developed? (c) Have the Validation, Verification, and Testing Plan and Specifications been developed? 5. System Security Specialist/Internal Control Specialist (a) Have the SSO/ICO components ofsystem/subsystem been reviewed? (b) Have the SSO/ICO components of the data base specifications been reviewed? (c) Have the SSO/ICO components ofthe Validation, Verification, andTest- ing Plan and Specifications been reviewed? 6. Contracting Officer (a) Has the Contracting Officer, ifappropriate, awarded the contract? 7. Contract Auditor (a) Has the Contract Auditor, ifappropriate, assured contract compliance? ADP Manager 8. VV&T (a) Have the components ofthe system/subsystem been reviewed? VV&T (b) Have the components of the Program and Data Base Speci- fications been reviewed? W&T (c) Have the Plan and Specifications been reviewed? (d) Has technical support been provided to the Project Manager and Spon- sor/User, ifrequired? 9. Quality Assurance Specialist VV&T (a) Have the system design, components, and documentation been reviewed for compliance to definition and data processing standards? 4.5.4 CustomizeAudit Objectives The audit objectives established for each AIS will vary depending upon (1) the purpose, objective, and scope of the application, and (2) the auditor's concern over the ability of the project team to successfully complete the project. This section offers a standard set of audit 127objectives/indicators for use by the review team. However, this listwill need tobe customized by the audit team, based upon their assessment ofthe AIS under review. 4.5.4.1 Design Methodology Audit Considerations - The auditor may encounter sig- nificantly different design methodologies from agency to agency and system to system. While the Initiation and Definition Phase of system development remain fairly constant, there are manydifferent methodologies for designingcomputersystems. Among the more common ap- proaches (which can be used singly or in combination) are: 1. Life cycle oriented design methodologies - The organization of this manual is oriented toward the life cycle designmethodology. In this concept, there are dis- tinct phases during which the design evolves. Each phase is distinct, producing deliverables (i.e., products) which are input to the next phase. 2. Structured design methodologies - These are similar to the phase design meth- odologies, except the documents produced are different. The structured design methodologies usually use Warnier-Orr diagrams to graphically illustrate the logic paths throughout the design structure. 3. Data base management systems - The significant difference between data base and non-database is the responsibility for data design. In database systems, data design is performed by data base administrators, and the utilization ofthat data requires a new series ofdocuments. 4. Skeletal code - This is a design concept normally oriented toward a data base structure.The keydesignconceptisthepartialconstructionofprograms. Inmany instances, one half or more of the program will be precoded in a generalized or skeletal format. The designers can pick and choose among these skeletal pro- grams for use in meeting Sponsor/User needs. In addition to the skeletal code, the designers may choose utility programs, general-purpose programs such as data retrieval and analysis or report generators, as well as languages provided by data base and data communication software. 5 . Prototyping-Prototypingis one ofthenewerdesignconceptswhichincorporates two new design principles. The first is an interactive design process. Prototyping recognizes that it is very difficult to define requirements correctly the first time. Therefore, prototypingproduces asystem as quicklyas possible sothat the Spon- sor/Usercandeterminewhetherornotitmeetsneeds. Ifitdoes not, theprototyp- ing process continues until the right system has been designed. The second characteristic of prototyping is the collapsing of system development phases. 128After basic requirements are done, the system design and remaining phases are normally collapsed into a single phase. The auditor must first determine what design methodology is used, and then learn the functional aspects of that design methodology. The documents identified in this audit guide mayvary significantly in this phase fromwhat the system design group actually produces. For example, if prototyping or skeletal code is used, then much of the information contained in the system design documents described in this audit guide may not be necessary. When the auditor encounters anunusual design methodology, the auditor should: 1. Reconcile the design methodology to the Hfe cycle development methodology described in this audit guide. Ifthe same basic information is produced, then the auditprograms outhnedin this auditguide are applicable. The auditorneed only customize the audit approach to the specific design methodology. Ifthe auditorcannotreconcilethe actualdesignmethodologytotheoneimbeddedinthisaudit guide, then the auditor should: 2. Study the design methodology sufficiently to see how the life cycle phases inthis auditguide are collapsed bythe methodology and regroup the auditprograms to conform to this condensed life cycle. It would then be a matter ofjudgement to decide what parts ofthe audit programs are applicable to this situation. 4,5.4.2 Contracting/Purchase Audit Considerations - There will be significant differen- cesinthe auditinvolvementinthisphaseifthe software is contractedorpurchasedratherthan developed in-house. For contracted software the auditor may: (1) interface with contractors; (2) be involved in evaluating requests for bid and analysis of those bids; and (3) be involved inthe selection ofcontractors from an audit perspective. Ifthe software is purchased off-the- shelf, then the auditor may be involved in that purchase to ensure that the acquired software meets the requirements established in the previous phase. For contracted software, the Project Manager or the Information Resources Manage- ment Official oversees the project during this phase to ensure objectivity of results and to preclude conflicts of interest between project goals and contractor expediency. The Auditor then oversees this activity to ensure its effectiveness. For off-the-shelfsoftware, the Sponsor/User reviews the proposed procurement for suf- ficiency; the Project Manager identifies and appoints a technical evaluation panel to review technical competency ofbids/offers; and the ADP Manager reviews requirements documents as well as provides technical assistance to the Contracting Officer relative to development of 129theprocurementaction.TheAuditorthenassuresthatallthese activitieshavetakenplaceand with appropriate care. For software that has been purchased or contracted, the auditor should address the fol- lowing specific points: 1. Has the contract been prepared in accordance with government purchasing re- quirements? 2. Does the contractprovide for audit review ofthe contractor/developerwork? 3. Ifthe contractor goes out ofbusiness, does the government obtain source code forthesoftware (inthecasewherethecontractordoesnotprovideoriginalsource code)? 4. Does the contractor/developer have appropriate controls and safeguards to as- sure the quality of the software being produced (e.g., a quality assurance func- tion, a detailed testing methodology)? 5. Does the contractprovide for maintenance ofthe software? 6. Does the contractor/vendor have a test plan? 7. Does the contractor/vendor develop essentially the same documents as defined in this audit guide? 4.5.5 Detailed Audit Testing 4.5.5.1 Introduction - Duringthe detailed audittesting, the auditor needsto concentrate on the three new documents created during the Design Phase, not, however, to the exclusion ofthethreeupdateddocuments.Theauditorshouldbeconcernedthattheupdateddocuments correctly reflect changes made in the areas covered by those documents during the Design Phase. The amount ofvalidation that the auditor will do on both the new and updated docu- ments will be dependent upon the degree ofrisk associated with the appHcation system. The greater the risk, the more extensive the validation. 4.5.5.2 System Design Phase Audit Test Program - The following system Design Phase auditprogram is aprogramforvalidating the Design Phase documents. This program is audit objective driven. For each objective to be accompHshed during vahdation, the auditor is providedwith aseries oftests toperform.Foreachtest, some toolsand techniquesare recom- 130mended. Note that in this phase, automated tools are proposed, but the use of these will be dependent upon their availability at the installationwhere the review occurs. (See Table 4.3) Indesigningan auditprogramforthesystemDesignPhase, the auditorshould read FIPS PUB 101. That document provides guidance on vahdating system Design Phase products. While the pubhcation was developed for data processing personnel, the validation insight in the document is equally helpful to the auditor inpreparing for and executing asystemDesign Phase review. 4.5.5.3 Survey Questionnaire Design Phase - The document verification process re- quires the auditor to examine the documents to ensure they are complete, reasonable, and consistent between documents. Verification can best be done by using a checklist provided with the system design methodology. However, ifverification has already beenperformed by data processing, quality assurance, or a project review team, the auditor may want to ensure the quahty of the designer's work and, ifit is determined to be satisfactory, then perform the validation step. Questions to ask for each document include: 1. System/Subsystem, Program, and Data Base Specifications (a) Does the document specify the design requirements? (b) Does the document specify the operating environment? (c) Does the document specify the design characteristics? (d) Does the document specify the program requirements? (e) Does the document specify the program operating environment? (f) Does the document specify the program design characteristics? (g) Does the document describe the functions and performance require- ments? (h) Ifso, are theseperformance requirements describedinterms ofaccuracy, validation, timing and flexibility, and also the operating environment? (i) Is the nature, logical, and physical characteristics of data bases used specified? Does the Data Base Specification address storage and design considera- (j) tions? 2. Security and Internal Control Related Specifications (a) Does the document specify the security design? (b) Does the document specify the internal control design? (c) Does the security design meet the security requirements? 131(d) Does the internal control designmeet the internal control requirements? (e) Are the security and internal control specifications in sufficient detail so thattestscanbedesignedthatwilltellwhetherrequirementsaresatisfied? (f) Are changes to the system evaluated to determine whether they impact internal control or security design? (g) Ifso, is internal control and security design changed accordingly? (h) Ifthis is a sensitive application, has itbeen reviewed and approvedbythe party responsible for security and control? 3. Validation, Verification, and Testing Plan and Specifications (a) Does the document include a plan for testing the software? (b) Does the plan include detailed specifications, descriptions, and proce- dures for testing all systems? (c) Does the test plan include test data reduction and evaluation criteria? VV&T (d) Is the Plan related to the system plan? VV&T (e) Does the system plan drive the Plan? VV&T (f) Does the Plan include general project background and informa- tion on the proposed solution to the mission deficiency(ies)? W&T VV&T (g) Does the Plan include requirements, measurement cri- teria, and constraints? W&T (h) Does the Plan include procedures to be appHed during develop- ment in general and by phase? W&T VV&T (i) Does the Plan include supporting information for selec- tions made? (j) Does this document include appendices which describe project and en- vironmental considerations? (k) Does this document include appendices which define the testing techni- que and tool selection information? 4.5.6 Audit Results/Reporting The resultsoftestingneedtobe analyzed, conclusions and recommendations developed, and that informationpresented to the auditee inreport format. The report should identify the potential deficiencies, indicate the potential effect of those deficiencies on meeting the sys- tems mission, and then present recommendations to overcome those deficiencies. 4.5.6.1 Potential Deficiencies - The deficiencies found will vary from application to ap- plication. However, experience has shown that certain deficiencies are common in the Design Phase, and, if these deficiencies are not corrected, serious application problems will occur 132during implementation. The following eight deficiencies are listed to assist the auditor in as- suringthatthetypesofdeficienciescommon todesignhavenotbeenoverlookedinthisreview: 1. System design documents will not be prepared, or not prepared in accordance with the document intent. 2. The system ofinternal control will not be fully developed. 3. The security procedures designed to protect the appHcation will not be fully developed. 4. Needed transactions for processing application information will not be defined, and/or the authorization rules for transactions will not be defined. 5. The audit trail that permits reconstruction ofprocessing will be incomplete. 6. An applicationvulnerability assessment will not be performed, orperformed in- adequately, so that all major potential vulnerabilities may not have been iden- tified, and thus the system design is incomplete. 7. The systemasdesignedwillnotmeetthe true Sponsor/Userneeds, and the Spon- sor/User will not have had the opportunity to review the design documents and comment on the inadequacy. 8. The phase will be concluded without the Validation, Verification, and Testing Plan being completed. 4.5.6.2 Potential Effects ofDeficiencies on Meeting System Mission - At the conclusion of the Design Phase, both the functional and structural aspects of the AIS have been estab- lished. Ifthe designhas beendone correctly, the followingphases need onlyfollowthat design andthe system'smissionshouldbe accomplished. On the otherhand, ifthe design is deficient, then an inadequate system might be implemented with potentially disastrous results. The effect of design deficiencies is twofold. First, they will impact on the implementa- tion, which will cause resources to be improperly utilized. Data processing personnel will be implementing the wrong system, and when it is uncovered will have to take out those incor- rectlyimplementedportions and redesign and reimplement the system. The cost ofdoing this rework can exceed the original cost ofimplementation, and frequently does. The secondary effects of design deficiencies are on the users of the AIS. Unless the deficiencies are caught in the Programming andTraining Phase, or in the Evaluation and Ac- 133ceptancePhase, theywill resultin incorrectorincompleteprocessing.The result canbe finan- cial loss, or it can be lost opportunities to effectively perform the agency's mission in accord- ance with the intent oflegislation. 4.5.7 Reassess Audit Strategy The audit strategyneeds tobe continuallyreviewed asthe systemprogresses throughthe developmental phases. The auditor will be looking at three aspects of audit strategy in the Design Phase as follows: 1. Reevaluate auditor's role in the design - The auditor needs to continually assess whether more or less audit effort is needed during design. If the system is progressingaccordingtorealisticschedules andbudgets,and theimplementation reflects the approved decisions ofthe previous phase, the amount ofaudit invol- vement can potentially be reduced. On the other hand, as the number of un- covered vulnerabilities increases, the greater the need for more audit involvement. Inparticular, internal control or securityweaknesses signifya need for greater audit involvement. 2. Ensure auditability of system - The auditor wants to ensure that the architec- ture/structure of the system provides the necessary features to make the system auditable. Reviewing the audit objectives for the Design Phase basically satisfies this aspect ofaudit strategy. For example, ifthe systems ofcontrol are adequate, ifthere is an adequate audit trail, and ifthat trail is saved for a reasonable time, then the system is normally auditable. As there are deficiencies in these areas, the system becomes less auditable and the greater the need for a specific audit recommendation to improve auditability. 3. Developmentofauditprogramsforthefinishedapplication-Asthesystemdesig- ners are designing the system, the auditors should be designing how the system will be audited once it goes into production. This means the design of audit programs, and the design/acquisitionofanyaudittools necessarytoperformthat audit. For example, the auditor may want to develop a skeletal extract program whichcanthenbecustomized for specifictransactions ormaywant to haveanin- tegrated test facility included in the system during development. 1341 » ' a :d 2 a a T3 o o 3 9 T q1O CS ,) O — X r0 s) 3 ^O >^ (1 L/ >3 O J tH0 3 3 0 0 o C 1n J )- c 0 ^ t"o —o £ Ml o -o a o ci, .T a3 ob iO a. J1 c/9 3 o a ^ -( o 1C /D 3 2C . CWA OO o >o 3 C uCO, T " O a1^ .• i2 o 33o : ^ . 3 oS r Xc X ii )Js 1 at 1o /s 3 o alu 1 Cl / oOd 1 nt u a 3 0ed o o Ci3 J3 O ^ «3 - <-o ola -l - J3 7 1 33 ) < .i° a 23 O 8 2 € I T3 . '1o a/ 33 . 3a ^ 1/3 1 s oc l2 ! s tU3 r 1u /i c 3t 5tU csi w b a C Ce /O 1 00 3 ^ a« ^Hi * .-S 4 a— ^Su « 3 . D 2 a2 - • o a ^a <> U au Ss 132 •? 1) i|o CC i OO .^ SO C li2l T "1 <1 1 CO5^/ -U O3 .3 O c 1 o/3 w tC 0 < kD h s.D h t< 13 c oe / aD r3 n D 0,t eHr c 0 t u do j .l O o ' >d :o S T3 c« ( CD w a 1/1 s CI- 5 H : 22 g 1= <= 5 0c .T 3 C3 O •C C0O O Q 1/1 D T3 -O ID =^ ^ C CO -fi M a CO zo ^ I aD W 00 si^" C- Oi " -I1 O2 / D1 .C1 C o2/ O3 5 a a o Ci j J I ID D 3 I a ID D U ( c/3 -C ( acCO D w. ID "l lo -O i . -= iia -^ «i tu I C C< D O o H u t < C: O^-2 iv^ID£ID IO o3D E •-ICO I a 3 o OD e CO I!- D! Ic aDj .r X3a I 8 I oD " o = X c 2u 0W Q 0 > C0 ^0 O I H Q O < £ "Ol aku 1^ - to ( c5 / o5 30 I 3 5D Jt IC C3j D Ou T X :I 3 g >a3 )D 1 C/ O3 lJ2 I I t3 ID C/ o DS D D i. " w C a U ^C § V Do -J O O) .-. -o C ( i 1 <12 / /S O D Di 3 JTB %D a U Ca 1 ID a33i -O ) ^ --C < t ( I I3 > 1 C C a5=D D DD O0 0 TT r T J§ I C I I ^a S33 3 DD O D1 fo O o o a u « 1 Ia /3 D3 ^ sO ^ I I ICD D DO - -To c C g 3 o2 aJ 5 - 3 11 C I I§ 5/ J D3- SI C ^ a 3 i o.D O 2 I UO3d o ^a - 2ac a "S Qu I£ D J! 3! ta s o U§ 2 a 0I ^D Jc a .V I aD a .a 1/3 ^ a o 73 I C/2 •2 f3 O Sa 2 T 7 u o c3 3 i 5 Ca 2i OP, "X •C oO 3O —u I 2D I& c aDo . 1 1 83 / /3 3 23 Ua § 1/3^ Ia 1 I/D D3 - t 2s .^ 2 .c 12 /3P.& o k> c C/ O3 "t DOo a jo 1= /1 -2 .0 T3 & U — O ^ S z ' _PUO hi' —I fjD - Co a ID — IC SO 2 JI 3D I& D 1/3 .1I1 -/ D "3 CO t > 1/o 3^ ^< ^ >^ % 3 ^ o CJ 1^ 2 D- "5 t Ii D yl a 3O ID (D ID T 1 C3 ) O 1 3> H 3 co i£ I3 D 1 a- . '1 C aO o. o3 n 1/3 i2 Q; . 1 I/ D^ 135I — r to ^ O o W o S ^ O 1-1 I— u w H 3 O J3 2 5 pq D o S2 ^ o ty5 at S a ^ J3 a CO O a .ta cr u S,.2 .a O T3 O o <u H <u a 1 w o H a o H 5 ^ a < T3 C O O > ' o'^> •a Saoa O O CO •r Jo3 e « o o O 1S-, <au c o a §2 o j3 el ^ 5 JC 3O ^ 8 O V5 -Ha U COQ Q' T3 3 136, . Io-1 I 1e/3 <S o .a .2 0 PZQ0 .a o re 1 (/ 13 1 re 0 U0 red c/3 rul( ned a N 2 3 D O O ti de 1 39 o all i-i t X o 1/3 ha re are _> re u IS w JO 3 T13/3 use re n rd e .9 1« . •3 S ! o3 tion vaJid o ransa < a a o o c (D o K -9 1a/3 3 1O/1 o h 12 o 1/3 C3 ll niq c C I DD , O jl IO D r C2e , <u J2 Mo o o iew ave 3 re o < «u 3 lO re J r3 e i> 1 « (oo/ 3 D1 c,O r 1> /e 3aU ( r3 D e j oa SID o 19 r 13/e 3 '-3 ^ 1- -I oD j2 a a o o =re s a ^ 3 W -f HIl ;D .^ - .'-S ' . 3^ a J§ 2 o r 1Ce ^ 3 o o 3 O H C ^ ^ . i-2 l c u 1/3 a 3 0U H H Q0 - oa a 3 O o ^re -c o ( I50 ID « O r Sov & 1 U/3 *I ^ r © jD e O° 3 Oe re X° o1 i/3 D < - '• Q4 "a I r Io 1UaB E^ SD e D - X tC 1 r 2 r3 o 1 r) / /e e e3 3 i £c O 1 r ( I1 a/ /e D D3 3 |^ — ? 3">I r lS- -eI i . • •D ra c o S o c5 Se. P -ao u <^ 4— D1 1 | j I >r I ae D1 T s1 3 r a a3 e . 'T - 7^ riI r c I ^ 3 r3 3 3eD e D e2r - .2Io 3 O o O Cc B aD ub i— T2w -O " rr o 3 33S ee re 4j -4—1 (D 1 1/) 1 r te 2 0W0 r 1/e 3 I3D Oh i i 3 Bo ^ U .3 a 3 t9 .r 3Se X -i O . 1"2 /f 3 CQ i« • 3I Cg e O Q D T3 re -( OD S -3 " < .<3 aD lis - 2D 1:1 3 (1/ D3 3 o o Q »3 -S re .a 1373 o o o o ID I 2 o ^ ^ <^ 5b a ^ a CD U H W H lQ-H D < 3 " < E S </} ,o CO Cu >> Q ' D > CO .s 1 § i < a CX CO 138H ™ 0o0 < S o u u T3 > to o Si -o > o ^ CO PQ D CQ a b Ph < Oh W o (50 U • • « s: 13 s s •9 .-^ O t/3 1) to 3 O .3 a t 8 .9 2 5"3 O (U cr g H -O <^ ^ s H c o IQ— to P < O O •SI 1a3 to -i-i a S > 3 u « to < cu x'52 ! X on o 3 cr ( ^D iOI t C- li . U CO W U > ^ .S " :2 « « JO a o u (SO g b. CI cQa T3 ^ g ^1 to U .2 ^^ O M13 m -a ^3 «3 ca .2 n a >1 SCO 3 w U ( (UT.i3a to_ T3 .ft T3 crja u to (U d, ^ _ ^ j!^ 3 ta -3 O o4—1 H"2 i o i o <a 5 ^ < .b 3o -3 g § 00 On 139< O 5ID O o gB 8 a o 2 a o J3 O Re*-' U o o Q .a gB2 PS o a 3 a ^ 2 <U 3 o X) a- — o a u u a o Cl. _a cd W H 3 w 03 o H goB oa H 1? 13) T^3 33 "o a Q u Q Q ^ " < o « - 8a | ^ .S W2 3i P o O o a u (U u - ^a ' <aO o .^i2 ^(u c gfl . a 8 o X) 1-1 TO 4-1 s •s a -o a 3 >03 J5ij xo : W -4—' 73 S" > nj =O^ a o, S g S 3 0W0 ^ a -o (U a-^ a -o CQ U -73 a I >/? ^ "oC tfl _a 1) <u 5u a 3 2^ XJ < 8l O (U a N l3-l 1U/3 < V3-^ ( n J 35 > ^ <C aU ^ a 1404.6 AUDIT PARTICIPATION IN THE PROGRAMMING AND TRAINING PHASE - PHASE IV During this phase, programs will be developed and tested. The implemented programs should be based on the detailed design/program specifications prepared in Phase III. If the designwaswellspecified, thisphasewillnotbe technicallydifficult, but ifthere are gaps in the specifications, thisphasewill be required to compensate forthose gaps because programming is very detailed and requires all decisions to be made before the code can be written. 4.6.1 PrimaryAudit Objective ofthe Programming and Training Phase During this phase, but prior to approval ofthe System Decision Paper by management, the auditor should accomplish these two primary objectives: "1. Ensure that the program/system fully implements the design specifications. 2. Ensure that documentation and training provide for a usable and maintainable system." The auditorwill accomplish these objectives through an evaluation ofthe Programming and Training Phase documentation. In order to do this, the auditor must understand the sys- tem development methodology, the documents that are produced by that methodology, and the flow in which the documents are produced. The auditor must also understand the status ofthe dataprocessing training program. The documentsproduced duringthisphasewillvaryfrommethodologyto methodology. Even the same methodology may be implemented differently between two or more agencies andthus produce different documents. In addition, ifthe software is contracted orpurchased, the documents within this phase will change dramatically. Also, as discussed in the Design Phase, if the newer design concepts are used, such as prototyping, the programming part of this phase may not exist and the training aspect may be significantly reduced. 4.6.2 Overview ofthe Programming and Training Phase Programming istheprocessofimplementingthedetailed designspecificationsintocode. The process of converting specifications to executable code is primarily dependent upon the completenessand specificityofthe programdesign. Iftheprogram iswell defined, theprocess ofprogramming is not technically complex. Most system development methodologies clearly define how systems move from the design to the programming phase. In fact, most data processingprofessionals are well trained inprogramming,but fewhave extensive trainingindesignprinciples andpractices.Thus, from 141a technical perspective, programming is frequently the best specified, and the most mastered skill. Although training is associated primarilywith the ProgrammingandTrainingPhase, the originsoftrainingshould commenceearlieras arequirement.Trainingis aspecialty,butmuch ofthe success ofthe system will be directly attributable to howwell the users are trained. For those parts of the system which they do not understand well, the probability exists that the users will not use those features, orwill use them incorrectly. Both impediments to a success- ful system canbe overcome through the proper development and use oftraining materials. Training is often excluded from the system development methodologies. Where it is in- cluded, it usually does not adequately address specific training requirements. Therefore, the auditormightfindaverystrongdevelopmentalmethodologyforprogrammingbutaveryweak methodology for training. BesidesProgrammingandTraining,UserandMaintenanceManualsarepreparedduring the fourth phase (see FIPS PUBS 38 and 64), as is a prehminary Installation Plan which specifies the approach to, and details of, the installation of the AIS. This phase results in programs which are ready for testing, evaluation, certification, and installation. 4.6.2.1 Participants and TheirTasks -The Programming andTraining Phase involves all ofthe same participants thatwere inthe DesignPhase. However, the projectplanners may as- sign different people to the Programming and Training Phase than they did for the previous phases. The responsible participants and their functions during this phase are: 1. InformationResources Management(IRM) Official- Approves updated System ADP Decision Paper to advance to Phase IV, in consultation with Sponsor and Manager (occurs between phases). 2. System Security Officer (SSO)/Internal Control Officer (ICO) - Reviews SSO/ICOcomponentsofUserManual, Operations/MaintenanceManual,Instal- W&T lation and Conversion Plan, and revised Plan and Specifications. 3. Auditor - Reviews/evaluates revised Project Plan, System Decision Paper, Validation, Verification and Testing Plan and Specifications, User Manual, Operations/MaintenanceManual, andInstallationandConversionPlan;updates Audit Plan. 142VV&T 4. Sponsor/User-ApprovesrevisedProjectPlan,revised PlanandSpecifica- tions, User Manual, Operations/Maintenance Manual and Installation and Conversion Plan; updates Systems Decision Paper; initiates user training. 5. Project Manager/Contracting Officer'sTechnical Representative (COTR) - Up- VV&T dates Project Plan; revises Plan and Specifications; develops User Manual,Operations/Maintenance Manual, andInstallationandConversionPlan. Project Manager is responsible for programming and testing. 6. SystemSecurity Specialists/Internal Control Specialist - Reviews SSO/ICO com- ponents of User Manual, Operations/Maintenance Manual, Installation and VV&T Conversion Plan, and revised Plan and Specifications. 7. Contracting Officer - Ifappropriate, awards contract. 8. Contract Auditor - Ifappropriate, assures contract compliance. 9. ADP Manager - Reviews VV&T relevant parts of User Manual, Opera- tions/Maintenance Manual, andInstallation andConversionPlan; provides tech- nical support to Project Manager and Sponsor/User; may conduct training. 10. QualityAssurance Specialist (QA) - Reviews program definition, program code, documentation,andtraining, forcompliance todesignanddataprocessingstand- ards. 4.6.2.2 Programming and Training Phase Documents - There are three new documents produced during this phase: 1. User Manual (FIPS PUB 38, DOD-STD-7935, OMB A-130, OMB A-123) The purpose of the User Manual is to sufficiently describe the functions performed by the software in non-ADP terminology, such that the user organization can determine its applicability, as well as when and how to use it. 2. Operations/MaintenanceManual(FIPSPUBS38& 106,DOD-STD-7935, OMB A-130, OMB A-123) Two separate manuals may be necessary. The purpose of the Operations Manual is to provide computer operations personnel with a descriptionofthe software and the operational environment so that the software can be run. The purpose of the Program Maintenance Manual is to provide the maintenanceprogrammerwith theinformation and source code necessarytoun- derstandtheprograms, their operatingenvironment, and theirmaintenancepro- cedures and security requirements. 143PUB 3. Installation and Conversion Plan (FIPS 101, "Implementation Procedures" DOD-STD 7935, OMB A-130, NBS SP 500-105) The Implementation Procedures are a tool for directing the installation or implementation ofan AIS at locations other than the test site. This tool is used after testing ofthe AIS, in- cluding security and internal control features, has been completed. 4.6.3 Audit Survey The Programming and Training Phase implements the system design. The auditor will have two challenges during this review. The first is to ensure that the implementation is con- sistent with the design; the second is to review the controls over changes. The survey will provide the auditor the background necessary to accomplish these tasks. 4.6.3.1 Review System Design Phase Outputs - As the Hfe cycle progresses, the size and detail contained in the system documents increases. The design document reviewwill be sig- nificantly more time consuming than the Initiation and Definition Phase document review. Forthat reason it is importantforthe auditor to focus the review on the key elements ofthose documents. The auditor should concentrate the review on (l)the Security and Internal Control Re- lated Specifications, and (2)the Validation, Verification, and Testing Plan and Specifications. Therole ofthe auditor, as definedinGAO's auditstandards, is heavilydirected toward assess- ingthe adequacyofinternal controls andsecuritycontrols. Inorderto dothis, the auditormust understand the design specifications for those controls. Thus, in reviewing the Programming and Training Phase, the auditor should concentrate on the adequacy ofinternal controls and security controls. Inthe evaluation ofinternal controls and security, the auditorhas three activities to per- form.The first is to identify the magnitude ofthe riskfacingtheAIS. Second, the auditormust determinewhat security controls and other internal controls are in place. The third activity is to determinewhether the controlswork. Based on these three activities, the auditor makes an assessment as to whether the working controls are adequate to reduce the risk to an accept- able level. The auditor's opinion is based on this assessment. The Validation, Verification, andTesting Plan provides the standards againstwhich im- plementation will be measured. This plan defines the test conditions that will validate con- trols. This document will indicate how the project team plans to implement the controls. Assuming that the auditor has reviewed these documents, the two define precisely how the controls shouldbe implemented, and thusprovide the guideHnesfor conducting theprogram- ming review. 144Training is an essential aspect of tlie proper performance of the operational MS. The auditor's concern in training is that the controls will be properly exercised. Thus, the analysis of the previously discussed two documents provides the background the auditor needs for evaluating training in the use ofinternal controls and security controls. 4.6.3.2 Review Programming and Training Phase Plans - Project teams which have firm implementation dates for AISs may need to make implementation compromises in order to meet those dates. If the project is late going into the Programming and Training Phase, the auditorcouldexpectmanyofthose compromises to occur.Two areasfrequentlycompromised are implementationofinternal and securitycontrols (including documentation), and develop- mentoftrainingprograms.The elimination orcurtailmentofeitherorboth ofthese areas may not directly impact the functional correctness of system outputs. In other words, the system may be able to produce the desired reports yet not in a controlled manner, or in an environ- ment inwhich the users are trained. It is the intent ofmanyproject teams to install these areas after implementation. The auditor wants to ensure that the Project Planis sufficient to guarantee that controls and training are adequately implemented. The plan should indicate who is responsible for these areas, and how they are to be implemented through specific documents. In reviewing the plan, the auditorwillwant to assure that the necessary control and trainingdocuments are included in the plan, and that there is sufficient time and resources to accomplish them. 4.6.3.3 Gather Information on Programming and Training Phase Status - Controlling system change is particularly troublesome during the Programming and Training Phase. It is duringthisphase thatitems are implemented onaverydetailed level. Since a computerworks in a binary mode, performing one event or another, there is no room for vague implementa- tion.Thus, there are normally many clarifications ofdesign duringprogramming. The auditor wants to ensure that these changes are received, logged, controlled, and implemented in an orderly manner. The auditor shouldbe particularly concerned, during implementation, about documents either not being produced, or being improperly or partially produced. The review of this phase's status should look not only at the status of the project, but at the status of the com- pleted documents. Again, the auditorshould be alert to the fact that ifthe project falls behind schedule, there is a strong tendency in many projects to delete the nonessential aspects of design, at leasttheproject'sviewofnonessentialdocuments, inorderto meetthe implementa- tion date. The auditor should gather the following six documents during the Programming and Training Phase: 1451. System Decision Paper (updated) 2. Project Plan (updated) 3. Validation, Verification and Testing Plan and Specifications (updated) 4. User Manual 5. Operations/Maintenance Manual 6. Installation and Conversion Plan Note that in different methodologies the same information may be in different docu- ments. Ifthe auditoris involved near the end ofthephase, all ofthese documents should have been produced. If the auditor reviews throughout the phase, then he/she may be able to get the documents and perform the review at the point those documents are prepared. 4.6.3.4 Verify Information on Programming and Testing Phase vStatus - The auditor should be looking for two general areas in verifying status. First, that internal controls and security controls are properly implemented, and second, that all of the design specifications are implemented. 4.6,3.4.1 Review Documents - The flow of work must be compared against the system development methodology in use. Ifother documents are produced, they should be included and if indicated documents are not produced or updated, that, too, should be noted. Where documentsare notproduced orupdated, it is normallyindicative ofapotentialprobleminthe application design. Verificationrequires the auditorto reviewthe documentsbeingproduced to ensure that the appropriate information has been collected, recorded, and is consistent with previous documents. Verificationisprimarilya quality controlresponsibility, and shouldbeperformed by the project team. In some organizations, it is performed by the quality assurance function. If it has been performed, the auditor need only test check to make sure the quality control functionisworkingeffectively.However, iftheprojectdoesnothave adocumentationverifica- tionprocedure in place, the auditor may need to do more extensive verification. The auditor, during the Programming and Training Phase, needs to verify three new documentsandthreeupdateddocuments.Theverificationquestionstobe usedforeachdocu- ment are the following. They are not listed in any priority order. 146User Manual verification questions (a) Are the functions described sufficiently? (b) Is the User Manual written in non-ADP terminology? (c) Does the manual indicate when and how it is to be used? (d) Does the manual serve as a reference document? (e) Does the manual explain how to prepare input data and parameters? (f) Does the manual explain how to interpret output results? (g) Does the manual provide a full description ofthe application? (h) Does the manual explain all ofthe user operating procedures? (i) Does the manual explain user responsibilities related to security, privacy, and internal controls? Does the manual describe how to detect and correct errors? (j) (k) Does the manual describe how to recover operations? (1) Does the manual describe how to perform a file query procedure? Operations/Maintenance Manual verification questions (a) Does the manual provide computer operations personnel with a descrip- tion ofthe software? (b) Doesthemanualprovidecomputeroperationspersonnelwiththe instruc- tions necessary to operate the software? (c) Doesthe manualprovidecomputeroperationspersonnelwith sectionson non-routine procedures, remote operations, and security requirements? (d) Does the manual provide computer operations personnelwith error pro- cedures? (e) Does the manual provide computer operations personnel with recovery procedures? (f) Doesthemanualprovidemaintenanceprogrammerswiththeinformation and source code necessary to understand the programs? (g) Does the manual provide the maintenance programmerwith anoverview ofthe architecture/structure ofthe system? (h) Doesthemanualprovidethemaintenanceprogrammerwithmaintenance guideline procedures? (i) Does the manual provide the maintenance programmer with the design ofinternal control and securityprocedures so that they can be individual- ly maintained? Installation and Conversion Plan (a) Does the plan explain how to install the software? (b) Does the plan explain how to activate securityprocedures? (c) Does the planexplainhow to interconnectthe softwarewith otherrelated software packages? 147(d) Does the plan explain how to install the software onto the operating en- vironment? (e) Arethepartsoftheplandirectedtowardstaffpersonnelpresentedinnon- technical language? (f) Are the parts directed toward operations personnel presented insuitable terminology? System Decision Paper (a) Has the System Decision Paper been reviewed and approved by the responsible participants? (b) Has appropriate informationbeen incorporated into the SystemDecision Paper to verify the correctness ofthat document? (c) Has this document been updated to reflect changes in strategy occurring during this phase? Project Plan (a) Is there a strategy for managing the software? (b) Are goals and activities stated for all phases and subphases? (c) Are resource estimates stated forthe duration ofthe system development process? (d) Are the intermediate milestones, including management and technical reviews, stated and being met? (e) Are the methods for design, documentation, problem reporting, and change control given? (f) Are there supporting techniques and tools identified? (g) Has this document been updated to reflect changes in strategy occurring during this phase? (h) Are controls in place to determine whether or not milestones have been met? (i) Are appropriate actions taken ifmilestones are not met? Validation, Verification, and Testing Plan and Specifications (a) Does the document include a plan for testing the software? (b) Does the plan include detailed specifications, descriptions, and. proce- dures for all system tests? (c) Does the test plan include a test data reduction and evaluation criterion? VV&T (d) Is the Plan related to the system plan? W&T (e) Does the system plan drive the Plan? VV&T (f) Does the Plan include general project background and informa- tion on the proposed solution to any mission deficiency(ies)? 148W&T (g) Does the Plan include VV&T requirements, measurement criteria, and constraints? VV&T (h) Does the Plan include procedures to be applied during develop- ment in general and in each phase? W&T VV&T (i) Does the Plan include supporting information for selec- tions made? Does this document include appendices which describe project and en- (j) vironmental considerations? VV&T (k) Does the Plan include tests ofsecurity and internal controls? (1) Does the document include appendices which define the testing techni- que and tool selection information? (m) Has this document been updated to reflect changes in strategy occurring during this phase? 7. User Manual and Operations/Maintenance Manual Change Control (a) Isaprocedureinplace tokeepthe trainingmaterials inthese manualsup- to-date? (b) Aretherecontrolsinplacetoensurethattrainingmaterialsbasedonthese manuals are updated as associated information in the manuals are up- dated? 4.6.3.4.2 Interview Key Participants -The auditorshould interviewall oftheparticipants in the Programming andTraining Phase. Ifthere are numerous participants in any functional area, (e.g., several Sponsors) the auditor should select the most appropriate individuals to in- terview to ensure that they have fulfilled their proper role and responsibilities. Listed below are the key questions that the auditor should ask of the responsible par- ticipants: 1. Information Resources Management (IRM) Official (a) Has the IRM Official reviewed the updated System Decision Paper? (b) Has the IRM Official approved the updated System Decision Paper? (c) Has the review of the Paper been done in consultation with a Spon- sor/User and ADP Manager? 1492. System Security Officer (SSO)/Internal Control Officer (ICO) (a) Has the SSO/ICO reviewed the SSO/ICO components of the User Manual? (b) Has the SSOACO reviewed the SSO/ICO components of the Oper- ations/Maintenance Manual? (c) Has the SSO/ICO reviewed the SSO/ICO components ofthe Installation W&T and Conversion Plan and the Plan and Specifications? 3. Sponsor/User (a) Has the Sponsor/User approved the revised Project Plan? (b) Has the Sponsor/User approved the revised User Manual? (c) Has the Sponsor/User approved the revised Operations/Maintenance Manual and Installation/Conversion Plan? (d) Has the Sponsor/User approved the updated System Decision Paper? (e) Has the Sponsor/User initiated the appropriate user training tasks? VV&T (f) Has the Sponsor/User approved the Plan and Specifications? 4. Project Manager(PM)/Contracting Officers Technical Representative (COTR) (a) Has the Project Plan been updated? VV&T (b) Has the Plan and Specifications been revised? (c) Has the Users' Manual been developed? (d) Has an Operations/Maintenance Manual been developed? (e) Has the Installation and Conversion Plan been developed? (f) Has it been ensured that appropriate programming was performed? 5. System Security Specialist/Internal Control Specialist (a) Have the SSO/ICO components ofthe Users' Manual been reviewed? (b) Have the SSO/ICO components ofthe Operations/Maintenance Manual been reviewed? (c) Have the SSO/ICO components of the Installation and Conversion Plan been reviewed? W&T (d) Have the SSO/ICO components of the Plan and Specifications been reviewed? 6. Contracting Officer (a) Ifappropriate, has the contract been awarded? 7. Contract Auditor (a) Ifappropriate, has contract compHance been assured? 150ADP Manager 8. (a) Have the VV&T relevant parts ofthe User Manual been reviewed? W&T (b) Have the relevant parts of the Operations/Maintenance Manual and Installation and Conversion Plan been reviewed? (c) Has the requested technical support been provided to the Project Manager? (d) Has the requested technical supportbeenprovided to the Sponsor/User? 9. QualityAssurance (QA) Specialist (a) Has the program definition been reviewed for compliance to design and data processing standards? (b) Has the program code been reviewed for compliance to design and data processing standards? (c) Has the documentationbeen reviewed for compliance to design and data processing standards? (d) Hasthetrainingbeenreviewedforcompliancetodesignanddataprocess- ing standards? 4.6.4 Customize Audit Objectives The audit objectives defined for this phase may need to be customized depending upon the designmethodologyused, andwhether ornottheAIS is acquired through contract orpur- chase. 4.6.4.1 Design Methodology Audit Considerations - The two audit objectives for this phase need to be customized based on the following three factors: 1. Status of design up to this point - The fewer problems involved in this applica- tion, the less need for audit involvement during this phase. Generally, if design is properly done, the audit involvement during this phase need only be minimal. Any problems can be readily detected by auditors in the next phase. 2. Type of design methodology used - Audit involvement will change significantly depending on whether the software is developed in-house, contracted, or pur- chased. (a) For in-house developed software, the audit involvement should be at key management checkpoints, normally at the end ofdevelopmental phases. (b) For contracted software, the audit involvement must be specified in the contract. Again, itwouldbe atkeymanagement checkpoints,but itwould bethose checkpointsspecifiedinthe contract.These shouldcoincidewith the contractor's developmental phases. 151(c) For purchased applications, the only audit involvement would be an as- sessment of the design methodology for the purpose of determining whether adequate controls were incorporated to develop an effective ap- plication.Thiswouldbe done inpreparationfor abuy/no-buydecision. In addition, it will change significantly depending on whether more tradi- tional statement-level languages are used for development, such as COBOL, orwhetherfourth-generationlanguagessuchasNATURAL are utilized. Many ofthe fourth-generation languages are really an output of the system Design Phase, and thus there is minimal work for the implementation team during this phase. 3. Technology integration factors - During the implementation phase, the risk at- tributes oftechnology integrationcanbe reassessed to evaluate the implementa- tion risk. The greater the risk, the greater the need for audit involvement. The technology integration attributes that need to be considered in evaluating the scope and objectives ofaudit work include: (a) Make-upofproject teaminrelationto technologyused (number, training and experience); (b) Applicability ofthe data processing design methodologies and standards to the technology in use; (c) User knowledge ofrelated technology; (d) Margin for error (i.e., is there reasonable time to make adjustments, cor- rections, or perform analyses before the transaction is completed?); (e) Availability ofautomated error detection/correction procedures; (f) Degree ofdependence on AIS; and (g) Criticality ofinterfaces with other systems and external organizations. 4.6.4.2 Contracting/Purchase Audit Considerations - Ifthe software is obtained through purchase and/or contract, the audit role will change. Rather than working with the project COTR team, the auditors will be working with the and the contractor personnel. Itis important in the issuance ofanycontract that the contract provide auditors the right to review contractor work. Without this contractual provision, the contractor may deny the auditor access to documents and/or charge additional fees for those reviews. Ifoff-the-shelfsoftware is acquired, this stepwill collapse into a trainingphase. Because training is agency dependent, itwill still be necessary to develop the training plan for training end users in use of the software. It is normally also necessary to develop operations manuals for purchased and/or contracted software, because of the unique internal operating conven- tions within an agency. 152No specific changes in audit approach are required for contracted or off-the-shelf software. The specific contracting/purchasing concerns that the auditor should have are: 1. Ifthe contractor/vendorshould goout ofbusiness, would the source code owner- ship revert to the government? 2. Will the training material be customized for the department/agency that will use the AIS outputs? 3. Ifthe implemented software is defective, will the vendor fix that software at no additional cost? 4. Will defects in the software be fixed on a timely basis? 5. Are provisions included in the contract that permit changes to be made to the AIS during development? 6. Ifthe AlS/software is contracted, is there an effective communication Hne estab- lished between the Sponsor/User and the contractor for clarification of design specifications prior to implementation? 7. Forpurchased software, is there auser group, or customerbase that can be used to inquire into problem and operation resolution? 4.6.5 Detailed Audit Testing Thepurposeofthisphaseistodevelop allappHcations andconversionprogramsandper- form initial unit testing. Tasks to be accomplished in this phase are: 1. Flowchart solutions; 2. Code data structures; 3. Translation ofprogram specifications into source language statements; 4. Installationofsoftwarepackages andsecurityfeatures and establishmentofcom- munication network; 5. Performance ofcomponent and unit testing; and 6. Production ofoperating instructions and systems User Manuals while consulting with user and computer service organizations. 153By the end ofthis phase, the following documentation should be finalized: User Manual. 1. 2. Operations/Maintenance Manual. 3. Installation and Conversion Plan 4.6.5.1 Introduction -Duringdetailedaudittesting,theauditorneedstoevaluatetheade- quacy of the programming effort by reviewing test results-unit, integration, and system test- ing. First, the auditor should evaluate the results of Quality Assurance reviews of testing efforts. The results of this evaluation should determine the effectiveness of Quality Assur- ance'sreviews,andtherebydeterminethenatureandextentofauditinvolvementinthisSDLC phase. Should there not be an effective Quahty Assurance function, the auditor will need to evaluate the adequacy oftesting efforts himself^erself. Inadditionto evaluatingtesting, the auditorneedstoevaluate the adequacyofdocumen- tation—user, programming, maintenance, installation, and training manuals—and training. Again, the auditor should review Quality Assurance efforts in these areas, and not duplicate the work done by that function. If, however, there is not an effective Quahty Assurance func- tion, the auditorwill need to evaluate the adequacy ofthe documentationproducedup to this pointinthe SDLC process. Note that inmany agencies this is aweakpart ofthis SDLC phase, andone towhich the auditor canmake asignificantcontributionsince he/sheneeds touse this documentation to understand the system, just like any system user. In addition, the auditor should attend training sessions on the system (just like any other system user) to determine the adequacy oftraining efforts. There are a number ofautomated tools that can be used during this and the next phase. Notethatsome ofthetools aredescribedinthisphaseforuseinvalidatingexecutableprogram code, and some are included in the final development phase. The auditor should determine if toolsinonephasemightbe equallyappropriateforaccomplishingauditobjectivesinthe other phase. 4.6.5.2 Programming and Training Phase Audit Tests - The Programming and Training Phasetestprogram isdesignedto assistthe auditorinevaluatingthisphase.The questionnaire (seeTable4.4) outlines the more common audit objectives. (Note that the customizationstep may change these slightly.) For each objective, the auditor will be provided with one or more tests to perform, and for each test, one or more tools and techniques will be suggested. 4.6.6 Audit Results/Reporting The result of the Programming and Training Phase review should be documented and given to project management. It is important that deficiencies are identified, the potential ef- fect of those deficiencies on meeting system mission described, and given to project manage- 154merit on a timely basis. Delays in submitting review reports could significantly increase the cost ofcorrecting deficiencies. 4.6.6.1 Potential Deficiencies - In the Programming and Training Phase some deficien- cies occur more frequently than others. The following list ofdeficiencies are among the more common ones for this phase, and are provided to assist the auditor in identifying them: 1. Documents and/or tasks ofthisphase are not completed or are not completed on time, i.e., milestones are met but documents/tasks are not completed. 2. Milestones are not met due to incomplete tasks ofthis phase. 3. Applications are coded which could be done more economically through con- tracting or purchasing off-the-shelfsoftware. 4. Documentationforprogrammingandtrainingisnotpreparedinaccordancewith standards, or not prepared at all, resulting in additional maintenance and opera- tional costs. 5. The program documentation is not maintained in a current state, meaning that as the programs are changed the documentation is not updated. The net result is the documentation is unusable for maintaining the system. 6. No quality control is exercised over the documentation to ensure that it is com- plete and in compliance with standards. 7. Programs are not fully tested, resulting in defective programs being placed into operation. 8. The users of the application are inadequately trained in the use of the applica- tion, so users either misuse the software, or are unable to use software features. 9. User Manuals are not prepared, or are not prepared in accordance with stand- ards, resulting in transactions being incorrectly entered, processed, or output being improperly utilized. 10. Auditand quality assurance tools and techniques are notincluded ornotproper- ly implemented in the AIS. 4.6.6.2 Potential Effects ofDeficiencies on Meeting System Mission - Deficiencies in programmingwill result in inaccurate or incomplete processing. The result may be abnormal terminations in processing, resulting in reruns of processing and late delivery of outputs. Deficienciesnotuncoveredthrough operationalcontrolswillresultinimproperprocessingby AIS users. Deficienciesindocumentaion andtrainingcananddo resultinoperationalmalfunctions and erroneous processing. Also, deficiencies in documentation and training may result in un- economical operationsbecause tasks need to beperformed several times inorder to get them performed correctly. 155The auditor probablywill not be able to quantify the impact ofthese potential deficien- cies; however, he/she shouldbe able to demonstrate the potential adverse effects which could occur due to inadequate programming, documentation, and training. Specifically, the auditor could: 1) process test data to show that the system was not properly programmed to prevent erroneousprocessing; 2) compareuserandprogrammerdocumentationto identifydiscrepan- cies between these two critical documents; and 3) compare user documentation to training documentation and instructions to identify inconsistencies. 4.6.7 Reassess Audit Strategy At the end ofthe Programming andTraining Phase, the auditor needs to determine the amount ofaudit involvement to be expended in the final phase. As with otherphases, ifthere are minimal problems detected by the end ofthis phase, the auditor may not need to expend extensive effort in the Evaluation and Acceptance Phase. Conversely, if the auditor suspects that there are potential weaknesses in the system, extensive audit involvement may be war- ranted during the next phase. The auditor should also complete any post-implementation audit programs, tools, and techniques during this phase. As the Sponsor/User is evaluating the system during the next phase, the auditor should beprepared to evaluate the auditprogramdevelopedforuse during operations. At a minimum, this audit program should include: A 1. list ofpotential areas for audit investigation; 2. Tools for file analysis and/or software packages for use during operation for file analysis; 3. Step-by-step audit programs for the audit team to use in auditing the operation- al AIS; and A 4. permanent working file on AIS, including key aspects ofdocumentation, with references to official AIS documents. 156^1 u o •a^ O ^ a = 2 1/5 a o 2 a oWn (U o 73 « a P O rougliance ol aici 7 MO3 7( 3u ^g S o T3 7 o3 _aa 0 a 2 a o 2 u o an .a " >S ; o w H > ure a 7( 3D -l oaU ^S^ <-°i-i Q ens -o ^ a 3 o' 00 11 « 73 3 c« t3a 00 wew Psta a t >o ^ o 7 O3 in a" , Q < 2 O O H . - _u u o 3 u2 5 2 > O c a o « k 1 a>3 ) .. *A ( a o wa «C2D U 7 oO > a r3 ) 2pW u" 1 5 —o Ob . a o o > o w O ( a o ia a C- OiX , , P H20 ^ « 1Oi /1 3 J 7 "1o O3 3 53 J O o ^ D12 -1• 7 <3 ^ s( cfl o 3 00 C Oh D o O 3 a O .2 "a J( 3U :z; a o 13/5 U o CO o <u 3 O 1/5 cfl 1) > a W 1/3 Q 3 a s a a O 3 O CO 3 o Q O o 73 05 l-H O 73 73 < VI TO d^J 7 33 (1> 4-1 »- 73 B o -2 ^. o 1/3 ^ S3 o a S 703/3 o 7 <O3 U 7c 3a o 3 O 3 3 CO r4 ti D I 13o cr (U 73 CO C/5 CO 73 > CO 3 ja o 3 73 U O D CQ S J3 (/3 3 D &^ Q 3 < O CO "3 O 3 O 157H (W/) H H P < W m u o 3 158a i-i o I 13 J3 o o a o J3 y 73 .3 o u ea a O 3 2 ^ a. H U H H « 3 S U( rjSO . ^tC 2o Hl QU I g 1 O/! .- - ^ w| ( a 9s s_ 3 I3 ^ ^ 1D u _^ C3 O O o a o3a 3 o . ^2 1^ s 3 s ?J -C cT S3 - .2D . ( aU _d o o D § o o a o. o < S o .ia o > O o 1> au U Ui- a oo . oa2 a <u a .o - -5 ^ S ;3 •^r c; R 9- - 3 ." ii2 O IS O uv-i u to D e c o n o, a 2^ ° i .2 o 13 X d u 3 X< )D ^ 3 cs a" C/2 T33 t2 a O o CO CO 1) S u COL, c3 1| u ^ o 3 ca3' S o a(SO 1 ^ 73 D 3 s <U d < a 1 o § 2 i ^ 159! 1- C8 J3 X5 O a 2 CO ^ o =U3 ^ a ^ S a 3 I"<« 3 e (/3 O It 9 a ^ a -2 U ^ a u 8-3 . -T3 3 a o 2 § I ' T 33 3 o a ci. . (J T3 O U5 "i oi o U3 t) >. •5^3 U O D •3 o if ^.3 ™ U « .3 a . ii D(u -a 3a a o 8 a o o D1-1 CO o 2 o ( oU o T3 (J u u a iS CO -oW lo CO 73 3 1 o 1 33 .3 H Ii > 60 Cw/5 CO H 1 o3 CO 3 O >. T"s 3o a o Q a c (U CO o a u J3 -zJ < CO 3 13 I (U w .3 o 13 o a at/5 •J C ^O .-3 o ja o COO ."S c u 8 05 • _ "- aCo3 O WO5 t: CO 3 -Tl co ua /2 1 Zo u3 g CDO.s O C aO Doa 5 3 CO o 2 o . OA a Xj)j o 2 § -3a o ja (J 8 So 1 33 C3O a O" m u 0) o T3 Q ' T3 u < 3 .3 O (U a o a,x> u < a, a O 1 D1 , 160d T3 fl CO c § r a* • < CO (U 1 ^3 SP T3 B H C a CWO (/3 a H Q O D 13 .a < < gD «g •5 S 1.^ 1) .3 a (U CO IS ^ h O i4 o u Q S 8 o ^ g T-i• CO D. 73 C3 C/2 ^ a O OS J3 o o a Q CO D 13 < a o o ^ a 00 On 161- 3 a O a> o aM, ( )»D 8 a (4o-1 2 -9 ^ .S2 .9 a ^ 8 o .2 " 2 1) lyj .a 73 .9 ^ *j o o o 3 3 " u to bC 9 ^ i H iWn H H Q D < .9^ a Oh 5 § ^ 2 3 e « 3 a £ 73 g 73 ^ S u ^ Q(U 7 23 §^W3 Hoi i -a 9 !3 o D a ci. o a *3 &.73 J 8 a < -3 < a0-3 O 1624.7 AUDIT PARTICIPATION IN THE EVALUATION AND ACCEPTANCE PHASE - PHASEV The objective of this phase is to ensure that the AIS is acceptable to the users prior to placing the system into aproduction mode. During this phase, unit testing will be completed, and integration and system testing undertaken. The results of these tests will provide user managementwith the information necessary to make a decision on acceptance, modification, or rejection ofthe AIS. The audit objective in thisphase is to ensure that the total system and data are vaHdated and fully meet all user requirements. The auditor should continue to em- phasize internal control requirements as anarearequiring specificaudit attention.The fulfill- ment of this objective may be done in conjunction with the VV&T Plan, or it may be independent ofthat plan. 4.7.1 PrimaryAudit Objective ofthe Evaluation and Acceptance Phase The primary audit objective ofthis phase is to: "Ensure that the total system and dataarevalidated as fully meeting all user and internal con- trol related requirements." W&T The fulfillment ofthis objective should be accomplished by reviewing the work ofthe test team, and conducting additional tests as appropriate. The actual performance ofthe task is normally too time-consuming for audit to perform. It has been estimated that this phase of the developmental process can consume up to 30 percent ofthe developmental effort. If testing is properly performed, a test plan, test results, and a test report will be avail- able. [Note that many Federal agencies neither plan nor formalize the results oftesting into a report.] The testplanshould indicate theAIS functions, and then cross-reference themto the tests designed to validate the correct operation of those functions. Test results should be specificallydocumentedandretained.The testreportshouldindicate theresultsofthosetests, andthenrelate the test resultsbackto the function, indicatingwhether ornot itperforms cor- rectly. If the test results and AIS Life Cycle Matrix are completed and prepared for the test report, the auditor's role becomes significantly easier. In these instances, the auditor only needstoperform sufficienttests to ensure himself/herselfthat the test results are correct.The auditor should then be able to draw the same conclusions from the test results and AIS Life Cycle Matrix as the test team. Incompletingtheauditobjective,theauditorshouldperformthesamesixstepsdescribed in the other development phases. These steps are individually described below for this phase. 1634.7.2 Overview ofthe Evaluation and Acceptance Phase The evaluation of the AIS should be conducted in accordance with the revised VY&T VV&T Plan. Completed code will undergo testing, as described in the revised Plan. General- ly, three types ofprogram testing are performed: unit, integration, and system. Ifperformed properly, unit testing will then validate the functioning of the unit; integration testing will validate the interfaces between the units and the operating environment; and system testing will validate the interaction between the application system and the user area. It is recom- mended, but often difficult to achieve, that unit testing be completed before integration test- ing commences, and integration testing be completed before system testing commences. GAO Itis importantthat adequatetimebe allocated to testing. Previous reportshave in- dicated that software testing is basically an underplanned and undermanaged part of the developmental process. This occurs because frequently the previous phases are completed late, even though the installation date remains fixed. In order to meet the installation dead- hne, the amount oftime and effort allocated to testing deteriorates to the point that it is inef- fective in accomplishing its objective. Afterthe review, analysis, and testing ofthe system, including executionofthe programs on test data, the AIS should be field tested in one or more representative operational sites. Forparticularly sensitive AISs, disaster recovery and continuity ofoperations plans should be fullydocumented and operationallytested aswell. Using actual transaction data, ifdesignated a "sensitive" system, it should be certified for technical adequacy in meeting its security re- quirements by an appropriate authority, prior to accreditation and installation. Before cer- W&T tification, all test results should be documented and a comparison of actual and expected results made. The OMB Circular A-130 and FIPS PUB 102 security evaluation should be part of the broader test results/test evaluation report. The accreditationstatement, the last keyactivity of IRM thephase,wouldbeastatementfromtheresponsible accreditingofficial (e.g.. Sponsoror Official) that the system is operating effectively and is ready to be installed. Any caveats or restrictions should be provided at this time. 4.7.2.1 Participants and Their Tasks - All or most ofthe participants responsible for the AIS play an active role in evaluation and acceptance. In the early phases, the responsible par- ticipants are frequently senior people in the area ofinvolvement. For example, the manager or assistantmanagers ofthe user area maybe personallyinvolved inthe earlydevelopmen- tal phases. As the work gets more technical, the responsibihties are frequently delegated downward to lower-level people in the operational areas. During the Evaluation and Accep- 164tance Phase, as critical decisions have tobe made, the more senior people should again be in- volved. The responsibilities ofthe participants in the Evaluation and Acceptance Phase are: 1. InformationResources Management (IRM) Official-Approvesupdated System Decision Paper to advance to Phase V, in consultation with Sponsor/User and ADP Manager (occurs betweenphases). 2. System Security Officer (SSO)/Internal Control Officer (ICO) - Reviews Test Results and Evaluation Report and SSO/ICO components of Installation and Conversion Plan. 3. Auditor(OIG) - Reviews/evaluates revised Project Plan, revised Installation and Conversion Plan, and Test Analysis and Security Evaluation Report; updates Audit Program. 4. Sponsor/User - Approves revised Project Plan and Installation and Conversion Plan; updates System Decision Paper; oversees training; accepts (accredits) sys- tem for operation. 5. Project Manager/Contracting Officer'sTechnical Representative (COTR) - Up- dates Project Plan; supports and oversees Test Analysis and Security Evaluation Report and certifies system security; revises User Manual, Operations/ Main- tenance Manual, and Installation and Conversion Planbased on test results. 6. System Security Specialist/Internal Control Specialist - Reviews Test Analysis and Security Evaluation Report and SSO/ICO impacted documentationupdates to User Manual, Operations/Maintenance Manual, and Installation and Conver- sion Plan. 7. Contracting Officer - Ifappropriate, awards contract. 8. Contract Auditor - Ifappropriate, assures contract compliance. 9. ADP Manager - Directs test reviews and validated VV&T components ofInstal- lation and Conversion Plan; continues to provide technical support. VV&T 10. QualityAssurance (QA) Specialist - Reviews results and advises respon- sible participants on system achievement ofNeeds Statement. 1654.7.2.2 Evaluation and Acceptance Phase Document - The auditor will evaluate the workperformedinthisphasebylookingatthephase documentation.Thephaseproducesone newdocument, and three updated documents (System Decision Paper, Project Plan, Installa- tion and Conversion Plan). The new document is: 1. TestAnalysis and SecurityEvaluation Report (NBS SP 500-98, DOD-STD-7935 'TestAnalysis Report," OMB A-130, OMB A-123, FIPS PUB 102) The purpose ofthe Test Analysis and Security Evaluation Report is to (1) document the test analysis results and findings; (2) present the demonstrated capabilities and deficiencies, includingthe SecurityEvaluationReportneededforcertificationof the AIS; and (3) provide abasis forpreparing a statement ofAlS/software readi- ness for implementation. 4.73 Audit Survey The main source ofinformation for this phase will be the audit results and workpapers from previous phases. If the same individuals are involved in evaluation and acceptance, as were involvedinpreviousphases,backgroundpreparationworkshouldbeminimal. However, the auditor is still concerned with the flow of work, the assurance that the responsible par- ticipantsfulfilled theirroles, and acquiring andreviewingthe documentationproduced during this phase. 4.7.3.1 Re view PrograTnming and Training Phase Outputs - At this point, the AIS has been completed. The objective of this phase is to identify and remove defects from the AIS. This is accomplished through creation of a series of test conditions, which, when processed against the executable code, produce the proper results by which the system will be judged correct (or inadequate). The auditor maywish to review some ofthe documents from the earlierphases because they indicate what the system is supposed to do. The programming phase documents are orientedtowardwhatthe systemdoes to meet its objectiveswhile the User Manual andTrain- ing Manual explainhow the system is to be operatedby the endusers. Itis recommended that theauditorunderstandboththewhatandthe how,inpreparationforreviewingthisfinalphase ofthe system development process. It is also important that the auditor ensure that the test data and testing documentation is saved foruse invalidating subsequent changes to the AIS and for auditorusage as required. 4.7.3.2 Review Evaluation and Acceptance Phase Plans -The final phase is one which is frequently squeezed between the point where the programs are complete, and the date when thoseprogramsmustbeplacedintoproduction.Iftheproductiondateisfirm,insufficienttime 166maybe allocated tothisphase.Therefore, itbecomesessential thatthe auditordetermine that at least the most critical AIS functions are tested. Itisunrealistictoexpectexhaustivetestingtooccur, though itiscertainlydesirable.There will always be compromises between budget and schedule, and complete testing. In many in- stances there are no options regarding when the AIS is placed into production, particularly when it is mandated by legislation. What is important is to optimize the test time available. 4.7.3.3 Gather Information on Evaluation and Acceptance Phase Status - Reports shouldbe maintainedonthe status oftesting.The criteriafor testingshouldbe included in the VY&T Plan. This will indicate which functions are to be tested, and what conditions will be used to test those functions. In the hierarchy oftesting, the units or programs should be tested first. Once these have been vaHdated as performing correctly, the integration or interfaces between the units or programs are tested. Once those interfaces have been validated, the acceptance test occurs, which validates the interfaces between people and the system. The status reports on testing should indicate which functions have been tested, which functions work, which functions are in the process of being corrected, and when those func- tions should be retested. The auditor, at any point, should be able to determine how many functions have beenvalidated and how many remain unvalidated. Ifthis status information is not available, the auditor should be concerned over whether the end product of testing will adequately indicate AIS performance prior to the system being placed into production. Withoutthistypeofinformation,managementcannotmakeaknowledgeabledecisionregard- ing installation and operation ofthe AIS. During this phase, the auditor should obtain for analysis purposes the following docu- ments: 1. Test Analysis and Security Evaluation Report, including certification and ac- creditation statements. 2. Updated Installation and Conversion Plan. 3. Updated User Manual. 4. Updated Operations/Maintenance Manual (including change control). 5. Updated Project Plan. 4.7.3.4 Verify Information on the Evaluation and Acceptance Phase Status - By the time this phase commences, all ofthework necessary to develop the AIS should be complete. The organization should have an executable AIS. What is needed is to be assured that the ex- ecutable system meets the system requirements/specifications. 1674.7.3.4.1 Review Documents -The flowofworkinthe EvaluationandAcceptance Phase is primarily a flow oftesting. This flow is illustrated in Figure 5. The flow shows that there are many modules (i.e., computer sub-programs) developed during this phase. Each of those modulesneeds tobe individuallytested.The modules are thenpulled togetherintoprograms. Note that some ofthe programs may involve utility programs and other aspects of operating software. These programs are then tested tovalidate that the multiple modules work correct- ly when intercoupled. Lastly, the programs are all put together as an AIS, and that AIS is validated to ensure that it works in the operating environment, that it workswhen interfacing with other systems, and that it meets user requirements. The auditor must become famiharwith the flow ofwork during thisphase.This includes familiarization with the various types of testing and the expectation from those tests. As in other aspects of system development, the exact flow ofdocuments will vary from methodol- ogy to methodology, and within agencies using the same methodology. The Evaluation and Acceptance Phase produces one new document (Test Analysis and Security Evaluation Report), and five updated documents (Audit Plan, Project Plan, User Manual, Operations/ Maintenance Manual, Installation and Conversion Plan). The auditor should look atall ofthese documents,butputemphasis onverifying thattheTestAnalysis and SecurityEvaluationReportproperlyimplementsandaccomplishesthetestplanobjective,and that the test results are properly reflected in the Security Evaluation Report. 4.7.3.4.2 Interview Key Participants - The auditor needs to verify that all of the ap- propriate responsible participants are involved in this phase, that theyhave been assignedthe appropriate role, and that theyhave correctly fulfilled that role. This step is normally done by interviewing the involved participants to verify their needed participation. Listed below for each of the desirable participants are the questions that the auditor needs to ask those participants: 1. Information Resources Management (IRM) Official (a) Have you approved the updated System Decision Paper? ADP (b) DidyoureviewthatpaperinconsultationwiththeSponsor/Userand Manager prior to approval? 2. System Security Officer (SSO)/Internal Control Officer (ICO) (a) Have you reviewed the test results? 168 IFigure 5. FLOW OF EVALUATION WORK EVALUATION DOCUMENTATION SYSTEM ARCHITECTURE I Test Plan Unit Test Results UNIT UNIT UNIT UNIT UNIT UNIT Integration Test Results MODULE MODULE System Test Results AIS SYSTEM ARCHITECTURE II Test Plan Unit Test Results UNIT UNIT UNIT UNIT UNIT UNIT Integration Test Results MODULE MODULE System Test Results AIS SYSTEM SYSTEM VV&T Report I / INTERFACE 169(b) Have you reviewed the Security Evaluation Report? (c) Have the SSO/ICO components of the Installation and Conversion Plan been reviewed? 3. Sponsor/User (a) Did you approve the revised Project Plan? (b) Did you approve the revised Installation and Conversion Plan? (c) Did you make the necessary updates in the System Decision Paper? (d) Have you/your area overseen the necessary training? (e) Did you as SponsorAJser accept the system for operation? 4. Project Manager/Contracting Officer's Technical Representative (a) Did you make appropriate updates to the Project Plan? (b) Did you support and oversee the Test Analysis and Security Evaluation Report? (c) Did you certify the system security? (d) Did you revise the User Manual, based on test results? (e) Did you update the Operations/Maintenance Manual, based on test results? (f) Did you update the Installation and Conversion Plan, based on test results? 5. System Security Specialist/Internal Control Specialist (a) Did you review the test results? (b) Did you review the Security Evaluation Report? (c) Did you ensure that the updates to the User Manual, Operations/Main- tenance Manual, and Installation and Conversion Plan reflect anyimpact on the SSO/ICO documentation? 6. Contracting Officer (a) Ifappropriate, have you awarded the contract? 7. Contract Auditor (a) Ifappropriate, have you assured contract compliance? ADP Manager 8. (a) Did you direct testing? W&T (b) Did you review the validated components of the Installation and Conversion Plan? (c) Did you provide the requested technical support? 1709. Quality Assurance Specialist VV&T (a) Did you review the test results? (b) Didyou advise responsible participants on system achievement ofNeeds Statement? 4.7.4 Customize Audit Objectives The specific audit objectives to be accomplished during this phase will vary depending onmanagement's need. Ifthe project teamdoes not have an adequate testplan, management may ask the auditors to play a more active role in testing. Sometimes the auditors perform some ofthe testing that occurs during this phase. While this is not recommended, it is some- times a necessitybecause testingwould not otherwise be performed. The test program outlined for this phase includes the more common audit objectives for this phase. It is those objectives that need to be customized based on the needs of manage- ment, aswell as the audit evaluationofpreviousphases.This phase is the auditor's last oppor- tunity to evaluate the system prior to its being placed into production. The greater the risks associated with the system, or the greater the concerns uncovered in previous phases, the greater the need for audit involvement during this phase. 4.7.4.1 Evaluation and Acceptance Phase Methodology Audit Considerations - Developmentactivitiesarefrequentlydeficientwith respecttotesting.Theymayincludesome testdocuments but areusually not extensive. Some methodologies containno test strategies/- documents. Development methodologies were developed years before test methodologies were W&T developed.FIPSPUB 101 on [FIPSlOl],GAO's[GA081-3] "EvaluatingInternalCon- trols in Computer Based Systems", and IEEE's "Standard for Software Test Documentation" [IEEE83] and "Standard for Software Unit Testing" [IEEE86] provide such a test methodol- ogy.TheauditormayalsowanttorefertoAUERBACH's"AStandard forComputerApplica- tions" [AUER86+ and NBS SP 500-136 on software acceptance testing [NBS136]. ] Ifthe development methodology is deficient in the testing area, the auditor maywish to suggest one ofthe above references as a test strategy. The key aspects of testing that need to be addressed during this phase are: 1. Development ofan adequate test plan; 2. Execution ofthe test plan; and 1713. Analysis and reporting oftest results. The auditor should be particularly concernedwith the test report. This report should in- dicate not onlywhat works and doesn'twork, but have an opinion from the test group regard- ing the adequacy ofthe system to be placed into a production status. Test approaches that are used by corporations include: 1. An independent test team (i.e., a group of people independent of the project people, who are professional testers). 2. UsersoftheAIS createtheirown testconditions, anddeterminewhethertheAIS is acceptable to them for use in production. 4.7.4.2 Contracting/Purchase Audit Considerations - The Evaluation and Acceptance Phase does not change significantlywhether the software is developed in-house, through con- tract, or off-the-shelf purchase. Obviously, with contracted and off-the-shelf software there wouldbe minimal unit testing and integration testing, with the concentrationbeing onsystem testing. However, the phase is the culmination of the test plan, which in itself is customized slightly depending on the source ofthe software. Contracted software introduces no particular changes in audit activity. Contractors may participate in all activities not otherwise precluded byFederal statute or departmental policy. VV&T Contractors should not be involved in performing ofsystems they develop due to con- flict ofinterest issues. Purchase of off-the-shelf software results in the following changes for project par- ticipants: (a) Sponsor/User reviews results of all pre-award test procedures. Concurs in any customizing and award. (b) Project Manageroversees completionof"live test demonstration" and otherpre- award test procedures, and defines/approves required customizing, (If cus- tomizing is required, that process should be done by returning to a sub-process identical, ifabbreviated, to that for full systems development (Phase II-IV). The Project Manager also approves award to selected bidder/offeror. ADP (c) Manager provides technical assistance in evaluating "live test demonstra- tion" and other pre-award testprocedures. Also oversees installationofsoftware at the test site. 172Some ofthe specific contracting/purchasing considerations for this phase are: 1. Does the contractor/vendor have atest plan, and is it available for examination? 2. Canthe contractor/vendorindicatewhichfunctionsworkandwhich functions do notwork? 3. Doesthe contractor/vendorguarantee the specifiedfunctions towork, andifnot, agree to fix them at no additional cost to the government? 4. Are the test conditions and results available to the government to validate that the system performs as specified? 5. Does the government have the right to validate the functioning of the system before accepting the system? 4.7.5 Detailed Audit Testing The SponsorAJser will rely upon the Security Evaluation Report to determine whether or not to accept the AIS. However, the Sponsor/User is usually not technically oriented, and thusdoes nothavethe necessarybackground to challenge the informationincludedwithinthe SecurityEvaluationReport.Theindependentopinionoftheadequacyofthatreport,provided by the auditor, can be important in determining whether or not the application will be ac- cepted, or ifit is accepted, whether any counter strategies are needed to be put into place to compensate for potential weaknesses. 4.7.5.1 Introduction -Testingis averycriticalphase ofthe SDLC. Programs and applica- tions must pass system and acceptance tests prior to certification for implementation. These tests cover two different areas of concern, yet they have the same goal. The system test will provide an internal assessment ofthe correctness, performance, and reliability ofthe opera- tional system, while the acceptance test will determine user reaction to the product, its per- formance, installation procedure, documentation, and reliability. Once these tests have been performed, the project team will review the results to ensure the system meets user require- ments and is acceptable to the user. The auditor has two major roles in this phase of the SDLC: (1) to ensure testing is ade- quatelyplanned andperformed incompliancewithapproved standards; and (2) to ensure test results are properly evaluated and included in system documentation. 1734.7.5.2 Evaluation and Acceptance Phase AuditTests - An Evaluation and Acceptance Phase audit program is provided to assist in completing this step (see Table 4.5). The audit program includes sub-objectives for audit, suggested tests for the auditor to undertake to ac- compHsh those objectives, and then tools that might prove helpful in conducting those tests. These are provided as guides to auditors to help them be more effective in reviewing AISs in the Evaluation and Acceptance Phase. 4.7.6 Audit Results/Reporting Oncetheauditoridentifiesaweakness,managementwillneedrecommendationstoover- come that weakness. The recommendations should be consistent with the magnitude of the variance. Variance with a minor impact may not warrant highlighting in an audit report or of- fering recommendations. Recommendations should be limited to those findings having a sig- nificant impact on the agency/organization mission. 4.7.6.1 Potential Deficiencies - Deficiencies identified in this phasewill normallyrepre- sent operational deficiencies. If they are not corrected prior to the application being placed into production, they may cause or contribute to a systemfailure. At thispointin the develop- ment cycle there is no time to compensate for deficiencies in future phases. Listed below are some of the more common deficiencies found in the Evaluation and Acceptance Phase. These deficiencies are listed to help the auditor ensure that one or more ofthe more commonEvaluationandAcceptancePhase deficiencieshas notbeenoverlooked. 1. Testing does not include all ofthe tests included in the test plan, resulting inun- tested functions being placed into production. A 2. test report is not prepared, or ifprepared does not adequately indicate which areas have been validated to function correctly, and which have not been validated. This results in applications being placed into production without the user knowingwhat works and what does not work. 3. User management is not involved in the decision whether or not to put the sys- tem into production, resulting in systems being placed in productionwhich may have defects which, ifknown, would result in the user stopping the system from being placed into production. 4. The test plan, test results, and test reports are either not complete, or not prepared in a manner that can be used as ongoing maintenance documentation. This results in maintenance personnel having the costly task ofreproducing test conditions and test results. 174A 5. parallel test is not conducted, resulting in the user being uncertain ifthe new systemcanproduce the same results as the old system (applicable onlywhen cur- rent automated capabilities are in existence). 6. The AIS is not field tested at selected locations and, therefore, does not work properly in the operational environment. 7. Systemdevelopmentdocumentation is notupdatedtoreflectthe changes and ac- tivities that occurred duringdevelopment. This results in maintenance occurring with inadequate documentation and with the potential of increasing the defect rate and/or costs ofmaintenance. A 8. written Conversion Plan is not prepared and followed, resulting in the poten- tial for increased conversion costs and inaccurately or incompletely performed conversion tasks. 9. System security is not certified. This results in potential security vulnerabilities in the operational AIS. 4.7.6.2 Potential Effects ofDeficiencies on Meeting System Mission - The impact of deficienciesinthisphase shouldbe calculatedas operational defects.The auditorshouldiden- tify the potential deficiency event, estimate the number oftimes that event will occur within the next year, determine the expected loss per event, and then multiply the two variables together to calculate the annual loss expectation. FIPS PUB 65 explains how to perform this calculation. 4.7.7 Reassess Audit Results/Plans The auditor should conclude the audit program once the system becomes operational. The insight gained during the developmental process should be passed on to the audit team reviewing the operational system in order to properly focus and maximize audit effort. The types ofinsight to be included in the programwas described in the previous phase. The auditor should select the final operational audit tools during this phase. These tools should be tested (at the same time the AIS is tested) to ensure they work. Thus, the auditor undergoes anevaluation and acceptance ofaudittools atthe same time thatusermanagement undergoes an evaluation and acceptance ofthe AIS. 175W D O X u o o H - u "I 8 1 ( aU , o u '3 4j £ e aj a -a H !g a W o p H 8^ U a > i2 PQ Q O < - i • Sa o^ 73 3'4—) > 1 .S "S u "O o 10 -o 73 T3 2 CL, ^ ca W 11 5 > !§' Pi u " H O H CQ. U< C3 73 •aJ 7 a3 t e3 3 a o1/3 o 3 a -S H g «3 .S u </3 t/3 D O < iO 73 ^<n 77t 33/3 </3 O a,73 .g . Od o H (u £ o 1/3 73 176S .£ < ^ =^ 0O0 ^<U w < C, CO u CH/5 i 2< 2 O D. ^ .s Q < « o w < t/5 D n o^ 4> C1 O '*i CO t; CO o a o U « C3 O §~ sa CO i • ao o •£ 'S j3 ! c § CO „ -oC tai a ^ 3 aB S 1C 3O a • Da 2 a; l;^ o^ to ' JI > u w C bO p a ° S .^2, S CO e O - ua u < H 2 8 a to U = (U0 c 3 ^ b cC Q S on C -O 210 t u/ ;) cr to .H s ^ ta ; ac i1 < O Hi 2 D- O O C UO U C C"3 O •- (/a 3 -2 1 W3 X c! - 2 i> 5a _ a 2CO J .^ —3 a -u (Ca 50TD CO JS C 3O is . as O 9--O"=5 >« > a 8 2 CO ^ - u o o o 3 o C DO , WCXO O ^ !C-> r! J? Cl< P > > CC QO UCO 2 ^ a 2 > ^- a CO w CO . "cO mI - ia£ —1^ -A g S • 23 2 c > C gO oP o a D, 10 = (U 3 S o ^ O CO 5) D O CO U > 3 O D i-S X) >- w «CO CO (^ rS 2 3 t/3 ^o -Sc oo -C <p. U ( < uf Ul t00 O ai)) too o U> c o 2o c « o 1c ? 7c C3 Or 2 3 S C oO III f Ce Oj u t3 o CO . «2 3E CJ <4O-, O oc , ft2 C:i Jo 33 'C =OO Ca 1O :12 3 •£ CO 3 u -§ .2 1^.1 t—' k« 177(/2 <5 U C3 s u a Z 1 ^ .2 a § Uo 8 o <« H 9I a I 3-D " U aO'SC" -J H 8 Q W "S to < c o fa a ^ -« 3 a U (0 . Ua oa •i H H «3 H « ( a/3 :' ^3= <1 /3 1<U a in C3 W .2 ^ T3 T-H .tS 3 CO 3 »- < 5 a -S ^« <wU <4O-l 00 3 25 (0 c 2 J3 3 O U § iS 3 a 3 £ •a w .9 a " c ^ o u ^ 8 Q-2 -o i: 3 O 00 On 178CH/3 00 00 ^ .a 4-i» -a rS U O w a « «Q, 21/3 ^ H .9 u U H <u a H <0 Q 3 a .r2 < S< <-Ua-D 1c-1 ;S (/3 o o o « S I w e S n) 1/3 > r-l C « w .9 2 I to 8 - ^ CO S ^ O u T^ t> Ao l%•*" -U <S ' ^ 3, m u ^ 3 u3 ^ z M (U u ^ -"(DuO-i Q W O D g I 3 H 1 C/ O5 1 43 -a O w a t) </3 179APPENDIXA PCIEWORK GROUP ON EDP SYSTEMS REVIEWAND SECURITY SUMMARY OF BACKGROUND AND CHARGE A.1 PresidentReaganestablished the President'sCouncil onIntegrityandEfficiency(PCIE) in March 1981 to coordinate government-wide efforts to attack fraud and waste and help en- sure system integrity in government programs and operations. Chaired by the Deputy Direc- tor of the Office of Management and Budget, the Council is composed of the Inspectors General (IGs), as well as representatives from the Federal Bureau of Investigations, the Department ofJustice, and the Office ofPersonnel Management. Among its other functions, thePCIE is chargedwith developinginteragencyprograms andprojects to deal efficientlyand effectively with those problems concerning fraud and waste which exceed the capability or jurisdiction ofan individual agency. In October 1983, the Council decided that Electronic Data Processing (EDP) Systems Review and Security was an issue requiring formal review, and established a working group. Responsibility for the PCIE Work Group was given to the Inspector General ofthe Depart- ment ofHealth and Human Services, to be included under their ongoing Computer Security Project. Composed ofOIG and management representatives from fourteen Federal depart- ments and agencies, the group was charged with facihtating and improving Office ofInspec- torGeneral/Auditorganizationreviewsofautomatedinformationsystems (AISs),particularly thosesystemsunderdevelopment.The objective ofthe PCIEWorkGroupwas toimprovethe likelihood that auditable and properly controlled systems are being developed. Toachievethis objective, thePCIEWorkGroupparticipantsdrewfrom theDepartment of Defense life-cycle approach to the management of automated systems, and the National Bureau ofStandards' Institute forComputer Science andTechnology's (NBS/ICST's) Special Publications and Federal Information Processing Standards, to develop a system life cycle matrix for AISs. That matrix, structured around critical AJS documentation requirements is EDP intended to clarify the role ofthe internal auditorvis-a-vis other key participants in the planning,design,implementation,andreviewprocesses.Withtheauditroleclearlydelineated, this audit guide has been developed to facilitate the successful fulfillment ofthat role, focus- ing on systems under development and major modifications to existing systems. A-1A.2 WORK GROUP DOCUMENTATION ACTIVITIES The PCIE Work Group pursued a number ofactivities that enabled the group to arrive at some consensus position regarding documentation needs during the SDLC. The following is abriefenumeration ofthose activities: 1. PCIE Work Group participants were asked to reviewwhat documentation their agenciesusedandtoprovidecopiesofthestandardsorpoUcytotheWorkGroup; 2. Experienced systems staff, managers, and PCIE members met to reconcile how the documents related to one another, and each life cycle phase; 3. Selectednon-Federalorganizations/firmswere contactedto reviewthe approach being taken regarding their systems development/review activities; 4. NationalBureauofStandards (NBS) representativeswere broughtintofacilitate the consohdation of NBS standards and legal requirements, with the PCIE ob- servations and recommendations. 5. General Services Administration (GSA) representatives were contacted to sup- port the evolution of GSA's software engineering and information resources management (IRM)procurementprograms,inconsonancewithbothNBS stand- ards and the work group recommendations; 6. General Accounting Office (GAG) representatives were contacted to see that theygenerallyagreedwiththe WorkGroup'sviewofthesystemdevelopmentlife EDP cycle, documentation needs, and review activities, 7. The Office of Management and Budget (OMB) representatives were contacted to see that the Work Group's view did not violate or disagree with the then OMB OMB developing revision to Circular A-71 TMl, found in the subsequent Circular A-130. 8. All Federal agencies were provided copies of the PCIE recommendations, and offeredanopportunityto commentboth onthe substanceofthematrix, the docu- ments, and the direction being taken. A-2A.3 PCIE WORK GROUP MEMBERS Bonnie Fisher Health and Human Services (Project Leader) Office ofInspector General Gail Shelton Health and Human Services Office ofInspector General Jim Cox Health and Human Services Office ofInspector General Wallace Keene Health and Human Services Office ofthe Assistant Secretary for Management and Budget Bob Gignilliat Health and Human Services Office ofthe Assistant Secretary for Management and Budget David Decker Housing and Urban Development Office ofInspector General Mike Houston Department ofDefense Office ofInspector General John Lainhart Department ofTransportation Office ofInspector General Mac MacDonald Veteran's Administration Office ofInspector General Roger Sies Department ofLabor Office ofInspector General William Lee Department ofCommerce Office ofInspector General Allen Winokur Department ofDefense Naval Audit Service Zella Ruthberg National Bureau ofStandards Institute for Computer Sciences and Technology A-3Jim HoUohan Smithsonian Institution Audit Agency David Petrocci Department ofTreasury Office ofInspector General Mary AnnTodd Department ofTreasury Financial Management Services Mark Gillen Department ofTreasury IRS Internal Audit Barry Snyder General Accounting Office IMTEC Jack Landers General Services Administration OIRM John Bjork Small Business Administration Office ofInspector General Larry Martin Department ofEnergy Office ofADP Management Benson Simon Environmental Protection Agency Office ofthe Comptroller Doug Hunt National Aeronautics & Space Administration Office ofInspector General & Tyrone Taylor National Aeronautics Space Administration Office ofInspector General A-41 APPENDIX B LAWS AND REGULATIONS B.l SPECIFYAUDIT INVOLVEMENT B.1.1 Standards for Audit of Governmental Organizations, Programs, Activities, and Func- lKma(Yellow Book), GAO, 1981 Revision [GA081-1]: In 1981, the Comptroller General of the United States (head ofGAO) issued audit standards that were intended for application to audits of all government organizations, programs, activities, and functions-whether they are performed by auditors employed by Federal, State, or local governments, The standards are designed to be general in nature and apply to audits ofall types. These standards are periodi- GAO cally updated to reflect the current audit direction. The current standards contain an optional standard regarding audit participation in sys- GAO tems development. The strongly recommends that auditors be actively involved in reviewingthe designanddevelopmentofnewdataprocessingsystemsorapplications, and sig- nificant modifications thereto, as a normal part ofthe audit function. B.1.2 The Inspector General Act of 1Q78(;PT,95-452. October 12, 1978) [IGA78]: TheActes- tablished the Office of Inspector General within major Federal agencies in order to form independent and objective units: To conduct and supervise audits and investigations relating to programs and operations ofthe Department ofAgriculture, the Department ofCommerce, the Department ofHousing and Urban Development, the Department ofthe Inter- ior,theDepartmentofLabor,theDepartmentofTransportation, theCommunity ServicesAdministration, theEnvironmentalProtectionAgency, theGeneralSer- vices Administration, the National Aeronautics and Space Administration, the Small Business Administration, and the Veterans' Administration; To provide leadership and coordination, and recommend policies for activities designed (a) to promote economy, efficiency, and effectiveness in the adminis- tration of, and (b) to prevent and detect fraud and abuse in, such programs and operations; To provide a means for keeping the head ofthe establishment and the Congress fully and currently informed about problems and deficiencies relating to the ad- ministration ofsuch programs and operations and the necessity for and progress ofcorrective action; and B-To comply with standards established by the Comptroller General (GAO) for audits ofFederal establishments. B.1.3 Budget and Accounting Procedures Act of IQSOrPI ,K1 -784. September 12, 1950) [BAPA50]: Part II ofthis Act is cited as the "Accounting and AuditingAct of 1950". This part states that: The accounting of the Government is to provide full disclosure of the results of financial operations, adequatefinancial informationneeded inthe managementofoperations andformulationandexecutionoftheBudget,andeffectivecontroloverincome, expenditures, funds, property, and other assets. The auditing for the Government, conductedbythe Comptroller General ofthe United States as an agent ofthe Congress, is to be directed at: determiningthe extenttowhich accounting andrelatedfinancialreportingfulfill the purposes specified; financial transactions have been consummated in accordance with laws, regula- tions, or other legal requirements; and adequate internal financial control overoperations is exercised, andafford anef- fective basis for the settlement ofaccounts ofaccountable officers. Emphasis is to be placed on effecting orderly improvements resulting in simplified and more effective accounting, financialreporting,budgeting, and auditingrequirements andpro- cedures, and on the elimination of those which involve duplication or which do not serve a purposecommensuratewith the costsinvolved.Financialtransactionsofeachexecutive, legis- lative, andjudicial agency are to be audited by the General Accounting Office (GAO) in ac- cordancewithsuchprinciples andprocedures, andundersuch rules and regulations asmaybe prescribedbythe ComptrollerGeneral oftheUnited States. Inthedetermination ofvouchers and other documents, the Comptroller General is to give due regard to generally accepted principles ofauditing, includingconsiderationofthe effectiveness ofaccountingorganizations andsystems, audit andcontrol, andrelatedadministrativepractices oftherespective agencies. B.1.4 Ouality Standards for Federal Offices ofInspector General, by President's Council on Integrityand Efficiency (PCIE), 1986 [PCIE86]: This document containsqualitystandards for the management, operation, and conduct ofthe Federal Offices ofInspector General (OIG). They have been formulated and adopted as advisory standards by those Inspectors General who are members ofthe PCIE. The subjects ofthe thirteen standards are: Maintaining Independence Planning - Organizing Assuring StaffQualifications B-2: Directing and Controlling Coordinating Reporting Preserving Confidentiality Maintaining Quality Assurance Reviewing Legislation and Regulations Receiving, Controlling, and Screening Allegations Investigating Auditing B.2 SPECIFYINTERNAL CONTROLS B.2.1 Federal Managers' Financial Integrity ActfPL97-255. September 8, 1982) [FMFIA82] This Act requires internal control systems that are reasonable, to ensure that the following objectives are achieved: Obligations and costs complywith applicable law. All assets are safeguarded against waste, loss, unauthorized use, and misap- propriation. Revenuesandexpendituresapplicabletoagencyoperationsarerecorded andac- countedforproperlysothataccountsandreliable financialand statisticalreports maybe prepared and accountability ofthe assets may be maintained. The Act directs the heads ofexecutive agencies to: Makeanannualevaluationoftheirinternalcontrolsusingguidelines established bythe Office ofManagement and Budget (OMB). Provide annual reports to the President and Congress that state whether agency systemsofinternalcontrolcomplywiththeobjectivesofinternalcontrolssetforth intheAct andwith the standardsprescribedbythe ComptrollerGeneral. Where systemsdonotcomply, agencyreports mustidentifytheweaknessesinvolved and describe the plans for corrective action. B-3B.2.2a Paperwork Reduction Act(;PL96-511. December 11, 1980) [PRA80]: This Act imposes Federal information policy-making responsibilities on the Director of the Office of ManagementBudget(OMB) andrequirementsonFederalagenciestocarryoutthesepolicies. Some ofthe more pertinent ones are: To develop and implement Federal information pohcies, principles, standards, and guidelines and to provide direction and oversee the review and approval of and acquisition and use ofautomatic data processing, telecommunications, and other technology for managing information resources. To evaluate agency information management practices to determine their ade- OMB quacy and efficiency and to determine compliance with information policies, principles, standards, and guidelines. To develop and implement policies, principles, standards, and guidelines on in- formation disclosure and confidentiality, and on safeguarding the security of agency information. To monitor compHance with the Privacy Act of 1974. B.2.2b Paperwork Reduction Reauthorization Act of 1986(PL99-591. October 30, 1986) [PRRA86]: This Act enhances and clarifies various sections of the original Paperwork Reduction Act of 1980. Some ofthe changes that are most pertinent to this report are: The term "information resources management" is added as a key definition and is defined as "the planning, budgeting, organizing, directing, training, promoting, controlling, and management activities associated with the burden, collection, creation, use, and dissemination ofinformation by agencies, ..." OMB is explicitly given the responsibility to provide direction and oversee the review and approval ofnot only privacy but also security ofrecords. OMB is to set a goal ofreducing the burden ofFederal information collections by at least 5% for each successive fiscal year from 1986 through 1989. OMB Federal agencies are to implement the directives generated by this Act. Federal agencies are to periodically evaluate, and, as needed, improve the ac- curacy, completeness, and reliability ofdata and records in Federal information systems. B.2.3 EmokaA£t(PL89-306, October 30, 1965) [BRA65]: The Federal ADP Standards program is authorized under this Act. It provides for the "economic and efficient purchase, lease, maintenance, operation, and utilization of automatic data processing equipment by Federal departments and agencies." Leadership roles forcarrying out the goals ofthis Act are assigned to the Department of Commerce (DOC), the Office of Management and Budget (OMB), and the General Ser\'ices Administration (GSA). B-4DOC It authorizes the to: 1. provide scientific and technological advisory services to other agencies for relat- ing to automatic data processing and related systems; 2. make appropriate recommendations to the President concerning the estab- lishment ofuniform Federal automatic data processing standards; and 3. undertake research in computer science and technology as needed to fulfill the above responsibilities. OMB Underthe Act, the is responsible for exercising fiscal control and providingpolicy guidance to the Federal agencies on automatic data processing matters. The GSA is respon- sible for equipment procurement and maintenance. GSA reviews procurements and agency requests for services to assure that Federal Information Processing Standards (FIPS) are properlycitedandused.TheActreserves to the agenciestheauthorityto determine howcom- puters will be used in accomplishing their missions. B.2.4 Management ofFederal Information Resources(OMB Circular A- 130, (includes the revisiontoTransmittalMemo #1, OMB CircularA-71) December 12, 1985) [OMB130]: This OMB calls for increased protection for Federal computers. established, in 1978, a Federal computersecurityprogramtoguardagainst illegaluse ofinformationstoredincomputers and to savetaxpayermoney.Theprogram requires all executivebranch departments and agencies to establish a management control and audit process for sensitive computer applications. OMB The program announced by requires each executive department and agency to: Establish a management control process to assure that appropriate safeguards are built into all new computer applications. Assign responsibility for security ofeach new installation to a management offi- cial. Establish personnel security policies forboth Federal and contractorpersonnel. Conduct periodic audits ofall sensitive computer applications. Include security requirements in specifications for the acquisition or operation ofcomputer facilities or related services. Conduct periodic risk analyses ofeach computer installation. B-5Assure that appropriate contingency plans are developed to reduce the effect of computer breakdown, fires, or natural disasters. B.2.5 The Privacy Act of 1974(;PL93-579. December3 1, 1974) [PYA74]:ThisAct definesthe privacy ofan individual as directly affected by the collection, maintenance, use, and dissemi- nationofpersonalinformationbyFederalagencies.Inaddition, theActstatesthattheincreas- inguse ofcomputersandsophisticatedinformationtechnologyhasgreatlymagnifiedtheharm to individual privacy. Verifying compliance to this Act is part of the audit function. The Act identifies which types of systems are included under the provisions ofthe Act. Basically, the Act covers those systems for which information is extracted by an individual identifier. The Act requires that systems covered under the Act be managed using good data management practices. From a compHance perspective, the Act identifies who may and may not have ac- cess to personal information. The Act identifies when the information ofthe individual must be obtained, and when information can be used without gaining permission ofthe individual involved. The Act also states the type ofdisclosure required by the agency responsible for the application system. B.2.6 The Freedom ofInformation Act(;PL90-23. June 5, 1967, as amended by PL93-502, November 21, 1974) [FIAA74]: This Act permits the public, except for specific categories of matters, to have access to informationheldbyFederal agencies.The categories ofmatters not included are those that would impair rights ofprivacy or important government operations. TheActwas primarily directed toward informationmaintained bythe executivebranch ofthe Federal government. The agencies ofthe executive branch should informthepublicwhere certain types ofin- formation may be obtained on request, and what internal agency appeals are available if a memberofthepublic isrefused requestedinformation. Agencydecisions towithhold identifi- able records requested under the Act are subject tojudicial review. B.2.7a Internal Control SystemsfOMB Circular A-123, October 28, 1981) [OMB123]: This Circular prescribes policies and standards to be followed by executive departments and agenciesinestablishing and maintaininginternal controls intheirprogram and administrative activities. It requires agency heads to: maintain effective systems ofaccounting and administrative control and have aninternal control directive and areviewplanin theform ofavulnerabiHty assessment. It requires agency Inspectors General, in conjunctionwith internal audit, to determine compliance with this Circular. B-6It states the internal control objectives are "toprovide managementwith reasonable, but not absolute, assurance thatfinancial and otherresources are safeguarded from unauthorized use or disposition; transactions are executed in accordance with authorization; financial and statistical records and reports are reliable; applicable laws, regulations, and policies are ad- hered to; and resources are efficiently and effectively managed." Itspecifiesstandardsforsystem(s)ofinternalcontrol,including: "documentation, record- ing oftransactions, execution oftransactions, separation of duties, adequate supervision, ac- cess to resources, competent personnel, and reasonable assurance." rOMR B.2.7b Internal Control Systems Circular A-123 Revised, August 16, 1983) [OMBR123]: Circular A-123 was revised to incorporate the requirements of the Federal Managers'FinancialIntegrityAct [FMFIA82], OMB's Internal ControlGuidelines [OMB82], and GAO's internal control standards [GA083]. The most significant changes are: The responsibiHty section now specifies the internal control responsibilities of the designated senior internal control official and heads of organizational units OMB to conformwith Internal Control Guidelines . Internal control objectives now conformwith the Act. Internal control standards include those prescribed by GAO. Employees for whom performance agreements should include internal control responsibihties are defined. An agency's responsibilityfor takingtimelycorrective actions onweaknesses dis- closed through its evaluation ofinternal controls is described. The Act's requirement for the agency head to submit an annual statement to the President and the Congress about the agency's system of internal control is in- cluded. B.2.8 Financial Management Systems(OMB Circular A-127, December 19, 1984) [OMB 127]: 'This Circular prescribes policies and procedures to be followed by executive departments and agencies in developing, operating, evaluating, and reporting on financial management systems." The responsibilites specified include: 'The head ofeach agency is responsible for ensuring that the planning, develop- ment, operation, review andreportingonthe agency'sfinancial management sys- tem are in accordance with this Circular. The manager of each financial system has responsibilities for performance of necessary system reviews and for issuance ofreports thereon." The agency Inspector General should provide technical assistance and advice in the agency effort to review and improve the agency's financial management sys- tem. B-7'Top agencymanagement, aswellasprogramandfunctionalmanagers, shallpar- ticipate in systems planning and evaluation to ensure that their needs are met." Financial management systems objectives are spelled out. For systems operations, the best acceptably priced contemporary technology should be used to achieve systems that are useful, timely, provide reliable and complete information, use uniform definitions for com- parabihty and consistency, and are efficient and economical. Reasonable controls for main- taining systems integrityshould beused. The datainthese systems shouldprovide support for budget preparation, for managers to carry out their responsibilities, and to enable full finan- cial disclosure as required. B.2.9 Standards for Internal Controls in the Federal Government(Green Book), GAO, 1983 [GA083]: Thisdocumentcontainsthe ComptrollerGeneral'sinternal controlstandards to be followed by executive agencies in establishing and maintaining systems ofinternal con- trol as required by the Federal Manager's Financial Integrity Act of 1982 [FMFIA82]. These standards fall into three categories: General, Specific, and Audit Resolution. The General standards consist of: 1. Reasonable Assurance that objectives ofthe systems will be accomplished; 2. Supportive Attitude maintained and demonstrated by managers and employees; 3. Competent Personnelwho can accomplish their duties and understand need for good internal controls; 4. Control Objectives developed for each agency activity; and 5. Control Techniques are efficient and effective. The specific standards consist of: 1. Documentation for internal control systems and all transactions and other sig- nificant events; 2. Recording ofTransactions and Events promptly and properly classified; 3. Execution ofTransactions and Events only by authorized persons; 4. Separation ofDuties for authorizing, processing, recording, and reviewingtrans- actions; 5. Supervision to ensure internal control objectives are achieved; and 6. Access to and Accountability forResources by authorized individuals,withperi- odic review ofaccountability. The Audit Resolution standard requires managers to promptly evaluate, determine the response to, and respond to audit findings. B-8APPENDIX C KEYCOMPUTER SECURITYAND AUDIT DEFINITIONS ThefollowingkeydefinitionsinADP internalcontrolandcomputersecurityareprovided to facilitate understanding ofthis guide. 1. Audit of computer security : A computer security audit is defined by NBS Special Publica- tion 500-57^ as: "An independent evaluation ofthe controls employed to ensure: 1. The appropriate protection of the organization's information assets (including hardware, software, firmware, and data) from all significant anticipated threats or hazards; 2. The accuracy and reliability of the data maintained on or generated by an automated data processing system; and 3. The operational reliability and performance assurance for accuracy and timeli- ness ofall components ofthe automated data processing system." 2. Auditofinternal controls Anindependent evaluationofthe internalcontrols related to the : areabeing audited. The evaluation should develop an opinionrelating to the adequacy ofthe internal controls to reduce riskto an acceptable level. Where internal controls are not accept- able,vulnerabilitiesshouldbeidentified.Auditingcomputersecurityisasubsetofthisactivity. 3. Audit risk : Audit risks are the risks that are ofconcern to auditors, 4. Audit risk exposure The possible forms ofloss or harm that are ofconcern to auditors, : 5. Audit risk exposure level Proportional to the the probability ofoccurrence ofthe possible : forms ofloss that are ofconcern to auditors, 6. Computer generated risk : Computer generated risk is the potential loss or damage to an organizationthatresultsfromtheuseormisuseofitscomputer.Thismayinvolveunauthorized disclosure, unauthorized modification, and/or loss of information resources as well as the authorized but incorrect use ofa computer. This risk canbe measured to some extent byper- forming a risk analysis. (Adapted from [NBS57], p.A-2) 1 [NBS57], p.A-3. C-17. Computer security : The current, generallyaccepted definitionofcomputersecurityisgiven in NBS Special Publication 500-57^ "Computersecurityisastateorconditionthatacomputersystempossesses.Com- puter security is never absolute. Rather, each system possesses security at some level. Computer security is provided by internal safeguards (built into the hardwareandsoftware) andexternalsafeguards (physicalandprocedural) against possible threats. The level of computer security is dependent on the degree to which: 1. Tliecomputersystem'scomponents(includinghardware,software,firmware,and data) are protected against all significant threats; 2. Datamaintained on or generatedby its dataprocessing systems are accurate and rehable; and 3. Its data processing systems are operationally reliable and satisfy criteria that as- sure the accurate and timely performance ofthe system." 8. Control: Anyprotectiveaction, device,procedure, technique, orothermeasurethatreduces exposures. (FIPS102, p.61) A 9. Exposure : possible form of loss or harm, e.g., unauthorized disclosure, modification, destruction, or denial ofservice. 10. Internal control Anymethod, procedure, orpracticeused to reduce theprobabilityofloss : or harm due to a flaw or weakness in the system. Note that various accounting pubHcations define control for specificpurposes, such as internal accounting controls are controls used to reduce financial risks. 11. OuaHty assurance The planned, systematic process that ensures that automated system : productsandacquisition/developmentprocesses complywithestablishedstandards,practices, and procedures. Some of the quality assurance activities include lifecycle (a) validation, verification, andtesting; (b) monitoringofdevelopment andtestingactivities, and change con- trols; (c) data integrity assurance; and (d) reviews and audits. 12. Risk : Risk is a potential damaging event which, if it occurs, can produce losses (see Sec- tion 1.2.1) 13. Risk analysis : Riskanalysis is ananalysis ofan organization's information resources, its ex- isting controls, and its remaining organization and computer system vulnerabiHties. It com- bines the loss potential for each resource or combination ofresources with an estimated rate 1 Ibid C-2ofoccurrence to establish a potential level of damage to assets or resources in terms of dol- lars or other assets. A 14. Systemdevelopment life cycle (^SDT.CV systematic methodused forbuildingautomated information systems (AISs). This systematicprocess defines the activities and products/docu- ments needed to create an AIS, and then divides the process into phases, assigning specific products/documents to each phase. The SDLC phases adopted in this document are: Initiation pha,se: This phase recognizes the users' need, validates that need, ex- plores alternative functional concepts in order to recommend one for approval. Definitionphase Defines the functional requirements and begins detailed plan- : ning for development ofan operable AIS. The activities and goals for all phases, including resource estimates and milestones, are determined during this phase. Systems designphase Thisphase develops the specification oftheproblemsolu- : tion. The detailed design specifications describe the physical solution in such a way that it can be implemented in code with little or no need for additional analysis. Programmingandtrainingphase:Thisphasecreatesprogramsinaccordancewith the system design. During this phase, a training plan and documents, as well as user and maintenance manuals are prepared. Evaluationand acceptance phase: Duringthisphase, completed codewillunder- go testing tovalidate its performance. The security requirements need to be cer- tified by an appropriate authority prior to accreditation and installation. Installation and operation phase :Thisphase is designed to: l)implementthe ap- proved operational plan, including extension to and installation at other sites; 2)continue approved operation; 3)budget adequately; and 4)control all changes and maintain/modify the AIS during its remaining life. 15. Vulnerability : A vulnerability is a design, implementation, or operations flaw that may be exploitedby a threat, to cause the computer system or application to operate in a fashion dif- ferentfrom itspublished specifications and to result indestruction or misuse ofequipment or data. ([NBS57], p.A-2] C-316. Vulnerability assessment The process of (l)identifying flaws and the controls associated : with those flaws in order to evaluate the adequacy ofthe control to reduce the riskes to an ac- ceptable level; and (2)identifying those flaws for management action where risk levels are found to be too high. C-41 APPENDIX D ADDITIONAL RISKS IN A COMPUTERIZED ENVIRONMENT IMPROPER USE OF TECHNOLOGY D.l Computer technology provides systems analysts and programmers with a variety of processing capabilities. This technology mustbe matched to the needs ofthe user to optimize A the implementation ofthose needs. mismatch oftechnology and needs can result in an un- necessary expenditure oforganizational resources. One of the more common misuses of technology is the introduction of new technology prior to the clear establishment of its need. For example, many organizations introduce data base technology without clearly establishing the need for that technology. Experience has shown that the early users ofa new technology frequently consume large amounts ofresour- ces during the process oflearning how to use that new technology. The type ofconditions that lead to the improper use oftechnology include: 1. Early and/or premature user ofnew hardware technology; 2. Early user ofnew software technology; 3. Minimalplanning for the installation ofnew hardware and software technology; and 4. Systems analyst/programmer improperly skilled in the use oftechnology. D.2 REPETITION OF ERRORS Inamanual processingenvironment, errors are made individually. Thus, aperson might process one item correctly, make an error on the next, process the next twenty correctly, and thenmake anothererror. Inautomated systems, the rules are applied consistently.Thus, ifthe rules are correct, processing is always correct, but if the rules are erroneous, processing will always be erroneous. Errors can result from application programs, hardware failures, and failures in vendor- supphed software. For example, awrongpercentage may have been entered for FICAdeduc- tions.Thus,everyemployeeforthatpayperiodwillhavethewrongamountdeductedforFICA purposes. D-The conditions that cause repetition oferrors include: 1. Insufficient program testing; 2. Inadequate checks on entry ofmaster information; and 3. Failure to monitor the results ofprocessing. D.3 CASCADING OF ERRORS The cascading oferrors is the domino effect oferrors throughout an application system. An error in one part of the program or application triggers a second yet unrelated error in anotherpart ofthe application system. This second error may trigger a third error, and so on. The cascading of error risk is frequently associated with making changes to application A systems. change is made and tested in the program in which the change occurs. However, some condition has been altered as a result of the change, which causes an error to occur in another part ofthe application system. Cascading oferrors can occur between applications. This risk intensifies as appHcations become more integrated. For example, asystem that is accepting orders may be tied through a series ofapplications to a system that replenishes inventorybased upon orders. Thus, an in- significant error in the order entry program can "cascade" through a series of applications resulting in avery serious error in the inventory replenishment program. The types ofconditions that lead to cascading oferrors include: 1. Inadequately tested appHcations; 2. Failure to communicate the type and date ofchanges being implemented; and 3. Limited testing ofprogram changes. D.4 ILLOGICAL PROCESSING Illogicalprocessingis theperformance ofanautomated eventwhichwould be highlyun- likelyin a manual processing environment, for example, producing apayroll check fora cleri- calindividual forover $1 million. Thisis possible inanautomated systemdue toprogramming or hardware errors, but highly unlikely in a manual system. D-2Computerizedapplications do not havethe same human oversightas is incorporated into manual systems. In addition, fewer people have a good understanding of the processing logic ofcomputerized applications. Thus, in some instances illogical processing may not be readily recognizable. The conditions that can result in illogical processing include: 1. Failure to check for unusually large amounts on output documents; 2. Fields that are eithertoo small ortoo large, thereby impactingthe completeness, accuracy, or efficiency ofthe data being processed; and 3. Failure to scan output documents. D.5 INABILITYTO TRANSLATEUSERNEEDS INTO TECHNICALREQUIREMENTS One ofthe major failures ofdataprocessing has been a communication failure between users and technical personnel. In many organizations users cannot adequately express their needsintermsthatfacilitatethepreparationofcomputerized applications. Likewise, the tech- nical computerpeople are oftenunable to appreciate the concerns and requirements oftheir users. The risk associated with failure to satisfy user needs is complex. Exposures include: (1) failure to implement needs because users were unaware of technical capabilities; (2) im- properlyimplementedneedsbecausethetechnicalpersonneldidnotunderstanduserrequire- ments; (3) users accepting improperly implemented needs because they are unsure how to specify changes; and (4) the building of redundant manual systems to compensate for weak- nesses in computerized applications. Theconditionsthat canlead totheinabilitytotranslateuserneedsintotechnicalrequire- ments include: EDP 1. Users without technical skills; 2. Technical people without sufficient understanding ofuser requirements; 3. User's inability to specify requirements in sufficient detail; and 4. Multi-user systems with no user "in charge" ofthe system. D-3D.6 INABILITYTO CONTROL TECHNOLOGY Theproblemsassociatedwiththeimplementationofnewtechnologyhaveabsorbedmost ofthe efforts of data processing personnel The SAC study [IIA-77-1,2,3] implied that there was too little time left to develop and install technological controls. The result is expenditure ofresources to correct technological problems. Controls are needed over the technological environment. The controls ensure that the proper version ofthe proper program is in production at the right time, that the proper files are mounted, that operators perform the proper instructions, that adequate procedures are developed to prevent, detect, and correct problems occuring in the operating environment, and that the proper data is maintained and retrievable when needed. The types ofconditions that result in uncontrolled technology include: 1. Selection ofvendor-offered system control capabilities bysystems programmers without considering audit needs; 2. Too many control tradeoffs for operational efficiency; 3. Inadequate restart/recoveryprocedures; 4. Inadequate control over differentversions ofprograms; 5. Inadequate control over schedulers, system operators, tape librarians, print capabihties, and data transmission capabilities; and 6. Inadequate review ofoutputs. D.7 INCORRECT ENTRYOF DATA In computerized applications, there is a mechanical step required to convert input data into machine-readable format. In the process of conducting this task, errors can occur. Data thatwas properlyprepared and authorized maybe enteredinto computerized applications in- correctly. Much of the data entered into batch type systems is entered using a keyboard device. Some of thse devices are keypunch machines and key-to-disk machines. The data originator manually transcribes the input information onto some type ofform, and the form is given to a key operator to enter on computer media. During this keying process, errors are made. D-4In the newer technology, data can be originated and entered at the same time. For ex- ample, order entry clerks receive orders by telephone and key them directly into computer memory. However, errors can still occur during this process. Other methods of data entry include optical scanners, process control computers that monitorsituations such asproductionmachinery, automaticcash dispensers and point-of-sale equipment. However, these are all mechanical devices and thus subject to failure. The types ofconditions that can cause incorrect entry ofdata include: Human 1. errors in keying data; 2. Mechanical failure ofhardware devices; 3. Misinterpretation ofcharacters or meaning ofmanually recorded input; 4. Misunderstanding ofdata entry procedures; and 5. Inadequate data verification procedures. D.8 CONCENTRATION OF DATA Computerized applications concentrate data in an easy to access format. In manual sys- tems,dataisvoluminousandstoredinmanyplaces.Itisdifficultforanunauthorizedindividual to spend much time browsingundetected through file cabinets or othermanual storage areas. Using computerized media, unauthorized individuals can browse using computer programs. This may be difficult to detect without adequate safeguards. In addition, the data can be copied quickly without leaving any visible trail or destroying the original data. Thus, the owners ofthe data may not be aware that the data has been compromised. Databasetechnologyincreases theriskofdatamanipulationand compromise.The more data stored in a single place, the greater the value ofthat data to an unauthorized individual. Forexample, theinformationabout anindividualinthepayroll applicationisrestrictedto cur- rentpay information, but whenthat data is coupledwith personnel history, not only is current payinformationavailable, but alsopayhistory, individual skills,years ofemployment, progres- sion ofemployment, and perhaps performance evaluation. The concentration ofdataincreases the problems ofgreater reliance on a singlepiece of dataand reliance on asingle computerfile. Ifthe data entered is erroneous, the more applica- tions that rely on that piece ofdata, the greater the impact ofthe error. In addition, the more D-5applications that use the concentrated data, the greater the impact when that data becomes unavailable due to problems with either the hardware or software used for processing that data. Theconditionsthatcancreateproblemsduetotheconcentrationofdataincomputerized applications include: 1. Erroneous data and its impact on multiple users ofthat data; 2. Impact ofhardware and software failures that ordinarily make the data available to multiple users; 3. Inadequate access controls enabling unauthorized access to data; and 4. Inefficient use of system for data storage and/or retrieval, which may impact response time or computer capacity. D.9 INABILITY TO REACT QUICKLY Much of the value of computerized appHcations is the ability to satisfy user needs on a timely basis. Some of these needs are predetermined and reports are prepared on a regular basistomeettheseneeds.Otherneedsoccurperiodicallywhichrequirespecialactionstosatis- fy. If the computerized application is unable to satisfy these special needs on a timely basis, redundant systems may be built for that purpose. One of the measures of success of a computerized application is the speed with which specialrequestscanbesatisfied. Some oftheneweron-linedatabaseapplicationswithaquery language can satisfy some requests within avery short time span. On the other hand, some of the older batch-oriented applications may take several days or weeks to satisfy a special re- quest. In some instances, the structuring of the application system is an inhibiting factor in satisfying requests. For example, if an auditor wanted all ofthe supporting information for a supply requisition in a tape batched system, the cost and difficulty of satisfying that request may be prohibitive. The reason is that the requisition could be spread over many weeks of processing, due to back orders, returned shipments, and shipping errors. The evidence sup- porting the transaction may be spread over many tape files and the cost ofprocessing those files may be exhorbitant. D-6The conditions that can cause computerized applications to be unable to react quickly include: 1. Computer time is unavailable to satisfy the request, or computer terminals/- microcomputers are not readily accessible to users; 2. Thestructureofthecomputerfilesisinconsistentwiththeinformationrequested; 3. General-purposeextractprogramsarenotavailabletosatisfythedesiredrequest; and 4. The cost ofprocessing exceeds the value ofthe information requested. D.IO INABILITYTO SUBSTANTIATE PROCESSING Computerizedapplicationsshould containthe capabilitytosubstantiate processing.This substantiation includes both the ability to reconstruct the processing of a single transaction and the ability to reconstruct control totals. Computerized applications should be able to produce all of the source transactions that support a control total, and substantiate that any source document is contained in a control total. Application systems need to substantiate processing for the purposes of correcting er- rors and proving the correctness ofprocessing. When errors occur, computerpersonnel need topinpoint the cause ofthose errors so they can be corrected. Computerized application cus- tomers,otherusers,and control-orientedpersonnel, suchasauditors, frequentlywanttoverify the correctness ofprocessing. The conditions that may result in the inability to substantiate processing include: 1. Evidence is not retained long enough; 2. The evidence from intermediate processing is not retained; 3. Evidence is not independently reviewed for quality assurance and/or data in- tegrity; 4. Outputs are not reviewed for quality by the users; and 5. The cost of substantiating processing exceeds the benefits derived from the process. D-7D.ll CONCENTRATION OF RESPONSIBILITIES The computerization ofan application tends to concentrate the responsibihties ofmany people into the automated application. Responsibilities that had been segregated for control purposes among many people may be concentrated into a single application system. In addi- tion, a single application system may concentrate responsibilities from many departments within an organization. The responsibilities inacomputerized environment maybe concentratedinboth the ap- plication system and computer-oriented personnel. For example, the data base administrator A may absorb data control responsibilities from many areas in the organization. single com- puter system project leader may have the processing responsibility for many areas in the or- ganization. New methods of separation of duties must be substituted for the previous segregation ofduties among people. The conditions that cause the concentration of responsibilities in a computerized en- vironment include: 1. The establishment of a data processing programming and systems group to develop computerized applications for an organization; 2. Centralized processing ofcomputerized applications; 3. Establishment ofa data base administration function; 4. The lack ofadequate standards and enforcement ofthose standards; and 5. The lack ofadequate quality assurance and systems or applications testing. D-8APPENDIX E VULNERABILITIES IN A COMPUTERIZED ENVIRONMENT The following five pages are an exact duplicate ofthe application system vulnerabilities list found in FTPS PUB 65, GUIDELINE FOR AUTOMATIC DATA PROCESSING RISK ANALYSIS. It is included here for the convenience ofthe reader. E-1. tics for stock market transactions before their public release. • A user whose job requires access to indi- 1. ERRONEOUS OR FALSIFIED DATA IN- vidual records in a file may manage to PUT. Erroneous or falsified input data is the compile a complete listing of the file and simplest and most common cause of undesirable then make unauthorized use of it (e.g., sell performance by an applications system. Vulner- a listing of employees' home addresses as abilities occur wherever data is collected, man- a mailing list) ually processed, or prepared for entry to the • Unauthorized altering of information may computer. be accomplished for an unauthorized end • Unreasonable or inconsistent source data user (e.g., altering of personnel records). values may not be detected. • An authorized user may use the system for • Keying errors during transcription may personal benefit (e.g., theft of services). not be detected. • A supervisor may manage to approve and • Incomplete or poorly formatted data rec- enter a fraudulent transaction. ords may be accepted and treated as if they • A disgruntled or terminated employee may were complete records. destroy or modify records—possibly in • Records in one format may be interpreted such a way that backup records are also according to a different format. corrupted and useless. • An employee may fraudulently add, delete, • An authorized user may accept a bribe to or modify data (e.g., payment vouchers, modify or obtain information. claims) to obtain benefits (e.g., checks, negotiable coupons) for himself. 3. UNCONTROLLED SYSTEM ACCESS. Or- • Lack of document counts and other controls ganizations expose themselves to unnecessary over source data or input transactions may risk if they fail to establish controls over who allov^ some of the data or —transactions to can enter the ADP area, who can use the ADP be lost M^ithout detection or allow extra system, and who can access the information records to be added. contained in the system. • Records about the data-entry personnel • Data or programs may be stolen from the (e.g., a record of a personnel action) may computer room or other storage areas. be modified during data entry. • ADP facilities may be destroyed or dam- • Data which arrives at the last minute (or aged by either intruders or employees. under some other special or emergency • Individuals may not be adequately identi- ADP condition) may not be verified prior to fied before they are allowed to enter processing. area. • Records in which errors have been detected • Remote terminals may not be adequately may be corrected without verification of protected from use by unauthorized per- the full record. sons. • An unauthorized user may gain access to 2. MISUSE BY AUTHORIZED END USERS. the system via a dial-in line and an author- End users are the people who are served by the ized user's password. ADP system. The system is designed for their • Passwords may be inadvertently revealed use, but they can also misuse it for undesirable to unauthorized individuals. A user may purposes. It is often very difficult to determine write his password in some convenient whether their use of the system is in accordance place, or the password may be obtained with the legitimate performance of their job. from card decks, discarded printouts, or • An employee may convert Government by observing the user as he types it. information to an unauthorized use; for • A user may leave a logged-in terminal example, he may sell privileged data about unattended, allowing an unauthorized per- an individual to a prospective employer, son to use it. credit agency, insurance company, or com- • A terminated employee may retain access petitor; or he may use Government statis- to ADP system because his name and pass- E-2. . . : . word are not immediately deleted from lapsed controls, and losses in storage media and authorization tables and control lists. output. • An unauthorized individual may gain ac- Procedures and Controls cess to the system for his own purposes • Files may be destroyed during data base (e.g., theft of computer services or data reorganization or during release of disk or programs, modification of data, altera- space. tion of programs, sabotage, denial of ser- • Operators may ignore operational proce- vices) dures for example, by allowing program- ; • Repeated attempts by the same user or mers to operate computer equipment. terminal to gain unauthorized access to the • Job control language parameters may be system or to a file may go undetected. erroneous. • An installation manager may circumvent INEFFECTIVE SECURITY PRACTICES 4. operational controls to obtain information. FOR THE APPLICATION. Inadequate man- • Careless or incorrect restarting after shut- ual checks and controls to insure correct down may cause the state of a transaction ADP processing by the system or negligence update to be unknown. by those responsible for carrying out these • An operator may enter erroneous informa- checks result in many vulnerabilities. tion at CPU console (e.g., control switch • Poorly defined criteria for authorized ac- in wrong position, terminal user allowed cess may result in employees not knowing full system access, operator cancels wrong what information they, or others, are per- job from queue) mitted to access. • Hardware maintenance may be performed • The person responsible for security may while production data is on-line and the fail to restrict user access to only those equipment undergoing maintenance is not processes and data which are needed to isolated. accomplish assigned tasks. • An operator may perform unauthorized • Large funds disbursements, unusual price acts for periSonal gain (e.g., make extra changes, and unanticipated inventory usage copies of competitive bidding reports, print may not be reviewed for correctness. copies of unemployment checks, delete a • Repeated payments to the same party may record from journal file). go unnoticed because there is no review. • Operations staff may sabotage the com- • Sensitive data may be carelessly handled puter (e.g., drop pieces of metal into a by the application staff, by the mail ser- terminal) vice, or by other personnel within the • The wrong version of a program may be organization. executed. • Post-processing reports analyzing system • A program may be executed using wrong operations may not be reviewed to detect data or may be executed twice using the security violations. sametransactions. • Inadvertent modification or destruction of • An operator may bypass required safety files may occur when trainees are allowed controls (e.g., write rings for tape reels) to work on live data. • Supervision of operations personnel may • Appropriate action may not be pursued not be adequate during non-working hour when a security variance is reported to shifts. the system security officer or to the per- • Due to incorrectly learned procedures, an petrating individual's supervisor; in fact, operator may alter or erasethemaster files. procedures covering such occurrences may • A console operator may override a label not exist. check without recording the action in the security log. PROCEDURAL ERRORS WITHIN THE 5. ADP FACILITY. Both errors and intentional Storage Media Handling: acts committed by the ADP operations staff • Critical tape files may be mounted without may result in improper operational procedures, being write protected. E-3. . • Inadvertently or intentionally mislabeled an environment will still contain undetected storage media are erased. In a case where errors, programs not developed in this manner they contain backup files, the erasure may will probably be rife with errors. Additionally, not be noticed until it is needed. programmers can deliberately modifyprograms • Internal labels on storage media may not to produce undesirable side effects or they can be checked for correctness. misuse the programs they are in charge of. • Files with missing or mislabeled expiration • Records may be deleted from sensitive files dates may be erased. without a guarantee that the deleted rec- • Incorrect processing of data or erroneous ords can be reconstructed. updating of files may occur when card • Programmers may insertspecial provisions decks have been dropped, partial input in programs that manipulate data concern- decks are used, write rings mistakenly are ing themselves (e.g., payroll programmer placed in tapes, paper tape is incorrectly may alter his own payroll records) mounted, or wrong tape is mounted. • Data may not be stored separately from • Scratch tapes used for jobs processing sen- code with the result that program modifi- sitive data may not be adequately erased cations are more difficult and must be after use. made more frequently. • Temporary files written during a job step • Program changes may not be tested ade- for use in subsequent steps may be errone- quately before being used in a production ously released or modified through inade- run. quate protection ofthe files or because of an • Changes to a program may result in new abnormal termination. errors because of unanticipated interac- • Storage media containing sensitive infor- tions between program modules. mation may not get adequate protection • Program acceptancetests may failto detect because operations staff is not advised of errors thatonlyoccurfor unusual combina- the nature of the information content. tions of input (e.g., a program that is « Tape managementprocedures may not ade- supposed to reject all except a specified quately account for the current status of range of values actually accepts an addi- all tapes. tional value) • Magnetic storage media that have con- • Programs, the contents of which should be tained very sensitive information may not safeguarded, may not be identified and be degaussed before being released. protected. • Outputmay be sentto the wrongindividual • Code, test data with its associated output, or terminal. and documentation for certified programs • Improperly operating output or post- may not be filed and retained for reference. processing units (e.g., bursters, decollators • Documentation for vital programs may not or multipart forms) may result in loss of be safeguarded. output. • Programmers may fail to keep a change • Surplus output material (e.g., duplicates of output data, used carbon paper) may not log, to maintain back copies, orto formalize recordkeeping activities. be disposed of properly. • Tapes and programs that label output for • An employee may steal programs he is distribution may be erroneous or not pro- maintaining and use them for personal tected from tampering. gain (e.g., sale to a commercial organiza- tion, hold another organization for extor- 6. PROGRAM ERRORS. Applications pro- tion) . grams should be developed in an environment • Poor program design may result in a criti- that requires and supports complete, correct, cal data value being initialized twice. An and consistent program design, good program- error may occur when the progra —m is ming practices, adequate testing, review, and modified to change the data value but documentation, and proper maintenance proce- only changes it in one place. dures. Although programs developed in such • Production data may be disclosed or E-4: : destroyed when it is used during testing. the. operating system may be tampered • Errors may result when the programmer with or sensitive information from on-line misunderstands requests for changes to the files may be disclosed). program. • An operating system may fail to record • Errors may be introduced by a program- that multiple copies of output have been mer who makes changes directlyto machine made from spooled storage devices. code. • An operating system may fail to maintain • Programs may contain routines not com- an unbroken audit trail. patible with their intended purpose, which • When restarting after a system crash, the can disable or bypass security protection operating system may fail to ascertain that mechanisms. For example, a programmer all terminal locations which were previ- who anticipates being fired inserts code ously occupied are still occupied by the into a program which will cause vital sys- same individuals. tem files to be deleted as soon as his name • A user may be able to get into monitor or no longer appears in the payroll file. supervisory mode. • Inadequate documentation or labeling may • The operating system may fail to erase all result in wrong version of program being scratch space assigned to a job after the modified. normal or abnormal termination ofthe job. • Files may be allowed to be read or written 7. OPERATING SYSTEM FLAWS. Design without having been opened. and implementation errors, system generation and maintenance problems, and deliberate pene- COMMUNICATIONS SYSTEM FAILURE. 8. trations resulting in modifications tothe operat- Information being routed from one location to ing system can produce undesirable effects in another over communication lines is vulnerable the application system. Flaws in the operating to accidental failures and to intentional inter- system are often difficult to prevent and detect. ception and modification by unauthorized • User jobs may be permitted to read or parties. write outside assigned storage area. • Inconsistencies may be introduced into data Accidental Failures because of simultaneous processing of the • Undetected communications errors may same file by two jobs. result in incorrect or modified data. • An operating system design or implemen- • Information may be accidentally misdi- tation error may allow a user to disable rected to the wrong terminal. audit controls or to access all system infor- • Communication nodes may leave unpro- mation. tected fragments of messages in memory • The operating system may not protect a during unanticipated interruptions in copy of information as thoroughly as it processing. protects the original. • Communication protocol may fail to posi- • Unauthorized modification to the operating tively identify the transmitter or receiver system may allow a data entry clerk to ofamessage. enter programs and thus subvert the sys- tem. IntentionalActs • An operating system crash may expose • Communications lines may be monitored valuable information such as password lists by unauthorized individuals. or authorization tables. • Data or programs may be stolen via tele- • Maintenancepersonnelmaybypass security phone circuits from a remote job entry controls while performing maintenance terminal. work. At such times the system is vulner- • Programs in the network switching com- able to errors or intentional acts of the puters may be modified to compromise maintenance personnel, or anyone else who security. might also be on the system and discover • Data may be deliberately changed by indi- the opening (e.g., microcoded sections of viduals tapping the line (requires some E-5. . sophistication, but is applicable to financial • If encryption is used, keys may be stolen. data) • A terminal user may be "spoofed" into ® An unauthorized user may "take over" a providing sensitive data. computer communication port as an au- • False messages may be inserted into the thorized user disconnects from it. Many system. systems cannot detect the change. This is • True messages may be deleted from the particularly true in much of the currently system. available communication equipment and in • Messages may be recorded and replayed many communication protocols. into the system ("Deposit $100" messages) E-6APPENDIX F EVIDENCE PROVIDED BYCOMPUTER TECHNOLOGY TRADITIONAL FORMS OF AUDIT EVIDENCE F.l The evidence produced by an AIS may be different than that produced by manual sys- tems. It is important for the auditor to understand these new forms of evidence because the methodsused for auditingwill change as the forms ofevidence change. The followingis a list- ingofthetraditionalformsofevidencethat existwhenmanualprocessingisused.Thedescrip- tionprovides an example ofhow the computer can change the forms ofthat evidence: 1. People-initiated transactions - Transactions originated by people and entered into a system for processing. In computerized applications, transactions can be automatically generated. For example, the application can automatically issue a replacement orderwhen inventory falls below a reorder point. 2. Hard-copy input - The manual recording ofthe information needed to originate a transaction. In computerized applications information can be entered through a terminal, which leaves no hard document. For example, a pay rate change can be entered on a computerized payroll master file through a computer terminal. 3. Manual authorization- People, usuallysupervisors, reviewtransactions and then affix their signature, initials, or stamp to the document indicating authorization for processing. In computerized applications, authorization can be predeter- mined. For example, sales on credit canbe automaticallyapproved ifapredeter- mined credit limit is not exceeded. Other methods of electronic authorization include entering a password, inserting a magnetically-encoded card, or turning a supervisory key in a terminal. 4. Movement of documents - People carry documents from one workstation to another, or move the documents by mail or equivalent service from one place of business to another. By these methods, a physical document is moved. In com- puterizedapplications, thedatacanbesentelectronically.Thedataistranscribed, coded, often condensed, and then moved electronically over communication lines. 5. Hard-copy processing - Processing is manually performed using the transaction documents. For example, a form might show the steps performed by a procure- ment officer in selecting a vendor. Normally the documents contain work space to perform the necessaryprocessing. In computerized apphcations, processing is F-1done electronically within computer storage by computer programs following predetermined rules. 6. Simplified processing - The processing performed must be simplified so that people can perform the steps repetitively without a high probability of error. In computerizedapplications,processingcanbeextremelycomplexduetothespeed and accuracy ofthe computer. For example, production scheduling canbe calcu- lated hundreds ofdifferent ways in order to select the most effective schedule. 7. Manuals of master information - The permanent-type information needed for processing, such as pay rates and product pricing, is maintained in manuals. For example, if GS pay rates by step are in manuals that evidence can be read by people. In computerized applications, this information is stored on computer media. 8. Hard-copy output -The results ofprocessing are listed on hard-copy documents, suchas checks and reports. Frequentlythese documents containthe intermediate processingresults. Incomputerized applications, processingmaynot resultinthe production of hard-copy documents. For example, funds can be transferred electronically, output reports displayed on video screens. In some systems, routineinformationiswithheldsothattherecipientreceivesonlyexceptionitems which require action. 9. File of documents - Input, processing, and output documents are stored in file cabinets or similar containers. When the data is needed, it can be manually lo- cated and retrieved fromthe physical storage area. Inaprocurementsystem, pur- chase orders might be stored in afile cabinet. Incomputerized apphcations, most filesexist oncomputer media, such astapes anddisks.Toretrieve datafromthese media requires the use ofextract programs. 10. Hard-copy audit trail -The information needed to reconstruct processing is con- tained in hard-copy documents. These documents contain source data, the authorization signature, methods of processing, and output results. This is nor- mally sufficient information to reconstruct the transaction and to trace the trans- action to control totals, or from control totals back to the source document. For example, a payroll paper audit trail would permit the reconstruction of each employee's salary. In computerized applications, the audit trail may be frag- mented, such as often occurs in a database environment. Also, much ofthe audit trail information may be stored on computer media. Computerized audit trails frequentlyrequire theuserofthe audittrail tounderstand therules ofprocessing F-2because it may not be obvious which processing path was taken, especiallywhen computer processing is complex. 11. Procedure manual -All ofthe stepsneeded toprocess transactions through asys- temarecontainedinoneormoreproceduremanuals.Theseareguidesforpeople in moving and processing transactions. For example, procedures might be developed to define the steps to follow when a transaction is outside normal processing, such as a claim for a nonreimbursed healthcare expense. 12. Manual monitoring - People, normally supervisors, oversee and review process- ing to determine its reasonableness, accuracy, completeness, and authorization. Forexample, asupervisorwould review departmentpurchase orders for correct- ness and need prior to sending them to procurement. In computerized applica- tions, much of this monitoring is performed automatically using predetermined program logic. It is difficult to have people monitor processing as computer sys- temsbecomemore integrated andcomplexandtheprocessingcycleisshortened. 13. Proof of segregation of duties - Segregation of duties occurs by dividing tasks among people. In computerized applications, segregation of duties not only in- volves the division of tasks among people, but the division of tasks among automated processing steps. For example, one computer program may process one part ofatransaction, while another computer programprocesses a different part. 14. Bulkprocessingtechniques-Theprocessingoflarge amountsofdatamayinvolve re-sequencing ormatching diverse data elements.This is often difficultand cost- lyinamanual system, soitis onlydonewhennecessary. Incomputerizedapplica- tions, large amounts of data can be stored in a single data base. The speed and processing capability of the computer makes this data available in any format desired. In a computerized environment, more complex analyses and secondary uses ofdata can be made. IMPACT OF COMPUTERTECHNOLOGYON EVIDENCE F.2 The introduction ofthe computer may change the traditional forms ofevidence. If this evidence changes, so must the methods ofauditing change. Tools and techniques that are ef- fectiveinamanual environmentmaynotbe applicable to audits inthecomputerizedenviron- ment. F-3The forms ofevidence that the auditor examines in a manual environment include: 1. Originationdocuments such as purchase orders, employee timecards, and requi- sition forms; 2. Approval evidence such as signatures, time stamps, and date stamps; 3. Processing evidence, including calculation forms, master data manuals, and ad- ding machine tapes; and 4. Output evidence, including checks, bank statements, invoices and reports. Understanding how computer technology impacts audit evidence enables the auditor to recognize and appreciate the need to audit differently in a computerized environment. This sectionwill review the traditional forms ofevidence in a manual environment and then iden- tify the types ofautomated technology that mayimpact the traditional forms ofevidence. This will assist auditors in determining whether they need to modify their audit methods because ofthe introduction ofthe computer. IMPACT OF CHANGING EVIDENCE ON AUDIT F.3 Most organizations subject to an audit functionhave a computer. Inthese organizations, mostapplicationsarecomputerized.Thus, thequestiontheauditormustaskis, "Doesthecom- puter impact my audit?" The audit is impacted if the form of audit evidence is changed. This changed form of evidence can create new audit concerns, and at the same time require the auditor to use new audit methods to obtain and/or examine the evidence. F.3.1 TheAudit Dilemma One canlookat two implementations ofacomputerizedpayroll applicationto assessthe audit impact of the computer on each implementation. An auditor is assigned to conduct an auditofapayroll application.The applicationis computerized and the auditorneeds to design an audit strategy. The audit dilemma is what, ifanything, is different about the audit because the application is computerized. A Case - Computerized Payroll Application A Organization computerized their payroll application. In this appHcation, each employee fills out a timecard and the employee's supervisor signs the timecard approving the hours. The data is entered into the application on a key-to-disk machine, and a copy of the enteredinformationisreturnedtothe supervisorforverification. Atthebeginningofeachpay F-4period, a listingis prepared ofall changes to the payroll rates and deductions. Also, a detailed reportisprintedlistingeachemployee'spay information,payhistory,paydeductions, andwage status at the end of that pay period. Each department gets a report showing all the informa- tion used for preparing payroll, together with the results of that processing. The checks are printed and then distributed by each employee's supervisor. The endorsed checks are inde- pendently reconciled bypersonnel outside the payroll department. This application has not significantly changed the traditional forms of evidence. Thus, the same methodsused to audit amanualpayroll systemwould be effective in the audit ofthis computerized payroll application. However, the auditor may wish to use automated audit methods, such as audit software, to improve the efficiency and economy ofthe audit. Case B - Computerized Payroll Application Organization B computerized their payroll application using data collection terminals. Employeeswere issued magnetically encoded cards and when they enter and leave work they insert these cards into the data collection equipment. This records employee start and stop times. The personnel department uses a terminal to enter payroll changes into a payroll data base. The effective date of the change is entered with the data so that information can be entered whenever available. The results of payroll processing are transmitted electronically tobanks and deposited to employee accounts inthatbank.Thepayinformationisprinted into sealed envelopes and mailed to the employee's home. Inthis application, the forms ofevidence have changed significantly.These newforms of evidence should raise audit concerns and cause the auditor to use new audit methods. Both casesrepresentedcomputerizedapplications.The casesareprovidedtoillustratethatthecom- puter itselfshould not be the key concern to the auditor but, rather, the effect ofthe applica- tion on the audit evidence. F.3.2 Changing Forms ofEvidence The method for assessing the impact of the computer on the audit is to review whether computertechnology has changed the traditional forms ofevidence. In Case A, the computer was introduced but the evidence did not change. Therefore, the computer had little or no im- pact on the audit. In Case B, therewas a significant change in the forms ofevidence, and thus the methods ofauditing need to be changed accordingly. F-5Prior to undertaking an audit ofa computerized application, the auditor should identify the type of technology used. For example, the auditor would identify whether or not data is stored on computer storage media, whether communication facilities are used, etc. Then, by usingtheAuditImpact Matrix (Figure F.l)l, the auditor canidentifythe type ofevidence that may be impacted by that technology. The auditor should then investigate whether or not the audit evidence has, in fact, been impacted. For example, on-line input/output devices canim- pact the means ofauthorization. Knowing this, the auditor determines if, in fact, the methods ofauthorization have changed. If so, the auditor needs to consider whether this creates new audit concerns and/or necessitates new audit methods. OBTAINING NEWFORMS OF EVIDENCE F.4 Computertechnologyproduces newformsofevidence. Muchoftheevidenceis encoded on computer media and thus requires special effort to transcribe it into human-readable for- mat. Other evidence is in the form of systems documentation. Special ADP skills may be needed in order to properly assess the completeness and usefulness ofthis documentation. Figure F.2, entitled "Comparison of Old and New Forms ofEvidence," is provided as a guide to auditors in identifying, obtaining, and assessing these new forms of evidence. The figure is not meant to be all-inclusive but, rather, representative ofthe types ofnew forms of evidence and the audit methods needed to obtain and utilize that evidence. ANTICIPATING EVIDENCE AND RELATED CONTROLS F.5 During AIS development, both managers and auditors must anticipate the evidence needed fromthe system to effectively discharge their responsibilities and thereby insure con- sideration is given to the related controls. 1 FiguresF.l andF.2havebeentakenfrom [AUER86+ AppendixB-1,withpermission. 1, F-6Figure F.1 Audit Impact Matrix . Computer Technology Input/ Output Media Audit Devices 3) Crt Evidence Ba Documentation (c0 Programming Online Commucalion Storage Systems O Data People-initiated transactions Hard copy input *^ Manual authorization Document transmission Hard copy processing (simplified procedures) (^) (^) ^ Manuals of master information Hard copy output >^ ' Documents filing Hard copy audit trail Procedure manuals Manual monitoring Segregation of duties Large volume processing (accessibility/usability) 1 F-7Figure F.2. Comparsion ofOld and New Forms ofEvidence Traditional Form New Form ot Evidence of Evidence Methods for Obtaining New Evidence Paople-initiated Computer-generated Auditor must examine systems transactions transactions documentation and/or programs to review where and how the computer generates transactions Transactions can be tested two ways; First, test data can be created for the program to determine whether transactions are correct and generated at the appropriate times. Second, using audit software, the auditor can extract the detailed records entering the program and the computer- generated transactions exiting the program. The auditor must then manually confirm whether the transaction was properly generated. Hard copy input Terminal-initiated input Audit software can be used to sample a number of the input transactions; their authenticity must then be verified with the individual(s) responsible for entering them. Manual authorization Automatic orelectronic Audit software can be used to prepare authorization letters asking the individual responsible for the authorization to confirm that it was, in fact, valid. Manual document Telecommunications The auditor can extract all of the transmission documents transmitted from one work station and compare them to an extract of the transactions received at another location Hard copy processing Computer There are several methods of verifying programming computer processing First, test data can be run through the program and compared against manually calculated results Second, the auditor can write a Simulation routine and compare actual processing against running the same data through the simulation routine. Third, the auditorcan flowchart the program using an automatic flow-charting routine and then "paper debug" the processing to determine that it is correct. Master information Computer master file Using audit software, the auditor can manual extract a sample of master information information) and compare it to the authorization documents to enter that information L/UUUfMt7Ml IIIIIIU ^Amniitor filo T 1h l eie xe traa\n ajr c\ll ti\tv\r njti er e^ ^ dCa l eln d1 iui isc neo fo:a r3ui mui aHir tlt iocd nnwfl ftt rww oaa mrioc thfl enu computer file to print as hard copy Procedure manuals Data dictionary The auditor can request printouts from the attributes. Manual monitoring Computer edits and Erroneous test data can be entered into audits the computer to determine that the edit and audit routines prevent or detect those errors Segregation of duties Division of automated The auditor can use a tiansaction conflict processing matrix to verify that there is adequate separation among automated processing steps F-81 APPENDIX G KEYREFERENCES ANNOTATED - AUTOMATIC DATA PROCHSSTNG AND TRLRCOMMUNICATIONS THE 1. IN FEDERAL GOVERNMENT Office of Information and Regulatory Affairs, Office of Management and Budget, Washington, DC 20503, January 1985 [OMB85]: This document is anarmotated bibliography. Much ofwhat is included here is new since 1982 and is likely to be under constant revision. Laws, policies, and regulations concerning ADP and telecom- munications change rapidly and present a bewildering complexity to the uninitiated. Both government and the private sector are publishing increasing numbers of guides for keeping abreast ofnew technologies, systems, and products as aids in planning for the future. A com- plete and current bibliography is impossible to maintain. The descriptions oflaws and other documentslisted herein are forinformationpurposes only and should not be interpreted as policy statements in themselves. The bibliography is arranged by issuing agency and type ofdocument. A subject guide is also provided at the end of the document. Citations are generally arranged in reverse chronological order, with the most current materials listed first. Exceptions to this rule are numbered series of documents, which are listed in numerical order regardless of issue date. Numbered series, such as Federal Information Processing Standards, are not indexed in the subject guide and hence must be scanned separately. For major reports, aimotations are provided. ADP AUDFT GUIDE. VOLUME GUIDELINES FOR AUDFFS OF COMPUTER- 2. 2. BASED SYSTEMS UNDER DEVELOPMENT . U.S. AirForceAuditAgency, November 1, 1980 [AFAA80]: This audit guide provides guidelines for auditing computer-based systems underdevelopment.The guidelines explainthe auditor'srole, thenprovide amethodologyfor surveyingtheenvironmentinwhichthesystemisbeingdeveloped.Theauditguideemphasizes the importance ofallocating audit effort toward the high-risk areas. The guide is divided into two major parts: (1) project planning and management; and (2) system development project execution. These two parts are subdivided into the key aspects of those two areas, and then there are twenty chapters, one provided for each criterion, providing guidelines for evaluat- ing that aspect ofproject planning and management, and system development project execu- tion. 3.INFORMATIONSYSTEMSAUDITPROCESS .S. RaoVallabhaneni, CPA, CMA, CISA^ EDP Auditors Foundation, Inc., P.O. Box 88180, Carol Stream, IL 60188, 1983 [VALLS83]: This book is designed to provide adequate coverage ofsubject material for candidates taking EDP the Certified Information Systems Auditor (CISA) examination, a program of the Auditors Foundation. The book focuses on the substantive issues covered by the CISA ex- G-amination. For general information such as examination study techniques, test-taking skills, sample examination questions and answers, development of the job dimensions, and ad- ministrative matters, please refer to the CISA Study Guide ofJanuary 1981. Thepurpose ofthis reference is to demonstrate the skills needed to audit systems under development. Auditors lacking skills in any ofthe elevenjob-dimension categories identified should obtain additional training in those areas prior to conducting audits of systems under development. 4. COMPUTER SYSTEM SECURITY (CSS) SCOPING FOR OPERATIONAL TEST ANDEV ATIlATION (OT&FXTheBDM Corporation, 1801RandolphRoad,SE,Albuquer- NM que, 87106, October 31, 1984 [BDM84]: This report describes the scope of operational test and evaluation for computer system security. In audits ofsensitive systems where security is important as a requirement, this document can be used to scope the nature of security problems, and then what type of operational test and evaluation needs to be taken based on thosepotentialsecurityrisks.Thebookidentifies securityrequirements andthenindicatesthe type oftests that can be undertaken in each ofthose areas. OFFICE OF INSPECTOR GENERAL AUDIT PLAN FOR REVIEWING DEVEI OP- 5. MENTAL SYSTEMS U.S. Department of the Interior, Office of Inspector General, 134 . UnionBlvd., Suite520, Lakewood, CO 80228, 1986 [DOI86] Thisauditplanproposesathree- : phase approach to auditing developmental systems in the department. The three phases are intended to provide maximum oversight during the developmental process with minimum auditor involvement. The primary objectives ofsuch an oversight role are to assure: Proposed systems are needed. Systems are properlyjustified, feasible, and cost beneficial. Systems development is properly planned and controlled. Users are fully involved and trained. Systems are adequately tested and converted in a controlled manner. All internal controls are adequate and work, including audit trails. Audit resources are conserved. AUDITOR'S MANUAL FOR SYSTEMS DEVELOPMENT LIFE CYCLE REVIEWS 6. . Bureau ofGovernment Financial Operations, Department ofthe Treasury, Office ofInspec- tor General [DOTR-1]: The purpose ofthis manual is to create a structured approach to sys- tems development hfe cycle (SDLC) audits. The authors researched existing publications on the subject and consulted organizations that conduct traininginthis area. Fromthese sources, the authorswere able to develop amethodology that detailed the audit objectives and techni- ques required to carry out an effective review ofthe development of a system throughout its life cycle. The auditor should look at this manual not as a cookbook for performing SDLC G-2audits but as a guide for effectively developing a structured audit approach geared to the specifics ofthe systems development project under review. Before the auditor can use this manual as a guide to structure an audit program, the specific objectives, parameters, and constraints of the systems development project under review must be clearly identified. In other words, the auditor must understand the system before he can determine the structure ofthe audit program. As was detailed in the introduc- tion, the primary function of an audit is to assure management that the system has adequate internal controls, meets identified objectives and user requirements, and is auditable. RFVTFWOFNEW OR MODTFTRD DRSTGN 7. Department oftheTreasury, Office ofthe , Inspector General, Bureau ofthe Public Debt [DOTR-2]: This audit guide is based on the six GAO objectivesofthe additional auditstandardonauditinvolvementinsystemsdevelopment (Appendix I in GA081-1). For each ofthe following sevenphases, the audit guide provides a briefsummaryofwhatthe auditorshould do, followedbydetailedaudit checklists: (1) systems plaiming, (2) user specifications, (3) technical specifications, (4) program development and testing, (5) userprocedures and training, (6) systems testing, and (7) conversion/implementa- tion. 8. SYSTEMREVIEWAUDITGUIDELINES . RichardP. Bush, GeorgeW. Steffen,Thomas M. O'Callaghan, Auditing Department, Federal Reserve Bank of Chicago, October 1981 [FRB81]: This audit guide keys the auditor involvement in systems development to specific control objectives. The guidehnes do not attempt to tell an auditor what steps to follow when auditing a system development project. Rather, they point out the most important objectives ofthe process and leave it to the auditor to determine the degree ofattention to these objec- tives. All objectives included in this set of guidelines are viewed to be critical to the system A development process. prudent auditor would therefore give appropriate consideration to all ofthese objectives when reviewing a system development project. It is expected that an auditor will use these guidelines as a basis for developing detailed audit procedures for reviewing system development projects. The authors of this document believe that the decision as to the type and extent ofaudit procedures employed is best left to the audit functionperforming the review. 9. MUFTI-AGENCY - ADP SYSTEM DEVET OPMENT FIFE CYCLE PROCESS . U.S. DC Department of Agriculture, Office of Inspector General, Washington, August 1983 [DOA83]: This document explains the system development life cycle process, from the perspective ofwhat shouldbe included in each life cycle phase. Knowing this information, the auditoris theninformed astowhat to lookfor during an auditofasystemunderdevelopment. G-3This auditguide isprovidedforuse by OIG auditors involved inthereviewofautomated system development activities. This guide was developed to provide a consistent approach withinOIG formonitoringADP systems development.Thisguideshouldbeusedforallaudits which involve the monitoring of an ongoing system development effort or the review of an operational system from a development standpoint. 10. EVALUATTNG INTERNAL CONTROT.S TN COMPTJTRR-RASRD SYSTFMS U.S. GovernmentAccountingOffice,June 1981 [GA081-3]:Thisguideisintendedtohelpauditors make a detailed review and evaluation ofinternal controls in computer-based systems. It in- cludes the kinds of controls an auditor should expect to find in computer-based systems but does not try to estabhsh standards for specific combinations of controls that should be used. Therefore, any one systemwould not include all the kinds ofcontrols in the guide. Detailed procedures are presented in sections as follows: Initial data collection Identification and evaluation ofinternal controls Detailed analysis and testing ofcontrols and records Reporting and recommendations It is not intended that all sections be applied to every audit. Questionnaires, checklists, internal control profiles, and internal control matrices are also included. 11. A STANDARD FOR AUDITING COMPIJTRR APPLICATIONS WilHam E. Perry, . AUERBACH PubHshers, 6560 N. Park Avenue, Pennsauken, NJ [AUER86 + This audit ]: EDP guide is directed primarily at audits ofoperational systems. It presents an audit in step- by-step format. However, the manual contains specialized sections, for example, a section on database controls, that should provebeneficial inapplications using these technologies. Also, the detailed operationalprograms should be beneficial in evaluating the adequacyofcontrols during development. All large CPA firms have their own audit guidelines. For example, Arthur Andersen is- sued "A Guide for Studying and Evaluating Internal Accounting Controls;" and Touche Ross & Companyhasthe'Touche RossAuditProcess."Generally,these areavailablefromtheCPA firms. Auditors should inquire of the firms auditing governmental agencies as to what audit guides they have available, and request them ifthe firms make them available to their cHents or other interested parties. 12. STANDARDS FOR AIJDTT OF GOVERNMENT ORGANIZATIONS. PROGRAMS. ACTIVITIES. AND FUNCTIONS GAO, 1981 Revision [GA081-1]: This document con- . tains the standards to be followed by Federal auditors in performing their independent audit G-4function. Auditingscope encompasses three areas: financial and compliance; economyand ef- ficiency; and program results. The four general standards relating to the scope ofaudit work are auditor qualifications, independence, due professional care, and scope impairments. This standards document also includes an appendix providing guidelines for the auditor's role during system development, design, and modification. 13. ATJDTTTNG rOMPTITFR SYSTFMS FTP Technical Library, Port Jefferson Station, N.Y. 11776, 1981 plus updates [FTP81 + ]: This extensive manual is currently in fourvolumes and covers the computer audit field. Volume II addresses audit participation in the design of systems, system conversion, and system and program change. 14. INTERNAL CONTROLS FTP Technical Library, Port Jefferson Station, N.Y. 11776, . 1980 plus updates [FTP80+ ]: This manual explains how controls should be built into automated information systems. It includes an appendix which describes the functioning of over 500 different controls. 15. EDPACS (EDPAUDFF, CONTROL, AND SECURFFY NEWSLETFER), Automation Training Center, Inc., Reston, Virginia 22090 [EDPACS]: EDPACS is a monthly newsletter on EDP audit, control, and security topics. The newsletter normally contains at least one ex- tensive article on a specific EDP audit or security topic. The remainder of the newsletter is usually devoted to a summarization ofthe recent literature on the topics of EDP audit, con- trol, and security. 16. STANDARDS FOR INTERNAL CONTROTi> IN THE FEDERAL GOVERNMENT . U.S. GeneralAccountingOffice (GAO), 1983 [GA083]:This documentdefinesstandardsfor internalcontrolsintheU.S.FederalGovernment. ItisdesignedasadocumenttoassistFederal managers in complying with the Federal Manager's Financial Integrity Act of 1982. The Act defines five general standards, six specific standards, and an audit resolution standard. The five general standards are reasonable assurance, supportive attitude, competent personnel, controlobjectives, and control techniques.The specific standards are documentation, record- ing oftransactions and events, execution oftransactions and events, separation ofduties, su- pervision, and access to and accountability for resources. The audit resolution standard addresses prompt resolution ofaudit findings. 17. SYSTEM DRVFJ OPMENT MONFTORTNG PROGRAM . U.S. Department of Labor, Office ofInspectorGeneral, WashingtonRegional Office, 1987 [DOL87]: This documentwas developed by the Office of Audits in the Office of Inspector General of the Department of Labor. The monitoring methodology uses three phases: Phase Pre-Survey I: Phase II: Survey Phase III: System Development Monitoring G-5The Pre-Survey allows the auditor to develop a picture ofthe general development environ- ment while the Survey allows the auditor to identify worksteps for System Development Monitoring. The System Development Monitoring is divided into seven modules: Planning and Initiation, Acquisition and Procurement, Project Administration, System Design and Development, Programming, Testing and Conversion, and Implementation. The first two phases and the seven modules of the third phase each contain a series of worksteps for the auditor with a detailed data gathering instrument for each workstep. Appendices on report- ing requirements, key terms, and key criteria are also included. MODEL FRAMEWORK FOR MANAGEMENT CONTROL OVER AUTOMATED 18. INFORMATION SYSTEMS President's Council on Management Improvement and . President's Council on Integrity and Efficiency, (Draft) August 1987 [PCMIIE]: This report synthesizesformanagersthemultitudeofdirectiveswhichcontainoverlappingandsometimes confusing guidance on how to protect automated information systems operations. It presents a model framework to help managers establish internal controls and document compliance for these systems. The framework has: 1. An analysis of Governing Directives that Federal Managers must follow. This yielded a set of55 Control Requirements derived from Governing Directives. A 2. life cycle approach to assure that the Control Requirements have beenmetby the system under review at each phase ofthe life cycle. A 3. document flow analysis that parallels the phases ofthe life cycle and gives the auditor a means ofchecking that the Control Requirements have been met. The life cycle phases and the documents for each phase are based on the work of the PCIE and can be found in greater detail in Chapter 2 ofthe present audit guide. G-61 APPENDIX H BIBLIOGRAPHY AFAA80 ADP Audit Guide. Volume 2. Guidelines for Audits of Computer-Based Systems Under Development U.S. Air Force Audit Agency, November . 1, 1980. AICPA78 Tentative Report ofthe Special Advisory Committee on Internal Account- ing Control American Institute of Certified Public Accountants, 1211 . Avenue ofthe Americas, New York, NY 10036, September 15, 1978. AUER86+ A Standard for Auditing Computer Applications William E. Perry, Auer- . bach Publishers, Inc., 6560 N. Park Ave., Pennsauken, New Jersey 08109, 1986 + updates. BAPA50 Budget and Accounting Procedures Act ot 1950 . PL81-784, September 12, 1950. BDM84 ComputerSystem Security(CSS) ScopingforOperationalTestand Evalua- BDM NM tion The Corporation, 1801 Randolph Road, SE, Albuqerque, . 87106, October 31, 1984. BOEMB81 Boehm, Barry W., Software Engineering Economics Prentice-Hall, Inc., . Englewood Chffs, NJ 07632, 1981. BRA65 Brooks Act PL89-306, October 30, 1965. . C&L86 System Develpment Audit Review Guide by Coopers & Lybrand, 1251 , Avenue ofthe Americas, New York, New York 10020, PubHsher: Institute of Internal Auditors, 249 Maitland Avenue, Altamonte Springs, Florida 32701, September 1986. DOD77 Automated Data Systems Documentation Standards DOD-STD-7935, . September 13, 1977. DOD DOD78-1 Life Cycle Management ofAISs Directive 7920.1, October 17, 1978. . DOD78-2 Major AIS Approval Process DOD Instruction 7920.2, October 20, 1978. . H-DOI86 Office ofInspector GeneralAudit Planfor Reviewing Developmental Sys- tems U.S. Department ofInterior, Office ofInspector General 134 Union . Blvd., Suite 520, Lakewood Co 80228, 1986. DOL87 SystemDevelopment MonitoringProgram U.S. DepartmentofLabor, Of- . fice ofInspector General, Washington Regional Office, 1987. DOT86 ADP Internal Control and VulnerabilityAssessment Guidelines Office of . Information Systems and Telecommunications and Office of Financial Management, Department ofTransportation, April 1986. DOTR- 1 Auditor's Manual for SystemsDevelopmentLife CycleReviews . Bureau of Government Financial Operations, Department ofthe Treasury, Office of Inspector General. DOTR-2 Review ofNew or Modified Design Department oftheTreasury, Office of . Inspector General, Bureau ofthe Public Debt. EAF83 Control Objectives-1983 . EDP Auditors Foundation, Inc., P.O. Box88180, Carol Stream, IL 60188, 1983. FIAA74 Freedom ofInformation Act . PL90-23, June 5, 1967, as amended byPL93- 502, November 21, 1974. FIPS21-2 COBOL (ANSI X3.23-1985), FIPS PUB 21-2, National Bureau of Stan- dards, March 18, 1986. FIPS38 Guidelines for Documentation of Computer Programs and Automated Data Systems . FIPS PUB 38, National Bureau of Standards, February 15, 1976. FIPS64 Guidelines for Documentation of Computer Programs and Automated Data Systems for the Initiation Phase FIPS PUB 64, National Bureau of . Standards, August 1, 1979. FIPS65 GuidelineforAutomaticDataProcessingRiskAnalysis FIPSPUB 65, Na- . tional Bureau ofStandards, August 1, 1979. FIPS68-2 BASIC (ANSI X3.113-1987), FIPS PUB 68-2, National Bureau of Stan- dards, August 28, 1987. H-2FIPS69-1 FORTRAN (ANSI X3.9-1978), PIPS PUB 69-1, National Bureau of Stan- dards, December 24, 1985. FIPS73 Guidelines for Security ofComputer Applications PIPS PUB 73, Nation- . al Bureau ofStandards, June 30, 1980. FIPS87 Guidelinesfor ADP ContingencyPlanning PIPSPUB 87,NationalBureau . ofStandards, March 27, 1981. PIPS101 Guideline for Lifecycle Validation, Verification, and Testing of Computer Software . PIPS PUB 101, National Bureau ofStandards, June 6, 1983. PIPS102 Guidelines for Computer Security Certification and Accreditation PIPS . PUB 102, National Bureau ofStandards, September 27, 1983. PIPS105 Guideline for Software Documentation Management PIPS PUB 105, Na- . tional Bureau ofStandards, June 6, 1984. PIPS106 Guideline on Software Maintenance PIPS PUB 106, National Bureau of . Standards, June 15, 1984. FIPS109 PASCAL (ANSI/IEEE 770X3.97-1983), PIPS PUB 109, National Bureau ofStandards, January 16, 1985. FIPSl10 GuidelineforChoosingaDataManagementApproach .PIPSPUB 110,Na- tional Bureau ofStandards, December 11, 1984. PIPS123 Specification for a Data Descriptive Pile for Information Interchange (DDU (ANSI/ISO 8211-1985), PIPS PUB 123, Nstional Bureau of Stan- dards, September 19, 1986. FIPS126 Database Language NDL (ANSI X3.133-1986), PIPS PUB 126, National Bureau ofStandards, March 10, 1987. PIPS127 Database language SOL (ANSI X3.135-1986), PIPS PUB 127, National Bureau ofStandards, March 10, 1987. FIPS128 Computer Graphics Metafile (CGM) ANSI X3.122-1986), PIPS PUB 128, National Bureau ofStandards, March 16, 1987. H-3Guideline for Software Verification and Validation Plans (ANSI/IEEE 1012-1986), FIPS PUB 132, National Bureau of Standards, November 19, 1987. Management of ADP Resources FIRMR 201-30.007, General Services . Administration, December 21, 1984. [This is part ofFIRMR Bulletin 15.] Federal Managers' Financial Integrity Act of 1982 PL97-255, September . 8, 1982. System Review Audit Guidelines Richard P. Bush, George W. Steffen, . Thomas M. O'Callaghan, Auditing Department, Federal Reserve Bank of Chicago, October 1981. Federal Records Management Act PL81-754, 1950. , Federal Records Management Act PL94-575, 1976. . Internal Controls FTPTechnicalLibrary,PortJeffersonStation,NewYork . 11776, 1980 + updates. Auditing Computer Systems FTP Technical Library, Port Jefferson Sta- . tion, New York 11776, 1981 + updates. DataBase Management Systems-WithoutCarefulPlanningThere CanBe Problems U.S. GeneralAccounting Office, June 29, 1979. FGMSD-79-35. . Contracting for Computer Software Development-Serious Problems Re- quire Management Attention to Avoid Wasting Additional MilHons U.S. . General Accounting Office, November 9, 1979. FGMSD-80-4 Standards for Audit ofGovernmental Organizations. Programs, Activities, and Functions "Yellow Book", U.S. General Accounting Office, 1981 . Revision. Federal Agencies' Maintenance of Computer Programs: Expensive and Undermanaged. U.S. General Accounting Office, February 26, 1981. AFMD-81-25. H-4GA081-3 Evaluating Internal Co ntrols in Computer-Based Systems "Black Book", U.S. General Accounting Office, June 1981. AFMD-81-76. GA081-4 Assessing Reliability of Computer Output U.S. General Accounting Of- . fice, June 1981. AFMD-81-91. GA083 StandardsforInternal C ontrols in the Federal Government "Green Book", , General Accounting Office, 1983. GSACFRl ADP Management Programs 41 CFR 201-20, General Services Ad- . ministration. GSACFR2 Contracting for ADP Resources 41 CFR 201-32, General Services Ad- . ministration. GSACFR3 Requirements Analysis 41 CFR 210-20.003, General ServicesAdministra- . tion. GSA81-1 Software Improvement - A Needed Process in the Federal Government . General Services Administration, June 1981. GSA81-2 Conversion Contracting Techniques Associated with Procurement of a Replacement ADP Hardware System General Services Administration, . Seprember 1981. GSA82-1 A Software Tools Project: A Means ofCapturingTechnology and Improv- ing Engineering General Services Administration, February 1982. . GSA82-2 Conversion Work Packages General Services Administration, July 1982. . GSA83-1 Conversion Plan Outline General Services Administration, January 1983. . GSA83-2 Software Conversion Lessons Learned, Volume I. General Services Ad- ministration, January 1983. GSA83-3 Guidelines for Planning and Implementing a Software Improvement Program (SW) General Services Administration, May 1983. . GSA83-4 Establishing a Software Engineering Technology (SET) General Services . Administration, June 1983. H-5GSA83-5 The Software Improvement Process-Its Phases and Tasks TParts 1 & 2) . General Services Administration, July 1983. GSA84-1 Preparing Software Conversion Studies General Services Administration, . January 1984. GSA84-2 Software Tool Evaluation and Selection Guidelines General Services Ad- . ministration, August 1984. GSA85 SoftwareAidsandTools Survey GeneralServicesAdministration,Novem- . ber 1985. GSA86-1 ConversionCostModel (Version4).GeneralServicesAdministration, May 1986. GSA86-2 Programmers Workbench Handbook General Services Administration, . June 1986. GSA86-3 Information Systems Planning Handbook General Services Administra- , tion, December 1986. IEEE83-1 Standard Glossary ofSoftware EngineeringTerminolog y. ANSI/IEEE Std 729-1983. IEEE83-2 Standard for Software Configuration Management Plans ANSI/IEEE Std . 828-1983. IEEE83-3 Standard for Software Test Documentation ANSI/IEEE Std 829-1983. . IEEE84-1 Standard for Software Quality Assurance Plans ANSI/IEEE Std 730-1984. . IEEE84-2 GuidetoSoftwareRequirementsSpecifications ANSI/IEEEStd830-1984. . IEEE86-1 Standard for Software Unit Testing ANSI/IEEE Std 1008-1986. . IEEE86-2 Standard for Software Verification and Validation Plans ANSI/IEEE Std . 1012-1986. H-6IGA78 Inspector General Act of 1978 . PL95-452, October 12, 1978. IIA77-1 Systems Auditahilityand Control, Data Processing Audit Practices Report . The Institute of Internal Auditors, 249 Maitland Avenue, Altamonte FL Springs, 32701, 1977. IIA77-2 Systems Auditahility and Control, Data Processing Control Practices Report The Institute of Internal Auditors, 249 Maitland Avenue, Al- . tamonte Springs, FL 32701, 1977. IIA77-3 Systems Auditahilityand Control, ExecutiveReport.The Institute ofInter- nal Auditors, 249 Maitland Avenue, Altamonte Springs, FL 32701, 1977. NBS57 Audit and Evaluation ofComputer Security II: System Vulnerahilities and Controls Edited by Zella G. Ruthberg, NBS Special Publication 500-57, . National Bureau ofStandards, April 1980. NBS98 Planning for Software Validation, Verification, and Testing Edited by . Patricia B. Powell, NBS Special Publication 500-98, National Bureau of Standards, November 1982 NBS105 Guide to Software Conversion Management Edited by M. Skall. NBS Spe- . cial Publication 500-105, National Bureau ofStandards, October 1983. NBS133 Technology Assessment: Methods for Measuring the Level of Computer Security William Neugent, John Gilligan, Lance Hoffman, Zella G. Ruth- . berg, NBS Special Publication 500-133, National Bureau ofStandards, Oc- tober 1985. NBS136 An Overview ofComputer Software Acceptance Testing Delores R. Wal- . lace, NBS SP 500-136, National Bureau of Standards, February 19, 1986. NBSIR86 Work Priority Scheme for EDP Audit and Computer Security Review . Zella G. Ruthberg and Bonnie Fisher-Wright, National Bureau of Stan- dards Internal Report, NBSIR 86-3386, March 1986. OMB OMB73 AuditofFederalOperations andPrograms CircularA-73 (Revised), . Office of Management and Budget, June 20, 1983. H-7OMB82 InternalControl Guideline Office ofManagement andBudget, December . 1982. OMB85 Automatic Data Processing and Telecommunications in the Federal Government Office of Information and Regulatory Affairs, Office of . Management and Budget, Washington, DC 20503, January 1985. OMB OMB 123 InternalControlSystems . CircularA-123,OfficeofManagementand Budget, October 28, 1981. OMBR OMB 123 Internal Control vSystems CircularA-123Revised, OfficeofManage- . ment and Budget, August 16, 1983. OMB OMB 127 Financial Management Systems Circular A-127, Office of Manage- . ment and Budget, December 19, 1984. OMB OMB 130 ManagementofFederalInformationResources CircularA-130, Of- . fice ofManagement and Budget, December 12, 1985. PCIE86 Ouality Standards for Federal Offices ofInspector General by President's , Council on Integrity and Efficiency (PCIE), 1986. PCMIIE Model FrameworkforManagement Contro l Over Automated Information Systems President's Council on Management Improvement and . President's Council on Integrity and Efficiency, (Draft), August 1987. PRA80 Paperwork R eduction A ct of 1980 , 44 U.S.C. 3501, PL96-511, December 11, 1980 PRRA86 PaperworkReductionReauthorizationActof 1986 PL99-591, October30, . 1986. PYA74 Privacy Act of 1974 5 U.S.C. 552, PL93-579, December 31, 1974. . VALLS83 Vallabhaneni, S. Rao, Information Systems A udit Process. EDP Auditors Foundation, Inc., P.O. Box 88180, Carol Stream, IL 60188, 1983. H-8APPENDIX I PCIE/NBS INVITATIONAL WORKSHOP CO-CHAIRPERSONS: Bonnie T. Fisher & Zella G. Ruthberg DISCUSSION GROUPS MEMBERSHIP The followingis alisting oftheparticipants inthe Invitational Workshop that resulted in the high level Risk Analysis presented in Chapter 3. This Risk Analysis is to be used for prioritizingthework ofADP auditors and security reviewers. The Workshop format used five discussion groups and the members are listed alphabetically for each group. I-lA GROUP John Lainhart Department ofTransportation (Group Leader) Office ofInspector General ADP Director, Office of Audits and Technical Support Robert L. Gignilliat Department ofHealth and Human Services (Recorder) Senior Systems Security Officer Nander Brown Federal Home Lx)an Mortgage Corporation Assistant General Auditor Peter S. Browne Profile Analysis Corporation President James E. Haines Boeing Computer Services Co. Director, Quality Assurance Kenneth Jannsen Blue Cross/Blue Shield ofIllinois Director, Internal Audits Jarlath O'Neill-Dunne Coopers and Lybrand, (New York, NY) Partner Tyrone Taylor National Aeronautics and Space Administration Space Station Management Analyst John Van Borssum Security Pacific National Bank EDP Vice President, Auditor J. Armand Villemaire Department ofDefense Air Force Audit Agency, StaffAuditor Patricia D, Williams Department ofTreasury Internal Revenue Service Head ofSecurity 1-2GROUP B Barry R. Snyder General Accounting Office, IMTEC (Group Leader) Group Director, Technical Services Mark J. Gillen Department ofTreasury (Recorder) Internal Revenue Service Internal Audit Manager EDP Robert P. Abbott Audit Controls, Inc. President Lorretta Ansbro Federal Reserve Bank ofNew York Audit Official Stephen F. Barnett Department ofDefense Computer Security Center Chief, Office ofApplication System Evaluation Larry Bergman Boeing Computer Services Co. EDP Audit Manager Robert Berndt Bank ofAmerica (San Francisco) Vice President, EDP Audit Manager & Keagle Davis Touche Ross Co. (Jacksonville) Partner Michael Goldfine General Motors Corporation Assistant Director, Audit Staff Ralph E. Gooch Department ofTreasury Financial Management Services ChiefofSecurity Branch Michael G. Houston Department ofDefense Office ofInspector General Program Director, Audit Policy and Oversight Jack Wheeler General Accounting Office, IMTEC Special Assistant, Technical Services 1-3GROUP C Wallace O. Keene Department ofHealth & Human Services (Group Leader) Acting Deputy Assistant Secretary for Management Analysis and Systems Allen Winokur Navy Audit Service EDP (Recorder) Auditor David L. Decker Department ofHousing and Urban Development Office ofInspector General EDP Director, Audit Frederick Gallegos General Accounting Office (Los Angeles) Manager, Management Services Group Carole A. Langelier DeLoitte, Haskins and Sells (Washington, D.C.) Partner Joseph T. McDermott Department ofDefense AUDIT Office ofInspector General/ Program Manager EDP Gerald Meyers Audit Consultants Managing Partner Carl A. Pabst Touche Ross & Company (Los Angeles) EDP Partner, Director of Audit Frederick G. Tompkins ORI, Incorporated Senior Principal Scientist Hart J. Will, Ph.D. University ofVictoria, B.C. Professor ofPublic Administration 1-4GROUP D Larry Martin Department ofEnergy (Group Leader) Manager, Computer Security Program Gail L. Shelton Department ofHealth & Human Services (Recorder) Office ofInspector General Program Analyst James Cox Department ofHealth & Human Services Office ofInspector General EDP Auditor Tim Grance, 2nd Lt. U.S. Air Force Computer Security Program Office Computer Security StaffOfficer Michael J. Henitz Peat Marwick Mitchell & Co. Computer Audit Office Partner William M. Hufford Sun Banks, Inc. EDP Vice President, Audit Manager; EDP Auditors Association Regional President StanleyJarocki Bankers Trust ofNew York Vice President, Group Manager & William C. Mair Touche Ross Co. (Detroit) Partner NARDAC Thomas Nugent Department ofNavy, Computer Specialist Kenneth A. Pollock EDP Auditors Foundation Director ofResearch F. A. Schlegel Management and Computer Services, Inc. President 1-5GROUP D (continued) D. L. Von Kleeck Management and Computer Services, Inc. General Manager H. C. Warner Florida Power and Light Director, Internal Audits 1-6GROUP E Douglas B, Hunt National Aeronautics and Space Administration (Group Leader) Office ofInspector General Director, Technical Services William C. Lee Department ofCommerce (Recorder) Office ofInspector General Office ofAutomated Information Systems Computer Specialist Philip Carollo Sears, Roebuck and Company EDP Director, Audits Don Coiner Basic Data Systems, Inc. President Robert V. Jacobson International SecurityTechnology, Inc. President Thomas Lux Touche Ross & Company (Chicago) Audit Supervisor Jim Manara Security Pacific National Bank Quality Assurance Division Vice President Brian McAndrew U.S. Navy Navy Audit Service Assistant Director, Audit Policy & Brian Morse Coopers Lybrand (Washington, D.C.) Partner Benson J. Simon Environmental Protection Agency Program Analyst Jane Tebbutt Department ofHealth and Human Services Office ofInspector General Director, Interagency Projects DivisioniAPPENDIX! TWO RISK SCORING METHODS A SIMPLE SCORING APPROACH J.l J.1.1 The Scoring Method This method risk scores each system by using Figure J.l to calculate the scores as described below. A Step 1 - Assign Tmportance Weights. weight, reflecting the importance ofthe dimension to the system under review, is assigned to each of the five dimensions shown in Figure J.l. This weightwillinturnreflecttheimportanceofthedimension'scharacteristicstothesystemunder review. One of the two suggested weighting schemes^ shown in Figure J.l can be used, al- though specificsituations mayrequire modification ofthese. The weights in set 1 addup to an arbitrary number while those in set 2 add up to 100. Set 2 allows for easy conversion of the weights to percentages. Step 2 - Assign Risk Level . For each dimension assigna risklevel from 1-5 which reflects the degree ofrisk for that dimension. Suggested risk level values are: 5 = High Risk 3 = Medium Risk 1 = Low Risk For example, a systemwith demonstrated rehability would pose a low risk and warrant a low risk level value ( = 1). Step 3 - Calculate Dimension Risk Score . The dimension risk score is its weight times its risk level. Step 4 - Calculate System Risk Score For a Level I type system risk score, use the risk score . forthe Criticality/MissionImpact dimension.The LevelIIsystemriskscore is the sum ofeach ofthe five dimension's risk scores. Step 5 - Rank System Scores . Perform Steps 2, 3, and 4 for each system under consideration and rank systems numerically from high to low. The highest scoring systems pose the highest risk and therefore deserve more audit/review attention. 1 Thesuggestedweightswere derivedfrom datacollectedfromrepresentatives attendingthe PCIE Workshop. J-1£ E o o Q O H UJ Q LU 6 z O E o ao> CO o in h- >- LU o I- (/) >- CO -3 X c o c c E o o o o o GO (c/) V> c E a> <D >v b cus E o in o c cs > x: N<b c O 00 LU QC CO J-2I 'c 3 3 E J2 to E e£ PS o o 3 —C «j C JS o. c E <1> o i9 c o o E E <-> o£ o ^ 3 75 T3I II ><i> w to O ^ C o ^ ic3 {E2 S ^ wi % 13 c 2? < S1> < t31 o> <i> 'N<1> _ O*- n3 oO . C 5 ^ 2.^ to (0 I- a. E o o o o o (A r CO 00 00 >, CO CO icS OI s 2 CL f O 00 00 O CC -J <i> if) :^ CL in o oc lO lO lO LU h- LU o o lO lO in >- Csl CO CO >- CO -3 X c o icn c E o o o o CO CcO c Hi J— <1> E E<1> o CO (« .o <N1> > .55 o CO LU CC cri J-3J.1.2 Example ofa Scored System Table J.l is an example ofa calculated risk score for one system. The suggested weights of set 1 in Figure J.l were used except for Technology Integration. This was given a higher weight of 15 because, in the organization, almost all new systems have failed whenever any new technology is introduced. The five dimensionswere thengiven a risk levelvalue based on A audit knowledge and surveys. total score of480 was then calculated for ranking purposes. A DETAILED SCORING APPROACH J.2 J.2.1 Risk Scoring a Dimension Although the "strawman" paper describes five approaches to analyzing risk (See Appen- dix B in [NBSIR86]), a method of ranking and rating is suggested here as an approach com- mensurate with the softness ofthe data available. Each dimension ofthe scheme is rated and ranked separately, with scores then combined. Since Criticality/ Mission Impact is the Level I dimension of the proposed scheme, one would analyze this dimension first. The procedure is as follows: First, the n characteristics within a dimension are ranked according to their respective importance to that dimension. The importance rank number ofcharacteristic i is I(i) and ran- ges from 1 to n with n correlated with the most important characteristic. For operational sys- tems one can use discriminant analysis applied to equal sets of known system failures and successestoobtainthis ranking. Fordevelopmentalsystems aconsensusviewofauditmanage- ment can be used, ideally obtaining Sponsor/User input. Second, the importance ranking number, I(i), is converted to an importance weighting factor, W(i), that is normalized to 20. (The reason for selecting 20willbe explained in Section J.2.4.) This means that the sum oftheweighting factors for the characteristics within a dimen- sion is set to 20 (or normalized to 20). Since each ofthe five dimensions has a different num- ber of characteristics and we wish to treat the dimensions as equals, normahzation will guarantee that the risk score range for each dimension will be the same. The normalization factor, F, is the numberwhich converts the importance ranking num- ber I(i) to the importance weighting factor W(i). The relationships are: W(i) = Fxl(i) (1) S W(i) = I]FxI(i) = 20 (2) i= 1 to n i = 1 to nSolving equation (2) for F, we find F= (3) S 20 I(i) i= 1 to n and substituting for F in equation (1) yields the importance weighting factor W(i) for charac- teristic i, i.e., (4) W(i) = 20x E 1(0 I(i) i= 1 to n Third, each characteristic is rated with respect to the risk ofoccurrence. One ofthe fol- lowing risk ratings, R(i), is assigned to characteristic i. R (i) = 3 (for High Risk) R (i) = 2 (for Medium Risk) R (i) = 1 (for Low Risk) These ratings canbe assigned by the auditor, againwith user assistance ifappropriate. Finally,aRiskScoreforthatdimension isobtainedbymultiplyingtheimportanceweight- ingbythe riskratingofthe characteristicand summingoverthe characteristicsforthatdimen- sion. The equationfor this is the following: =S DRSG) W(i)xR(i) i= 1 to n where i = characteristics 1 to n W = (i) importance weighting for characterististic i R = (i) risk rating for characteristic i DRS (j) = dimension j's risk score,] = 1 to 5 The Risk Score for each of the five dimensions will range from 20 to 60 using these impor- tance weighting and risk rating number assignments. J-5J.2.2 Level I System Risk Score i After completing a Level I review for an organization's universe of AISs, using the analysis scheme in Section J.2.1, one can use the Criticality/Mission Impact dimension risk score as afirstorder approximationto asystemriskscore. Since these riskscores have allbeen normalized to the same number (20), it is possible to compare these risk scores across AISs and eliminate from further consideration AIS's having a low risk with respect to Criticality/Mission Impact. J.2.3 Level II Review Considerations Ifit is decided that the more detailed Level II review is appropriate and/or affordable, onemustdecideuponasequenceforreviewingthe remainingdimensionsofthehighriskcriti- cal AISs. While there is no "correct"way to do this, it mightbe appropriate to considerthe fol- lowing. Since the Environment/Stabilitydimension includes the organization's general controls, includingthe strengthandinvolvementofqualityassurance, projectmanagement, andsecurity functionsthroughoutthe SDLC (ofbothsystemsandmajorenhancementstoexistingsystems), it may be most useful to review this dimension first in a Level II review. These general con- trolswouldheavilyimpacttheneedforaudit coverage aswellas thescope andexpertise neces- sary in that coverage. The EDP auditors could confidently reduce their scope and related testing of applications if they could rely on the organization's general controls and the safeguards these various review functions provide in the SDLC process. Any ranking or prioritizing of the elements in the work priority scheme, beyond the overriding factors described above (i.e., external influence and mission criticahty), could nol be reasonably ac- compHshed without a survey of the organization's general and applications controls and/or without an institutional knowledge of the organization, its SDLC process, and any facts and circumstances affecting system development activities. The characteristics in all four Level II dimensions shouldbeweighted andrated inthe lightofsuchbackground information, and the dimension risk score, DRS, obtained for each ofthe four Level II dimensions. J.2.4 Level 11 System Risk Score As a second order approximation one can treat the dimensions as equal contributors to theriskscore for the AIS as awhole. Underthis assumptionthe systemriskscore, SRS, is then a simple sum ofthe five dimension risk scores, DRS. i 3-6S SRS = DRS (5) 0) j= 1 to 5 where SRS = system risk score = j dimensions 1 to 5 DRS (j) = dimension j's risk score Since DRSO') can range from 20 to 60, SRS will range from 100 to 300. The choice of 20 for the sum of the weights ofthe characteristics within a dimension is arbitrary and was made in order to place SRS in a reasonable range for comparing one system's risk score to another's. An Example J.2.5 Itmaybe auseful exercise to go through an example ofthe arithmetic involved. Assume we wish to calculate dimension risk scores and system risk scores for two AISs. To simplify matters we shall assume small numbers of characteristics for each dimension. Dimension 1 has four characteristics, dimension 2 has three characteristics, dimension 3 has five charac- teristics, dimension 4 has three characteristics and dimension five has 2 characteristics. The importance rankings I(i) and the risk ratings R(i) are obtained from audit management and the auditor respectively. The rest of the numbers in Tables J.2 and J.3 are calculated using equations (1) - (5). (Apractice template ofthe table has been included in Figure J.2 to assist the reader in learning the methodology.) Using dimension 1 as a first order system risk score, we find AIS 1, with DRS = 42, is more at risk thanAIS 2, with DRS = 38. We obtain the second order risk score by adding the five dimension risk scores for each AIS. Using these numbers, AIS 1, with SRS = 191.4, is again more at risk than AIS 2, with its SRS = 180.0. Only experience with the method will enable the reviewer to obtain more refined interpretations ofthe calculations.Figure J.2. PRACTICE TEMPLATE FOR RISK SCORING OF AN AIS AIS WxR DIMENSION F W(i) R(i) DRS(j) DIM1 C(1) C(2) C(3) C(4) DIM 2 C(1) C(2) C(3) DIM 3 C(1) C(2) C(3) C(4) C(5) DIM 4 C(1) C(2) C(3) DIM 5 C(1) C(2) SRS J-8Table J.2. DIMENSION RISK SCORES AND SYSTEM RISK SCORES FORMS 1 AIS 1 wen W DIMENSION F y R DRS { i DIM 1 C(1) 2 2 4 1 4 C(2) 1 2 2 2 4 C(3) 4 2 8 2 16 C(4) 3 2 6 3 18 10 - 20 - 42 42.0 DIM 2 C(1) 3 10/3 10 1 10 0(2) 2 1013 20/3 2 40/3 C(3) 1 10/3 10/3 3 10 6 - 20 - 33.3 33.3 DIM 3 C(1) 4 4/3 16/3 3 16 0(2) 2 4/3 8/3 2 16/3 0(3) 5 4/3 20/3 1 20/3 0(4) 1 4/3 4/3 2 8/3 0(5) 3 4/3 4 3 12 15 20 42.7 42.7 DIM 4 0(1) 1 10/3 10/3 3 10 0(2) 3 10/3 10 3 30 0(3) 2 10/3 20/3 1 20/3 6 20 46.7 46.7 DIM 5 0(1) 1 20/3 20/3 2 40/3 0(2) 2 20/3 40/3 1 40/3 3 20 26.7 26.7 SRS 191.4 IstOrder SRS (Range = 20 to 60) = DRS(1) = 42.0 2nd Order SRS (Range = 100 to 300)= SRS = 191.4i Table J.3. DIMENSION RISK SCORES AND SYSTEM RISK SCORES F0RAIS2 AIS__ 2 DIMENSION F W YYf ^ i1 ) ; Wx R DRS ( i ^ DIM 1 C(1) 4 2 8 3 24 C(2) 2 2 4 1 4 C(3) 1 2 2 2 4 C(4) 3 2 6 1 6 10 - 20 = 38 38.0 DIM 2 C(1) 2 10/3 20/3 3 20 C(2) 1 10/3 10/3 1 10/3 C(3) 3 10/3 10 2 20 6 - 20 - 43.3 43.3 DIM 3 C(1) 5 4/3 20/3 3 20 C(2) 3 4/3 4 1 4 C(3) 1 4/3 4/3 2 8/3 C(4) 2 4/3 8/3 1 8/3 C(5) 4 4/3 16/3 3 16 15 20 45.4 45.4 DIM 4 C(1) 2 4 20/3 2 40/3 C(2) 2 4 10 1 10 C(3) 1 4 10/3 3 10 5 20 33.3 33.3 DIM 5 C(1) 2 20/3 40/3 1 40/3 C(2) 1 20/3 20/3 1 20/3 3 20 20 20.0 SRS 180.0 1stOrder SRS (Range = 20 to 60) = DRS(1) = 38.0 2nd Order SRS (Range = 100 to 300)= SRS = 180.0 J- 10, NBS-li4A (REV. 2-80) r' U.S. DEPT. OF COMM. 1 1. PUBLICATION OR 2. Performing Orsan, Report No. 3. Publication Date REPORT NO. BIBLIOGRAPHIC DATA SHEET(See instructions) NBS/SP-500/153 4. TITLE AND SUBTITLE Guide to Auditing for Controls and Security: A System Development Life Cycle Appro^c^ 5. AUTHOR(S) zella G. Ruthberg, Bonnie Fisher-Wright, William E. Perry, John Lainhart, James G. Cox, Mark Gillen, Douglas B. Hunt 6. PERFORMING ORGANIZATION (Ifjoint or other than NBS, see instructions) 7. Contract/Grant No. NATIONAL BUREAU OF STANDARDS DEPARTMENT OF COMMERCE S. Type of Report & Period Covered U.S. GAITHERSBURG, MD 20899 Final 9. SPONSORING ORGANIZATION NAME AND COMPLETE ADDRESS(Street. City, State, ZIP) NBS and President's Council on Integrity and Efficiency c/o Richard Kusserow, Inspector General, HHS 330 C. St. S. W. Washington, DC 20201 10. SUPPLEMENTARY NOTES This document is the result of a joint effort of ICST/NBS and a Work Group of the Computer Security Project of the President's Council on Integrity and Efficiency. Library of Congress Catalog Card Number: 88-600518 Document describes a computer program; SF-185, FlPS Software Summary, Is attached. [ I 11. ABSTRACT(A 200-word or less foctual sunnmary ofmost significant inforwatlon. If document includes a significant bibliography or literature survey, mention it here) This guide addresses auditing the system development life cycle (SDLC) process for an automated information system (AIS) to ensure that controls and security are designed and built into the system. It is directed toward mid-level ADP auditors having a minimum of two years experience in ADP auditing, but can also be used by security reviewers, quality assurance personnel, and as a training tool for less experienced ADP auditors. ADP managers and system developers will also find it useful guidance on security and control issues. It is designed to provide audit/review programs for each major phase of the SDLC process. It presents: (1) the model arrived at for describing the phases and functional roles in the entire AIS life cycle, (2) the accompanying flow of documents as the system progresses through the life cycle phases of Initiation, Definition, Design, Programming and Training, Evaluation and Acceptance, and Installation and Operation, (3) a security audit/review work priority scheme, and (4) audit/review programs for Initiation through Evaluation and Acceptance. The Installation and Operation phase is not treated because of already existing literature in this area. The guide represents the results of the past four years of activities by the Electronic Data Processing (EDP) Systems Review and Security Work Group of the Computer Security Project within the President's Council on Integrity and Efficiency (PCIE) . It contains an annotated bibliography of important documents, a general bibliography, and a description of pertinent laws and regulations. 12. KEY WORDS(Six to twelve entries; alphabetical order; capitalize only proper names; and separate key words by semicolons) Audit/review work prTority scheme; automated information system; computer security review/audit; controls audit/review; controls/security regulations; life cycle documenta tion flow chart; phase audit tests; President's Council on Integrity and Efficiency 13. A ^VAILABILITY r de ev vi ee lw o/ pma eu nd tit lp ifr eogr ca ym c; les me oc du er lity/controls laws; system 14. N PO R. INO TF ED PAGES [X3Unlimited For Official Distribution. Do Not Release to NTIS 266 I I [Y]Order From Superintendent of Documents, U.S. Government PrintingOffice,Washington, D.C. 20402. 15. Price n Order FromNational Technical Information Service (NTIS). Springfield, VA. 22161 USCOMM-DC 004S-P«0 201-597 82557 * U.S.GOVERNMENTPRINTINGOFFICE: 198&- /ANNOUNCEMENT OF NEW PUBLICATIONS ON COMPUTER SCIENCE & TECHNOLOGY Superintendent ofDocuments, Goverament Printing Office, DC Washington, 20402 Dear Sir: Please add my name to the announcement list ofnew publications to be issued in the series: National Bureau ofStandards Special Publication S0O-. Name Company Address City State Zip Code (NodflcadoakeyN-503)::S* #Technical Publications Periodical — Journal of Research The Journal of Research of the National Bureau of Standards reports NBS research and development in those disciplines of the physical and engineering sciences in which the Bureau is active. These include physics, chemistry, engineering, mathematics, and computer sciences. Papers cover a broad range of subjects, with major emphasis on measurement methodology and the basic technology underlying standardization. Also included from time to time are survey articles on topics closely related to the Bureau's technical and scientific programs. Issued six times a year. Nonperiodicals — Monographs Major contributions to the technical literature on various subjects related to the Bureau's scien- tific and technical activities. — Handbooks Recommended codes of engineering and industrial practice (including safety codes) developed in cooperation with interested industries, professional organizations, and regulatory bodies. — Special Publications Include proceedings of conferences sponsored by NBS, NBS annual reports, and other special publications appropriate to this grouping such as wall charts, pocket cards, and bibliographies. — Applied Mathematics Series Mathematical tables, manuals, and studies of special interest to physicists, engineers, chemists, biologists, mathematicians, computer programmers, and others engaged in scientific and technical work. — National Standard Reference Data Series Provides quantitative data on the physical and chemical properties of materials, compiled from the world's literature and critically evaluated. Developed under a worldwide pro- gram coordinated by NBS under the authority of the National Standard Data Act (Public Law 90-3%). NOTE: The Journal of Physical and Chemical Reference Data (JPCRD) is published quarterly for NBS by the American Chemical Society (ACS) and the American Institute of Physics (AIP). Subscriptions, reprints, and supplements are available from ACS, 1155 Sixteenth St., NW, Washington, DC 20056. — Building Science Series Disseminates technical information developed at the Bureau on building materials, components, systems, and whole structures. The series presents research results, test methods, and perfor- mance criteria related to the structural and environmental functions and the durability and safety characteristics of building elements and systems. — Technical Notes Studies or reports which are complete in themselves but restrictive in their treatment of a subject. Analogous to monographs but not so comprehensive in scope or definitive in treatment of the subject area. Often serve as a vehicle for final reports of work performed at NBS under the sponsorship of other government agencies. Voluntary Product Standards—Developed under procedures published by the Department of Commerce in Part 10, Title 15, of the Code of Federal Regulations. The standards establish nationally recognized re- quirements for products, and provide all concerned interests with a basis for common understanding of the characteristics of the products. NBS administers this program as a supplement to the activities of the private sector standardizing organizations. Consumer Information Series—Practical information, based on NBS research and experience, covering areas of interest to the consumer. Easily understandable language and illustrations provide useful background knowledge for shopping in today's technological marketplace. Order the above NBSpublicationsfrom: Superintendent ofDocuments, Government Printing Office, DC Washington, 20402. Order the following NBSpublications—FIPS andNBSIR's—from theNational Technical Information Ser- vice, Springfield, VA 22161. Federal Information Processing Standards Publications (FIPS PUB)—Publications in this series collectively constitute the Federal Information Processing Standards Register. The Register serves as the official source of information in the Federal Government regarding standards issued by NBS pursuant to the Federal Property and Administrative Services Act of 1949 as amended. Public Law 89-306 (79 Stat. 1127), and as implemented by Executive Order 11717 (38 FR 12315, dated May 11, 1973) and Part 6 of Title 15 CFR (Code of Federal Regulations). NBS Interagency Reports (NBSIR)—A special series of interim or final reports on work performed by NBS for outside sponsors (both government and non-government). In general, initial distribution is handled by the sponsor; public distribution is by the National Technical Information Service, Springfield, VA 22161, in paper copy or microfiche form.U.S. Department of Commerce National Bureau of Standards Gaithersburg, MD 20899 Official Business PenaltyforPrivate Use$300 SlimulalingAmericasProgress 1913-1988