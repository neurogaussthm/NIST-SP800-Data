[
  {
    "title": "Abstract",
    "subsections": [
      {
        "content": "The increasing trend in building microservices-based applications calls for addressing security in all aspects of service-to-service interactions due to their unique characteristics. The distributed cross-domain nature of microservices needs secure token service (STS), key management and encryption services for authentication and authorization, and secure communication protocols. The ephemeral nature of clustered containers (by which microservices are implemented) calls for secure service discovery. The availability requirement calls for: (a) resiliency techniques, such as load balancing, circuit breaking, and throttling, and (b) continuous monitoring (for the health of the service). The service mesh is the best-known approach that can facilitate specification of these requirements at a level of abstraction such that it can be uniformly and consistently defined while also being effectively implemented without making changes to individual microservice code. The purpose of this document is to provide deployment guidance for proxy-based Service Mesh components that collectively form a robust security infrastructure for supporting microservices-based applications."
      }
    ]
  },
  {
    "title": "Executive Summary",
    "subsections": [
      {
        "content": "Microservices-based application architectures are becoming the norm for building cloud-based and large enterprise applications because of their inherent scalability, agility of deployment, and availability of tools. At the same time, the characteristics of microservices-based applications bring with them modified/enhanced security requirements."
      },
      {
        "content": "A few examples of these characteristics and their security impacts include:\na. The sheer number of microservices results in more interconnections and more communication links to be protected.\nb. The ephemeral nature of microservices calls for secure service discovery mechanisms.\nc. The fine-grained nature of microservices calls for the ability to support fine-grained authorization policies."
      },
      {
        "content": "The supporting services (e.g., authentication/authorization, security monitoring, etc.) for a microservices-based application must be tightly coordinated through a dedicated infrastructure, such as the Service Mesh. There are multiple ways of deploying the components of the Service Mesh, including embedding them in the application (microservice) code, coupling them to the application code by implementing them as libraries, or implementing them as service proxies that are independent of application code. This last deployment approach has been found to be the most efficient in terms of scalability and flexibility in many scenarios for implementing the supporting infrastructure for microservices-based applications."
      },
      {
        "content": "The purpose of this document is to provide deployment guidance for service mesh components in the service proxy-based approach. The Service Mesh deployment recommendations span the following aspects:\n- Configuration for communication between service proxies\n- Configuration for ingress proxies\n- Configuration for access to external services# Configuration for Identity and Access Management"
      }
    ]
  },
  {
    "title": "Configuration for Monitoring Capabilities",
    "subsections": []
  },
  {
    "title": "Configuration for Network Resilience",
    "subsections": []
  },
  {
    "title": "Configuration for Cross-Origin Resource Sharing (CORS)",
    "subsections": []
  },
  {
    "title": "Configuration of Permissions for Administrative Operations",
    "subsections": [
      {
        "title": "1 Introduction",
        "content": [
          {
            "text": "Microservices architecture has become an established approach for building enterprise and cloud-based applications due to the following:"
          },
          {
            "text": "Agility \u2013 The loose coupling and increased modularity of microservices have enabled independent and quicker modification and deployment without affecting other components (microservices) of a microservices-based application.\nScalability \u2013 The characteristics of the microservices allow them to be independently scaled.\nUsability \u2013 The use of well-defined application programming interfaces (APIs) makes integration or onboarding of various microservices easier.\nAvailability of tools \u2013 The increasing availability of automation tools facilitate error-free configuration and deployment."
          },
          {
            "text": "In spite of the above advantages, the architecture of microservices-based applications has some challenges with modified/enhanced security requirements, such as:"
          },
          {
            "text": "More microservices lead to more interconnections between these components as well as more communication links to be protected.\nComponents (microservices) can come and go dynamically, so the environment needs secure service discovery requirements.\nThere is no concept of a network perimeter.\nAll microservices must be treated as non-trustworthy.\nThe fine-grained nature of microservices requires fine-grained authorizations at each microservice. However, this may require security policies to be centrally defined and the configurations reflecting them to be defined in each microservice to enable uniform, consistent enforcement across all microservices."
          }
        ]
      },
      {
        "title": "1.1 Why Service Mesh",
        "content": [
          {
            "text": "Due to the security requirements for microservices-based applications stated above, the infrastructure that supports the application and that infrastructure's associated services (e.g., security) should be tightly coordinated. One such dedicated infrastructure is the Service Mesh."
          },
          {
            "text": "The code that implements the Service Mesh can be organized in the following ways with respect to the components of a microservices-based application architecture (Each architectural pattern is denoted using the acronym SM-ARx where SM stands for Service Mesh, AR stands for architecture and x is the sequence number):"
          },
          {
            "text": "SM-AR1: Service Mesh code can be embedded in the microservices application code, making the Service Mesh an integral part of the application development framework.\nSM-AR2: Service Mesh code implemented as libraries and, therefore, applications are coupled to the services provided by the Service Mesh via API calls.\nSM-AR3: Service Mesh functions are implemented in proxies with each proxy deployed in front of a microservice instance and collectively providing infrastructure services for.# The Microservices-Based Application"
          },
          {
            "text": "The microservices-based application. These proxies are called \"side-car proxies\" and can be implemented and operated independently of the application code. Side-car proxies enable heterogeneous platforms (different languages and application development frameworks) to be controlled consistently by adopting the lowest common denominator API\u2014the network."
          },
          {
            "text": "SM-AR4: Service Mesh functions are implemented in proxies with a proxy deployed per node (physical host) rather than per microservice instance (such as SM-AR3)."
          }
        ]
      },
      {
        "title": "1.2 Scope",
        "content": [
          {
            "text": "For the purpose of this document, the only Service Mesh architecture that will be considered will be SM-AR3, where a dedicated infrastructure layer provides all security functionality to the microservices-based application without any modification to the application service's code. Compared to SM-AR4, SM-AR3 avoids a range of privilege escalation and noisy neighbor problems by deploying one instance of the service proxy per microservice instance and relying on the underlying platform's isolation guarantees to ensure the application's traffic is only mediated by its dedicated service proxy. Compared to SM-AR1 and SM-AR2, SM-AR3 decouples the application lifecycle from the modules that provide the service mesh functionality and avoids the combinatorial explosion of having to maintain the multiple versions of the library across languages, which could potentially happen in SM-AR2. Based on this context, the primary function of Service Mesh from the perspective of this document is to mediate and broker client-to-microservice and microservice-to-microservice communications where the mediating and brokering agents or functional modules do not have tight coupling with the microservice's code."
          }
        ]
      },
      {
        "title": "1.3 Target Audience",
        "content": [
          {
            "text": "The target audience of the guidance document for supporting microservices-based applications using the Service Mesh framework includes security solutions architects who want to design a security framework for microservices-based applications and system integrators who build a common infrastructure services framework for different microservices-based applications residing in the enterprise and the cloud."
          }
        ]
      },
      {
        "title": "1.4 Relationship to Other NIST Guidance Documents",
        "content": [
          {
            "text": "This guidance document focuses on building a specific security framework or infrastructure for microservices-based applications. Understanding the characteristics of microservices-based applications and their overall security requirements and strategies is beneficial, and information is provided in the NIST Special Publication (SP) 800-204, Security Strategies for Microservices-based Application Systems [1]."
          }
        ]
      },
      {
        "title": "1.5 Organization of This Document",
        "content": [
          {
            "text": "The organization of this document is as follows:"
          },
          {
            "text": "Chapter 2 recaps the security requirements for microservices-based applications by referencing those that were discussed in [1].\n\nChapter 3 introduces Service Mesh and provides a brief description of its components, capabilities, and unique role as a communication middleware for microservices-based applications.# applications.\n\n\nChapter 4 provides detailed deployment recommendations for Service Mesh components spanning configuration areas such as service proxies, ingress proxies, egress proxies, identity and access management, monitoring capabilities, network resilience techniques, and cross-origin resource sharing.\n\nChapter 5 provides the summary and conclusions."
          },
          {
            "text": "Chapter 3 introduces Service Mesh and provides a brief description of its components, capabilities, and unique role as a communication middleware for microservices-based applications.# applications."
          },
          {
            "text": "Chapter 4 provides detailed deployment recommendations for Service Mesh components spanning configuration areas such as service proxies, ingress proxies, egress proxies, identity and access management, monitoring capabilities, network resilience techniques, and cross-origin resource sharing."
          }
        ]
      }
    ]
  },
  {
    "title": "CURRENT_PAGE_RAW_OCR_TEXT",
    "subsections": [
      {
        "title": "Load balancing",
        "content": [
          {
            "text": "There is a need to have multiple instances of the same service, and the loads on these instances must be evenly distributed to avoid delayed responses or service crashes due to overload."
          }
        ]
      },
      {
        "title": "Circuit breaker",
        "content": [
          {
            "text": "Large-scale distributed systems, no matter how they are architected, have one defining characteristic\u2014they provide many opportunities for small, localized failures to escalate into system-wide catastrophic failures. The Service Mesh must be designed to safeguard against these escalations by shedding load and failing quickly when the underlying systems approach their limits. Circuit breaking involves setting a threshold for the failed responses from an instance of a microservice and cutting off forwarding requests to that instance when the failure is above the threshold (e.g., when the circuit breaker trips). This mitigates the possibility of cascading failure and allows for time to analyze logs, implement the necessary fix, and push an update for the failing instance. Thus, circuit breaking is a temporary measure that prevents total disruption to responses for service requests. The service requests will be restored to the instance once the service is responsive."
          }
        ]
      },
      {
        "title": "Rate limiting (throttling)",
        "content": [
          {
            "text": "The rate of requests coming into a microservice must be limited to ensure continued availability of service for all clients."
          }
        ]
      },
      {
        "title": "Blue/green deployments",
        "content": [
          {
            "text": "When a new version of a microservice is deployed, requests from customers using the old version can be redirected to the new version using the API gateway that can be programmed to maintain awareness of the locations of both versions."
          }
        ]
      },
      {
        "title": "Canary releases",
        "content": [
          {
            "text": "Only a limited amount of traffic is initially sent to a new version of a microservice since the correctness of its response or performance metric under all operating scenarios is not fully known. Once sufficient data is gathered about its operating characteristics, then all of the requests can be proxied to the new version of the microservice."
          }
        ]
      }
    ]
  },
  {
    "title": "Service Mesh \u2013 Definitions and Technology Background",
    "subsections": [
      {
        "content": "From the description of microservices in the previous chapter, it should be clear that a microservice has two broad functions [2]:"
      },
      {
        "title": "Business Logic",
        "content": [
          {
            "text": "Which implements the business functionalities, computations, and service composition/integration logic, and"
          }
        ]
      },
      {
        "title": "Network Functions",
        "content": [
          {
            "text": "Which take care of the inter-service communication mechanisms (e.g., basic service invocation through a given protocol, apply resiliency and stability).\n```# Patterns and Service Discovery"
          },
          {
            "text": "These network functions are built on top of the underlying OS level network stack."
          }
        ]
      },
      {
        "title": "Business Logic Function",
        "content": [
          {
            "text": "The business logic function must be an integral part of the microservice code since that service is the one that executes or supports a business process. The difficulty with the microservice directly performing the network functions is that it uses different libraries depending on the programming language it is written in or the development framework it is hosted on. With the practical reality of microservices being written in multiple languages (e.g., Java, JavaScript, Python, etc.) within the same application to optimize the development or runtime process, it becomes a tedious task to provide the communication capability for each service node."
          }
        ]
      },
      {
        "title": "Service Mesh",
        "content": [
          {
            "text": "A Service Mesh is a dedicated infrastructure layer with a set of deployed infrastructure functions that facilitate service-to-service communication through service discovery, routing and internal load balancing, traffic configuration, encryption, authentication, authorization, metrics, and monitoring. It provides the capability to declaratively define network behavior, microservice instance identity, and traffic flow through policy in an environment of changing network topology due to service instances coming and going offline and continuously being relocated. It can be looked upon as a networking model that sits at a layer of abstraction above the transport layer of the Open Systems Interconnection (OSI) model (e.g., Transmission Control Protocol/Internet Protocol (TCP/IP)) and addresses the service's session layer (Layer 5 of the OSI model) concerns. However, fine-grained authorization may still need to be performed at the microservice level since that is the only entity that has full knowledge of the business logic."
          },
          {
            "text": "Alternatively, the Service Mesh can be defined as \"a distributed computing middleware that optimizes communications between application services.\" The service-to-service communication is most effectively enabled using a proxy (see Section 1.1). A Service Mesh is typically implemented as an array of lightweight network proxies that are deployed alongside application code without the application needing to be aware."
          }
        ]
      },
      {
        "title": "Monitoring and Security",
        "content": [
          {
            "text": "In addition, the Service Mesh can be leveraged to monitor and secure communication. Because it is intercepting and routing all cluster traffic and gathering health metrics, the Service Mesh can learn and intelligently route traffic. Examples of this higher-level functionality include A/B testing, canary deployments, beta channels, automatic retries, circuit breakers, and injecting faults. These features are only possible because the Service Mesh is able to view and learn from the entire cluster's traffic."
          }
        ]
      },
      {
        "title": "Economic Considerations",
        "content": [
          {
            "text": "It is considered economical to deploy Service Mesh when the number of microservices in the application is in the order of hundreds or thousands. However, the Service Mesh is not without some drawbacks. Because each microservice requires its own service proxy, the number of...# Runtime Instances and the Overall Attack Surface"
          },
          {
            "text": "As the functionality built into a service proxy increases, it may become a communication bottleneck."
          }
        ]
      },
      {
        "title": "3.1 Service Mesh Components & Capabilities",
        "content": [
          {
            "text": "A Service Mesh consists of two main architectural layers or components:"
          },
          {
            "text": "Data plane\nControl plane"
          },
          {
            "text": "The interconnected set of proxies in a Service Mesh that control the inter-services communication represents its data plane. The data plane is the data path and provides the ability to forward requests from the applications. A data plane may also provide more sophisticated features like health checking, load balancing, circuit breaking, timeouts, retries, authentication, and authorization [5]. The specialized proxy that is created for each service instance (i.e., sidecar proxy) performs the runtime operations needed for enforcing security (e.g., access control, communication-related), which are enabled by injecting policies (e.g., access control policies) into the proxy from the control plane. This also provides the flexibility to dynamically change policies without modifying the microservice's code."
          },
          {
            "text": "A control plane is a set of APIs and tools used to control and configure data plane (proxy) behavior across the mesh. The Service Mesh control plane is distinct from the orchestrator's control plane\u2014the former controls the Service Mesh, while the latter controls the cluster. The control plane is where users specify authentication policies and naming information, gather metrics (in general telemetry collection), and configure the data plane as a whole [6]. The intelligence, data, and other artifacts required for implementing all security functions lie in the control plane. These include the software for generating authentication certificates and the repository for storing them, policies for authentication, authorization engine, software for receiving telemetry/monitoring data regarding each microservice and aggregating them, and APIs for modifying the behavior of the network through various features, such as load balancing, circuit breaking, or rate limiting. The control plane of the Service Mesh platform has to be integrated with the orchestration platform (as it gets critical data from the platform, such as service registry) of the microservices-based application and should therefore have the required integration capabilities to be useful. Since the control plane is a critical component of the Service Mesh, it must be highly available and distributed. A control plane can be implemented through configuration files, API calls, and user interfaces [7]."
          },
          {
            "text": "As part of the process of providing the communication, the following functions are supported [1,2]:"
          },
          {
            "text": "Authentication and authorization \u2013 Certificate generation, key management, whitelist and blacklist, Single sign-on (SSO) tokens, API keys\nSecure service discovery \u2013 Discovery of service endpoints through a dedicated service registry# CURRENT_PAGE_RAW_OCR_TEXT"
          }
        ]
      },
      {
        "title": "Secure communication",
        "content": [
          {
            "text": "Mutual Transport Layer Security (TLS), encryption, dynamic route generation, multiple protocol support, including protocol translation where required (e.g., Hypertext Transfer Protocol (HTTP)1.x, HTTP2, gRPC, etc.)"
          }
        ]
      },
      {
        "title": "Resilience/stability features for communication",
        "content": [
          {
            "text": "Circuit breakers, retries, timeouts, fault injection/handling, load balancing, failover, rate limiting, request shadowing"
          }
        ]
      },
      {
        "title": "Observability/monitoring features",
        "content": [
          {
            "text": "Logging, metrics, distributed tracing"
          },
          {
            "subsection": "3.1.1 Ingress Controller",
            "text": []
          },
          {
            "text": "The service proxy of a Service Mesh can be deployed for control of ingress traffic (i.e., external traffic coming into microservices application as opposed to microservice-to-microservice communication). In this sense, it realizes the functions of an API gateway. Conceptually, the ingress controller can be looked upon as a side-car proxy for an external client. The ingress controller (sometimes called the front proxy) provides the following functions:\n- A common API for all clients shielding the actual API inside the Service Mesh\n- Protocol translation from web-friendly protocols, such as HTTP/Hypertext Transfer Protocol Secure (HTTPS), to protocols used by microservices, such as RPC/gRPC/Representational State Transfer (REST)\n- Composition of results received from calls to multiple services inside the Service Mesh in response to a single call from the client\n- Load balancing\n- Public TLS termination"
          },
          {
            "subsection": "3.1.2 Egress Controller",
            "text": []
          },
          {
            "text": "The service proxy of a Service Mesh can be deployed for control of egress traffic (i.e., internal traffic coming from microservices destined for microservices outside of the mesh). In this sense, it functions as an egress-only gateway. Conceptually, the egress controller can be looked upon as a side-car proxy for one or more external servers. The egress proxy provides the following functions:\n- A single set of workloads (e.g., hosts, IP addresses) to whitelist for communication to external networks (e.g., firewalls can be configured to allow only egress proxies to forward traffic out of the local network)\n- Credential exchange: Translate from internal (mesh) identity credentials to external credentials (e.g., SSO tokens or API keys) without the application directly accessing the external system's credentials\n- Protocol translation from microservice-friendly protocols (e.g., RPC/gRPC/REST) to web-friendly protocols (e.g., HTTP/HTTPS)"
          }
        ]
      },
      {
        "title": "3.2 Service Mesh as Communication Middleware: What is Different",
        "content": [
          {
            "text": "Prior to the Service Mesh, in order to provide infrastructure functionality (e.g., service discovery, load balancing, circuit breaking, fault injection, security monitoring, authorization, and distributed tracing for distributed systems such as microservices-based applications), a set of components and frameworks that provide these functionalities must be carefully chosen. Some components will only work within certain frameworks, and frameworks themselves are tied to specific languages. Additionally, the application service's code must be# Service Mesh and Microservices"
          },
          {
            "text": "Modified to work with or be integrated into these components [8]. In the case of Service Mesh, the technology or programming language in which the individual microservices are written do not matter since operation occurs at the network level. For example, if the microservices application developer develops an HTTP server, they have complete freedom to choose any language\u2014Java, C++, Rust, Go, JavaScript, Python, etc."
          }
        ]
      },
      {
        "title": "Decoupling Application Code",
        "content": [
          {
            "text": "Service Mesh decouples application code from the management of service-to-service communication. The application code does not need to know about network topology, service discovery, load balancing, or connection management logic [9]. Features like telemetry, traffic shaping, service discovery, and network policy control can be provided out of the box as well."
          }
        ]
      },
      {
        "title": "Differentiating from Traditional Middleware",
        "content": [
          {
            "text": "Since Service Mesh is defined as a communication middleware, the next question that arises is, \"how does it differ from any other distributed system middleware?\" The traditional middleware for distributed systems includes application delivery controllers (ADCs), load balancers, and API gateways. In addition to having heavy costs and operating overheads, these middleware appliances are unsuitable in contexts where the application components they serve are in the form of loosely coupled modular microservices since these components require fine-grained capabilities and functionalities, such as dynamic discovery, which are not required by modules of monolithic applications."
          }
        ]
      },
      {
        "title": "Understanding Communication in Distributed Systems",
        "content": [
          {
            "text": "In order to understand the unsuitability of traditional communication middleware components for distributed systems and the need for lightweight solutions for microservices-based application systems, consider the nature of communications in those systems. Clients of various types interface with an application made up of a huge number of microservices. The communication traffic between the clients and any application service is called \"north-south\" traffic, and those between one microservice and another is called \"east-west\" traffic. Because of the relatively high number of microservices as components in a microservices-based application compared to a monolithic application, the amount of east-west traffic is so high that a lightweight communication middleware, such as the Service Mesh, is needed to provide an acceptable level of performance for a production application."
          }
        ]
      },
      {
        "title": "Cloud-Native Applications",
        "content": [
          {
            "text": "Though a microservices-based application can be implemented without a container and its associated orchestration service, it is often identified as a cloud-native application with a service-based architecture, API-driven communications, container-based infrastructure, and a bias for DevOps (i.e., development and operations) processes (e.g., continuous improvement, agile development, continuous delivery, collaborative development among developers, quality assurance teams, security professionals, IT operations, and line-of-business stakeholders [3]). Part of the reason for this perspective is that monolithic software development and deployment...# CURRENT_PAGE_RAW_OCR_TEXT"
          },
          {
            "text": "relies on a server-centric infrastructure with tightly integrated application modules rather than on loosely coupled, services-based architectures with API-based communications."
          }
        ]
      },
      {
        "title": "3.3 Service Mesh: State of the Art",
        "content": [
          {
            "text": "Conceptually, a Service Mesh can be used to provide infrastructure services for all applications based on microservices architecture in which there are hundreds of services and tens of instances in each service. However, based on the Off-the-Shelf implementations available today, Service Mesh is most suitable and productive for application platforms with the following configurations:"
          },
          {
            "text": "Each microservice is implemented as a container.\nThe application makes use of container clusters (for improved availability and performance) that are managed using container orchestration tools.\nThe application is hosted through a Container-as-a-Service (CaaS) offered by cloud providers and has the necessary deployment and configuration tools found in container management/orchestration environments."
          }
        ]
      },
      {
        "title": "4 Service Mesh Deployment Recommendations",
        "content": [
          {
            "text": "This chapter considers the deployment options in Service Mesh and provides recommendations for secure microservices-based application for various application scenarios. Since the primary runtime functions are performed by proxies, the first deployment recommendations are in the context of configuring the various aspects of proxy functions. Each of the deployment recommendations are identified through the symbol SM-DRx, where SM stands for Service Mesh, DR stands for deployment recommendation, and x is the number in the sequence."
          },
          {
            "subsection": "4.1 Communication Configuration for Service Proxies",
            "text": []
          },
          {
            "text": "Recommendation for Allowed Traffic into Service Proxies (SM-DR1): There should be a feature to specify the set of protocols and ports into which a service proxy can accept traffic for its associated service. By default, a service proxy should not allow traffic except as specified by this configuration."
          },
          {
            "text": "Recommendation for Reachability of Service Proxies (SM-DR2): The set of services that a service proxy can reach must be limited. There should be features to limit access based on namespace, a specific named service within a given namespace, or the service's runtime identity. Access to the control plane of the Service Mesh must always be provided to relay discovery, different policies, and telemetry data."
          },
          {
            "text": "Recommendation for Protocol Translation Capabilities (SM-DR3): The service proxy should have built-in capabilities to support clients communicating with different protocols than the target microservice (e.g., convert REST/HTTP requests to gRPC requests or upgrade HTTP/1.1 to HTTP/2). This is required to avoid the need for building a separate server per client protocol, which increases the attack surface."
          },
          {
            "text": "Recommendation for User Extensibility (SM-DR4): The service proxy should have features for defining custom logic in addition to built-in logic for handling network functions. This is# CURRENT_PAGE_RAW_OCR_TEXT"
          }
        ]
      },
      {
        "title": "Required to Ensure Extensibility",
        "content": [
          {
            "text": "Required to ensure that the service proxy can be extended to implement use case specific policies (e.g., preexisting or home-grown policy engines). The implementation should provide means to control the risks of extensibility, such as sandboxing, restricting the APIs/runtimes of languages used, or performing pre-analysis that ensures safety (e.g. WASM or eBPF)."
          }
        ]
      },
      {
        "title": "Recommendation for Dynamic Configuration Features for Proxies (SM-DR5)",
        "content": [
          {
            "text": "There should be options to configure proxies dynamically (e.g., event-driven configuration updates) in addition to static configuration. In other words, there should be discovery services for those entities that are expected to be dynamic rather than known at the time of deployment. Further, the proxy should atomically swap to the new dynamic configuration at runtime while efficiently handling (i.e., completing or terminating) outstanding requests under the previous configuration. This is required for timely enforcement of policy changes at runtime without any degradation of user traffic or downtime (i.e., without restarting the service proxy)."
          }
        ]
      },
      {
        "title": "Recommendation for Configuring Communication Between Application Service to Its Proxy (SM-DR6)",
        "content": [
          {
            "text": "The application service and its associated proxy should only communicate through a loopback channel (e.g., localhost IP address, UNIX domain socket, etc.). Further, service proxies should only communicate with each other by setting up a mutual TLS (mTLS) session where every exchanged data packet is encrypted."
          },
          {
            "subsection": "4.2 Configuration for Ingress Proxies",
            "text": []
          },
          {
            "text": "There should be features for configuring traffic routing rules for ingress (standalone) proxies just like service proxies. This is needed because consistent enforcement of routing policy is required all the way to the edge of the application deployment."
          },
          {
            "subsection": "4.3 Configuration for Access to External Services",
            "text": []
          },
          {
            "text": "Certain services in the microservices-based application may have to access some public or private web APIs, third-party services, legacy applications, or applications in different virtualized infrastructures, such as in VMs or different clusters (than the one in which the Service Mesh runs). To provide the same security assurance for access to these resources, the following recommendations are provided:"
          },
          {
            "text": "Access to external resources or services outside of the mesh should be disabled by default and only allowed by an explicit policy that restricts access to specified destinations. Additionally, those external resources or services should be modeled as services in the Service Mesh itself (e.g., by including them in the Service Mesh's service discovery mechanism)."
          },
          {
            "text": "The same availability improvement features (e.g., retries, timeouts, circuit breakers, etc.) that are configured for services inside of the Service Mesh must be provided for access to external resources and services.# Recommendation for Egress Proxies (SM-DR10)"
          },
          {
            "text": "There should be features for configuring traffic routing rules for egress (standalone) proxies just like service and ingress proxies. When deployed, access to external resources and services should be mediated by these egress proxies. The egress proxy should implement access and availability policies (SM-DR8). This is useful for working with traditional network-oriented security models. For example, suppose that outbound traffic to the internet is only allowed from a specific IP in the network; an egress proxy can be configured to run with that address while proxying traffic for a range of services in the mesh."
          }
        ]
      },
      {
        "title": "4.4 Configuration for Identity and Access Management",
        "content": [
          {
            "text": "The three main communicating entities of a microservices-based application are clients, microservices, and external services. During the communication events of any pair (i.e., client-to-microservice, microservice-to-microservice, or microservice-to-egress-service), both entities need to have distinct identities and perform mutual authentication. Since mutual TLS (mTLS) is the de facto mechanism for doing this, the authentication certificate that a client or microservice holds should carry its identity in its \"subject name\" or \"subject alternative name\" fields. This identity can either be a server identity (also known as a host or domain) or a service identity (usually service account ID). The recommendations relating to certificate deployment are as follows:"
          },
          {
            "subsection": "Recommendation for a Universal Identity Domain (SM-DR11)",
            "text": []
          },
          {
            "text": "The identity of all instances of a microservice should be consistent and unique\u2014consistent in that a service should have the same name regardless of where it is running and unique in that across the entire system, the service's name corresponds only to that service. This does not mean different logical services in different locations; a typical usage of Domain Name System (DNS) where each service is assigned its own DNS name would satisfy this recommendation. Consistent names (identities) for services are required so that the system policy is manageable."
          },
          {
            "subsection": "Recommendation for Signing Certificate Deployment (SM-DR12)",
            "text": []
          },
          {
            "text": "The Service Mesh control plane's certificate management system should have its ability to generate self-signed certificates disabled. This functionality is frequently used to bootstrap an initial signing certificate for all other identity certificates in the Service Mesh. Instead, the signing certificate used by the mesh's control plane should always be rooted in the enterprise's existing PKI's root of trust and provided securely to the Service Mesh control plane at startup. This simplifies the management of those certificates by an existing PKI (e.g., for revocation or audit). Further, we recommend that separate intermediate signing certificates should be generated for different domains to simplify rotation and enable fine-grained revocation."
          },
          {
            "subsection": "Recommendation for Identity Certificate Rotation (SM-DR13)",
            "text": []
          },
          {
            "text": "The lifetime of a microservice's identity certificate should be as short as is manageable within the...# Infrastructure Recommendations"
          }
        ]
      },
      {
        "title": "Recommendation for the Service Proxy to Cycle Connections on Identity Change (SM-DR14)",
        "content": [
          {
            "text": "When a service proxy's identity certificate is rotated, the service proxy should efficiently retire existing connections and establish all new connections with the new certificate. Certificates are only validated during the mTLS handshake, so replacing existing connections when a new certificate is issued is not strictly required; rather, this is important for limiting attacks in time."
          }
        ]
      },
      {
        "title": "Recommendation for Non-Signing Identity Certificates (SM-DR15)",
        "content": [
          {
            "text": "Certificates used to identify microservices should not be signing certificates."
          }
        ]
      },
      {
        "title": "Recommendation for Workload Authentication before Certificate Issuance (SM-DR16)",
        "content": [
          {
            "text": "The Service Mesh control plane's certificate management system should perform authentication of a service instance before issuing it an identity certificate. In many systems, this can be achieved by attesting the instance against the system's orchestration engine, and by using other local proofs (e.g. secrets retrieved from an HSM)."
          },
          {
            "text": "The same care should be taken in provisioning the signing certificate for the Service Mesh control plane's certificate management system. That signing certificate should be retrievable only by the Service Mesh control plane and only after some form of attestation has been done against it."
          }
        ]
      },
      {
        "title": "Recommendation for Secure Naming Service (SM-DR17)",
        "content": [
          {
            "text": "If the certificate used for mTLS carries server identity, then the Service Mesh should provide a secure naming service that maps the server identity to the microservice name that is provided by the secure discovery service or DNS. This requirement is needed to ensure that the server is the authorized location for the microservices and to protect against network hijacking."
          },
          {
            "text": "If the certificate used for mTLS carries the service identity, no additional secure naming service is required. This also ensures that when the microservice is ported to a different network domain (different cluster or different cloud location), the identity and associated access control policies need not be defined again for the new location."
          },
          {
            "text": "Setting up certificates for microservices based on service identity enables two communicating services to establish a secure communication channel but does not specify whether they are allowed to communicate at all in the place. To specify this, a feature to define policies for allowed inbound and outbound traffic for each microservice node is required."
          }
        ]
      },
      {
        "title": "Recommendation for Granular Identity (SM-DR18)",
        "content": [
          {
            "text": "Each microservice should have its own identity, and all instances of this service should present the same identity at runtime. This allows for access policy at the level of microservice in a given namespace. This is required.# CURRENT_PAGE_RAW_OCR_TEXT"
          },
          {
            "text": "since common microservice runtimes default to issuing identities per namespace rather than per service so that all services in the same namespace present the same runtime identity unless otherwise specified. In addition, labels can be used to augment the service name (identity) to enable granular logging configuration and to support granular authorization policies."
          }
        ]
      },
      {
        "title": "Recommendation for Authentication Policy Scope (SM-DR19)",
        "content": [
          {
            "text": "The feature to specify the policy scope for authentication should have the following minimal options: (a) all microservices in all namespaces, (b) all microservices in a particular namespace, and (c) a specific microservice in a given namespace (using the runtime identity referred to in SM-DR17)."
          },
          {
            "text": "The above described approach enables authentication using static parameters (i.e., service identity and pre-defined policies). An additional requirement is the ability to incorporate some contextual information (such as the user invoking the microservice) in some scenarios. A mechanism for this is to use tokens encoded in platform-neutral format (e.g., JavaScript Object Notation (JSON) Web Tokens or JWT). The requirements for the token are:"
          }
        ]
      },
      {
        "title": "Recommendation for Authentication Token (SM-DR20)",
        "content": [
          {
            "text": "Tokens should be digitally signed and encrypted so that claims included in them have the assurance of authenticity since these claims can be used to augment or be part of an authenticated identity to build access control decisions. Further, these tokens must only be passed by loopback device (to ensure that there is no network path involved) or through an encrypted channel."
          }
        ]
      },
      {
        "title": "4.5 Configuration for Monitoring Capabilities",
        "content": [
          {
            "text": "All proxies (ingress, egress, and service) should have the capability to collect all monitoring data. Monitoring data is classified into three categories: logging, metrics, and traces in software systems, as identified by Peter Bourgon [10]. This capability is realized by enabling integration support in the Service Mesh for specialized tools that can generate one or more of the categories of data mentioned above. Examples include AppSensor and Fluentd for event logging, Prometheus for aggregatable metrics, and Jaeger [11] and Zipkin [12] for distributed tracing."
          },
          {
            "text": "This allows Service Mesh deployment teams to minimize the effort of building the pipelines for data collection and focus on data analytics. Depending on the use case context, example could include event mining, anomaly detection, or service dependency extraction."
          },
          {
            "text": "The logging data should, at a minimum, record the following events to detect some common attacks:"
          }
        ]
      },
      {
        "title": "Recommendation for Logging Events (SM-DR21)",
        "content": [
          {
            "text": "The proxy should log input validation errors and extra (unexpected) parameters errors, crashes, and core dumps. Common attack detection capabilities should include bearer token reuse attack and injection attacks."
          }
        ]
      },
      {
        "title": "Recommendation for Logging Requests (SM-DR22)",
        "content": [
          {
            "text": "The proxy should log at least the Common Log Format fields for irregular requests (e.g., non-200 responses when using HTTP). Logging for successful requests (e.g., 200 responses) tends to be of little value when# CURRENT_PAGE_RAW_OCR_TEXT"
          }
        ]
      },
      {
        "title": "Metrics are available.",
        "content": [
          {
            "subsection": "Recommendation for Log Message Content (SM-DR22)",
            "text": []
          },
          {
            "text": "Log messages should contain, at a minimum, the event date/time, microservice name or identity, request trace id, message, and other contextual information (e.g., requesting user identity and URL). However, logging should take care to mask sensitive information, for example Bearer tokens."
          },
          {
            "text": "On the metrics side, a baseline for normal, uncompromised behavior in terms of the outcome of business logic decisions, contact attempts, and other behavior should be created. To enable this:"
          },
          {
            "subsection": "Recommendations for Mandatory Metrics (SM-DR23)",
            "text": []
          },
          {
            "text": "The configuration for gathering metrics using Service Mesh for external client and microservice calls should involve, at a minimum, the following:\n- (a) the number of client/service requests in a given duration,\n- (b) the number of failed client/service requests by failure code, and\n- (c) the average latency per service as well as the average total latency per complete request lifecycle (ideally as a histogram; also by failure code)."
          },
          {
            "text": "A trace is a representation of a series of causally related distributed events that encode the end-to-end request flow through a distributed system [13]. A trace can provide visibility into both the path traversed by a request (various microservices involved) and the structure of a request (forking logic and the nature of the request\u2014synchronous or asynchronous). In the context of a microservices-based application and Service Mesh, it is called distributed tracing since the tracing function is enabled by a combination of various application services and their associated service proxies. Because of its use for debugging steady-state problems and in providing data for capacity planning, the distributed tracing feature has a direct impact on the application system availability."
          },
          {
            "subsection": "Recommendation for Implementing Distributed Tracing (SM-DR24)",
            "text": []
          },
          {
            "text": "When configuring the service proxies for implementing distributed tracing, care should be taken to ensure that the application services are instrumented to forward the headers for communication packets they received."
          },
          {
            "text": "It is important to note that in order to carry out the above recommendation, a minimal amount of instrumenting the application service is necessary, unlike other infrastructure functions provided under Service Mesh architecture [14]."
          }
        ]
      },
      {
        "title": "4.6 Configuration for Network Resilience Techniques",
        "content": [
          {
            "subsection": "Recommendation for Storing Data for Implementation of Network Resilience (SM-DR25)",
            "text": []
          },
          {
            "text": "Data pertaining to retries, timeouts, circuit breaking settings, or canary deployments (in general, all control plane configuration data) should be stored in robust data stores, such as Key/Value stores."
          },
          {
            "subsection": "Recommendation for Implementation of Health Checking of Service Instances (SM-DR26)",
            "text": []
          },
          {
            "text": "The health checking function for service instances should be tightly integrated with the service.# Discovery Function"
          },
          {
            "text": "To maintain the integrity of the information used for load balancing. This health data can be reported to a central health checking service (or a central service discovery system), but it may also be used locally only (e.g., a service proxy performs health checking on open connections it maintains, makes local load balancing decisions, and avoids hosts it deems to be unhealthy)."
          }
        ]
      },
      {
        "title": "4.7 Configuration for Cross-Origin Resource Sharing (CORS)",
        "content": [
          {
            "text": "Recommendation for Cross-Origin Resource Sharing (CORS) (SM-DR27): An edge service (i.e., entry point for microservice) may often have to be configured for CORS for communicating with external services, such as a web UI client service [15]. The CORS policy for an edge service should be configured using the Service Mesh capability (e.g., VirtualService resource's CorsPolicy configuration in Istio) rather than handling it through the microservice application service code."
          }
        ]
      }
    ]
  },
  {
    "title": "5 Summary and Conclusions",
    "subsections": [
      {
        "content": "The increasing adoption of microservices-based applications in cloud and large enterprise environments has prompted the identification of an infrastructure that provides a comprehensive, consistent, and coordinated set of support services. The Service Mesh is one such infrastructure, and the state of practice for deployment of Service Mesh components is a proxy-based approach that can provide all support services without any change to the application code."
      },
      {
        "content": "The proxy-based Service Mesh can be engineered to build and integrate support service components that provide secure service discovery, definition, and enforcement of authentication and authorization policies, network resilience features, and performance and security monitoring capabilities. The primary contribution of this document is to provide detailed deployment guidance for each of the Service Mesh components spanning the areas listed above."
      }
    ]
  }
]